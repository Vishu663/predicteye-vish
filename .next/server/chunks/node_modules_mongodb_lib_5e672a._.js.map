{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/bson.ts"],"sourcesContent":["/* eslint-disable no-restricted-imports */\nimport { BSON, type DeserializeOptions, type SerializeOptions } from 'bson';\n\nexport {\n  Binary,\n  BSON,\n  BSONError,\n  BSONRegExp,\n  BSONSymbol,\n  BSONType,\n  calculateObjectSize,\n  Code,\n  DBRef,\n  Decimal128,\n  deserialize,\n  type DeserializeOptions,\n  Document,\n  Double,\n  EJSON,\n  EJSONOptions,\n  Int32,\n  Long,\n  MaxKey,\n  MinKey,\n  ObjectId,\n  type ObjectIdLike,\n  serialize,\n  Timestamp,\n  UUID\n} from 'bson';\n\n/** @internal */\nexport type BSONElement = BSON.OnDemand['BSONElement'];\n\nexport function parseToElementsToArray(bytes: Uint8Array, offset?: number): BSONElement[] {\n  const res = BSON.onDemand.parseToElements(bytes, offset);\n  return Array.isArray(res) ? res : [...res];\n}\n\nexport const getInt32LE = BSON.onDemand.NumberUtils.getInt32LE;\nexport const getFloat64LE = BSON.onDemand.NumberUtils.getFloat64LE;\nexport const getBigInt64LE = BSON.onDemand.NumberUtils.getBigInt64LE;\nexport const toUTF8 = BSON.onDemand.ByteUtils.toUTF8;\n\n/**\n * BSON Serialization options.\n * @public\n */\nexport interface BSONSerializeOptions\n  extends Omit<SerializeOptions, 'index'>,\n    Omit<\n      DeserializeOptions,\n      | 'evalFunctions'\n      | 'cacheFunctions'\n      | 'cacheFunctionsCrc32'\n      | 'allowObjectSmallerThanBufferSize'\n      | 'index'\n      | 'validation'\n    > {\n  /**\n   * Enabling the raw option will return a [Node.js Buffer](https://nodejs.org/api/buffer.html)\n   * which is allocated using [allocUnsafe API](https://nodejs.org/api/buffer.html#static-method-bufferallocunsafesize).\n   * See this section from the [Node.js Docs here](https://nodejs.org/api/buffer.html#what-makes-bufferallocunsafe-and-bufferallocunsafeslow-unsafe)\n   * for more detail about what \"unsafe\" refers to in this context.\n   * If you need to maintain your own editable clone of the bytes returned for an extended life time of the process, it is recommended you allocate\n   * your own buffer and clone the contents:\n   *\n   * @example\n   * ```ts\n   * const raw = await collection.findOne({}, { raw: true });\n   * const myBuffer = Buffer.alloc(raw.byteLength);\n   * myBuffer.set(raw, 0);\n   * // Only save and use `myBuffer` beyond this point\n   * ```\n   *\n   * @remarks\n   * Please note there is a known limitation where this option cannot be used at the MongoClient level (see [NODE-3946](https://jira.mongodb.org/browse/NODE-3946)).\n   * It does correctly work at `Db`, `Collection`, and per operation the same as other BSON options work.\n   */\n  raw?: boolean;\n\n  /** Enable utf8 validation when deserializing BSON documents.  Defaults to true. */\n  enableUtf8Validation?: boolean;\n}\n\nexport function pluckBSONSerializeOptions(options: BSONSerializeOptions): BSONSerializeOptions {\n  const {\n    fieldsAsRaw,\n    useBigInt64,\n    promoteValues,\n    promoteBuffers,\n    promoteLongs,\n    serializeFunctions,\n    ignoreUndefined,\n    bsonRegExp,\n    raw,\n    enableUtf8Validation\n  } = options;\n  return {\n    fieldsAsRaw,\n    useBigInt64,\n    promoteValues,\n    promoteBuffers,\n    promoteLongs,\n    serializeFunctions,\n    ignoreUndefined,\n    bsonRegExp,\n    raw,\n    enableUtf8Validation\n  };\n}\n\n/**\n * Merge the given BSONSerializeOptions, preferring options over the parent's options, and\n * substituting defaults for values not set.\n *\n * @internal\n */\nexport function resolveBSONOptions(\n  options?: BSONSerializeOptions,\n  parent?: { bsonOptions?: BSONSerializeOptions }\n): BSONSerializeOptions {\n  const parentOptions = parent?.bsonOptions;\n  return {\n    raw: options?.raw ?? parentOptions?.raw ?? false,\n    useBigInt64: options?.useBigInt64 ?? parentOptions?.useBigInt64 ?? false,\n    promoteLongs: options?.promoteLongs ?? parentOptions?.promoteLongs ?? true,\n    promoteValues: options?.promoteValues ?? parentOptions?.promoteValues ?? true,\n    promoteBuffers: options?.promoteBuffers ?? parentOptions?.promoteBuffers ?? false,\n    ignoreUndefined: options?.ignoreUndefined ?? parentOptions?.ignoreUndefined ?? false,\n    bsonRegExp: options?.bsonRegExp ?? parentOptions?.bsonRegExp ?? false,\n    serializeFunctions: options?.serializeFunctions ?? parentOptions?.serializeFunctions ?? false,\n    fieldsAsRaw: options?.fieldsAsRaw ?? parentOptions?.fieldsAsRaw ?? {},\n    enableUtf8Validation:\n      options?.enableUtf8Validation ?? parentOptions?.enableUtf8Validation ?? true\n  };\n}\n\n/** @internal */\nexport function parseUtf8ValidationOption(options?: { enableUtf8Validation?: boolean }): {\n  utf8: { writeErrors: false } | false;\n} {\n  const enableUtf8Validation = options?.enableUtf8Validation;\n  if (enableUtf8Validation === false) {\n    return { utf8: false };\n  }\n  return { utf8: { writeErrors: false } };\n}\n"],"names":[],"mappings":";;;;;AAkCA,QAAA,sBAAA,GAAA;AAmDA,QAAA,yBAAA,GAAA;AAiCA,QAAA,kBAAA,GAAA;AAqBA,QAAA,yBAAA,GAAA;AA3IA,wCAAA,GACA,MAAA;AAEA,IAAA;AACE,OAAA,cAAA,CAAA,SAAA,UAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,MAAM;IAAA;AAAA;AACN,OAAA,cAAA,CAAA,SAAA,QAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,IAAI;IAAA;AAAA;AACJ,OAAA,cAAA,CAAA,SAAA,aAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,SAAS;IAAA;AAAA;AACT,OAAA,cAAA,CAAA,SAAA,cAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,UAAU;IAAA;AAAA;AACV,OAAA,cAAA,CAAA,SAAA,cAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,UAAU;IAAA;AAAA;AACV,OAAA,cAAA,CAAA,SAAA,YAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,QAAQ;IAAA;AAAA;AACR,OAAA,cAAA,CAAA,SAAA,uBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,mBAAmB;IAAA;AAAA;AACnB,OAAA,cAAA,CAAA,SAAA,QAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,IAAI;IAAA;AAAA;AACJ,OAAA,cAAA,CAAA,SAAA,SAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,KAAK;IAAA;AAAA;AACL,OAAA,cAAA,CAAA,SAAA,cAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,UAAU;IAAA;AAAA;AACV,OAAA,cAAA,CAAA,SAAA,eAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,WAAW;IAAA;AAAA;AAGX,OAAA,cAAA,CAAA,SAAA,UAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,MAAM;IAAA;AAAA;AACN,OAAA,cAAA,CAAA,SAAA,SAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,KAAK;IAAA;AAAA;AAEL,OAAA,cAAA,CAAA,SAAA,SAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,KAAK;IAAA;AAAA;AACL,OAAA,cAAA,CAAA,SAAA,QAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,IAAI;IAAA;AAAA;AACJ,OAAA,cAAA,CAAA,SAAA,UAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,MAAM;IAAA;AAAA;AACN,OAAA,cAAA,CAAA,SAAA,UAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,MAAM;IAAA;AAAA;AACN,OAAA,cAAA,CAAA,SAAA,YAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,QAAQ;IAAA;AAAA;AAER,OAAA,cAAA,CAAA,SAAA,aAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,SAAS;IAAA;AAAA;AACT,OAAA,cAAA,CAAA,SAAA,aAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,SAAS;IAAA;AAAA;AACT,OAAA,cAAA,CAAA,SAAA,QAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,IAAI;IAAA;AAAA;AAMN,SAAgB,uBAAuB,KAAiB,EAAE,MAAe;IACvE,MAAM,MAAM,OAAA,IAAI,CAAC,QAAQ,CAAC,eAAe,CAAC,OAAO;IACjD,OAAO,MAAM,OAAO,CAAC,OAAO,MAAM;WAAI;KAAI;AAC5C;AAEa,QAAA,UAAU,GAAG,OAAA,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC,UAAU;AACjD,QAAA,YAAY,GAAG,OAAA,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC,YAAY;AACrD,QAAA,aAAa,GAAG,OAAA,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC,aAAa;AACvD,QAAA,MAAM,GAAG,OAAA,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,MAAM;AA2CpD,SAAgB,0BAA0B,OAA6B;IACrE,MAAM,EACJ,WAAW,EACX,WAAW,EACX,aAAa,EACb,cAAc,EACd,YAAY,EACZ,kBAAkB,EAClB,eAAe,EACf,UAAU,EACV,GAAG,EACH,oBAAoB,EACrB,GAAG;IACJ,OAAO;QACL;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;;AAEJ;AAEA;;;;;IAMA,SAAgB,mBACd,OAA8B,EAC9B,MAA+C;IAE/C,MAAM,gBAAgB,QAAQ;IAC9B,OAAO;QACL,KAAK,SAAS,OAAO,eAAe,OAAO;QAC3C,aAAa,SAAS,eAAe,eAAe,eAAe;QACnE,cAAc,SAAS,gBAAgB,eAAe,gBAAgB;QACtE,eAAe,SAAS,iBAAiB,eAAe,iBAAiB;QACzE,gBAAgB,SAAS,kBAAkB,eAAe,kBAAkB;QAC5E,iBAAiB,SAAS,mBAAmB,eAAe,mBAAmB;QAC/E,YAAY,SAAS,cAAc,eAAe,cAAc;QAChE,oBAAoB,SAAS,sBAAsB,eAAe,sBAAsB;QACxF,aAAa,SAAS,eAAe,eAAe,eAAe,CAAA;QACnE,sBACE,SAAS,wBAAwB,eAAe,wBAAwB;;AAE9E;AAEA,cAAA,GACA,SAAgB,0BAA0B,OAA4C;IAGpF,MAAM,uBAAuB,SAAS;IACtC,IAAI,yBAAyB,OAAO;QAClC,OAAO;YAAE,MAAM;QAAK;IACtB;IACA,OAAO;QAAE,MAAM;YAAE,aAAa;QAAK;IAAE;AACvC"}},
    {"offset": {"line": 199, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 203, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/error.ts"],"sourcesContent":["import type { Document } from './bson';\nimport {\n  type ClientBulkWriteError,\n  type ClientBulkWriteResult\n} from './operations/client_bulk_write/common';\nimport type { ServerType } from './sdam/common';\nimport type { TopologyVersion } from './sdam/server_description';\nimport type { TopologyDescription } from './sdam/topology_description';\n\n/** @public */\nexport type AnyError = MongoError | Error;\n\n/**\n * @internal\n * The legacy error message from the server that indicates the node is not a writable primary\n * https://github.com/mongodb/specifications/blob/921232976f9913cf17415b5ef937ee772e45e6ae/source/server-discovery-and-monitoring/server-discovery-and-monitoring.md#not-writable-primary-and-node-is-recovering\n */\nexport const LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE = new RegExp('not master', 'i');\n\n/**\n * @internal\n * The legacy error message from the server that indicates the node is not a primary or secondary\n * https://github.com/mongodb/specifications/blob/921232976f9913cf17415b5ef937ee772e45e6ae/source/server-discovery-and-monitoring/server-discovery-and-monitoring.md#not-writable-primary-and-node-is-recovering\n */\nexport const LEGACY_NOT_PRIMARY_OR_SECONDARY_ERROR_MESSAGE = new RegExp(\n  'not master or secondary',\n  'i'\n);\n\n/**\n * @internal\n * The error message from the server that indicates the node is recovering\n * https://github.com/mongodb/specifications/blob/921232976f9913cf17415b5ef937ee772e45e6ae/source/server-discovery-and-monitoring/server-discovery-and-monitoring.md#not-writable-primary-and-node-is-recovering\n */\nexport const NODE_IS_RECOVERING_ERROR_MESSAGE = new RegExp('node is recovering', 'i');\n\n/** @internal MongoDB Error Codes */\nexport const MONGODB_ERROR_CODES = Object.freeze({\n  HostUnreachable: 6,\n  HostNotFound: 7,\n  AuthenticationFailed: 18,\n  NetworkTimeout: 89,\n  ShutdownInProgress: 91,\n  PrimarySteppedDown: 189,\n  ExceededTimeLimit: 262,\n  SocketException: 9001,\n  NotWritablePrimary: 10107,\n  InterruptedAtShutdown: 11600,\n  InterruptedDueToReplStateChange: 11602,\n  NotPrimaryNoSecondaryOk: 13435,\n  NotPrimaryOrSecondary: 13436,\n  StaleShardVersion: 63,\n  StaleEpoch: 150,\n  StaleConfig: 13388,\n  RetryChangeStream: 234,\n  FailedToSatisfyReadPreference: 133,\n  CursorNotFound: 43,\n  LegacyNotPrimary: 10058,\n  // WriteConcernTimeout is WriteConcernFailed on pre-8.1 servers\n  WriteConcernTimeout: 64,\n  NamespaceNotFound: 26,\n  IllegalOperation: 20,\n  MaxTimeMSExpired: 50,\n  UnknownReplWriteConcern: 79,\n  UnsatisfiableWriteConcern: 100,\n  Reauthenticate: 391,\n  ReadConcernMajorityNotAvailableYet: 134\n} as const);\n\n// From spec https://github.com/mongodb/specifications/blob/921232976f9913cf17415b5ef937ee772e45e6ae/source/change-streams/change-streams.md#resumable-error\nexport const GET_MORE_RESUMABLE_CODES = new Set<number>([\n  MONGODB_ERROR_CODES.HostUnreachable,\n  MONGODB_ERROR_CODES.HostNotFound,\n  MONGODB_ERROR_CODES.NetworkTimeout,\n  MONGODB_ERROR_CODES.ShutdownInProgress,\n  MONGODB_ERROR_CODES.PrimarySteppedDown,\n  MONGODB_ERROR_CODES.ExceededTimeLimit,\n  MONGODB_ERROR_CODES.SocketException,\n  MONGODB_ERROR_CODES.NotWritablePrimary,\n  MONGODB_ERROR_CODES.InterruptedAtShutdown,\n  MONGODB_ERROR_CODES.InterruptedDueToReplStateChange,\n  MONGODB_ERROR_CODES.NotPrimaryNoSecondaryOk,\n  MONGODB_ERROR_CODES.NotPrimaryOrSecondary,\n  MONGODB_ERROR_CODES.StaleShardVersion,\n  MONGODB_ERROR_CODES.StaleEpoch,\n  MONGODB_ERROR_CODES.StaleConfig,\n  MONGODB_ERROR_CODES.RetryChangeStream,\n  MONGODB_ERROR_CODES.FailedToSatisfyReadPreference,\n  MONGODB_ERROR_CODES.CursorNotFound\n]);\n\n/** @public */\nexport const MongoErrorLabel = Object.freeze({\n  RetryableWriteError: 'RetryableWriteError',\n  TransientTransactionError: 'TransientTransactionError',\n  UnknownTransactionCommitResult: 'UnknownTransactionCommitResult',\n  ResumableChangeStreamError: 'ResumableChangeStreamError',\n  HandshakeError: 'HandshakeError',\n  ResetPool: 'ResetPool',\n  PoolRequstedRetry: 'PoolRequstedRetry',\n  InterruptInUseConnections: 'InterruptInUseConnections',\n  NoWritesPerformed: 'NoWritesPerformed'\n} as const);\n\n/** @public */\nexport type MongoErrorLabel = (typeof MongoErrorLabel)[keyof typeof MongoErrorLabel];\n\n/** @public */\nexport interface ErrorDescription extends Document {\n  message?: string;\n  errmsg?: string;\n  $err?: string;\n  errorLabels?: string[];\n  errInfo?: Document;\n}\n\nfunction isAggregateError(e: unknown): e is Error & { errors: Error[] } {\n  return e != null && typeof e === 'object' && 'errors' in e && Array.isArray(e.errors);\n}\n\n/**\n * @public\n * @category Error\n *\n * @privateRemarks\n * mongodb-client-encryption has a dependency on this error, it uses the constructor with a string argument\n */\nexport class MongoError extends Error {\n  /** @internal */\n  private readonly errorLabelSet: Set<string> = new Set();\n  public get errorLabels(): string[] {\n    return Array.from(this.errorLabelSet);\n  }\n\n  /**\n   * This is a number in MongoServerError and a string in MongoDriverError\n   * @privateRemarks\n   * Define the type override on the subclasses when we can use the override keyword\n   */\n  code?: number | string;\n  topologyVersion?: TopologyVersion;\n  connectionGeneration?: number;\n  override cause?: Error;\n\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string, options?: { cause?: Error }) {\n    super(message, options);\n  }\n\n  /** @internal */\n  static buildErrorMessage(e: unknown): string {\n    if (typeof e === 'string') {\n      return e;\n    }\n    if (isAggregateError(e) && e.message.length === 0) {\n      return e.errors.length === 0\n        ? 'AggregateError has an empty errors array. Please check the `cause` property for more information.'\n        : e.errors.map(({ message }) => message).join(', ');\n    }\n\n    return e != null && typeof e === 'object' && 'message' in e && typeof e.message === 'string'\n      ? e.message\n      : 'empty error message';\n  }\n\n  override get name(): string {\n    return 'MongoError';\n  }\n\n  /** Legacy name for server error responses */\n  get errmsg(): string {\n    return this.message;\n  }\n\n  /**\n   * Checks the error to see if it has an error label\n   *\n   * @param label - The error label to check for\n   * @returns returns true if the error has the provided error label\n   */\n  hasErrorLabel(label: string): boolean {\n    return this.errorLabelSet.has(label);\n  }\n\n  addErrorLabel(label: string): void {\n    this.errorLabelSet.add(label);\n  }\n}\n\n/**\n * An error coming from the mongo server\n *\n * @public\n * @category Error\n */\nexport class MongoServerError extends MongoError {\n  /** Raw error result document returned by server. */\n  errorResponse: ErrorDescription;\n  codeName?: string;\n  writeConcernError?: Document;\n  errInfo?: Document;\n  ok?: number;\n  [key: string]: any;\n\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: ErrorDescription) {\n    super(message.message || message.errmsg || message.$err || 'n/a');\n\n    if (message.errorLabels) {\n      for (const label of message.errorLabels) this.addErrorLabel(label);\n    }\n\n    this.errorResponse = message;\n\n    for (const name in message) {\n      if (\n        name !== 'errorLabels' &&\n        name !== 'errmsg' &&\n        name !== 'message' &&\n        name !== 'errorResponse'\n      ) {\n        this[name] = message[name];\n      }\n    }\n  }\n\n  override get name(): string {\n    return 'MongoServerError';\n  }\n}\n\n/**\n * An error generated by the driver\n *\n * @public\n * @category Error\n */\nexport class MongoDriverError extends MongoError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string, options?: { cause?: Error }) {\n    super(message, options);\n  }\n\n  override get name(): string {\n    return 'MongoDriverError';\n  }\n}\n\n/**\n * An error generated when the driver API is used incorrectly\n *\n * @privateRemarks\n * Should **never** be directly instantiated\n *\n * @public\n * @category Error\n */\n\nexport class MongoAPIError extends MongoDriverError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string, options?: { cause?: Error }) {\n    super(message, options);\n  }\n\n  override get name(): string {\n    return 'MongoAPIError';\n  }\n}\n\n/**\n * An error generated when the driver encounters unexpected input\n * or reaches an unexpected/invalid internal state.\n *\n * @privateRemarks\n * Should **never** be directly instantiated.\n *\n * @public\n * @category Error\n */\nexport class MongoRuntimeError extends MongoDriverError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string, options?: { cause?: Error }) {\n    super(message, options);\n  }\n\n  override get name(): string {\n    return 'MongoRuntimeError';\n  }\n}\n\n/**\n * An error generated when a primary server is marked stale, never directly thrown\n *\n * @public\n * @category Error\n */\nexport class MongoStalePrimaryError extends MongoRuntimeError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string, options?: { cause?: Error }) {\n    super(message, options);\n  }\n\n  override get name(): string {\n    return 'MongoStalePrimaryError';\n  }\n}\n\n/**\n * An error generated when a batch command is re-executed after one of the commands in the batch\n * has failed\n *\n * @public\n * @category Error\n */\nexport class MongoBatchReExecutionError extends MongoAPIError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message = 'This batch has already been executed, create new batch to execute') {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoBatchReExecutionError';\n  }\n}\n\n/**\n * An error generated when the driver fails to decompress\n * data received from the server.\n *\n * @public\n * @category Error\n */\nexport class MongoDecompressionError extends MongoRuntimeError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string) {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoDecompressionError';\n  }\n}\n\n/**\n * An error thrown when the user attempts to operate on a database or collection through a MongoClient\n * that has not yet successfully called the \"connect\" method\n *\n * @public\n * @category Error\n */\nexport class MongoNotConnectedError extends MongoAPIError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string) {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoNotConnectedError';\n  }\n}\n\n/**\n * An error generated when the user makes a mistake in the usage of transactions.\n * (e.g. attempting to commit a transaction with a readPreference other than primary)\n *\n * @public\n * @category Error\n */\nexport class MongoTransactionError extends MongoAPIError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string) {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoTransactionError';\n  }\n}\n\n/**\n * An error generated when the user attempts to operate\n * on a session that has expired or has been closed.\n *\n * @public\n * @category Error\n */\nexport class MongoExpiredSessionError extends MongoAPIError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message = 'Cannot use a session that has ended') {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoExpiredSessionError';\n  }\n}\n\n/**\n * A error generated when the user attempts to authenticate\n * via Kerberos, but fails to connect to the Kerberos client.\n *\n * @public\n * @category Error\n */\nexport class MongoKerberosError extends MongoRuntimeError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string) {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoKerberosError';\n  }\n}\n\n/**\n * A error generated when the user attempts to authenticate\n * via AWS, but fails\n *\n * @public\n * @category Error\n */\nexport class MongoAWSError extends MongoRuntimeError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string, options?: { cause?: Error }) {\n    super(message, options);\n  }\n\n  override get name(): string {\n    return 'MongoAWSError';\n  }\n}\n\n/**\n * A error generated when the user attempts to authenticate\n * via OIDC callbacks, but fails.\n *\n * @public\n * @category Error\n */\nexport class MongoOIDCError extends MongoRuntimeError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string) {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoOIDCError';\n  }\n}\n\n/**\n * A error generated when the user attempts to authenticate\n * via Azure, but fails.\n *\n * @public\n * @category Error\n */\nexport class MongoAzureError extends MongoOIDCError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string) {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoAzureError';\n  }\n}\n\n/**\n * A error generated when the user attempts to authenticate\n * via GCP, but fails.\n *\n * @public\n * @category Error\n */\nexport class MongoGCPError extends MongoOIDCError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string) {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoGCPError';\n  }\n}\n\n/**\n * An error indicating that an error occurred when executing the bulk write.\n *\n * @public\n * @category Error\n */\nexport class MongoClientBulkWriteError extends MongoServerError {\n  /**\n   * Write concern errors that occurred while executing the bulk write. This list may have\n   * multiple items if more than one server command was required to execute the bulk write.\n   */\n  writeConcernErrors: Document[];\n  /**\n   * Errors that occurred during the execution of individual write operations. This map will\n   * contain at most one entry if the bulk write was ordered.\n   */\n  writeErrors: Map<number, ClientBulkWriteError>;\n  /**\n   * The results of any successful operations that were performed before the error was\n   * encountered.\n   */\n  partialResult?: ClientBulkWriteResult;\n\n  /**\n   * Initialize the client bulk write error.\n   * @param message - The error message.\n   */\n  constructor(message: ErrorDescription) {\n    super(message);\n    this.writeConcernErrors = [];\n    this.writeErrors = new Map();\n  }\n\n  override get name(): string {\n    return 'MongoClientBulkWriteError';\n  }\n}\n\n/**\n * An error indicating that an error occurred when processing bulk write results.\n *\n * @public\n * @category Error\n */\nexport class MongoClientBulkWriteCursorError extends MongoRuntimeError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string) {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoClientBulkWriteCursorError';\n  }\n}\n\n/**\n * An error indicating that an error occurred on the client when executing a client bulk write.\n *\n * @public\n * @category Error\n */\nexport class MongoClientBulkWriteExecutionError extends MongoRuntimeError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string) {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoClientBulkWriteExecutionError';\n  }\n}\n\n/**\n * An error generated when a ChangeStream operation fails to execute.\n *\n * @public\n * @category Error\n */\nexport class MongoChangeStreamError extends MongoRuntimeError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string) {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoChangeStreamError';\n  }\n}\n\n/**\n * An error thrown when the user calls a function or method not supported on a tailable cursor\n *\n * @public\n * @category Error\n */\nexport class MongoTailableCursorError extends MongoAPIError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message = 'Tailable cursor does not support this operation') {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoTailableCursorError';\n  }\n}\n\n/** An error generated when a GridFSStream operation fails to execute.\n *\n * @public\n * @category Error\n */\nexport class MongoGridFSStreamError extends MongoRuntimeError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string) {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoGridFSStreamError';\n  }\n}\n\n/**\n * An error generated when a malformed or invalid chunk is\n * encountered when reading from a GridFSStream.\n *\n * @public\n * @category Error\n */\nexport class MongoGridFSChunkError extends MongoRuntimeError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string) {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoGridFSChunkError';\n  }\n}\n\n/**\n * An error generated when a **parsable** unexpected response comes from the server.\n * This is generally an error where the driver in a state expecting a certain behavior to occur in\n * the next message from MongoDB but it receives something else.\n * This error **does not** represent an issue with wire message formatting.\n *\n * #### Example\n * When an operation fails, it is the driver's job to retry it. It must perform serverSelection\n * again to make sure that it attempts the operation against a server in a good state. If server\n * selection returns a server that does not support retryable operations, this error is used.\n * This scenario is unlikely as retryable support would also have been determined on the first attempt\n * but it is possible the state change could report a selectable server that does not support retries.\n *\n * @public\n * @category Error\n */\nexport class MongoUnexpectedServerResponseError extends MongoRuntimeError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string, options?: { cause?: Error }) {\n    super(message, options);\n  }\n\n  override get name(): string {\n    return 'MongoUnexpectedServerResponseError';\n  }\n}\n\n/**\n * @public\n * @category Error\n *\n * The `MongoOperationTimeoutError` class represents an error that occurs when an operation could not be completed within the specified `timeoutMS`.\n * It is generated by the driver in support of the \"client side operation timeout\" feature so inherits from `MongoDriverError`.\n * When `timeoutMS` is enabled `MongoServerError`s relating to `MaxTimeExpired` errors will be converted to `MongoOperationTimeoutError`\n *\n * @example\n * ```ts\n * try {\n *   await blogs.insertOne(blogPost, { timeoutMS: 60_000 })\n * } catch (error) {\n *   if (error instanceof MongoOperationTimeoutError) {\n *     console.log(`Oh no! writer's block!`, error);\n *   }\n * }\n * ```\n */\nexport class MongoOperationTimeoutError extends MongoDriverError {\n  override get name(): string {\n    return 'MongoOperationTimeoutError';\n  }\n}\n\n/**\n * An error thrown when the user attempts to add options to a cursor that has already been\n * initialized\n *\n * @public\n * @category Error\n */\nexport class MongoCursorInUseError extends MongoAPIError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message = 'Cursor is already initialized') {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoCursorInUseError';\n  }\n}\n\n/**\n * An error generated when an attempt is made to operate\n * on a closed/closing server.\n *\n * @public\n * @category Error\n */\nexport class MongoServerClosedError extends MongoAPIError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message = 'Server is closed') {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoServerClosedError';\n  }\n}\n\n/**\n * An error thrown when an attempt is made to read from a cursor that has been exhausted\n *\n * @public\n * @category Error\n */\nexport class MongoCursorExhaustedError extends MongoAPIError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message?: string) {\n    super(message || 'Cursor is exhausted');\n  }\n\n  override get name(): string {\n    return 'MongoCursorExhaustedError';\n  }\n}\n\n/**\n * An error generated when an attempt is made to operate on a\n * dropped, or otherwise unavailable, database.\n *\n * @public\n * @category Error\n */\nexport class MongoTopologyClosedError extends MongoAPIError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message = 'Topology is closed') {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoTopologyClosedError';\n  }\n}\n\n/**\n * An error generated when the MongoClient is closed and async\n * operations are interrupted.\n *\n * @public\n * @category Error\n */\nexport class MongoClientClosedError extends MongoAPIError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor() {\n    super('Operation interrupted because client was closed');\n  }\n\n  override get name(): string {\n    return 'MongoClientClosedError';\n  }\n}\n\n/** @public */\nexport interface MongoNetworkErrorOptions {\n  /** Indicates the timeout happened before a connection handshake completed */\n  beforeHandshake?: boolean;\n  cause?: Error;\n}\n\n/**\n * An error indicating an issue with the network, including TCP errors and timeouts.\n * @public\n * @category Error\n */\nexport class MongoNetworkError extends MongoError {\n  /** @internal */\n  public readonly beforeHandshake: boolean;\n\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string, options?: MongoNetworkErrorOptions) {\n    super(message, { cause: options?.cause });\n    this.beforeHandshake = !!options?.beforeHandshake;\n  }\n\n  override get name(): string {\n    return 'MongoNetworkError';\n  }\n}\n\n/**\n * An error indicating a network timeout occurred\n * @public\n * @category Error\n *\n * @privateRemarks\n * mongodb-client-encryption has a dependency on this error with an instanceof check\n */\nexport class MongoNetworkTimeoutError extends MongoNetworkError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string, options?: MongoNetworkErrorOptions) {\n    super(message, options);\n  }\n\n  override get name(): string {\n    return 'MongoNetworkTimeoutError';\n  }\n}\n\n/**\n * An error used when attempting to parse a value (like a connection string)\n * @public\n * @category Error\n */\nexport class MongoParseError extends MongoDriverError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string) {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoParseError';\n  }\n}\n\n/**\n * An error generated when the user supplies malformed or unexpected arguments\n * or when a required argument or field is not provided.\n *\n *\n * @public\n * @category Error\n */\nexport class MongoInvalidArgumentError extends MongoAPIError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string, options?: { cause?: Error }) {\n    super(message, options);\n  }\n\n  override get name(): string {\n    return 'MongoInvalidArgumentError';\n  }\n}\n\n/**\n * An error generated when a feature that is not enabled or allowed for the current server\n * configuration is used\n *\n *\n * @public\n * @category Error\n */\nexport class MongoCompatibilityError extends MongoAPIError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string) {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoCompatibilityError';\n  }\n}\n\n/**\n * An error generated when the user fails to provide authentication credentials before attempting\n * to connect to a mongo server instance.\n *\n *\n * @public\n * @category Error\n */\nexport class MongoMissingCredentialsError extends MongoAPIError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string) {\n    super(message);\n  }\n\n  override get name(): string {\n    return 'MongoMissingCredentialsError';\n  }\n}\n\n/**\n * An error generated when a required module or dependency is not present in the local environment\n *\n * @public\n * @category Error\n */\nexport class MongoMissingDependencyError extends MongoAPIError {\n  dependencyName: string;\n\n  /** @remarks This property is assigned in the `Error` constructor. */\n  declare cause: Error;\n\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string, options: { cause: Error; dependencyName: string }) {\n    super(message, options);\n    this.dependencyName = options.dependencyName;\n  }\n\n  override get name(): string {\n    return 'MongoMissingDependencyError';\n  }\n}\n/**\n * An error signifying a general system issue\n * @public\n * @category Error\n */\nexport class MongoSystemError extends MongoError {\n  /** An optional reason context, such as an error saved during flow of monitoring and selecting servers */\n  reason?: TopologyDescription;\n\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string, reason: TopologyDescription) {\n    if (reason && reason.error) {\n      super(MongoError.buildErrorMessage(reason.error.message || reason.error), {\n        cause: reason.error\n      });\n    } else {\n      super(message);\n    }\n\n    if (reason) {\n      this.reason = reason;\n    }\n\n    this.code = reason.error?.code;\n  }\n\n  override get name(): string {\n    return 'MongoSystemError';\n  }\n}\n\n/**\n * An error signifying a client-side server selection error\n * @public\n * @category Error\n */\nexport class MongoServerSelectionError extends MongoSystemError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string, reason: TopologyDescription) {\n    super(message, reason);\n  }\n\n  override get name(): string {\n    return 'MongoServerSelectionError';\n  }\n}\n\n/**\n * The type of the result property of MongoWriteConcernError\n * @public\n */\nexport interface WriteConcernErrorResult {\n  writeConcernError: {\n    code: number;\n    errmsg: string;\n    codeName?: string;\n    errInfo?: Document;\n  };\n  ok: number;\n  code?: number;\n  errorLabels?: string[];\n  [x: string | number]: unknown;\n}\n\n/**\n * An error thrown when the server reports a writeConcernError\n * @public\n * @category Error\n */\nexport class MongoWriteConcernError extends MongoServerError {\n  /** The result document */\n  result: Document;\n\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(result: WriteConcernErrorResult) {\n    super({ ...result.writeConcernError, ...result });\n    this.errInfo = result.writeConcernError.errInfo;\n    this.result = result;\n  }\n\n  override get name(): string {\n    return 'MongoWriteConcernError';\n  }\n}\n\n// https://github.com/mongodb/specifications/blob/master/source/retryable-reads/retryable-reads.md#retryable-error\nconst RETRYABLE_READ_ERROR_CODES = new Set<number>([\n  MONGODB_ERROR_CODES.HostUnreachable,\n  MONGODB_ERROR_CODES.HostNotFound,\n  MONGODB_ERROR_CODES.NetworkTimeout,\n  MONGODB_ERROR_CODES.ShutdownInProgress,\n  MONGODB_ERROR_CODES.PrimarySteppedDown,\n  MONGODB_ERROR_CODES.SocketException,\n  MONGODB_ERROR_CODES.NotWritablePrimary,\n  MONGODB_ERROR_CODES.InterruptedAtShutdown,\n  MONGODB_ERROR_CODES.InterruptedDueToReplStateChange,\n  MONGODB_ERROR_CODES.NotPrimaryNoSecondaryOk,\n  MONGODB_ERROR_CODES.NotPrimaryOrSecondary,\n  MONGODB_ERROR_CODES.ExceededTimeLimit,\n  MONGODB_ERROR_CODES.ReadConcernMajorityNotAvailableYet\n]);\n\n// see: https://github.com/mongodb/specifications/blob/master/source/retryable-writes/retryable-writes.md#terms\nconst RETRYABLE_WRITE_ERROR_CODES = RETRYABLE_READ_ERROR_CODES;\n\nexport function needsRetryableWriteLabel(\n  error: Error,\n  maxWireVersion: number,\n  serverType: ServerType\n): boolean {\n  // pre-4.4 server, then the driver adds an error label for every valid case\n  // execute operation will only inspect the label, code/message logic is handled here\n  if (error instanceof MongoNetworkError) {\n    return true;\n  }\n\n  if (error instanceof MongoError) {\n    if (\n      (maxWireVersion >= 9 || isRetryableWriteError(error)) &&\n      !error.hasErrorLabel(MongoErrorLabel.HandshakeError)\n    ) {\n      // If we already have the error label no need to add it again. 4.4+ servers add the label.\n      // In the case where we have a handshake error, need to fall down to the logic checking\n      // the codes.\n      return false;\n    }\n  }\n\n  if (error instanceof MongoWriteConcernError) {\n    if (serverType === 'Mongos' && maxWireVersion < 9) {\n      // use original top-level code from server response\n      return RETRYABLE_WRITE_ERROR_CODES.has(error.result.code ?? 0);\n    }\n    const code = error.result.writeConcernError.code ?? Number(error.code);\n    return RETRYABLE_WRITE_ERROR_CODES.has(Number.isNaN(code) ? 0 : code);\n  }\n\n  if (error instanceof MongoError) {\n    return RETRYABLE_WRITE_ERROR_CODES.has(Number(error.code));\n  }\n\n  const isNotWritablePrimaryError = LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.test(error.message);\n  if (isNotWritablePrimaryError) {\n    return true;\n  }\n\n  const isNodeIsRecoveringError = NODE_IS_RECOVERING_ERROR_MESSAGE.test(error.message);\n  if (isNodeIsRecoveringError) {\n    return true;\n  }\n\n  return false;\n}\n\nexport function isRetryableWriteError(error: MongoError): boolean {\n  return (\n    error.hasErrorLabel(MongoErrorLabel.RetryableWriteError) ||\n    error.hasErrorLabel(MongoErrorLabel.PoolRequstedRetry)\n  );\n}\n\n/** Determines whether an error is something the driver should attempt to retry */\nexport function isRetryableReadError(error: MongoError): boolean {\n  const hasRetryableErrorCode =\n    typeof error.code === 'number' ? RETRYABLE_READ_ERROR_CODES.has(error.code) : false;\n  if (hasRetryableErrorCode) {\n    return true;\n  }\n\n  if (error instanceof MongoNetworkError) {\n    return true;\n  }\n\n  const isNotWritablePrimaryError = LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.test(error.message);\n  if (isNotWritablePrimaryError) {\n    return true;\n  }\n\n  const isNodeIsRecoveringError = NODE_IS_RECOVERING_ERROR_MESSAGE.test(error.message);\n  if (isNodeIsRecoveringError) {\n    return true;\n  }\n\n  return false;\n}\n\nconst SDAM_RECOVERING_CODES = new Set<number>([\n  MONGODB_ERROR_CODES.ShutdownInProgress,\n  MONGODB_ERROR_CODES.PrimarySteppedDown,\n  MONGODB_ERROR_CODES.InterruptedAtShutdown,\n  MONGODB_ERROR_CODES.InterruptedDueToReplStateChange,\n  MONGODB_ERROR_CODES.NotPrimaryOrSecondary\n]);\n\nconst SDAM_NOT_PRIMARY_CODES = new Set<number>([\n  MONGODB_ERROR_CODES.NotWritablePrimary,\n  MONGODB_ERROR_CODES.NotPrimaryNoSecondaryOk,\n  MONGODB_ERROR_CODES.LegacyNotPrimary\n]);\n\nconst SDAM_NODE_SHUTTING_DOWN_ERROR_CODES = new Set<number>([\n  MONGODB_ERROR_CODES.InterruptedAtShutdown,\n  MONGODB_ERROR_CODES.ShutdownInProgress\n]);\n\nfunction isRecoveringError(err: MongoError) {\n  if (typeof err.code === 'number') {\n    // If any error code exists, we ignore the error.message\n    return SDAM_RECOVERING_CODES.has(err.code);\n  }\n\n  return (\n    LEGACY_NOT_PRIMARY_OR_SECONDARY_ERROR_MESSAGE.test(err.message) ||\n    NODE_IS_RECOVERING_ERROR_MESSAGE.test(err.message)\n  );\n}\n\nfunction isNotWritablePrimaryError(err: MongoError) {\n  if (typeof err.code === 'number') {\n    // If any error code exists, we ignore the error.message\n    return SDAM_NOT_PRIMARY_CODES.has(err.code);\n  }\n\n  if (isRecoveringError(err)) {\n    return false;\n  }\n\n  return LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.test(err.message);\n}\n\nexport function isNodeShuttingDownError(err: MongoError): boolean {\n  return !!(typeof err.code === 'number' && SDAM_NODE_SHUTTING_DOWN_ERROR_CODES.has(err.code));\n}\n\n/**\n * Determines whether SDAM can recover from a given error. If it cannot\n * then the pool will be cleared, and server state will completely reset\n * locally.\n *\n * @see https://github.com/mongodb/specifications/blob/master/source/server-discovery-and-monitoring/server-discovery-and-monitoring.md#not-writable-primary-and-node-is-recovering\n */\nexport function isSDAMUnrecoverableError(error: MongoError): boolean {\n  // NOTE: null check is here for a strictly pre-CMAP world, a timeout or\n  //       close event are considered unrecoverable\n  if (error instanceof MongoParseError || error == null) {\n    return true;\n  }\n\n  return isRecoveringError(error) || isNotWritablePrimaryError(error);\n}\n\nexport function isNetworkTimeoutError(err: MongoError): err is MongoNetworkError {\n  return !!(err instanceof MongoNetworkError && err.message.match(/timed out/));\n}\n\nexport function isResumableError(error?: Error, wireVersion?: number): boolean {\n  if (error == null || !(error instanceof MongoError)) {\n    return false;\n  }\n\n  if (error instanceof MongoNetworkError) {\n    return true;\n  }\n\n  if (wireVersion != null && wireVersion >= 9) {\n    // DRIVERS-1308: For 4.4 drivers running against 4.4 servers, drivers will add a special case to treat the CursorNotFound error code as resumable\n    if (error.code === MONGODB_ERROR_CODES.CursorNotFound) {\n      return true;\n    }\n    return error.hasErrorLabel(MongoErrorLabel.ResumableChangeStreamError);\n  }\n\n  if (typeof error.code === 'number') {\n    return GET_MORE_RESUMABLE_CODES.has(error.code);\n  }\n\n  return false;\n}\n"],"names":[],"mappings":";;;;;AAk3CA,QAAA,wBAAA,GAAA;AAiDA,QAAA,qBAAA,GAAA;AAQA,QAAA,oBAAA,GAAA;AAoEA,QAAA,uBAAA,GAAA;AAWA,QAAA,wBAAA,GAAA;AAUA,QAAA,qBAAA,GAAA;AAIA,QAAA,gBAAA,GAAA;AA5/CA;;;;IAKa,QAAA,yCAAyC,GAAG,IAAI,OAAO,cAAc;AAElF;;;;IAKa,QAAA,6CAA6C,GAAG,IAAI,OAC/D,2BACA;AAGF;;;;IAKa,QAAA,gCAAgC,GAAG,IAAI,OAAO,sBAAsB;AAEjF,kCAAA,GACa,QAAA,mBAAmB,GAAG,OAAO,MAAM,CAAC;IAC/C,iBAAiB;IACjB,cAAc;IACd,sBAAsB;IACtB,gBAAgB;IAChB,oBAAoB;IACpB,oBAAoB;IACpB,mBAAmB;IACnB,iBAAiB;IACjB,oBAAoB;IACpB,uBAAuB;IACvB,iCAAiC;IACjC,yBAAyB;IACzB,uBAAuB;IACvB,mBAAmB;IACnB,YAAY;IACZ,aAAa;IACb,mBAAmB;IACnB,+BAA+B;IAC/B,gBAAgB;IAChB,kBAAkB;IAClB,+DAA+D;IAC/D,qBAAqB;IACrB,mBAAmB;IACnB,kBAAkB;IAClB,kBAAkB;IAClB,yBAAyB;IACzB,2BAA2B;IAC3B,gBAAgB;IAChB,oCAAoC;;AAGtC,4JAA4J;AAC/I,QAAA,wBAAwB,GAAG,IAAI,IAAY;IACtD,QAAA,mBAAmB,CAAC,eAAe;IACnC,QAAA,mBAAmB,CAAC,YAAY;IAChC,QAAA,mBAAmB,CAAC,cAAc;IAClC,QAAA,mBAAmB,CAAC,kBAAkB;IACtC,QAAA,mBAAmB,CAAC,kBAAkB;IACtC,QAAA,mBAAmB,CAAC,iBAAiB;IACrC,QAAA,mBAAmB,CAAC,eAAe;IACnC,QAAA,mBAAmB,CAAC,kBAAkB;IACtC,QAAA,mBAAmB,CAAC,qBAAqB;IACzC,QAAA,mBAAmB,CAAC,+BAA+B;IACnD,QAAA,mBAAmB,CAAC,uBAAuB;IAC3C,QAAA,mBAAmB,CAAC,qBAAqB;IACzC,QAAA,mBAAmB,CAAC,iBAAiB;IACrC,QAAA,mBAAmB,CAAC,UAAU;IAC9B,QAAA,mBAAmB,CAAC,WAAW;IAC/B,QAAA,mBAAmB,CAAC,iBAAiB;IACrC,QAAA,mBAAmB,CAAC,6BAA6B;IACjD,QAAA,mBAAmB,CAAC,cAAc;CACnC;AAED,YAAA,GACa,QAAA,eAAe,GAAG,OAAO,MAAM,CAAC;IAC3C,qBAAqB;IACrB,2BAA2B;IAC3B,gCAAgC;IAChC,4BAA4B;IAC5B,gBAAgB;IAChB,WAAW;IACX,mBAAmB;IACnB,2BAA2B;IAC3B,mBAAmB;;AAerB,SAAS,iBAAiB,CAAU;IAClC,OAAO,KAAK,QAAQ,OAAO,MAAM,YAAY,YAAY,KAAK,MAAM,OAAO,CAAC,EAAE,MAAM;AACtF;AAEA;;;;;;IAOA,MAAa,mBAAmB;IAG9B,IAAW,cAAW;QACpB,OAAO,MAAM,IAAI,CAAC,IAAI,CAAC,aAAa;IACtC;IAYA;;;;;;;;;;SAWA,YAAY,OAAe,EAAE,OAA2B,CAAA;QACtD,KAAK,CAAC,SAAS;QA5BjB,cAAA,GACiB,IAAA,CAAA,aAAa,GAAgB,IAAI;IA4BlD;IAEA,cAAA,GACA,OAAO,kBAAkB,CAAU,EAAA;QACjC,IAAI,OAAO,MAAM,UAAU;YACzB,OAAO;QACT;QACA,IAAI,iBAAiB,MAAM,EAAE,OAAO,CAAC,MAAM,KAAK,GAAG;YACjD,OAAO,EAAE,MAAM,CAAC,MAAM,KAAK,IACvB,sGACA,EAAE,MAAM,CAAC,GAAG,CAAC,CAAC,EAAE,OAAO,EAAE,GAAK,SAAS,IAAI,CAAC;QAClD;QAEA,OAAO,KAAK,QAAQ,OAAO,MAAM,YAAY,aAAa,KAAK,OAAO,EAAE,OAAO,KAAK,WAChF,EAAE,OAAO,GACT;IACN;IAEA,IAAa,OAAI;QACf,OAAO;IACT;IAEA,2CAAA,GACA,IAAI,SAAM;QACR,OAAO,IAAI,CAAC,OAAO;IACrB;IAEA;;;;;QAMA,cAAc,KAAa,EAAA;QACzB,OAAO,IAAI,CAAC,aAAa,CAAC,GAAG,CAAC;IAChC;IAEA,cAAc,KAAa,EAAA;QACzB,IAAI,CAAC,aAAa,CAAC,GAAG,CAAC;IACzB;;AArEF,QAAA,UAAA,GAAA;AAwEA;;;;;IAMA,MAAa,yBAAyB;IASpC;;;;;;;;;;SAWA,YAAY,OAAyB,CAAA;QACnC,KAAK,CAAC,QAAQ,OAAO,IAAI,QAAQ,MAAM,IAAI,QAAQ,IAAI,IAAI;QAE3D,IAAI,QAAQ,WAAW,EAAE;YACvB,KAAK,MAAM,SAAS,QAAQ,WAAW,CAAE,IAAI,CAAC,aAAa,CAAC;QAC9D;QAEA,IAAI,CAAC,aAAa,GAAG;QAErB,IAAK,MAAM,QAAQ,QAAS;YAC1B,IACE,SAAS,iBACT,SAAS,YACT,SAAS,aACT,SAAS,iBACT;gBACA,IAAI,CAAC,KAAK,GAAG,OAAO,CAAC,KAAK;YAC5B;QACF;IACF;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AA3CF,QAAA,gBAAA,GAAA;AA8CA;;;;;IAMA,MAAa,yBAAyB;IACpC;;;;;;;;;;SAWA,YAAY,OAAe,EAAE,OAA2B,CAAA;QACtD,KAAK,CAAC,SAAS;IACjB;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,gBAAA,GAAA;AAqBA;;;;;;;;IAUA,MAAa,sBAAsB;IACjC;;;;;;;;;;SAWA,YAAY,OAAe,EAAE,OAA2B,CAAA;QACtD,KAAK,CAAC,SAAS;IACjB;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,aAAA,GAAA;AAqBA;;;;;;;;;IAUA,MAAa,0BAA0B;IACrC;;;;;;;;;;SAWA,YAAY,OAAe,EAAE,OAA2B,CAAA;QACtD,KAAK,CAAC,SAAS;IACjB;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,iBAAA,GAAA;AAqBA;;;;;IAMA,MAAa,+BAA+B;IAC1C;;;;;;;;;;SAWA,YAAY,OAAe,EAAE,OAA2B,CAAA;QACtD,KAAK,CAAC,SAAS;IACjB;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,sBAAA,GAAA;AAqBA;;;;;;IAOA,MAAa,mCAAmC;IAC9C;;;;;;;;;;SAWA,YAAY,UAAU,mEAAmE,CAAA;QACvF,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,0BAAA,GAAA;AAqBA;;;;;;IAOA,MAAa,gCAAgC;IAC3C;;;;;;;;;;SAWA,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,uBAAA,GAAA;AAqBA;;;;;;IAOA,MAAa,+BAA+B;IAC1C;;;;;;;;;;SAWA,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,sBAAA,GAAA;AAqBA;;;;;;IAOA,MAAa,8BAA8B;IACzC;;;;;;;;;;SAWA,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,qBAAA,GAAA;AAqBA;;;;;;IAOA,MAAa,iCAAiC;IAC5C;;;;;;;;;;SAWA,YAAY,UAAU,qCAAqC,CAAA;QACzD,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,wBAAA,GAAA;AAqBA;;;;;;IAOA,MAAa,2BAA2B;IACtC;;;;;;;;;;SAWA,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,kBAAA,GAAA;AAqBA;;;;;;IAOA,MAAa,sBAAsB;IACjC;;;;;;;;;;SAWA,YAAY,OAAe,EAAE,OAA2B,CAAA;QACtD,KAAK,CAAC,SAAS;IACjB;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,aAAA,GAAA;AAqBA;;;;;;IAOA,MAAa,uBAAuB;IAClC;;;;;;;;;;SAWA,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,cAAA,GAAA;AAqBA;;;;;;IAOA,MAAa,wBAAwB;IACnC;;;;;;;;;;SAWA,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,eAAA,GAAA;AAqBA;;;;;;IAOA,MAAa,sBAAsB;IACjC;;;;;;;;;;SAWA,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,aAAA,GAAA;AAqBA;;;;;IAMA,MAAa,kCAAkC;IAiB7C;;;QAIA,YAAY,OAAyB,CAAA;QACnC,KAAK,CAAC;QACN,IAAI,CAAC,kBAAkB,GAAG,EAAE;QAC5B,IAAI,CAAC,WAAW,GAAG,IAAI;IACzB;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AA7BF,QAAA,yBAAA,GAAA;AAgCA;;;;;IAMA,MAAa,wCAAwC;IACnD;;;;;;;;;;SAWA,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,+BAAA,GAAA;AAqBA;;;;;IAMA,MAAa,2CAA2C;IACtD;;;;;;;;;;SAWA,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,kCAAA,GAAA;AAqBA;;;;;IAMA,MAAa,+BAA+B;IAC1C;;;;;;;;;;SAWA,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,sBAAA,GAAA;AAqBA;;;;;IAMA,MAAa,iCAAiC;IAC5C;;;;;;;;;;SAWA,YAAY,UAAU,iDAAiD,CAAA;QACrE,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,wBAAA,GAAA;AAqBA;;;;IAKA,MAAa,+BAA+B;IAC1C;;;;;;;;;;SAWA,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,sBAAA,GAAA;AAqBA;;;;;;IAOA,MAAa,8BAA8B;IACzC;;;;;;;;;;SAWA,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,qBAAA,GAAA;AAqBA;;;;;;;;;;;;;;;IAgBA,MAAa,2CAA2C;IACtD;;;;;;;;;;SAWA,YAAY,OAAe,EAAE,OAA2B,CAAA;QACtD,KAAK,CAAC,SAAS;IACjB;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,kCAAA,GAAA;AAqBA;;;;;;;;;;;;;;;;;;IAmBA,MAAa,mCAAmC;IAC9C,IAAa,OAAI;QACf,OAAO;IACT;;AAHF,QAAA,0BAAA,GAAA;AAMA;;;;;;IAOA,MAAa,8BAA8B;IACzC;;;;;;;;;;SAWA,YAAY,UAAU,+BAA+B,CAAA;QACnD,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,qBAAA,GAAA;AAqBA;;;;;;IAOA,MAAa,+BAA+B;IAC1C;;;;;;;;;;SAWA,YAAY,UAAU,kBAAkB,CAAA;QACtC,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,sBAAA,GAAA;AAqBA;;;;;IAMA,MAAa,kCAAkC;IAC7C;;;;;;;;;;SAWA,YAAY,OAAgB,CAAA;QAC1B,KAAK,CAAC,WAAW;IACnB;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,yBAAA,GAAA;AAqBA;;;;;;IAOA,MAAa,iCAAiC;IAC5C;;;;;;;;;;SAWA,YAAY,UAAU,oBAAoB,CAAA;QACxC,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,wBAAA,GAAA;AAqBA;;;;;;IAOA,MAAa,+BAA+B;IAC1C;;;;;;;;;;SAWA,aAAA;QACE,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,sBAAA,GAAA;AA4BA;;;;IAKA,MAAa,0BAA0B;IAIrC;;;;;;;;;;SAWA,YAAY,OAAe,EAAE,OAAkC,CAAA;QAC7D,KAAK,CAAC,SAAS;YAAE,OAAO,SAAS;QAAK;QACtC,IAAI,CAAC,eAAe,GAAG,CAAC,CAAC,SAAS;IACpC;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAtBF,QAAA,iBAAA,GAAA;AAyBA;;;;;;;IAQA,MAAa,iCAAiC;IAC5C;;;;;;;;;;SAWA,YAAY,OAAe,EAAE,OAAkC,CAAA;QAC7D,KAAK,CAAC,SAAS;IACjB;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,wBAAA,GAAA;AAqBA;;;;IAKA,MAAa,wBAAwB;IACnC;;;;;;;;;;SAWA,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,eAAA,GAAA;AAqBA;;;;;;;IAQA,MAAa,kCAAkC;IAC7C;;;;;;;;;;SAWA,YAAY,OAAe,EAAE,OAA2B,CAAA;QACtD,KAAK,CAAC,SAAS;IACjB;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,yBAAA,GAAA;AAqBA;;;;;;;IAQA,MAAa,gCAAgC;IAC3C;;;;;;;;;;SAWA,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,uBAAA,GAAA;AAqBA;;;;;;;IAQA,MAAa,qCAAqC;IAChD;;;;;;;;;;SAWA,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,4BAAA,GAAA;AAqBA;;;;;IAMA,MAAa,oCAAoC;IAM/C;;;;;;;;;;SAWA,YAAY,OAAe,EAAE,OAAiD,CAAA;QAC5E,KAAK,CAAC,SAAS;QACf,IAAI,CAAC,cAAc,GAAG,QAAQ,cAAc;IAC9C;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAxBF,QAAA,2BAAA,GAAA;AA0BA;;;;IAKA,MAAa,yBAAyB;IAIpC;;;;;;;;;;SAWA,YAAY,OAAe,EAAE,MAA2B,CAAA;QACtD,IAAI,UAAU,OAAO,KAAK,EAAE;YAC1B,KAAK,CAAC,WAAW,iBAAiB,CAAC,OAAO,KAAK,CAAC,OAAO,IAAI,OAAO,KAAK,GAAG;gBACxE,OAAO,OAAO,KAAK;;QAEvB,OAAO;YACL,KAAK,CAAC;QACR;QAEA,IAAI,QAAQ;YACV,IAAI,CAAC,MAAM,GAAG;QAChB;QAEA,IAAI,CAAC,IAAI,GAAG,OAAO,KAAK,EAAE;IAC5B;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAjCF,QAAA,gBAAA,GAAA;AAoCA;;;;IAKA,MAAa,kCAAkC;IAC7C;;;;;;;;;;SAWA,YAAY,OAAe,EAAE,MAA2B,CAAA;QACtD,KAAK,CAAC,SAAS;IACjB;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,yBAAA,GAAA;AAsCA;;;;IAKA,MAAa,+BAA+B;IAI1C;;;;;;;;;;SAWA,YAAY,MAA+B,CAAA;QACzC,KAAK,CAAC;YAAE,GAAG,OAAO,iBAAiB;YAAE,GAAG,MAAM;QAAA;QAC9C,IAAI,CAAC,OAAO,GAAG,OAAO,iBAAiB,CAAC,OAAO;QAC/C,IAAI,CAAC,MAAM,GAAG;IAChB;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAvBF,QAAA,sBAAA,GAAA;AA0BA,kHAAkH;AAClH,MAAM,6BAA6B,IAAI,IAAY;IACjD,QAAA,mBAAmB,CAAC,eAAe;IACnC,QAAA,mBAAmB,CAAC,YAAY;IAChC,QAAA,mBAAmB,CAAC,cAAc;IAClC,QAAA,mBAAmB,CAAC,kBAAkB;IACtC,QAAA,mBAAmB,CAAC,kBAAkB;IACtC,QAAA,mBAAmB,CAAC,eAAe;IACnC,QAAA,mBAAmB,CAAC,kBAAkB;IACtC,QAAA,mBAAmB,CAAC,qBAAqB;IACzC,QAAA,mBAAmB,CAAC,+BAA+B;IACnD,QAAA,mBAAmB,CAAC,uBAAuB;IAC3C,QAAA,mBAAmB,CAAC,qBAAqB;IACzC,QAAA,mBAAmB,CAAC,iBAAiB;IACrC,QAAA,mBAAmB,CAAC,kCAAkC;CACvD;AAED,+GAA+G;AAC/G,MAAM,8BAA8B;AAEpC,SAAgB,yBACd,KAAY,EACZ,cAAsB,EACtB,UAAsB;IAEtB,2EAA2E;IAC3E,oFAAoF;IACpF,IAAI,iBAAiB,mBAAmB;QACtC,OAAO;IACT;IAEA,IAAI,iBAAiB,YAAY;QAC/B,IACE,CAAC,kBAAkB,KAAK,sBAAsB,MAAM,KACpD,CAAC,MAAM,aAAa,CAAC,QAAA,eAAe,CAAC,cAAc,GACnD;YACA,0FAA0F;YAC1F,uFAAuF;YACvF,aAAa;YACb,OAAO;QACT;IACF;IAEA,IAAI,iBAAiB,wBAAwB;QAC3C,IAAI,eAAe,YAAY,iBAAiB,GAAG;YACjD,mDAAmD;YACnD,OAAO,4BAA4B,GAAG,CAAC,MAAM,MAAM,CAAC,IAAI,IAAI;QAC9D;QACA,MAAM,OAAO,MAAM,MAAM,CAAC,iBAAiB,CAAC,IAAI,IAAI,OAAO,MAAM,IAAI;QACrE,OAAO,4BAA4B,GAAG,CAAC,OAAO,KAAK,CAAC,QAAQ,IAAI;IAClE;IAEA,IAAI,iBAAiB,YAAY;QAC/B,OAAO,4BAA4B,GAAG,CAAC,OAAO,MAAM,IAAI;IAC1D;IAEA,MAAM,4BAA4B,QAAA,yCAAyC,CAAC,IAAI,CAAC,MAAM,OAAO;IAC9F,IAAI,2BAA2B;QAC7B,OAAO;IACT;IAEA,MAAM,0BAA0B,QAAA,gCAAgC,CAAC,IAAI,CAAC,MAAM,OAAO;IACnF,IAAI,yBAAyB;QAC3B,OAAO;IACT;IAEA,OAAO;AACT;AAEA,SAAgB,sBAAsB,KAAiB;IACrD,OACE,MAAM,aAAa,CAAC,QAAA,eAAe,CAAC,mBAAmB,KACvD,MAAM,aAAa,CAAC,QAAA,eAAe,CAAC,iBAAiB;AAEzD;AAEA,gFAAA,GACA,SAAgB,qBAAqB,KAAiB;IACpD,MAAM,wBACJ,OAAO,MAAM,IAAI,KAAK,WAAW,2BAA2B,GAAG,CAAC,MAAM,IAAI,IAAI;IAChF,IAAI,uBAAuB;QACzB,OAAO;IACT;IAEA,IAAI,iBAAiB,mBAAmB;QACtC,OAAO;IACT;IAEA,MAAM,4BAA4B,QAAA,yCAAyC,CAAC,IAAI,CAAC,MAAM,OAAO;IAC9F,IAAI,2BAA2B;QAC7B,OAAO;IACT;IAEA,MAAM,0BAA0B,QAAA,gCAAgC,CAAC,IAAI,CAAC,MAAM,OAAO;IACnF,IAAI,yBAAyB;QAC3B,OAAO;IACT;IAEA,OAAO;AACT;AAEA,MAAM,wBAAwB,IAAI,IAAY;IAC5C,QAAA,mBAAmB,CAAC,kBAAkB;IACtC,QAAA,mBAAmB,CAAC,kBAAkB;IACtC,QAAA,mBAAmB,CAAC,qBAAqB;IACzC,QAAA,mBAAmB,CAAC,+BAA+B;IACnD,QAAA,mBAAmB,CAAC,qBAAqB;CAC1C;AAED,MAAM,yBAAyB,IAAI,IAAY;IAC7C,QAAA,mBAAmB,CAAC,kBAAkB;IACtC,QAAA,mBAAmB,CAAC,uBAAuB;IAC3C,QAAA,mBAAmB,CAAC,gBAAgB;CACrC;AAED,MAAM,sCAAsC,IAAI,IAAY;IAC1D,QAAA,mBAAmB,CAAC,qBAAqB;IACzC,QAAA,mBAAmB,CAAC,kBAAkB;CACvC;AAED,SAAS,kBAAkB,GAAe;IACxC,IAAI,OAAO,IAAI,IAAI,KAAK,UAAU;QAChC,wDAAwD;QACxD,OAAO,sBAAsB,GAAG,CAAC,IAAI,IAAI;IAC3C;IAEA,OACE,QAAA,6CAA6C,CAAC,IAAI,CAAC,IAAI,OAAO,KAC9D,QAAA,gCAAgC,CAAC,IAAI,CAAC,IAAI,OAAO;AAErD;AAEA,SAAS,0BAA0B,GAAe;IAChD,IAAI,OAAO,IAAI,IAAI,KAAK,UAAU;QAChC,wDAAwD;QACxD,OAAO,uBAAuB,GAAG,CAAC,IAAI,IAAI;IAC5C;IAEA,IAAI,kBAAkB,MAAM;QAC1B,OAAO;IACT;IAEA,OAAO,QAAA,yCAAyC,CAAC,IAAI,CAAC,IAAI,OAAO;AACnE;AAEA,SAAgB,wBAAwB,GAAe;IACrD,OAAO,CAAC,CAAC,CAAC,OAAO,IAAI,IAAI,KAAK,YAAY,oCAAoC,GAAG,CAAC,IAAI,IAAI,CAAC;AAC7F;AAEA;;;;;;IAOA,SAAgB,yBAAyB,KAAiB;IACxD,uEAAuE;IACvE,iDAAiD;IACjD,IAAI,iBAAiB,mBAAmB,SAAS,MAAM;QACrD,OAAO;IACT;IAEA,OAAO,kBAAkB,UAAU,0BAA0B;AAC/D;AAEA,SAAgB,sBAAsB,GAAe;IACnD,OAAO,CAAC,CAAC,CAAC,eAAe,qBAAqB,IAAI,OAAO,CAAC,KAAK,CAAC,YAAY;AAC9E;AAEA,SAAgB,iBAAiB,KAAa,EAAE,WAAoB;IAClE,IAAI,SAAS,QAAQ,CAAC,CAAC,iBAAiB,UAAU,GAAG;QACnD,OAAO;IACT;IAEA,IAAI,iBAAiB,mBAAmB;QACtC,OAAO;IACT;IAEA,IAAI,eAAe,QAAQ,eAAe,GAAG;QAC3C,iJAAiJ;QACjJ,IAAI,MAAM,IAAI,KAAK,QAAA,mBAAmB,CAAC,cAAc,EAAE;YACrD,OAAO;QACT;QACA,OAAO,MAAM,aAAa,CAAC,QAAA,eAAe,CAAC,0BAA0B;IACvE;IAEA,IAAI,OAAO,MAAM,IAAI,KAAK,UAAU;QAClC,OAAO,QAAA,wBAAwB,CAAC,GAAG,CAAC,MAAM,IAAI;IAChD;IAEA,OAAO;AACT"}},
    {"offset": {"line": 1487, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1491, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/read_preference.ts"],"sourcesContent":["import type { Document } from './bson';\nimport { MongoInvalidArgumentError } from './error';\nimport type { TagSet } from './sdam/server_description';\nimport type { ClientSession } from './sessions';\n\n/** @public */\nexport type ReadPreferenceLike = ReadPreference | ReadPreferenceMode;\n\n/** @public */\nexport const ReadPreferenceMode = Object.freeze({\n  primary: 'primary',\n  primaryPreferred: 'primaryPreferred',\n  secondary: 'secondary',\n  secondaryPreferred: 'secondaryPreferred',\n  nearest: 'nearest'\n} as const);\n\n/** @public */\nexport type ReadPreferenceMode = (typeof ReadPreferenceMode)[keyof typeof ReadPreferenceMode];\n\n/** @public */\nexport interface HedgeOptions {\n  /** Explicitly enable or disable hedged reads. */\n  enabled?: boolean;\n}\n\n/** @public */\nexport interface ReadPreferenceOptions {\n  /** Max secondary read staleness in seconds, Minimum value is 90 seconds.*/\n  maxStalenessSeconds?: number;\n  /** Server mode in which the same query is dispatched in parallel to multiple replica set members. */\n  hedge?: HedgeOptions;\n}\n\n/** @public */\nexport interface ReadPreferenceLikeOptions extends ReadPreferenceOptions {\n  readPreference?:\n    | ReadPreferenceLike\n    | {\n        mode?: ReadPreferenceMode;\n        preference?: ReadPreferenceMode;\n        tags?: TagSet[];\n        maxStalenessSeconds?: number;\n      };\n}\n\n/** @public */\nexport interface ReadPreferenceFromOptions extends ReadPreferenceLikeOptions {\n  session?: ClientSession;\n  readPreferenceTags?: TagSet[];\n  hedge?: HedgeOptions;\n}\n\n/**\n * The **ReadPreference** class is a class that represents a MongoDB ReadPreference and is\n * used to construct connections.\n * @public\n *\n * @see https://www.mongodb.com/docs/manual/core/read-preference/\n */\nexport class ReadPreference {\n  mode: ReadPreferenceMode;\n  tags?: TagSet[];\n  hedge?: HedgeOptions;\n  maxStalenessSeconds?: number;\n  minWireVersion?: number;\n\n  public static PRIMARY = ReadPreferenceMode.primary;\n  public static PRIMARY_PREFERRED = ReadPreferenceMode.primaryPreferred;\n  public static SECONDARY = ReadPreferenceMode.secondary;\n  public static SECONDARY_PREFERRED = ReadPreferenceMode.secondaryPreferred;\n  public static NEAREST = ReadPreferenceMode.nearest;\n\n  public static primary = new ReadPreference(ReadPreferenceMode.primary);\n  public static primaryPreferred = new ReadPreference(ReadPreferenceMode.primaryPreferred);\n  public static secondary = new ReadPreference(ReadPreferenceMode.secondary);\n  public static secondaryPreferred = new ReadPreference(ReadPreferenceMode.secondaryPreferred);\n  public static nearest = new ReadPreference(ReadPreferenceMode.nearest);\n\n  /**\n   * @param mode - A string describing the read preference mode (primary|primaryPreferred|secondary|secondaryPreferred|nearest)\n   * @param tags - A tag set used to target reads to members with the specified tag(s). tagSet is not available if using read preference mode primary.\n   * @param options - Additional read preference options\n   */\n  constructor(mode: ReadPreferenceMode, tags?: TagSet[], options?: ReadPreferenceOptions) {\n    if (!ReadPreference.isValid(mode)) {\n      throw new MongoInvalidArgumentError(`Invalid read preference mode ${JSON.stringify(mode)}`);\n    }\n    if (options == null && typeof tags === 'object' && !Array.isArray(tags)) {\n      options = tags;\n      tags = undefined;\n    } else if (tags && !Array.isArray(tags)) {\n      throw new MongoInvalidArgumentError('ReadPreference tags must be an array');\n    }\n\n    this.mode = mode;\n    this.tags = tags;\n    this.hedge = options?.hedge;\n    this.maxStalenessSeconds = undefined;\n    this.minWireVersion = undefined;\n\n    options = options ?? {};\n    if (options.maxStalenessSeconds != null) {\n      if (options.maxStalenessSeconds <= 0) {\n        throw new MongoInvalidArgumentError('maxStalenessSeconds must be a positive integer');\n      }\n\n      this.maxStalenessSeconds = options.maxStalenessSeconds;\n\n      // NOTE: The minimum required wire version is 5 for this read preference. If the existing\n      //       topology has a lower value then a MongoError will be thrown during server selection.\n      this.minWireVersion = 5;\n    }\n\n    if (this.mode === ReadPreference.PRIMARY) {\n      if (this.tags && Array.isArray(this.tags) && this.tags.length > 0) {\n        throw new MongoInvalidArgumentError('Primary read preference cannot be combined with tags');\n      }\n\n      if (this.maxStalenessSeconds) {\n        throw new MongoInvalidArgumentError(\n          'Primary read preference cannot be combined with maxStalenessSeconds'\n        );\n      }\n\n      if (this.hedge) {\n        throw new MongoInvalidArgumentError(\n          'Primary read preference cannot be combined with hedge'\n        );\n      }\n    }\n  }\n\n  // Support the deprecated `preference` property introduced in the porcelain layer\n  get preference(): ReadPreferenceMode {\n    return this.mode;\n  }\n\n  static fromString(mode: string): ReadPreference {\n    return new ReadPreference(mode as ReadPreferenceMode);\n  }\n\n  /**\n   * Construct a ReadPreference given an options object.\n   *\n   * @param options - The options object from which to extract the read preference.\n   */\n  static fromOptions(options?: ReadPreferenceFromOptions): ReadPreference | undefined {\n    if (!options) return;\n    const readPreference =\n      options.readPreference ?? options.session?.transaction.options.readPreference;\n    const readPreferenceTags = options.readPreferenceTags;\n\n    if (readPreference == null) {\n      return;\n    }\n\n    if (typeof readPreference === 'string') {\n      return new ReadPreference(readPreference, readPreferenceTags, {\n        maxStalenessSeconds: options.maxStalenessSeconds,\n        hedge: options.hedge\n      });\n    } else if (!(readPreference instanceof ReadPreference) && typeof readPreference === 'object') {\n      const mode = readPreference.mode || readPreference.preference;\n      if (mode && typeof mode === 'string') {\n        return new ReadPreference(mode, readPreference.tags ?? readPreferenceTags, {\n          maxStalenessSeconds: readPreference.maxStalenessSeconds,\n          hedge: options.hedge\n        });\n      }\n    }\n\n    if (readPreferenceTags) {\n      readPreference.tags = readPreferenceTags;\n    }\n\n    return readPreference as ReadPreference;\n  }\n\n  /**\n   * Replaces options.readPreference with a ReadPreference instance\n   */\n  static translate(options: ReadPreferenceLikeOptions): ReadPreferenceLikeOptions {\n    if (options.readPreference == null) return options;\n    const r = options.readPreference;\n\n    if (typeof r === 'string') {\n      options.readPreference = new ReadPreference(r);\n    } else if (r && !(r instanceof ReadPreference) && typeof r === 'object') {\n      const mode = r.mode || r.preference;\n      if (mode && typeof mode === 'string') {\n        options.readPreference = new ReadPreference(mode, r.tags, {\n          maxStalenessSeconds: r.maxStalenessSeconds\n        });\n      }\n    } else if (!(r instanceof ReadPreference)) {\n      throw new MongoInvalidArgumentError(`Invalid read preference: ${r}`);\n    }\n\n    return options;\n  }\n\n  /**\n   * Validate if a mode is legal\n   *\n   * @param mode - The string representing the read preference mode.\n   */\n  static isValid(mode: string): boolean {\n    const VALID_MODES = new Set([\n      ReadPreference.PRIMARY,\n      ReadPreference.PRIMARY_PREFERRED,\n      ReadPreference.SECONDARY,\n      ReadPreference.SECONDARY_PREFERRED,\n      ReadPreference.NEAREST,\n      null\n    ]);\n\n    return VALID_MODES.has(mode as ReadPreferenceMode);\n  }\n\n  /**\n   * Validate if a mode is legal\n   *\n   * @param mode - The string representing the read preference mode.\n   */\n  isValid(mode?: string): boolean {\n    return ReadPreference.isValid(typeof mode === 'string' ? mode : this.mode);\n  }\n\n  /**\n   * Indicates that this readPreference needs the \"SecondaryOk\" bit when sent over the wire\n   * @see https://www.mongodb.com/docs/manual/reference/mongodb-wire-protocol/#op-query\n   */\n  secondaryOk(): boolean {\n    const NEEDS_SECONDARYOK = new Set<string>([\n      ReadPreference.PRIMARY_PREFERRED,\n      ReadPreference.SECONDARY,\n      ReadPreference.SECONDARY_PREFERRED,\n      ReadPreference.NEAREST\n    ]);\n\n    return NEEDS_SECONDARYOK.has(this.mode);\n  }\n\n  /**\n   * Check if the two ReadPreferences are equivalent\n   *\n   * @param readPreference - The read preference with which to check equality\n   */\n  equals(readPreference: ReadPreference): boolean {\n    return readPreference.mode === this.mode;\n  }\n\n  /** Return JSON representation */\n  toJSON(): Document {\n    const readPreference = { mode: this.mode } as Document;\n    if (Array.isArray(this.tags)) readPreference.tags = this.tags;\n    if (this.maxStalenessSeconds) readPreference.maxStalenessSeconds = this.maxStalenessSeconds;\n    if (this.hedge) readPreference.hedge = this.hedge;\n    return readPreference;\n  }\n}\n"],"names":[],"mappings":";;;;;AACA,MAAA;AAOA,YAAA,GACa,QAAA,kBAAkB,GAAG,OAAO,MAAM,CAAC;IAC9C,SAAS;IACT,kBAAkB;IAClB,WAAW;IACX,oBAAoB;IACpB,SAAS;;AAuCX;;;;;;IAOA,MAAa;IAmBX;;;;QAKA,YAAY,IAAwB,EAAE,IAAe,EAAE,OAA+B,CAAA;QACpF,IAAI,CAAC,eAAe,OAAO,CAAC,OAAO;YACjC,MAAM,IAAI,QAAA,yBAAyB,CAAC,CAAA,6BAAA,EAAgC,KAAK,SAAS,CAAC,MAAK,CAAE;QAC5F;QACA,IAAI,WAAW,QAAQ,OAAO,SAAS,YAAY,CAAC,MAAM,OAAO,CAAC,OAAO;YACvE,UAAU;YACV,OAAO;QACT,OAAO,IAAI,QAAQ,CAAC,MAAM,OAAO,CAAC,OAAO;YACvC,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,IAAI,CAAC,IAAI,GAAG;QACZ,IAAI,CAAC,IAAI,GAAG;QACZ,IAAI,CAAC,KAAK,GAAG,SAAS;QACtB,IAAI,CAAC,mBAAmB,GAAG;QAC3B,IAAI,CAAC,cAAc,GAAG;QAEtB,UAAU,WAAW,CAAA;QACrB,IAAI,QAAQ,mBAAmB,IAAI,MAAM;YACvC,IAAI,QAAQ,mBAAmB,IAAI,GAAG;gBACpC,MAAM,IAAI,QAAA,yBAAyB,CAAC;YACtC;YAEA,IAAI,CAAC,mBAAmB,GAAG,QAAQ,mBAAmB;YAEtD,yFAAyF;YACzF,6FAA6F;YAC7F,IAAI,CAAC,cAAc,GAAG;QACxB;QAEA,IAAI,IAAI,CAAC,IAAI,KAAK,eAAe,OAAO,EAAE;YACxC,IAAI,IAAI,CAAC,IAAI,IAAI,MAAM,OAAO,CAAC,IAAI,CAAC,IAAI,KAAK,IAAI,CAAC,IAAI,CAAC,MAAM,GAAG,GAAG;gBACjE,MAAM,IAAI,QAAA,yBAAyB,CAAC;YACtC;YAEA,IAAI,IAAI,CAAC,mBAAmB,EAAE;gBAC5B,MAAM,IAAI,QAAA,yBAAyB,CACjC;YAEJ;YAEA,IAAI,IAAI,CAAC,KAAK,EAAE;gBACd,MAAM,IAAI,QAAA,yBAAyB,CACjC;YAEJ;QACF;IACF;IAEA,iFAAiF;IACjF,IAAI,aAAU;QACZ,OAAO,IAAI,CAAC,IAAI;IAClB;IAEA,OAAO,WAAW,IAAY,EAAA;QAC5B,OAAO,IAAI,eAAe;IAC5B;IAEA;;;;QAKA,OAAO,YAAY,OAAmC,EAAA;QACpD,IAAI,CAAC,SAAS;QACd,MAAM,iBACJ,QAAQ,cAAc,IAAI,QAAQ,OAAO,EAAE,YAAY,QAAQ;QACjE,MAAM,qBAAqB,QAAQ,kBAAkB;QAErD,IAAI,kBAAkB,MAAM;YAC1B;QACF;QAEA,IAAI,OAAO,mBAAmB,UAAU;YACtC,OAAO,IAAI,eAAe,gBAAgB,oBAAoB;gBAC5D,qBAAqB,QAAQ,mBAAmB;gBAChD,OAAO,QAAQ,KAAK;;QAExB,OAAO,IAAI,CAAC,CAAC,0BAA0B,cAAc,KAAK,OAAO,mBAAmB,UAAU;YAC5F,MAAM,OAAO,eAAe,IAAI,IAAI,eAAe,UAAU;YAC7D,IAAI,QAAQ,OAAO,SAAS,UAAU;gBACpC,OAAO,IAAI,eAAe,MAAM,eAAe,IAAI,IAAI,oBAAoB;oBACzE,qBAAqB,eAAe,mBAAmB;oBACvD,OAAO,QAAQ,KAAK;;YAExB;QACF;QAEA,IAAI,oBAAoB;YACtB,eAAe,IAAI,GAAG;QACxB;QAEA,OAAO;IACT;IAEA;;QAGA,OAAO,UAAU,OAAkC,EAAA;QACjD,IAAI,QAAQ,cAAc,IAAI,MAAM,OAAO;QAC3C,MAAM,IAAI,QAAQ,cAAc;QAEhC,IAAI,OAAO,MAAM,UAAU;YACzB,QAAQ,cAAc,GAAG,IAAI,eAAe;QAC9C,OAAO,IAAI,KAAK,CAAC,CAAC,aAAa,cAAc,KAAK,OAAO,MAAM,UAAU;YACvE,MAAM,OAAO,EAAE,IAAI,IAAI,EAAE,UAAU;YACnC,IAAI,QAAQ,OAAO,SAAS,UAAU;gBACpC,QAAQ,cAAc,GAAG,IAAI,eAAe,MAAM,EAAE,IAAI,EAAE;oBACxD,qBAAqB,EAAE,mBAAmB;;YAE9C;QACF,OAAO,IAAI,CAAC,CAAC,aAAa,cAAc,GAAG;YACzC,MAAM,IAAI,QAAA,yBAAyB,CAAC,CAAA,yBAAA,EAA4B,EAAC,CAAE;QACrE;QAEA,OAAO;IACT;IAEA;;;;QAKA,OAAO,QAAQ,IAAY,EAAA;QACzB,MAAM,cAAc,IAAI,IAAI;YAC1B,eAAe,OAAO;YACtB,eAAe,iBAAiB;YAChC,eAAe,SAAS;YACxB,eAAe,mBAAmB;YAClC,eAAe,OAAO;YACtB;SACD;QAED,OAAO,YAAY,GAAG,CAAC;IACzB;IAEA;;;;QAKA,QAAQ,IAAa,EAAA;QACnB,OAAO,eAAe,OAAO,CAAC,OAAO,SAAS,WAAW,OAAO,IAAI,CAAC,IAAI;IAC3E;IAEA;;;QAIA,cAAW;QACT,MAAM,oBAAoB,IAAI,IAAY;YACxC,eAAe,iBAAiB;YAChC,eAAe,SAAS;YACxB,eAAe,mBAAmB;YAClC,eAAe,OAAO;SACvB;QAED,OAAO,kBAAkB,GAAG,CAAC,IAAI,CAAC,IAAI;IACxC;IAEA;;;;QAKA,OAAO,cAA8B,EAAA;QACnC,OAAO,eAAe,IAAI,KAAK,IAAI,CAAC,IAAI;IAC1C;IAEA,+BAAA,GACA,SAAM;QACJ,MAAM,iBAAiB;YAAE,MAAM,IAAI,CAAC,IAAI;QAAA;QACxC,IAAI,MAAM,OAAO,CAAC,IAAI,CAAC,IAAI,GAAG,eAAe,IAAI,GAAG,IAAI,CAAC,IAAI;QAC7D,IAAI,IAAI,CAAC,mBAAmB,EAAE,eAAe,mBAAmB,GAAG,IAAI,CAAC,mBAAmB;QAC3F,IAAI,IAAI,CAAC,KAAK,EAAE,eAAe,KAAK,GAAG,IAAI,CAAC,KAAK;QACjD,OAAO;IACT;;AAxMF,QAAA,cAAA,GAAA;AAOgB,eAAA,OAAO,GAAG,QAAA,kBAAkB,CAAC,OAAO;AACpC,eAAA,iBAAiB,GAAG,QAAA,kBAAkB,CAAC,gBAAgB;AACvD,eAAA,SAAS,GAAG,QAAA,kBAAkB,CAAC,SAAS;AACxC,eAAA,mBAAmB,GAAG,QAAA,kBAAkB,CAAC,kBAAkB;AAC3D,eAAA,OAAO,GAAG,QAAA,kBAAkB,CAAC,OAAO;AAEpC,eAAA,OAAO,GAAG,IAAI,eAAe,QAAA,kBAAkB,CAAC,OAAO;AACvD,eAAA,gBAAgB,GAAG,IAAI,eAAe,QAAA,kBAAkB,CAAC,gBAAgB;AACzE,eAAA,SAAS,GAAG,IAAI,eAAe,QAAA,kBAAkB,CAAC,SAAS;AAC3D,eAAA,kBAAkB,GAAG,IAAI,eAAe,QAAA,kBAAkB,CAAC,kBAAkB;AAC7E,eAAA,OAAO,GAAG,IAAI,eAAe,QAAA,kBAAkB,CAAC,OAAO"}},
    {"offset": {"line": 1670, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1674, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/constants.ts"],"sourcesContent":["export const SYSTEM_NAMESPACE_COLLECTION = 'system.namespaces';\nexport const SYSTEM_INDEX_COLLECTION = 'system.indexes';\nexport const SYSTEM_PROFILE_COLLECTION = 'system.profile';\nexport const SYSTEM_USER_COLLECTION = 'system.users';\nexport const SYSTEM_COMMAND_COLLECTION = '$cmd';\nexport const SYSTEM_JS_COLLECTION = 'system.js';\n\n// events\nexport const ERROR = 'error' as const;\nexport const TIMEOUT = 'timeout' as const;\nexport const CLOSE = 'close' as const;\nexport const OPEN = 'open' as const;\nexport const CONNECT = 'connect' as const;\nexport const CLOSED = 'closed' as const;\nexport const ENDED = 'ended' as const;\nexport const MESSAGE = 'message' as const;\nexport const PINNED = 'pinned' as const;\nexport const UNPINNED = 'unpinned' as const;\nexport const DESCRIPTION_RECEIVED = 'descriptionReceived';\n/** @internal */\nexport const SERVER_OPENING = 'serverOpening' as const;\n/** @internal */\nexport const SERVER_CLOSED = 'serverClosed' as const;\n/** @internal */\nexport const SERVER_DESCRIPTION_CHANGED = 'serverDescriptionChanged' as const;\n/** @internal */\nexport const TOPOLOGY_OPENING = 'topologyOpening' as const;\n/** @internal */\nexport const TOPOLOGY_CLOSED = 'topologyClosed' as const;\n/** @internal */\nexport const TOPOLOGY_DESCRIPTION_CHANGED = 'topologyDescriptionChanged' as const;\n/** @internal */\nexport const SERVER_SELECTION_STARTED = 'serverSelectionStarted' as const;\n/** @internal */\nexport const SERVER_SELECTION_FAILED = 'serverSelectionFailed' as const;\n/** @internal */\nexport const SERVER_SELECTION_SUCCEEDED = 'serverSelectionSucceeded' as const;\n/** @internal */\nexport const WAITING_FOR_SUITABLE_SERVER = 'waitingForSuitableServer' as const;\n/** @internal */\nexport const CONNECTION_POOL_CREATED = 'connectionPoolCreated' as const;\n/** @internal */\nexport const CONNECTION_POOL_CLOSED = 'connectionPoolClosed' as const;\n/** @internal */\nexport const CONNECTION_POOL_CLEARED = 'connectionPoolCleared' as const;\n/** @internal */\nexport const CONNECTION_POOL_READY = 'connectionPoolReady' as const;\n/** @internal */\nexport const CONNECTION_CREATED = 'connectionCreated' as const;\n/** @internal */\nexport const CONNECTION_READY = 'connectionReady' as const;\n/** @internal */\nexport const CONNECTION_CLOSED = 'connectionClosed' as const;\n/** @internal */\nexport const CONNECTION_CHECK_OUT_STARTED = 'connectionCheckOutStarted' as const;\n/** @internal */\nexport const CONNECTION_CHECK_OUT_FAILED = 'connectionCheckOutFailed' as const;\n/** @internal */\nexport const CONNECTION_CHECKED_OUT = 'connectionCheckedOut' as const;\n/** @internal */\nexport const CONNECTION_CHECKED_IN = 'connectionCheckedIn' as const;\nexport const CLUSTER_TIME_RECEIVED = 'clusterTimeReceived' as const;\n/** @internal */\nexport const COMMAND_STARTED = 'commandStarted' as const;\n/** @internal */\nexport const COMMAND_SUCCEEDED = 'commandSucceeded' as const;\n/** @internal */\nexport const COMMAND_FAILED = 'commandFailed' as const;\n/** @internal */\nexport const SERVER_HEARTBEAT_STARTED = 'serverHeartbeatStarted' as const;\n/** @internal */\nexport const SERVER_HEARTBEAT_SUCCEEDED = 'serverHeartbeatSucceeded' as const;\n/** @internal */\nexport const SERVER_HEARTBEAT_FAILED = 'serverHeartbeatFailed' as const;\nexport const RESPONSE = 'response' as const;\nexport const MORE = 'more' as const;\nexport const INIT = 'init' as const;\nexport const CHANGE = 'change' as const;\nexport const END = 'end' as const;\nexport const RESUME_TOKEN_CHANGED = 'resumeTokenChanged' as const;\n\n/** @public */\nexport const HEARTBEAT_EVENTS = Object.freeze([\n  SERVER_HEARTBEAT_STARTED,\n  SERVER_HEARTBEAT_SUCCEEDED,\n  SERVER_HEARTBEAT_FAILED\n] as const);\n\n/** @public */\nexport const CMAP_EVENTS = Object.freeze([\n  CONNECTION_POOL_CREATED,\n  CONNECTION_POOL_READY,\n  CONNECTION_POOL_CLEARED,\n  CONNECTION_POOL_CLOSED,\n  CONNECTION_CREATED,\n  CONNECTION_READY,\n  CONNECTION_CLOSED,\n  CONNECTION_CHECK_OUT_STARTED,\n  CONNECTION_CHECK_OUT_FAILED,\n  CONNECTION_CHECKED_OUT,\n  CONNECTION_CHECKED_IN\n] as const);\n\n/** @public */\nexport const TOPOLOGY_EVENTS = Object.freeze([\n  SERVER_OPENING,\n  SERVER_CLOSED,\n  SERVER_DESCRIPTION_CHANGED,\n  TOPOLOGY_OPENING,\n  TOPOLOGY_CLOSED,\n  TOPOLOGY_DESCRIPTION_CHANGED,\n  ERROR,\n  TIMEOUT,\n  CLOSE\n] as const);\n\n/** @public */\nexport const APM_EVENTS = Object.freeze([\n  COMMAND_STARTED,\n  COMMAND_SUCCEEDED,\n  COMMAND_FAILED\n] as const);\n\n/**\n * All events that we relay to the `Topology`\n * @internal\n */\nexport const SERVER_RELAY_EVENTS = Object.freeze([\n  SERVER_HEARTBEAT_STARTED,\n  SERVER_HEARTBEAT_SUCCEEDED,\n  SERVER_HEARTBEAT_FAILED,\n  COMMAND_STARTED,\n  COMMAND_SUCCEEDED,\n  COMMAND_FAILED,\n  ...CMAP_EVENTS\n] as const);\n\n/**\n * All events we listen to from `Server` instances, but do not forward to the client\n * @internal\n */\nexport const LOCAL_SERVER_EVENTS = Object.freeze([\n  CONNECT,\n  DESCRIPTION_RECEIVED,\n  CLOSED,\n  ENDED\n] as const);\n\n/** @public */\nexport const MONGO_CLIENT_EVENTS = Object.freeze([\n  ...CMAP_EVENTS,\n  ...APM_EVENTS,\n  ...TOPOLOGY_EVENTS,\n  ...HEARTBEAT_EVENTS\n] as const);\n\n/**\n * @internal\n * The legacy hello command that was deprecated in MongoDB 5.0.\n */\nexport const LEGACY_HELLO_COMMAND = 'ismaster';\n\n/**\n * @internal\n * The legacy hello command that was deprecated in MongoDB 5.0.\n */\nexport const LEGACY_HELLO_COMMAND_CAMEL_CASE = 'isMaster';\n\n// Typescript errors if we index objects with `Symbol.for(...)`, so\n// to avoid TS errors we pull them out into variables.  Then we can type\n// the objects (and class) that we expect to see them on and prevent TS\n// errors.\n/** @internal */\nexport const kDecorateResult = Symbol.for('@@mdb.decorateDecryptionResult');\n/** @internal */\nexport const kDecoratedKeys = Symbol.for('@@mdb.decryptedKeys');\n"],"names":[],"mappings":";;;;;;AAAa,QAAA,2BAA2B,GAAG;AAC9B,QAAA,uBAAuB,GAAG;AAC1B,QAAA,yBAAyB,GAAG;AAC5B,QAAA,sBAAsB,GAAG;AACzB,QAAA,yBAAyB,GAAG;AAC5B,QAAA,oBAAoB,GAAG;AAEpC,SAAS;AACI,QAAA,KAAK,GAAG;AACR,QAAA,OAAO,GAAG;AACV,QAAA,KAAK,GAAG;AACR,QAAA,IAAI,GAAG;AACP,QAAA,OAAO,GAAG;AACV,QAAA,MAAM,GAAG;AACT,QAAA,KAAK,GAAG;AACR,QAAA,OAAO,GAAG;AACV,QAAA,MAAM,GAAG;AACT,QAAA,QAAQ,GAAG;AACX,QAAA,oBAAoB,GAAG;AACpC,cAAA,GACa,QAAA,cAAc,GAAG;AAC9B,cAAA,GACa,QAAA,aAAa,GAAG;AAC7B,cAAA,GACa,QAAA,0BAA0B,GAAG;AAC1C,cAAA,GACa,QAAA,gBAAgB,GAAG;AAChC,cAAA,GACa,QAAA,eAAe,GAAG;AAC/B,cAAA,GACa,QAAA,4BAA4B,GAAG;AAC5C,cAAA,GACa,QAAA,wBAAwB,GAAG;AACxC,cAAA,GACa,QAAA,uBAAuB,GAAG;AACvC,cAAA,GACa,QAAA,0BAA0B,GAAG;AAC1C,cAAA,GACa,QAAA,2BAA2B,GAAG;AAC3C,cAAA,GACa,QAAA,uBAAuB,GAAG;AACvC,cAAA,GACa,QAAA,sBAAsB,GAAG;AACtC,cAAA,GACa,QAAA,uBAAuB,GAAG;AACvC,cAAA,GACa,QAAA,qBAAqB,GAAG;AACrC,cAAA,GACa,QAAA,kBAAkB,GAAG;AAClC,cAAA,GACa,QAAA,gBAAgB,GAAG;AAChC,cAAA,GACa,QAAA,iBAAiB,GAAG;AACjC,cAAA,GACa,QAAA,4BAA4B,GAAG;AAC5C,cAAA,GACa,QAAA,2BAA2B,GAAG;AAC3C,cAAA,GACa,QAAA,sBAAsB,GAAG;AACtC,cAAA,GACa,QAAA,qBAAqB,GAAG;AACxB,QAAA,qBAAqB,GAAG;AACrC,cAAA,GACa,QAAA,eAAe,GAAG;AAC/B,cAAA,GACa,QAAA,iBAAiB,GAAG;AACjC,cAAA,GACa,QAAA,cAAc,GAAG;AAC9B,cAAA,GACa,QAAA,wBAAwB,GAAG;AACxC,cAAA,GACa,QAAA,0BAA0B,GAAG;AAC1C,cAAA,GACa,QAAA,uBAAuB,GAAG;AAC1B,QAAA,QAAQ,GAAG;AACX,QAAA,IAAI,GAAG;AACP,QAAA,IAAI,GAAG;AACP,QAAA,MAAM,GAAG;AACT,QAAA,GAAG,GAAG;AACN,QAAA,oBAAoB,GAAG;AAEpC,YAAA,GACa,QAAA,gBAAgB,GAAG,OAAO,MAAM,CAAC;IAC5C,QAAA,wBAAwB;IACxB,QAAA,0BAA0B;IAC1B,QAAA,uBAAuB;CACf;AAEV,YAAA,GACa,QAAA,WAAW,GAAG,OAAO,MAAM,CAAC;IACvC,QAAA,uBAAuB;IACvB,QAAA,qBAAqB;IACrB,QAAA,uBAAuB;IACvB,QAAA,sBAAsB;IACtB,QAAA,kBAAkB;IAClB,QAAA,gBAAgB;IAChB,QAAA,iBAAiB;IACjB,QAAA,4BAA4B;IAC5B,QAAA,2BAA2B;IAC3B,QAAA,sBAAsB;IACtB,QAAA,qBAAqB;CACb;AAEV,YAAA,GACa,QAAA,eAAe,GAAG,OAAO,MAAM,CAAC;IAC3C,QAAA,cAAc;IACd,QAAA,aAAa;IACb,QAAA,0BAA0B;IAC1B,QAAA,gBAAgB;IAChB,QAAA,eAAe;IACf,QAAA,4BAA4B;IAC5B,QAAA,KAAK;IACL,QAAA,OAAO;IACP,QAAA,KAAK;CACG;AAEV,YAAA,GACa,QAAA,UAAU,GAAG,OAAO,MAAM,CAAC;IACtC,QAAA,eAAe;IACf,QAAA,iBAAiB;IACjB,QAAA,cAAc;CACN;AAEV;;;IAIa,QAAA,mBAAmB,GAAG,OAAO,MAAM,CAAC;IAC/C,QAAA,wBAAwB;IACxB,QAAA,0BAA0B;IAC1B,QAAA,uBAAuB;IACvB,QAAA,eAAe;IACf,QAAA,iBAAiB;IACjB,QAAA,cAAc;OACX,QAAA,WAAW;CACN;AAEV;;;IAIa,QAAA,mBAAmB,GAAG,OAAO,MAAM,CAAC;IAC/C,QAAA,OAAO;IACP,QAAA,oBAAoB;IACpB,QAAA,MAAM;IACN,QAAA,KAAK;CACG;AAEV,YAAA,GACa,QAAA,mBAAmB,GAAG,OAAO,MAAM,CAAC;OAC5C,QAAA,WAAW;OACX,QAAA,UAAU;OACV,QAAA,eAAe;OACf,QAAA,gBAAgB;CACX;AAEV;;;IAIa,QAAA,oBAAoB,GAAG;AAEpC;;;IAIa,QAAA,+BAA+B,GAAG;AAE/C,mEAAmE;AACnE,wEAAwE;AACxE,uEAAuE;AACvE,UAAU;AACV,cAAA,GACa,QAAA,eAAe,GAAG,OAAO,GAAG,CAAC;AAC1C,cAAA,GACa,QAAA,cAAc,GAAG,OAAO,GAAG,CAAC"}},
    {"offset": {"line": 1807, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1811, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/read_concern.ts"],"sourcesContent":["import type { Document } from './bson';\n\n/** @public */\nexport const ReadConcernLevel = Object.freeze({\n  local: 'local',\n  majority: 'majority',\n  linearizable: 'linearizable',\n  available: 'available',\n  snapshot: 'snapshot'\n} as const);\n\n/** @public */\nexport type ReadConcernLevel = (typeof ReadConcernLevel)[keyof typeof ReadConcernLevel];\n\n/** @public */\nexport type ReadConcernLike = ReadConcern | { level: ReadConcernLevel } | ReadConcernLevel;\n\n/**\n * The MongoDB ReadConcern, which allows for control of the consistency and isolation properties\n * of the data read from replica sets and replica set shards.\n * @public\n *\n * @see https://www.mongodb.com/docs/manual/reference/read-concern/index.html\n */\nexport class ReadConcern {\n  level: ReadConcernLevel | string;\n\n  /** Constructs a ReadConcern from the read concern level.*/\n  constructor(level: ReadConcernLevel) {\n    /**\n     * A spec test exists that allows level to be any string.\n     * \"invalid readConcern with out stage\"\n     * @see ./test/spec/crud/v2/aggregate-out-readConcern.json\n     * @see https://github.com/mongodb/specifications/blob/master/source/read-write-concern/read-write-concern.md#unknown-levels-and-additional-options-for-string-based-readconcerns\n     */\n    this.level = ReadConcernLevel[level] ?? level;\n  }\n\n  /**\n   * Construct a ReadConcern given an options object.\n   *\n   * @param options - The options object from which to extract the write concern.\n   */\n  static fromOptions(options?: {\n    readConcern?: ReadConcernLike;\n    level?: ReadConcernLevel;\n  }): ReadConcern | undefined {\n    if (options == null) {\n      return;\n    }\n\n    if (options.readConcern) {\n      const { readConcern } = options;\n      if (readConcern instanceof ReadConcern) {\n        return readConcern;\n      } else if (typeof readConcern === 'string') {\n        return new ReadConcern(readConcern);\n      } else if ('level' in readConcern && readConcern.level) {\n        return new ReadConcern(readConcern.level);\n      }\n    }\n\n    if (options.level) {\n      return new ReadConcern(options.level);\n    }\n    return;\n  }\n\n  static get MAJORITY(): 'majority' {\n    return ReadConcernLevel.majority;\n  }\n\n  static get AVAILABLE(): 'available' {\n    return ReadConcernLevel.available;\n  }\n\n  static get LINEARIZABLE(): 'linearizable' {\n    return ReadConcernLevel.linearizable;\n  }\n\n  static get SNAPSHOT(): 'snapshot' {\n    return ReadConcernLevel.snapshot;\n  }\n\n  toJSON(): Document {\n    return { level: this.level };\n  }\n}\n"],"names":[],"mappings":";;;;;AAEA,YAAA,GACa,QAAA,gBAAgB,GAAG,OAAO,MAAM,CAAC;IAC5C,OAAO;IACP,UAAU;IACV,cAAc;IACd,WAAW;IACX,UAAU;;AASZ;;;;;;IAOA,MAAa;IAGX,yDAAA,GACA,YAAY,KAAuB,CAAA;QACjC;;;;;YAMA,IAAI,CAAC,KAAK,GAAG,QAAA,gBAAgB,CAAC,MAAM,IAAI;IAC1C;IAEA;;;;QAKA,OAAO,YAAY,OAGlB,EAAA;QACC,IAAI,WAAW,MAAM;YACnB;QACF;QAEA,IAAI,QAAQ,WAAW,EAAE;YACvB,MAAM,EAAE,WAAW,EAAE,GAAG;YACxB,IAAI,uBAAuB,aAAa;gBACtC,OAAO;YACT,OAAO,IAAI,OAAO,gBAAgB,UAAU;gBAC1C,OAAO,IAAI,YAAY;YACzB,OAAO,IAAI,WAAW,eAAe,YAAY,KAAK,EAAE;gBACtD,OAAO,IAAI,YAAY,YAAY,KAAK;YAC1C;QACF;QAEA,IAAI,QAAQ,KAAK,EAAE;YACjB,OAAO,IAAI,YAAY,QAAQ,KAAK;QACtC;QACA;IACF;IAEA,WAAW,WAAQ;QACjB,OAAO,QAAA,gBAAgB,CAAC,QAAQ;IAClC;IAEA,WAAW,YAAS;QAClB,OAAO,QAAA,gBAAgB,CAAC,SAAS;IACnC;IAEA,WAAW,eAAY;QACrB,OAAO,QAAA,gBAAgB,CAAC,YAAY;IACtC;IAEA,WAAW,WAAQ;QACjB,OAAO,QAAA,gBAAgB,CAAC,QAAQ;IAClC;IAEA,SAAM;QACJ,OAAO;YAAE,OAAO,IAAI,CAAC,KAAK;QAAA;IAC5B;;AA9DF,QAAA,WAAA,GAAA"}},
    {"offset": {"line": 1880, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1884, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/write_concern.ts"],"sourcesContent":["import { type Document } from './bson';\nimport { MongoDBResponse } from './cmap/wire_protocol/responses';\nimport { MongoWriteConcernError } from './error';\n\n/** @public */\nexport type W = number | 'majority';\n\n/** @public */\nexport interface WriteConcernOptions {\n  /** Write Concern as an object */\n  writeConcern?: WriteConcern | WriteConcernSettings;\n}\n\n/** @public */\nexport interface WriteConcernSettings {\n  /** The write concern */\n  w?: W;\n  /**\n   * The write concern timeout.\n   */\n  wtimeoutMS?: number;\n  /** The journal write concern */\n  journal?: boolean;\n\n  // legacy options\n  /**\n   * The journal write concern.\n   * @deprecated Will be removed in the next major version. Please use the journal option.\n   */\n  j?: boolean;\n  /**\n   * The write concern timeout.\n   */\n  wtimeout?: number;\n  /**\n   * The file sync write concern.\n   * @deprecated Will be removed in the next major version. Please use the journal option.\n   */\n  fsync?: boolean | 1;\n}\n\nexport const WRITE_CONCERN_KEYS = ['w', 'wtimeout', 'j', 'journal', 'fsync'];\n\n/** The write concern options that decorate the server command. */\ninterface CommandWriteConcernOptions {\n  /** The write concern */\n  w?: W;\n  /** The journal write concern. */\n  j?: boolean;\n  /** The write concern timeout. */\n  wtimeout?: number;\n}\n\n/**\n * A MongoDB WriteConcern, which describes the level of acknowledgement\n * requested from MongoDB for write operations.\n * @public\n *\n * @see https://www.mongodb.com/docs/manual/reference/write-concern/\n */\nexport class WriteConcern {\n  /**\n   * Request acknowledgment that the write operation has propagated to a specified number of mongod instances or to mongod instances with specified tags.\n   * If w is 0 and is set on a write operation, the server will not send a response.\n   */\n  readonly w?: W;\n  /** Request acknowledgment that the write operation has been written to the on-disk journal */\n  readonly journal?: boolean;\n  /**\n   * Specify a time limit to prevent write operations from blocking indefinitely.\n   */\n  readonly wtimeoutMS?: number;\n  /**\n   * Specify a time limit to prevent write operations from blocking indefinitely.\n   * @deprecated Will be removed in the next major version. Please use wtimeoutMS.\n   */\n  wtimeout?: number;\n  /**\n   * Request acknowledgment that the write operation has been written to the on-disk journal.\n   * @deprecated Will be removed in the next major version. Please use journal.\n   */\n  j?: boolean;\n  /**\n   * Equivalent to the j option.\n   * @deprecated Will be removed in the next major version. Please use journal.\n   */\n  fsync?: boolean | 1;\n\n  /**\n   * Constructs a WriteConcern from the write concern properties.\n   * @param w - request acknowledgment that the write operation has propagated to a specified number of mongod instances or to mongod instances with specified tags.\n   * @param wtimeoutMS - specify a time limit to prevent write operations from blocking indefinitely\n   * @param journal - request acknowledgment that the write operation has been written to the on-disk journal\n   * @param fsync - equivalent to the j option. Is deprecated and will be removed in the next major version.\n   */\n  constructor(w?: W, wtimeoutMS?: number, journal?: boolean, fsync?: boolean | 1) {\n    if (w != null) {\n      if (!Number.isNaN(Number(w))) {\n        this.w = Number(w);\n      } else {\n        this.w = w;\n      }\n    }\n    if (wtimeoutMS != null) {\n      this.wtimeoutMS = this.wtimeout = wtimeoutMS;\n    }\n    if (journal != null) {\n      this.journal = this.j = journal;\n    }\n    if (fsync != null) {\n      this.journal = this.j = fsync ? true : false;\n    }\n  }\n\n  /**\n   * Apply a write concern to a command document. Will modify and return the command.\n   */\n  static apply(command: Document, writeConcern: WriteConcern): Document {\n    const wc: CommandWriteConcernOptions = {};\n    // The write concern document sent to the server has w/wtimeout/j fields.\n    if (writeConcern.w != null) wc.w = writeConcern.w;\n    if (writeConcern.wtimeoutMS != null) wc.wtimeout = writeConcern.wtimeoutMS;\n    if (writeConcern.journal != null) wc.j = writeConcern.j;\n    command.writeConcern = wc;\n    return command;\n  }\n\n  /** Construct a WriteConcern given an options object. */\n  static fromOptions(\n    options?: WriteConcernOptions | WriteConcern | W,\n    inherit?: WriteConcernOptions | WriteConcern\n  ): WriteConcern | undefined {\n    if (options == null) return undefined;\n    inherit = inherit ?? {};\n    let opts: WriteConcernSettings | WriteConcern | undefined;\n    if (typeof options === 'string' || typeof options === 'number') {\n      opts = { w: options };\n    } else if (options instanceof WriteConcern) {\n      opts = options;\n    } else {\n      opts = options.writeConcern;\n    }\n    const parentOpts: WriteConcern | WriteConcernSettings | undefined =\n      inherit instanceof WriteConcern ? inherit : inherit.writeConcern;\n\n    const {\n      w = undefined,\n      wtimeout = undefined,\n      j = undefined,\n      fsync = undefined,\n      journal = undefined,\n      wtimeoutMS = undefined\n    } = {\n      ...parentOpts,\n      ...opts\n    };\n    if (\n      w != null ||\n      wtimeout != null ||\n      wtimeoutMS != null ||\n      j != null ||\n      journal != null ||\n      fsync != null\n    ) {\n      return new WriteConcern(w, wtimeout ?? wtimeoutMS, j ?? journal, fsync);\n    }\n    return undefined;\n  }\n}\n\n/** Called with either a plain object or MongoDBResponse */\nexport function throwIfWriteConcernError(response: unknown): void {\n  if (typeof response === 'object' && response != null) {\n    const writeConcernError: object | null =\n      MongoDBResponse.is(response) && response.has('writeConcernError')\n        ? response.toObject()\n        : !MongoDBResponse.is(response) && 'writeConcernError' in response\n          ? response\n          : null;\n\n    if (writeConcernError != null) {\n      throw new MongoWriteConcernError(writeConcernError as any);\n    }\n  }\n}\n"],"names":[],"mappings":";;;;;AA2KA,QAAA,wBAAA,GAAA;AA1KA,MAAA;AACA,MAAA;AAuCa,QAAA,kBAAkB,GAAG;IAAC;IAAK;IAAY;IAAK;IAAW;CAAQ;AAY5E;;;;;;IAOA,MAAa;IA4BX;;;;;;QAOA,YAAY,CAAK,EAAE,UAAmB,EAAE,OAAiB,EAAE,KAAmB,CAAA;QAC5E,IAAI,KAAK,MAAM;YACb,IAAI,CAAC,OAAO,KAAK,CAAC,OAAO,KAAK;gBAC5B,IAAI,CAAC,CAAC,GAAG,OAAO;YAClB,OAAO;gBACL,IAAI,CAAC,CAAC,GAAG;YACX;QACF;QACA,IAAI,cAAc,MAAM;YACtB,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,QAAQ,GAAG;QACpC;QACA,IAAI,WAAW,MAAM;YACnB,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,CAAC,GAAG;QAC1B;QACA,IAAI,SAAS,MAAM;YACjB,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,CAAC,GAAG,QAAQ,OAAO;QACzC;IACF;IAEA;;QAGA,OAAO,MAAM,OAAiB,EAAE,YAA0B,EAAA;QACxD,MAAM,KAAiC,CAAA;QACvC,yEAAyE;QACzE,IAAI,aAAa,CAAC,IAAI,MAAM,GAAG,CAAC,GAAG,aAAa,CAAC;QACjD,IAAI,aAAa,UAAU,IAAI,MAAM,GAAG,QAAQ,GAAG,aAAa,UAAU;QAC1E,IAAI,aAAa,OAAO,IAAI,MAAM,GAAG,CAAC,GAAG,aAAa,CAAC;QACvD,QAAQ,YAAY,GAAG;QACvB,OAAO;IACT;IAEA,sDAAA,GACA,OAAO,YACL,OAAgD,EAChD,OAA4C,EAAA;QAE5C,IAAI,WAAW,MAAM,OAAO;QAC5B,UAAU,WAAW,CAAA;QACrB,IAAI;QACJ,IAAI,OAAO,YAAY,YAAY,OAAO,YAAY,UAAU;YAC9D,OAAO;gBAAE,GAAG;YAAO;QACrB,OAAO,IAAI,mBAAmB,cAAc;YAC1C,OAAO;QACT,OAAO;YACL,OAAO,QAAQ,YAAY;QAC7B;QACA,MAAM,aACJ,mBAAmB,eAAe,UAAU,QAAQ,YAAY;QAElE,MAAM,EACJ,IAAI,SAAS,EACb,WAAW,SAAS,EACpB,IAAI,SAAS,EACb,QAAQ,SAAS,EACjB,UAAU,SAAS,EACnB,aAAa,SAAS,EACvB,GAAG;YACF,GAAG,UAAU;YACb,GAAG,IAAI;;QAET,IACE,KAAK,QACL,YAAY,QACZ,cAAc,QACd,KAAK,QACL,WAAW,QACX,SAAS,MACT;YACA,OAAO,IAAI,aAAa,GAAG,YAAY,YAAY,KAAK,SAAS;QACnE;QACA,OAAO;IACT;;AA3GF,QAAA,YAAA,GAAA;AA8GA,yDAAA,GACA,SAAgB,yBAAyB,QAAiB;IACxD,IAAI,OAAO,aAAa,YAAY,YAAY,MAAM;QACpD,MAAM,oBACJ,YAAA,eAAe,CAAC,EAAE,CAAC,aAAa,SAAS,GAAG,CAAC,uBACzC,SAAS,QAAQ,KACjB,CAAC,YAAA,eAAe,CAAC,EAAE,CAAC,aAAa,uBAAuB,WACtD,WACA;QAER,IAAI,qBAAqB,MAAM;YAC7B,MAAM,IAAI,QAAA,sBAAsB,CAAC;QACnC;IACF;AACF"}},
    {"offset": {"line": 1974, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1978, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/utils.ts"],"sourcesContent":["import * as crypto from 'crypto';\nimport type { SrvRecord } from 'dns';\nimport { type EventEmitter } from 'events';\nimport { promises as fs } from 'fs';\nimport * as http from 'http';\nimport { clearTimeout, setTimeout } from 'timers';\nimport * as url from 'url';\nimport { URL } from 'url';\nimport { promisify } from 'util';\n\nimport { deserialize, type Document, ObjectId, resolveBSONOptions } from './bson';\nimport type { Connection } from './cmap/connection';\nimport { MAX_SUPPORTED_WIRE_VERSION } from './cmap/wire_protocol/constants';\nimport type { Collection } from './collection';\nimport { kDecoratedKeys, LEGACY_HELLO_COMMAND } from './constants';\nimport type { AbstractCursor } from './cursor/abstract_cursor';\nimport type { FindCursor } from './cursor/find_cursor';\nimport type { Db } from './db';\nimport {\n  type AnyError,\n  MongoAPIError,\n  MongoCompatibilityError,\n  MongoInvalidArgumentError,\n  MongoNetworkTimeoutError,\n  MongoNotConnectedError,\n  MongoParseError,\n  MongoRuntimeError\n} from './error';\nimport type { MongoClient } from './mongo_client';\nimport { type Abortable } from './mongo_types';\nimport type { CommandOperationOptions, OperationParent } from './operations/command';\nimport type { Hint, OperationOptions } from './operations/operation';\nimport { ReadConcern } from './read_concern';\nimport { ReadPreference } from './read_preference';\nimport { ServerType } from './sdam/common';\nimport type { Server } from './sdam/server';\nimport type { Topology } from './sdam/topology';\nimport type { ClientSession } from './sessions';\nimport { type TimeoutContextOptions } from './timeout';\nimport { WriteConcern } from './write_concern';\n\n/**\n * MongoDB Driver style callback\n * @public\n */\nexport type Callback<T = any> = (error?: AnyError, result?: T) => void;\n\nexport type AnyOptions = Document;\n\nexport const ByteUtils = {\n  toLocalBufferType(this: void, buffer: Buffer | Uint8Array): Buffer {\n    return Buffer.isBuffer(buffer)\n      ? buffer\n      : Buffer.from(buffer.buffer, buffer.byteOffset, buffer.byteLength);\n  },\n\n  equals(this: void, seqA: Uint8Array, seqB: Uint8Array) {\n    return ByteUtils.toLocalBufferType(seqA).equals(seqB);\n  },\n\n  compare(this: void, seqA: Uint8Array, seqB: Uint8Array) {\n    return ByteUtils.toLocalBufferType(seqA).compare(seqB);\n  },\n\n  toBase64(this: void, uint8array: Uint8Array) {\n    return ByteUtils.toLocalBufferType(uint8array).toString('base64');\n  }\n};\n\n/**\n * Returns true if value is a Uint8Array or a Buffer\n * @param value - any value that may be a Uint8Array\n */\nexport function isUint8Array(value: unknown): value is Uint8Array {\n  return (\n    value != null &&\n    typeof value === 'object' &&\n    Symbol.toStringTag in value &&\n    value[Symbol.toStringTag] === 'Uint8Array'\n  );\n}\n\n/**\n * Determines if a connection's address matches a user provided list\n * of domain wildcards.\n */\nexport function hostMatchesWildcards(host: string, wildcards: string[]): boolean {\n  for (const wildcard of wildcards) {\n    if (\n      host === wildcard ||\n      (wildcard.startsWith('*.') && host?.endsWith(wildcard.substring(2, wildcard.length))) ||\n      (wildcard.startsWith('*/') && host?.endsWith(wildcard.substring(2, wildcard.length)))\n    ) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Ensure Hint field is in a shape we expect:\n * - object of index names mapping to 1 or -1\n * - just an index name\n * @internal\n */\nexport function normalizeHintField(hint?: Hint): Hint | undefined {\n  let finalHint = undefined;\n\n  if (typeof hint === 'string') {\n    finalHint = hint;\n  } else if (Array.isArray(hint)) {\n    finalHint = {};\n\n    hint.forEach(param => {\n      finalHint[param] = 1;\n    });\n  } else if (hint != null && typeof hint === 'object') {\n    finalHint = {} as Document;\n    for (const name in hint) {\n      finalHint[name] = hint[name];\n    }\n  }\n\n  return finalHint;\n}\n\nconst TO_STRING = (object: unknown) => Object.prototype.toString.call(object);\n/**\n * Checks if arg is an Object:\n * - **NOTE**: the check is based on the `[Symbol.toStringTag]() === 'Object'`\n * @internal\n */\n\nexport function isObject(arg: unknown): arg is object {\n  return '[object Object]' === TO_STRING(arg);\n}\n\n/** @internal */\nexport function mergeOptions<T, S>(target: T, source: S): T & S {\n  return { ...target, ...source };\n}\n\n/** @internal */\nexport function filterOptions(options: AnyOptions, names: ReadonlyArray<string>): AnyOptions {\n  const filterOptions: AnyOptions = {};\n\n  for (const name in options) {\n    if (names.includes(name)) {\n      filterOptions[name] = options[name];\n    }\n  }\n\n  // Filtered options\n  return filterOptions;\n}\n\ninterface HasRetryableWrites {\n  retryWrites?: boolean;\n}\n/**\n * Applies retryWrites: true to a command if retryWrites is set on the command's database.\n * @internal\n *\n * @param target - The target command to which we will apply retryWrites.\n * @param db - The database from which we can inherit a retryWrites value.\n */\nexport function applyRetryableWrites<T extends HasRetryableWrites>(target: T, db?: Db): T {\n  if (db && db.s.options?.retryWrites) {\n    target.retryWrites = true;\n  }\n\n  return target;\n}\n\n/**\n * Applies a write concern to a command based on well defined inheritance rules, optionally\n * detecting support for the write concern in the first place.\n * @internal\n *\n * @param target - the target command we will be applying the write concern to\n * @param sources - sources where we can inherit default write concerns from\n * @param options - optional settings passed into a command for write concern overrides\n */\n\n/**\n * Checks if a given value is a Promise\n *\n * @typeParam T - The resolution type of the possible promise\n * @param value - An object that could be a promise\n * @returns true if the provided value is a Promise\n */\nexport function isPromiseLike<T = unknown>(value?: unknown): value is PromiseLike<T> {\n  return (\n    value != null &&\n    typeof value === 'object' &&\n    'then' in value &&\n    typeof value.then === 'function'\n  );\n}\n\n/**\n * Applies collation to a given command.\n * @internal\n *\n * @param command - the command on which to apply collation\n * @param target - target of command\n * @param options - options containing collation settings\n */\nexport function decorateWithCollation(\n  command: Document,\n  target: MongoClient | Db | Collection,\n  options: AnyOptions\n): void {\n  const capabilities = getTopology(target).capabilities;\n  if (options.collation && typeof options.collation === 'object') {\n    if (capabilities && capabilities.commandsTakeCollation) {\n      command.collation = options.collation;\n    } else {\n      throw new MongoCompatibilityError(`Current topology does not support collation`);\n    }\n  }\n}\n\n/**\n * Applies a read concern to a given command.\n * @internal\n *\n * @param command - the command on which to apply the read concern\n * @param coll - the parent collection of the operation calling this method\n */\nexport function decorateWithReadConcern(\n  command: Document,\n  coll: { s: { readConcern?: ReadConcern } },\n  options?: OperationOptions\n): void {\n  if (options && options.session && options.session.inTransaction()) {\n    return;\n  }\n  const readConcern = Object.assign({}, command.readConcern || {});\n  if (coll.s.readConcern) {\n    Object.assign(readConcern, coll.s.readConcern);\n  }\n\n  if (Object.keys(readConcern).length > 0) {\n    Object.assign(command, { readConcern: readConcern });\n  }\n}\n\n/**\n * @internal\n */\nexport type TopologyProvider =\n  | MongoClient\n  | ClientSession\n  | FindCursor\n  | AbstractCursor\n  | Collection<any>\n  | Db;\n\n/**\n * A helper function to get the topology from a given provider. Throws\n * if the topology cannot be found.\n * @throws MongoNotConnectedError\n * @internal\n */\nexport function getTopology(provider: TopologyProvider): Topology {\n  // MongoClient or ClientSession or AbstractCursor\n  if ('topology' in provider && provider.topology) {\n    return provider.topology;\n  } else if ('client' in provider && provider.client.topology) {\n    return provider.client.topology;\n  }\n\n  throw new MongoNotConnectedError('MongoClient must be connected to perform this operation');\n}\n\n/** @internal */\nexport function ns(ns: string): MongoDBNamespace {\n  return MongoDBNamespace.fromString(ns);\n}\n\n/** @public */\nexport class MongoDBNamespace {\n  /**\n   * Create a namespace object\n   *\n   * @param db - database name\n   * @param collection - collection name\n   */\n  constructor(\n    public db: string,\n    public collection?: string\n  ) {\n    this.collection = collection === '' ? undefined : collection;\n  }\n\n  toString(): string {\n    return this.collection ? `${this.db}.${this.collection}` : this.db;\n  }\n\n  withCollection(collection: string): MongoDBCollectionNamespace {\n    return new MongoDBCollectionNamespace(this.db, collection);\n  }\n\n  static fromString(namespace?: string): MongoDBNamespace {\n    if (typeof namespace !== 'string' || namespace === '') {\n      // TODO(NODE-3483): Replace with MongoNamespaceError\n      throw new MongoRuntimeError(`Cannot parse namespace from \"${namespace}\"`);\n    }\n\n    const [db, ...collectionParts] = namespace.split('.');\n    const collection = collectionParts.join('.');\n    return new MongoDBNamespace(db, collection === '' ? undefined : collection);\n  }\n}\n\n/**\n * @public\n *\n * A class representing a collection's namespace.  This class enforces (through Typescript) that\n * the `collection` portion of the namespace is defined and should only be\n * used in scenarios where this can be guaranteed.\n */\nexport class MongoDBCollectionNamespace extends MongoDBNamespace {\n  constructor(\n    db: string,\n    override collection: string\n  ) {\n    super(db, collection);\n  }\n\n  static override fromString(namespace?: string): MongoDBCollectionNamespace {\n    return super.fromString(namespace) as MongoDBCollectionNamespace;\n  }\n}\n\n/** @internal */\nexport function* makeCounter(seed = 0): Generator<number> {\n  let count = seed;\n  while (true) {\n    const newCount = count;\n    count += 1;\n    yield newCount;\n  }\n}\n\n/**\n * Synchronously Generate a UUIDv4\n * @internal\n */\nexport function uuidV4(): Buffer {\n  const result = crypto.randomBytes(16);\n  result[6] = (result[6] & 0x0f) | 0x40;\n  result[8] = (result[8] & 0x3f) | 0x80;\n  return result;\n}\n\n/**\n * A helper function for determining `maxWireVersion` between legacy and new topology instances\n * @internal\n */\nexport function maxWireVersion(topologyOrServer?: Connection | Topology | Server): number {\n  if (topologyOrServer) {\n    if (topologyOrServer.loadBalanced || topologyOrServer.serverApi?.version) {\n      // Since we do not have a monitor in the load balanced mode,\n      // we assume the load-balanced server is always pointed at the latest mongodb version.\n      // There is a risk that for on-prem deployments\n      // that don't upgrade immediately that this could alert to the\n      // application that a feature is available that is actually not.\n      // We also return the max supported wire version for serverAPI.\n      return MAX_SUPPORTED_WIRE_VERSION;\n    }\n    if (topologyOrServer.hello) {\n      return topologyOrServer.hello.maxWireVersion;\n    }\n\n    if ('lastHello' in topologyOrServer && typeof topologyOrServer.lastHello === 'function') {\n      const lastHello = topologyOrServer.lastHello();\n      if (lastHello) {\n        return lastHello.maxWireVersion;\n      }\n    }\n\n    if (\n      topologyOrServer.description &&\n      'maxWireVersion' in topologyOrServer.description &&\n      topologyOrServer.description.maxWireVersion != null\n    ) {\n      return topologyOrServer.description.maxWireVersion;\n    }\n  }\n\n  return 0;\n}\n\n/** @internal */\nexport function arrayStrictEqual(arr: unknown[], arr2: unknown[]): boolean {\n  if (!Array.isArray(arr) || !Array.isArray(arr2)) {\n    return false;\n  }\n\n  return arr.length === arr2.length && arr.every((elt, idx) => elt === arr2[idx]);\n}\n\n/** @internal */\nexport function errorStrictEqual(lhs?: AnyError | null, rhs?: AnyError | null): boolean {\n  if (lhs === rhs) {\n    return true;\n  }\n\n  if (!lhs || !rhs) {\n    return lhs === rhs;\n  }\n\n  if ((lhs == null && rhs != null) || (lhs != null && rhs == null)) {\n    return false;\n  }\n\n  if (lhs.constructor.name !== rhs.constructor.name) {\n    return false;\n  }\n\n  if (lhs.message !== rhs.message) {\n    return false;\n  }\n\n  return true;\n}\n\ninterface StateTable {\n  [key: string]: string[];\n}\ninterface ObjectWithState {\n  s: { state: string };\n  emit(event: 'stateChanged', state: string, newState: string): void;\n}\ninterface StateTransitionFunction {\n  (target: ObjectWithState, newState: string): void;\n}\n\n/** @public */\nexport type EventEmitterWithState = {\n  /** @internal */\n  stateChanged(previous: string, current: string): void;\n};\n\n/** @internal */\nexport function makeStateMachine(stateTable: StateTable): StateTransitionFunction {\n  return function stateTransition(target, newState) {\n    const legalStates = stateTable[target.s.state];\n    if (legalStates && legalStates.indexOf(newState) < 0) {\n      throw new MongoRuntimeError(\n        `illegal state transition from [${target.s.state}] => [${newState}], allowed: [${legalStates}]`\n      );\n    }\n\n    target.emit('stateChanged', target.s.state, newState);\n    target.s.state = newState;\n  };\n}\n\n/** @internal */\nexport function now(): number {\n  const hrtime = process.hrtime();\n  return Math.floor(hrtime[0] * 1000 + hrtime[1] / 1000000);\n}\n\n/** @internal */\nexport function calculateDurationInMs(started: number | undefined): number {\n  if (typeof started !== 'number') {\n    return -1;\n  }\n\n  const elapsed = now() - started;\n  return elapsed < 0 ? 0 : elapsed;\n}\n\n/** @internal */\nexport function hasAtomicOperators(\n  doc: Document | Document[],\n  options?: CommandOperationOptions\n): boolean {\n  if (Array.isArray(doc)) {\n    for (const document of doc) {\n      if (hasAtomicOperators(document)) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  const keys = Object.keys(doc);\n  // In this case we need to throw if all the atomic operators are undefined.\n  if (options?.ignoreUndefined) {\n    let allUndefined = true;\n    for (const key of keys) {\n      // eslint-disable-next-line no-restricted-syntax\n      if (doc[key] !== undefined) {\n        allUndefined = false;\n        break;\n      }\n    }\n    if (allUndefined) {\n      throw new MongoInvalidArgumentError(\n        'Update operations require that all atomic operators have defined values, but none were provided.'\n      );\n    }\n  }\n\n  return keys.length > 0 && keys[0][0] === '$';\n}\n\nexport function resolveTimeoutOptions<T extends Partial<TimeoutContextOptions>>(\n  client: MongoClient,\n  options: T\n): T &\n  Pick<\n    MongoClient['s']['options'],\n    'timeoutMS' | 'serverSelectionTimeoutMS' | 'waitQueueTimeoutMS' | 'socketTimeoutMS'\n  > {\n  const { socketTimeoutMS, serverSelectionTimeoutMS, waitQueueTimeoutMS, timeoutMS } =\n    client.s.options;\n  return { socketTimeoutMS, serverSelectionTimeoutMS, waitQueueTimeoutMS, timeoutMS, ...options };\n}\n/**\n * Merge inherited properties from parent into options, prioritizing values from options,\n * then values from parent.\n *\n * @param parent - An optional owning class of the operation being run. ex. Db/Collection/MongoClient.\n * @param options - The options passed to the operation method.\n *\n * @internal\n */\nexport function resolveOptions<T extends CommandOperationOptions>(\n  parent: OperationParent | undefined,\n  options?: T\n): T {\n  const result: T = Object.assign({}, options, resolveBSONOptions(options, parent));\n\n  const timeoutMS = options?.timeoutMS ?? parent?.timeoutMS;\n  // Users cannot pass a readConcern/writeConcern to operations in a transaction\n  const session = options?.session;\n\n  if (!session?.inTransaction()) {\n    const readConcern = ReadConcern.fromOptions(options) ?? parent?.readConcern;\n    if (readConcern) {\n      result.readConcern = readConcern;\n    }\n\n    let writeConcern = WriteConcern.fromOptions(options) ?? parent?.writeConcern;\n    if (writeConcern) {\n      if (timeoutMS != null) {\n        writeConcern = WriteConcern.fromOptions({\n          writeConcern: {\n            ...writeConcern,\n            wtimeout: undefined,\n            wtimeoutMS: undefined\n          }\n        });\n      }\n      result.writeConcern = writeConcern;\n    }\n  }\n\n  result.timeoutMS = timeoutMS;\n\n  const readPreference = ReadPreference.fromOptions(options) ?? parent?.readPreference;\n  if (readPreference) {\n    result.readPreference = readPreference;\n  }\n\n  const isConvenientTransaction = session?.explicit && session?.timeoutContext != null;\n  if (isConvenientTransaction && options?.timeoutMS != null) {\n    throw new MongoInvalidArgumentError(\n      'An operation cannot be given a timeoutMS setting when inside a withTransaction call that has a timeoutMS setting'\n    );\n  }\n\n  return result;\n}\n\nexport function isSuperset(set: Set<any> | any[], subset: Set<any> | any[]): boolean {\n  set = Array.isArray(set) ? new Set(set) : set;\n  subset = Array.isArray(subset) ? new Set(subset) : subset;\n  for (const elem of subset) {\n    if (!set.has(elem)) {\n      return false;\n    }\n  }\n  return true;\n}\n\n/**\n * Checks if the document is a Hello request\n * @internal\n */\nexport function isHello(doc: Document): boolean {\n  return doc[LEGACY_HELLO_COMMAND] || doc.hello ? true : false;\n}\n\n/** Returns the items that are uniquely in setA */\nexport function setDifference<T>(setA: Iterable<T>, setB: Iterable<T>): Set<T> {\n  const difference = new Set<T>(setA);\n  for (const elem of setB) {\n    difference.delete(elem);\n  }\n  return difference;\n}\n\nconst HAS_OWN = (object: unknown, prop: string) =>\n  Object.prototype.hasOwnProperty.call(object, prop);\n\nexport function isRecord<T extends readonly string[]>(\n  value: unknown,\n  requiredKeys: T\n): value is Record<T[number], any>;\nexport function isRecord(value: unknown): value is Record<string, any>;\nexport function isRecord(\n  value: unknown,\n  requiredKeys: string[] | undefined = undefined\n): value is Record<string, any> {\n  if (!isObject(value)) {\n    return false;\n  }\n\n  const ctor = (value as any).constructor;\n  if (ctor && ctor.prototype) {\n    if (!isObject(ctor.prototype)) {\n      return false;\n    }\n\n    // Check to see if some method exists from the Object exists\n    if (!HAS_OWN(ctor.prototype, 'isPrototypeOf')) {\n      return false;\n    }\n  }\n\n  if (requiredKeys) {\n    const keys = Object.keys(value as Record<string, any>);\n    return isSuperset(keys, requiredKeys);\n  }\n\n  return true;\n}\n\ntype ListNode<T> = {\n  value: T;\n  next: ListNode<T> | HeadNode<T>;\n  prev: ListNode<T> | HeadNode<T>;\n};\n\ntype HeadNode<T> = {\n  value: null;\n  next: ListNode<T>;\n  prev: ListNode<T>;\n};\n\n/**\n * When a list is empty the head is a reference with pointers to itself\n * So this type represents that self referential state\n */\ntype EmptyNode = {\n  value: null;\n  next: EmptyNode;\n  prev: EmptyNode;\n};\n\n/**\n * A sequential list of items in a circularly linked list\n * @remarks\n * The head node is special, it is always defined and has a value of null.\n * It is never \"included\" in the list, in that, it is not returned by pop/shift or yielded by the iterator.\n * The circular linkage and always defined head node are to reduce checks for null next/prev references to zero.\n * New nodes are declared as object literals with keys always in the same order: next, prev, value.\n * @internal\n */\nexport class List<T = unknown> {\n  private readonly head: HeadNode<T> | EmptyNode;\n  private count: number;\n\n  get length() {\n    return this.count;\n  }\n\n  get [Symbol.toStringTag]() {\n    return 'List' as const;\n  }\n\n  constructor() {\n    this.count = 0;\n\n    // this is carefully crafted:\n    // declaring a complete and consistently key ordered\n    // object is beneficial to the runtime optimizations\n    this.head = {\n      next: null,\n      prev: null,\n      value: null\n    } as unknown as EmptyNode;\n    this.head.next = this.head;\n    this.head.prev = this.head;\n  }\n\n  toArray() {\n    return Array.from(this);\n  }\n\n  toString() {\n    return `head <=> ${this.toArray().join(' <=> ')} <=> head`;\n  }\n\n  *[Symbol.iterator](): Generator<T, void, void> {\n    for (const node of this.nodes()) {\n      yield node.value;\n    }\n  }\n\n  private *nodes(): Generator<ListNode<T>, void, void> {\n    let ptr: HeadNode<T> | ListNode<T> | EmptyNode = this.head.next;\n    while (ptr !== this.head) {\n      // Save next before yielding so that we make removing within iteration safe\n      const { next } = ptr as ListNode<T>;\n      yield ptr as ListNode<T>;\n      ptr = next;\n    }\n  }\n\n  /** Insert at end of list */\n  push(value: T) {\n    this.count += 1;\n    const newNode: ListNode<T> = {\n      next: this.head as HeadNode<T>,\n      prev: this.head.prev as ListNode<T>,\n      value\n    };\n    this.head.prev.next = newNode;\n    this.head.prev = newNode;\n  }\n\n  /** Inserts every item inside an iterable instead of the iterable itself */\n  pushMany(iterable: Iterable<T>) {\n    for (const value of iterable) {\n      this.push(value);\n    }\n  }\n\n  /** Insert at front of list */\n  unshift(value: T) {\n    this.count += 1;\n    const newNode: ListNode<T> = {\n      next: this.head.next as ListNode<T>,\n      prev: this.head as HeadNode<T>,\n      value\n    };\n    this.head.next.prev = newNode;\n    this.head.next = newNode;\n  }\n\n  private remove(node: ListNode<T> | EmptyNode): T | null {\n    if (node === this.head || this.length === 0) {\n      return null;\n    }\n\n    this.count -= 1;\n\n    const prevNode = node.prev;\n    const nextNode = node.next;\n    prevNode.next = nextNode;\n    nextNode.prev = prevNode;\n\n    return node.value;\n  }\n\n  /** Removes the first node at the front of the list */\n  shift(): T | null {\n    return this.remove(this.head.next);\n  }\n\n  /** Removes the last node at the end of the list */\n  pop(): T | null {\n    return this.remove(this.head.prev);\n  }\n\n  /** Iterates through the list and removes nodes where filter returns true */\n  prune(filter: (value: T) => boolean) {\n    for (const node of this.nodes()) {\n      if (filter(node.value)) {\n        this.remove(node);\n      }\n    }\n  }\n\n  clear() {\n    this.count = 0;\n    this.head.next = this.head as EmptyNode;\n    this.head.prev = this.head as EmptyNode;\n  }\n\n  /** Returns the first item in the list, does not remove */\n  first(): T | null {\n    // If the list is empty, value will be the head's null\n    return this.head.next.value;\n  }\n\n  /** Returns the last item in the list, does not remove */\n  last(): T | null {\n    // If the list is empty, value will be the head's null\n    return this.head.prev.value;\n  }\n}\n\n/**\n * A pool of Buffers which allow you to read them as if they were one\n * @internal\n */\nexport class BufferPool {\n  private buffers: List<Buffer>;\n  private totalByteLength: number;\n\n  constructor() {\n    this.buffers = new List();\n    this.totalByteLength = 0;\n  }\n\n  get length(): number {\n    return this.totalByteLength;\n  }\n\n  /** Adds a buffer to the internal buffer pool list */\n  append(buffer: Buffer): void {\n    this.buffers.push(buffer);\n    this.totalByteLength += buffer.length;\n  }\n\n  /**\n   * If BufferPool contains 4 bytes or more construct an int32 from the leading bytes,\n   * otherwise return null. Size can be negative, caller should error check.\n   */\n  getInt32(): number | null {\n    if (this.totalByteLength < 4) {\n      return null;\n    }\n    const firstBuffer = this.buffers.first();\n    if (firstBuffer != null && firstBuffer.byteLength >= 4) {\n      return firstBuffer.readInt32LE(0);\n    }\n\n    // Unlikely case: an int32 is split across buffers.\n    // Use read and put the returned buffer back on top\n    const top4Bytes = this.read(4);\n    const value = top4Bytes.readInt32LE(0);\n\n    // Put it back.\n    this.totalByteLength += 4;\n    this.buffers.unshift(top4Bytes);\n\n    return value;\n  }\n\n  /** Reads the requested number of bytes, optionally consuming them */\n  read(size: number): Buffer {\n    if (typeof size !== 'number' || size < 0) {\n      throw new MongoInvalidArgumentError('Argument \"size\" must be a non-negative number');\n    }\n\n    // oversized request returns empty buffer\n    if (size > this.totalByteLength) {\n      return Buffer.alloc(0);\n    }\n\n    // We know we have enough, we just don't know how it is spread across chunks\n    // TODO(NODE-4732): alloc API should change based on raw option\n    const result = Buffer.allocUnsafe(size);\n\n    for (let bytesRead = 0; bytesRead < size; ) {\n      const buffer = this.buffers.shift();\n      if (buffer == null) {\n        break;\n      }\n      const bytesRemaining = size - bytesRead;\n      const bytesReadable = Math.min(bytesRemaining, buffer.byteLength);\n      const bytes = buffer.subarray(0, bytesReadable);\n\n      result.set(bytes, bytesRead);\n\n      bytesRead += bytesReadable;\n      this.totalByteLength -= bytesReadable;\n      if (bytesReadable < buffer.byteLength) {\n        this.buffers.unshift(buffer.subarray(bytesReadable));\n      }\n    }\n\n    return result;\n  }\n}\n\n/** @public */\nexport class HostAddress {\n  host: string | undefined = undefined;\n  port: number | undefined = undefined;\n  socketPath: string | undefined = undefined;\n  isIPv6 = false;\n\n  constructor(hostString: string) {\n    const escapedHost = hostString.split(' ').join('%20'); // escape spaces, for socket path hosts\n\n    if (escapedHost.endsWith('.sock')) {\n      // heuristically determine if we're working with a domain socket\n      this.socketPath = decodeURIComponent(escapedHost);\n      return;\n    }\n\n    const urlString = `iLoveJS://${escapedHost}`;\n    let url;\n    try {\n      url = new URL(urlString);\n    } catch (urlError) {\n      const runtimeError = new MongoRuntimeError(`Unable to parse ${escapedHost} with URL`);\n      runtimeError.cause = urlError;\n      throw runtimeError;\n    }\n\n    const hostname = url.hostname;\n    const port = url.port;\n\n    let normalized = decodeURIComponent(hostname).toLowerCase();\n    if (normalized.startsWith('[') && normalized.endsWith(']')) {\n      this.isIPv6 = true;\n      normalized = normalized.substring(1, hostname.length - 1);\n    }\n\n    this.host = normalized.toLowerCase();\n\n    if (typeof port === 'number') {\n      this.port = port;\n    } else if (typeof port === 'string' && port !== '') {\n      this.port = Number.parseInt(port, 10);\n    } else {\n      this.port = 27017;\n    }\n\n    if (this.port === 0) {\n      throw new MongoParseError('Invalid port (zero) with hostname');\n    }\n    Object.freeze(this);\n  }\n\n  [Symbol.for('nodejs.util.inspect.custom')](): string {\n    return this.inspect();\n  }\n\n  inspect(): string {\n    return `new HostAddress('${this.toString()}')`;\n  }\n\n  toString(): string {\n    if (typeof this.host === 'string') {\n      if (this.isIPv6) {\n        return `[${this.host}]:${this.port}`;\n      }\n      return `${this.host}:${this.port}`;\n    }\n    return `${this.socketPath}`;\n  }\n\n  static fromString(this: void, s: string): HostAddress {\n    return new HostAddress(s);\n  }\n\n  static fromHostPort(host: string, port: number): HostAddress {\n    if (host.includes(':')) {\n      host = `[${host}]`; // IPv6 address\n    }\n    return HostAddress.fromString(`${host}:${port}`);\n  }\n\n  static fromSrvRecord({ name, port }: SrvRecord): HostAddress {\n    return HostAddress.fromHostPort(name, port);\n  }\n\n  toHostPort(): { host: string; port: number } {\n    if (this.socketPath) {\n      return { host: this.socketPath, port: 0 };\n    }\n\n    const host = this.host ?? '';\n    const port = this.port ?? 0;\n    return { host, port };\n  }\n}\n\nexport const DEFAULT_PK_FACTORY = {\n  // We prefer not to rely on ObjectId having a createPk method\n  createPk(): ObjectId {\n    return new ObjectId();\n  }\n};\n\n/**\n * When the driver used emitWarning the code will be equal to this.\n * @public\n *\n * @example\n * ```ts\n * process.on('warning', (warning) => {\n *  if (warning.code === MONGODB_WARNING_CODE) console.error('Ah an important warning! :)')\n * })\n * ```\n */\nexport const MONGODB_WARNING_CODE = 'MONGODB DRIVER';\n\n/** @internal */\nexport function emitWarning(message: string): void {\n  return process.emitWarning(message, { code: MONGODB_WARNING_CODE } as any);\n}\n\nconst emittedWarnings = new Set();\n/**\n * Will emit a warning once for the duration of the application.\n * Uses the message to identify if it has already been emitted\n * so using string interpolation can cause multiple emits\n * @internal\n */\nexport function emitWarningOnce(message: string): void {\n  if (!emittedWarnings.has(message)) {\n    emittedWarnings.add(message);\n    return emitWarning(message);\n  }\n}\n\n/**\n * Takes a JS object and joins the values into a string separated by ', '\n */\nexport function enumToString(en: Record<string, unknown>): string {\n  return Object.values(en).join(', ');\n}\n\n/**\n * Determine if a server supports retryable writes.\n *\n * @internal\n */\nexport function supportsRetryableWrites(server?: Server): boolean {\n  if (!server) {\n    return false;\n  }\n\n  if (server.loadBalanced) {\n    // Loadbalanced topologies will always support retry writes\n    return true;\n  }\n\n  if (server.description.logicalSessionTimeoutMinutes != null) {\n    // that supports sessions\n    if (server.description.type !== ServerType.Standalone) {\n      // and that is not a standalone\n      return true;\n    }\n  }\n\n  return false;\n}\n\n/**\n * FisherYates Shuffle\n *\n * Reference: https://bost.ocks.org/mike/shuffle/\n * @param sequence - items to be shuffled\n * @param limit - Defaults to `0`. If nonzero shuffle will slice the randomized array e.g, `.slice(0, limit)` otherwise will return the entire randomized array.\n */\nexport function shuffle<T>(sequence: Iterable<T>, limit = 0): Array<T> {\n  const items = Array.from(sequence); // shallow copy in order to never shuffle the input\n\n  if (limit > items.length) {\n    throw new MongoRuntimeError('Limit must be less than the number of items');\n  }\n\n  let remainingItemsToShuffle = items.length;\n  const lowerBound = limit % items.length === 0 ? 1 : items.length - limit;\n  while (remainingItemsToShuffle > lowerBound) {\n    // Pick a remaining element\n    const randomIndex = Math.floor(Math.random() * remainingItemsToShuffle);\n    remainingItemsToShuffle -= 1;\n\n    // And swap it with the current element\n    const swapHold = items[remainingItemsToShuffle];\n    items[remainingItemsToShuffle] = items[randomIndex];\n    items[randomIndex] = swapHold;\n  }\n\n  return limit % items.length === 0 ? items : items.slice(lowerBound);\n}\n\n/**\n * TODO(NODE-4936): read concern eligibility for commands should be codified in command construction\n * @internal\n * @see https://github.com/mongodb/specifications/blob/master/source/read-write-concern/read-write-concern.md#read-concern\n */\nexport function commandSupportsReadConcern(command: Document): boolean {\n  if (command.aggregate || command.count || command.distinct || command.find || command.geoNear) {\n    return true;\n  }\n\n  return false;\n}\n\n/**\n * Compare objectIds. `null` is always less\n * - `+1 = oid1 is greater than oid2`\n * - `-1 = oid1 is less than oid2`\n * - `+0 = oid1 is equal oid2`\n */\nexport function compareObjectId(oid1?: ObjectId | null, oid2?: ObjectId | null): 0 | 1 | -1 {\n  if (oid1 == null && oid2 == null) {\n    return 0;\n  }\n\n  if (oid1 == null) {\n    return -1;\n  }\n\n  if (oid2 == null) {\n    return 1;\n  }\n\n  return ByteUtils.compare(oid1.id, oid2.id);\n}\n\nexport function parseInteger(value: unknown): number | null {\n  if (typeof value === 'number') return Math.trunc(value);\n  const parsedValue = Number.parseInt(String(value), 10);\n\n  return Number.isNaN(parsedValue) ? null : parsedValue;\n}\n\nexport function parseUnsignedInteger(value: unknown): number | null {\n  const parsedInt = parseInteger(value);\n\n  return parsedInt != null && parsedInt >= 0 ? parsedInt : null;\n}\n\n/**\n * This function throws a MongoAPIError in the event that either of the following is true:\n * * If the provided address domain does not match the provided parent domain\n * * If the parent domain contains less than three `.` separated parts and the provided address does not contain at least one more domain level than its parent\n *\n * If a DNS server were to become compromised SRV records would still need to\n * advertise addresses that are under the same domain as the srvHost.\n *\n * @param address - The address to check against a domain\n * @param srvHost - The domain to check the provided address against\n * @returns void\n */\nexport function checkParentDomainMatch(address: string, srvHost: string): void {\n  // Remove trailing dot if exists on either the resolved address or the srv hostname\n  const normalizedAddress = address.endsWith('.') ? address.slice(0, address.length - 1) : address;\n  const normalizedSrvHost = srvHost.endsWith('.') ? srvHost.slice(0, srvHost.length - 1) : srvHost;\n\n  const allCharacterBeforeFirstDot = /^.*?\\./;\n  const srvIsLessThanThreeParts = normalizedSrvHost.split('.').length < 3;\n  // Remove all characters before first dot\n  // Add leading dot back to string so\n  //   an srvHostDomain = '.trusted.site'\n  //   will not satisfy an addressDomain that endsWith '.fake-trusted.site'\n  const addressDomain = `.${normalizedAddress.replace(allCharacterBeforeFirstDot, '')}`;\n  let srvHostDomain = srvIsLessThanThreeParts\n    ? normalizedSrvHost\n    : `.${normalizedSrvHost.replace(allCharacterBeforeFirstDot, '')}`;\n\n  if (!srvHostDomain.startsWith('.')) {\n    srvHostDomain = '.' + srvHostDomain;\n  }\n  if (\n    srvIsLessThanThreeParts &&\n    normalizedAddress.split('.').length <= normalizedSrvHost.split('.').length\n  ) {\n    throw new MongoAPIError(\n      'Server record does not have at least one more domain level than parent URI'\n    );\n  }\n  if (!addressDomain.endsWith(srvHostDomain)) {\n    throw new MongoAPIError('Server record does not share hostname with parent URI');\n  }\n}\n\ninterface RequestOptions {\n  json?: boolean;\n  method?: string;\n  timeout?: number;\n  headers?: http.OutgoingHttpHeaders;\n}\n\n/**\n * Perform a get request that returns status and body.\n * @internal\n */\nexport function get(\n  url: URL | string,\n  options: http.RequestOptions = {}\n): Promise<{ body: string; status: number | undefined }> {\n  return new Promise((resolve, reject) => {\n    /* eslint-disable prefer-const */\n    let timeoutId: NodeJS.Timeout;\n    const request = http\n      .get(url, options, response => {\n        response.setEncoding('utf8');\n        let body = '';\n        response.on('data', chunk => (body += chunk));\n        response.on('end', () => {\n          clearTimeout(timeoutId);\n          resolve({ status: response.statusCode, body });\n        });\n      })\n      .on('error', error => {\n        clearTimeout(timeoutId);\n        reject(error);\n      })\n      .end();\n    timeoutId = setTimeout(() => {\n      request.destroy(new MongoNetworkTimeoutError(`request timed out after 10 seconds`));\n    }, 10000);\n  });\n}\n\nexport async function request(uri: string): Promise<Record<string, any>>;\nexport async function request(\n  uri: string,\n  options?: { json?: true } & RequestOptions\n): Promise<Record<string, any>>;\nexport async function request(\n  uri: string,\n  options?: { json: false } & RequestOptions\n): Promise<string>;\nexport async function request(\n  uri: string,\n  options: RequestOptions = {}\n): Promise<string | Record<string, any>> {\n  return await new Promise<string | Record<string, any>>((resolve, reject) => {\n    const requestOptions = {\n      method: 'GET',\n      timeout: 10000,\n      json: true,\n      ...url.parse(uri),\n      ...options\n    };\n\n    const req = http.request(requestOptions, res => {\n      res.setEncoding('utf8');\n\n      let data = '';\n      res.on('data', d => {\n        data += d;\n      });\n\n      res.once('end', () => {\n        if (options.json === false) {\n          resolve(data);\n          return;\n        }\n\n        try {\n          const parsed = JSON.parse(data);\n          resolve(parsed);\n        } catch {\n          // TODO(NODE-3483)\n          reject(new MongoRuntimeError(`Invalid JSON response: \"${data}\"`));\n        }\n      });\n    });\n\n    req.once('timeout', () =>\n      req.destroy(\n        new MongoNetworkTimeoutError(\n          `Network request to ${uri} timed out after ${options.timeout} ms`\n        )\n      )\n    );\n    req.once('error', error => reject(error));\n    req.end();\n  });\n}\n\n/** @internal */\nexport const DOCUMENT_DB_CHECK = /(\\.docdb\\.amazonaws\\.com$)|(\\.docdb-elastic\\.amazonaws\\.com$)/;\n/** @internal */\nexport const COSMOS_DB_CHECK = /\\.cosmos\\.azure\\.com$/;\n\n/** @internal */\nexport const DOCUMENT_DB_MSG =\n  'You appear to be connected to a DocumentDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/documentdb';\n/** @internal */\nexport const COSMOS_DB_MSG =\n  'You appear to be connected to a CosmosDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/cosmosdb';\n\n/** @internal */\nexport function isHostMatch(match: RegExp, host?: string): boolean {\n  return host && match.test(host.toLowerCase()) ? true : false;\n}\n\nexport function promiseWithResolvers<T>(): {\n  promise: Promise<T>;\n  resolve: (value: T) => void;\n  reject: (error: Error) => void;\n} {\n  let resolve!: (value: T) => void;\n  let reject!: (error: Error) => void;\n  const promise = new Promise<T>(function withResolversExecutor(promiseResolve, promiseReject) {\n    resolve = promiseResolve;\n    reject = promiseReject;\n  });\n  return { promise, resolve, reject } as const;\n}\n\n/**\n * A noop function intended for use in preventing unhandled rejections.\n *\n * @example\n * ```js\n * const promise = myAsyncTask();\n * // eslint-disable-next-line github/no-then\n * promise.then(undefined, squashError);\n * ```\n */\nexport function squashError(_error: unknown) {\n  return;\n}\n\nexport const randomBytes = promisify(crypto.randomBytes);\n\n/**\n * Replicates the events.once helper.\n *\n * Removes unused signal logic and It **only** supports 0 or 1 argument events.\n *\n * @param ee - An event emitter that may emit `ev`\n * @param name - An event name to wait for\n */\nexport async function once<T>(ee: EventEmitter, name: string, options?: Abortable): Promise<T> {\n  options?.signal?.throwIfAborted();\n\n  const { promise, resolve, reject } = promiseWithResolvers<T>();\n  const onEvent = (data: T) => resolve(data);\n  const onError = (error: Error) => reject(error);\n  const abortListener = addAbortListener(options?.signal, function () {\n    reject(this.reason);\n  });\n\n  ee.once(name, onEvent).once('error', onError);\n\n  try {\n    return await promise;\n  } finally {\n    ee.off(name, onEvent);\n    ee.off('error', onError);\n    abortListener?.[kDispose]();\n  }\n}\n\nexport function maybeAddIdToDocuments(\n  coll: Collection,\n  docs: Document[],\n  options: { forceServerObjectId?: boolean }\n): Document[];\nexport function maybeAddIdToDocuments(\n  coll: Collection,\n  docs: Document,\n  options: { forceServerObjectId?: boolean }\n): Document;\nexport function maybeAddIdToDocuments(\n  coll: Collection,\n  docOrDocs: Document[] | Document,\n  options: { forceServerObjectId?: boolean }\n): Document[] | Document {\n  const forceServerObjectId =\n    typeof options.forceServerObjectId === 'boolean'\n      ? options.forceServerObjectId\n      : coll.s.db.options?.forceServerObjectId;\n\n  // no need to modify the docs if server sets the ObjectId\n  if (forceServerObjectId === true) {\n    return docOrDocs;\n  }\n\n  const transform = (doc: Document): Document => {\n    if (doc._id == null) {\n      doc._id = coll.s.pkFactory.createPk();\n    }\n\n    return doc;\n  };\n  return Array.isArray(docOrDocs) ? docOrDocs.map(transform) : transform(docOrDocs);\n}\n\nexport async function fileIsAccessible(fileName: string, mode?: number) {\n  try {\n    await fs.access(fileName, mode);\n    return true;\n  } catch {\n    return false;\n  }\n}\n\nexport function csotMin(duration1: number, duration2: number): number {\n  if (duration1 === 0) return duration2;\n  if (duration2 === 0) return duration1;\n  return Math.min(duration1, duration2);\n}\n\nexport function noop() {\n  return;\n}\n\n/**\n * Recurse through the (identically-shaped) `decrypted` and `original`\n * objects and attach a `decryptedKeys` property on each sub-object that\n * contained encrypted fields. Because we only call this on BSON responses,\n * we do not need to worry about circular references.\n *\n * @internal\n */\nexport function decorateDecryptionResult(\n  decrypted: Document & { [kDecoratedKeys]?: Array<string> },\n  original: Document,\n  isTopLevelDecorateCall = true\n): void {\n  if (isTopLevelDecorateCall) {\n    // The original value could have been either a JS object or a BSON buffer\n    if (Buffer.isBuffer(original)) {\n      original = deserialize(original);\n    }\n    if (Buffer.isBuffer(decrypted)) {\n      throw new MongoRuntimeError('Expected result of decryption to be deserialized BSON object');\n    }\n  }\n\n  if (!decrypted || typeof decrypted !== 'object') return;\n  for (const k of Object.keys(decrypted)) {\n    const originalValue = original[k];\n\n    // An object was decrypted by libmongocrypt if and only if it was\n    // a BSON Binary object with subtype 6.\n    if (originalValue && originalValue._bsontype === 'Binary' && originalValue.sub_type === 6) {\n      if (!decrypted[kDecoratedKeys]) {\n        Object.defineProperty(decrypted, kDecoratedKeys, {\n          value: [],\n          configurable: true,\n          enumerable: false,\n          writable: false\n        });\n      }\n      // this is defined in the preceding if-statement\n      // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n      decrypted[kDecoratedKeys]!.push(k);\n      // Do not recurse into this decrypted value. It could be a sub-document/array,\n      // in which case there is no original value associated with its subfields.\n      continue;\n    }\n\n    decorateDecryptionResult(decrypted[k], originalValue, false);\n  }\n}\n\n/** @internal */\nexport const kDispose: unique symbol = (Symbol.dispose as any) ?? Symbol('dispose');\n\n/** @internal */\nexport interface Disposable {\n  [kDispose](): void;\n}\n\n/**\n * A utility that helps with writing listener code idiomatically\n *\n * @example\n * ```js\n * using listener = addAbortListener(signal, function () {\n *   console.log('aborted', this.reason);\n * });\n * ```\n *\n * @param signal - if exists adds an abort listener\n * @param listener - the listener to be added to signal\n * @returns A disposable that will remove the abort listener\n */\nexport function addAbortListener(\n  signal: AbortSignal | undefined | null,\n  listener: (this: AbortSignal, event: Event) => void\n): Disposable | undefined {\n  if (signal == null) return;\n  signal.addEventListener('abort', listener, { once: true });\n  return { [kDispose]: () => signal.removeEventListener('abort', listener) };\n}\n\n/**\n * Takes a promise and races it with a promise wrapping the abort event of the optionally provided signal.\n * The given promise is _always_ ordered before the signal's abort promise.\n * When given an already rejected promise and an already aborted signal, the promise's rejection takes precedence.\n *\n * Any asynchronous processing in `promise` will continue even after the abort signal has fired,\n * but control will be returned to the caller\n *\n * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/race\n *\n * @param promise - A promise to discard if the signal aborts\n * @param options - An options object carrying an optional signal\n */\nexport async function abortable<T>(\n  promise: Promise<T>,\n  { signal }: { signal?: AbortSignal }\n): Promise<T> {\n  if (signal == null) {\n    return await promise;\n  }\n\n  const { promise: aborted, reject } = promiseWithResolvers<never>();\n\n  const abortListener = signal.aborted\n    ? reject(signal.reason)\n    : addAbortListener(signal, function () {\n        reject(this.reason);\n      });\n\n  try {\n    return await Promise.race([promise, aborted]);\n  } finally {\n    abortListener?.[kDispose]();\n  }\n}\n"],"names":[],"mappings":";;;;;AAyEA,QAAA,YAAA,GAAA;AAaA,QAAA,oBAAA,GAAA;AAmBA,QAAA,kBAAA,GAAA;AA4BA,QAAA,QAAA,GAAA;AAKA,QAAA,YAAA,GAAA;AAKA,QAAA,aAAA,GAAA;AAuBA,QAAA,oBAAA,GAAA;AAyBA,QAAA,aAAA,GAAA;AAiBA,QAAA,qBAAA,GAAA;AAsBA,QAAA,uBAAA,GAAA;AAmCA,QAAA,WAAA,GAAA;AAYA,QAAA,EAAA,GAAA;AA4DA,QAAA,WAAA,GAAA;AAaA,QAAA,MAAA,GAAA;AAWA,QAAA,cAAA,GAAA;AAmCA,QAAA,gBAAA,GAAA;AASA,QAAA,gBAAA,GAAA;AA0CA,QAAA,gBAAA,GAAA;AAeA,QAAA,GAAA,GAAA;AAMA,QAAA,qBAAA,GAAA;AAUA,QAAA,kBAAA,GAAA;AAkCA,QAAA,qBAAA,GAAA;AAqBA,QAAA,cAAA,GAAA;AAgDA,QAAA,UAAA,GAAA;AAeA,QAAA,OAAA,GAAA;AAKA,QAAA,aAAA,GAAA;AAgBA,QAAA,QAAA,GAAA;AA2YA,QAAA,WAAA,GAAA;AAWA,QAAA,eAAA,GAAA;AAUA,QAAA,YAAA,GAAA;AASA,QAAA,uBAAA,GAAA;AA4BA,QAAA,OAAA,GAAA;AA4BA,QAAA,0BAAA,GAAA;AAcA,QAAA,eAAA,GAAA;AAgBA,QAAA,YAAA,GAAA;AAOA,QAAA,oBAAA,GAAA;AAkBA,QAAA,sBAAA,GAAA;AA2CA,QAAA,GAAA,GAAA;AAqCA,QAAA,OAAA,GAAA;AA8DA,QAAA,WAAA,GAAA;AAIA,QAAA,oBAAA,GAAA;AAwBA,QAAA,WAAA,GAAA;AAcA,QAAA,IAAA,GAAA;AA+BA,QAAA,qBAAA,GAAA;AAyBA,QAAA,gBAAA,GAAA;AASA,QAAA,OAAA,GAAA;AAMA,QAAA,IAAA,GAAA;AAYA,QAAA,wBAAA,GAAA;AAgEA,QAAA,gBAAA,GAAA;AAsBA,QAAA,SAAA,GAAA;AAl+CA,MAAA;AAGA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAEA,MAAA;AAEA,MAAA;AAEA,MAAA;AAIA,MAAA;AAcA,MAAA;AACA,MAAA;AACA,MAAA;AAKA,MAAA;AAUa,QAAA,SAAS,GAAG;IACvB,mBAA8B,MAA2B;QACvD,OAAO,OAAO,QAAQ,CAAC,UACnB,SACA,OAAO,IAAI,CAAC,OAAO,MAAM,EAAE,OAAO,UAAU,EAAE,OAAO,UAAU;IACrE;IAEA,QAAmB,IAAgB,EAAE,IAAgB;QACnD,OAAO,QAAA,SAAS,CAAC,iBAAiB,CAAC,MAAM,MAAM,CAAC;IAClD;IAEA,SAAoB,IAAgB,EAAE,IAAgB;QACpD,OAAO,QAAA,SAAS,CAAC,iBAAiB,CAAC,MAAM,OAAO,CAAC;IACnD;IAEA,UAAqB,UAAsB;QACzC,OAAO,QAAA,SAAS,CAAC,iBAAiB,CAAC,YAAY,QAAQ,CAAC;IAC1D;;AAGF;;;IAIA,SAAgB,aAAa,KAAc;IACzC,OACE,SAAS,QACT,OAAO,UAAU,YACjB,OAAO,WAAW,IAAI,SACtB,KAAK,CAAC,OAAO,WAAW,CAAC,KAAK;AAElC;AAEA;;;IAIA,SAAgB,qBAAqB,IAAY,EAAE,SAAmB;IACpE,KAAK,MAAM,YAAY,UAAW;QAChC,IACE,SAAS,YACR,SAAS,UAAU,CAAC,SAAS,MAAM,SAAS,SAAS,SAAS,CAAC,GAAG,SAAS,MAAM,MACjF,SAAS,UAAU,CAAC,SAAS,MAAM,SAAS,SAAS,SAAS,CAAC,GAAG,SAAS,MAAM,IAClF;YACA,OAAO;QACT;IACF;IACA,OAAO;AACT;AAEA;;;;;IAMA,SAAgB,mBAAmB,IAAW;IAC5C,IAAI,YAAY;IAEhB,IAAI,OAAO,SAAS,UAAU;QAC5B,YAAY;IACd,OAAO,IAAI,MAAM,OAAO,CAAC,OAAO;QAC9B,YAAY,CAAA;QAEZ,KAAK,OAAO,CAAC,CAAA;YACX,SAAS,CAAC,MAAM,GAAG;QACrB;IACF,OAAO,IAAI,QAAQ,QAAQ,OAAO,SAAS,UAAU;QACnD,YAAY,CAAA;QACZ,IAAK,MAAM,QAAQ,KAAM;YACvB,SAAS,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK;QAC9B;IACF;IAEA,OAAO;AACT;AAEA,MAAM,YAAY,CAAC,SAAoB,OAAO,SAAS,CAAC,QAAQ,CAAC,IAAI,CAAC;AACtE;;;;IAMA,SAAgB,SAAS,GAAY;IACnC,OAAO,sBAAsB,UAAU;AACzC;AAEA,cAAA,GACA,SAAgB,aAAmB,MAAS,EAAE,MAAS;IACrD,OAAO;QAAE,GAAG,MAAM;QAAE,GAAG,MAAM;IAAA;AAC/B;AAEA,cAAA,GACA,SAAgB,cAAc,OAAmB,EAAE,KAA4B;IAC7E,MAAM,gBAA4B,CAAA;IAElC,IAAK,MAAM,QAAQ,QAAS;QAC1B,IAAI,MAAM,QAAQ,CAAC,OAAO;YACxB,aAAa,CAAC,KAAK,GAAG,OAAO,CAAC,KAAK;QACrC;IACF;IAEA,mBAAmB;IACnB,OAAO;AACT;AAKA;;;;;;IAOA,SAAgB,qBAAmD,MAAS,EAAE,EAAO;IACnF,IAAI,MAAM,GAAG,CAAC,CAAC,OAAO,EAAE,aAAa;QACnC,OAAO,WAAW,GAAG;IACvB;IAEA,OAAO;AACT;AAEA;;;;;;;;IAUA;;;;;;IAOA,SAAgB,cAA2B,KAAe;IACxD,OACE,SAAS,QACT,OAAO,UAAU,YACjB,UAAU,SACV,OAAO,MAAM,IAAI,KAAK;AAE1B;AAEA;;;;;;;IAQA,SAAgB,sBACd,OAAiB,EACjB,MAAqC,EACrC,OAAmB;IAEnB,MAAM,eAAe,YAAY,QAAQ,YAAY;IACrD,IAAI,QAAQ,SAAS,IAAI,OAAO,QAAQ,SAAS,KAAK,UAAU;QAC9D,IAAI,gBAAgB,aAAa,qBAAqB,EAAE;YACtD,QAAQ,SAAS,GAAG,QAAQ,SAAS;QACvC,OAAO;YACL,MAAM,IAAI,QAAA,uBAAuB,CAAC,CAAA,2CAAA,CAA6C;QACjF;IACF;AACF;AAEA;;;;;;IAOA,SAAgB,wBACd,OAAiB,EACjB,IAA0C,EAC1C,OAA0B;IAE1B,IAAI,WAAW,QAAQ,OAAO,IAAI,QAAQ,OAAO,CAAC,aAAa,IAAI;QACjE;IACF;IACA,MAAM,cAAc,OAAO,MAAM,CAAC,CAAA,GAAI,QAAQ,WAAW,IAAI,CAAA;IAC7D,IAAI,KAAK,CAAC,CAAC,WAAW,EAAE;QACtB,OAAO,MAAM,CAAC,aAAa,KAAK,CAAC,CAAC,WAAW;IAC/C;IAEA,IAAI,OAAO,IAAI,CAAC,aAAa,MAAM,GAAG,GAAG;QACvC,OAAO,MAAM,CAAC,SAAS;YAAE,aAAa;QAAW;IACnD;AACF;AAaA;;;;;IAMA,SAAgB,YAAY,QAA0B;IACpD,iDAAiD;IACjD,IAAI,cAAc,YAAY,SAAS,QAAQ,EAAE;QAC/C,OAAO,SAAS,QAAQ;IAC1B,OAAO,IAAI,YAAY,YAAY,SAAS,MAAM,CAAC,QAAQ,EAAE;QAC3D,OAAO,SAAS,MAAM,CAAC,QAAQ;IACjC;IAEA,MAAM,IAAI,QAAA,sBAAsB,CAAC;AACnC;AAEA,cAAA,GACA,SAAgB,GAAG,EAAU;IAC3B,OAAO,iBAAiB,UAAU,CAAC;AACrC;AAEA,YAAA,GACA,MAAa;IACX;;;;;QAMA,YACS,EAAU,EACV,UAAmB,CAAA;QADnB,IAAA,CAAA,EAAE,GAAF;QACA,IAAA,CAAA,UAAU,GAAV;QAEP,IAAI,CAAC,UAAU,GAAG,eAAe,KAAK,YAAY;IACpD;IAEA,WAAQ;QACN,OAAO,IAAI,CAAC,UAAU,GAAG,CAAA,EAAG,IAAI,CAAC,EAAE,CAAA,CAAA,EAAI,IAAI,CAAC,UAAU,CAAA,CAAE,GAAG,IAAI,CAAC,EAAE;IACpE;IAEA,eAAe,UAAkB,EAAA;QAC/B,OAAO,IAAI,2BAA2B,IAAI,CAAC,EAAE,EAAE;IACjD;IAEA,OAAO,WAAW,SAAkB,EAAA;QAClC,IAAI,OAAO,cAAc,YAAY,cAAc,IAAI;YACrD,oDAAoD;YACpD,MAAM,IAAI,QAAA,iBAAiB,CAAC,CAAA,6BAAA,EAAgC,UAAS,CAAA,CAAG;QAC1E;QAEA,MAAM,CAAC,IAAI,GAAG,gBAAgB,GAAG,UAAU,KAAK,CAAC;QACjD,MAAM,aAAa,gBAAgB,IAAI,CAAC;QACxC,OAAO,IAAI,iBAAiB,IAAI,eAAe,KAAK,YAAY;IAClE;;AA/BF,QAAA,gBAAA,GAAA;AAkCA;;;;;;IAOA,MAAa,mCAAmC;IAC9C,YACE,EAAU,EACD,UAAkB,CAAA;QAE3B,KAAK,CAAC,IAAI;QAFD,IAAA,CAAA,UAAU,GAAV;IAGX;IAEA,OAAgB,WAAW,SAAkB,EAAA;QAC3C,OAAO,KAAK,CAAC,WAAW;IAC1B;;AAVF,QAAA,0BAAA,GAAA;AAaA,cAAA,GACA,UAAiB,YAAY,OAAO,CAAC;IACnC,IAAI,QAAQ;IACZ,MAAO,KAAM;QACX,MAAM,WAAW;QACjB,SAAS;QACT,MAAM;IACR;AACF;AAEA;;;IAIA,SAAgB;IACd,MAAM,SAAS,OAAO,WAAW,CAAC;IAClC,MAAM,CAAC,EAAE,GAAG,AAAC,MAAM,CAAC,EAAE,GAAG,OAAQ;IACjC,MAAM,CAAC,EAAE,GAAG,AAAC,MAAM,CAAC,EAAE,GAAG,OAAQ;IACjC,OAAO;AACT;AAEA;;;IAIA,SAAgB,eAAe,gBAAiD;IAC9E,IAAI,kBAAkB;QACpB,IAAI,iBAAiB,YAAY,IAAI,iBAAiB,SAAS,EAAE,SAAS;YACxE,4DAA4D;YAC5D,sFAAsF;YACtF,+CAA+C;YAC/C,8DAA8D;YAC9D,gEAAgE;YAChE,+DAA+D;YAC/D,OAAO,YAAA,0BAA0B;QACnC;QACA,IAAI,iBAAiB,KAAK,EAAE;YAC1B,OAAO,iBAAiB,KAAK,CAAC,cAAc;QAC9C;QAEA,IAAI,eAAe,oBAAoB,OAAO,iBAAiB,SAAS,KAAK,YAAY;YACvF,MAAM,YAAY,iBAAiB,SAAS;YAC5C,IAAI,WAAW;gBACb,OAAO,UAAU,cAAc;YACjC;QACF;QAEA,IACE,iBAAiB,WAAW,IAC5B,oBAAoB,iBAAiB,WAAW,IAChD,iBAAiB,WAAW,CAAC,cAAc,IAAI,MAC/C;YACA,OAAO,iBAAiB,WAAW,CAAC,cAAc;QACpD;IACF;IAEA,OAAO;AACT;AAEA,cAAA,GACA,SAAgB,iBAAiB,GAAc,EAAE,IAAe;IAC9D,IAAI,CAAC,MAAM,OAAO,CAAC,QAAQ,CAAC,MAAM,OAAO,CAAC,OAAO;QAC/C,OAAO;IACT;IAEA,OAAO,IAAI,MAAM,KAAK,KAAK,MAAM,IAAI,IAAI,KAAK,CAAC,CAAC,KAAK,MAAQ,QAAQ,IAAI,CAAC,IAAI;AAChF;AAEA,cAAA,GACA,SAAgB,iBAAiB,GAAqB,EAAE,GAAqB;IAC3E,IAAI,QAAQ,KAAK;QACf,OAAO;IACT;IAEA,IAAI,CAAC,OAAO,CAAC,KAAK;QAChB,OAAO,QAAQ;IACjB;IAEA,IAAI,AAAC,OAAO,QAAQ,OAAO,QAAU,OAAO,QAAQ,OAAO,MAAO;QAChE,OAAO;IACT;IAEA,IAAI,IAAI,WAAW,CAAC,IAAI,KAAK,IAAI,WAAW,CAAC,IAAI,EAAE;QACjD,OAAO;IACT;IAEA,IAAI,IAAI,OAAO,KAAK,IAAI,OAAO,EAAE;QAC/B,OAAO;IACT;IAEA,OAAO;AACT;AAmBA,cAAA,GACA,SAAgB,iBAAiB,UAAsB;IACrD,OAAO,SAAS,gBAAgB,MAAM,EAAE,QAAQ;QAC9C,MAAM,cAAc,UAAU,CAAC,OAAO,CAAC,CAAC,KAAK,CAAC;QAC9C,IAAI,eAAe,YAAY,OAAO,CAAC,YAAY,GAAG;YACpD,MAAM,IAAI,QAAA,iBAAiB,CACzB,CAAA,+BAAA,EAAkC,OAAO,CAAC,CAAC,KAAK,CAAA,MAAA,EAAS,SAAQ,aAAA,EAAgB,YAAW,CAAA,CAAG;QAEnG;QAEA,OAAO,IAAI,CAAC,gBAAgB,OAAO,CAAC,CAAC,KAAK,EAAE;QAC5C,OAAO,CAAC,CAAC,KAAK,GAAG;IACnB;AACF;AAEA,cAAA,GACA,SAAgB;IACd,MAAM,SAAS,QAAQ,MAAM;IAC7B,OAAO,KAAK,KAAK,CAAC,MAAM,CAAC,EAAE,GAAG,OAAO,MAAM,CAAC,EAAE,GAAG;AACnD;AAEA,cAAA,GACA,SAAgB,sBAAsB,OAA2B;IAC/D,IAAI,OAAO,YAAY,UAAU;QAC/B,OAAO,CAAC;IACV;IAEA,MAAM,UAAU,QAAQ;IACxB,OAAO,UAAU,IAAI,IAAI;AAC3B;AAEA,cAAA,GACA,SAAgB,mBACd,GAA0B,EAC1B,OAAiC;IAEjC,IAAI,MAAM,OAAO,CAAC,MAAM;QACtB,KAAK,MAAM,YAAY,IAAK;YAC1B,IAAI,mBAAmB,WAAW;gBAChC,OAAO;YACT;QACF;QACA,OAAO;IACT;IAEA,MAAM,OAAO,OAAO,IAAI,CAAC;IACzB,2EAA2E;IAC3E,IAAI,SAAS,iBAAiB;QAC5B,IAAI,eAAe;QACnB,KAAK,MAAM,OAAO,KAAM;YACtB,gDAAgD;YAChD,IAAI,GAAG,CAAC,IAAI,KAAK,WAAW;gBAC1B,eAAe;gBACf;YACF;QACF;QACA,IAAI,cAAc;YAChB,MAAM,IAAI,QAAA,yBAAyB,CACjC;QAEJ;IACF;IAEA,OAAO,KAAK,MAAM,GAAG,KAAK,IAAI,CAAC,EAAE,CAAC,EAAE,KAAK;AAC3C;AAEA,SAAgB,sBACd,MAAmB,EACnB,OAAU;IAMV,MAAM,EAAE,eAAe,EAAE,wBAAwB,EAAE,kBAAkB,EAAE,SAAS,EAAE,GAChF,OAAO,CAAC,CAAC,OAAO;IAClB,OAAO;QAAE;QAAiB;QAA0B;QAAoB;QAAW,GAAG,OAAO;IAAA;AAC/F;AACA;;;;;;;;IASA,SAAgB,eACd,MAAmC,EACnC,OAAW;IAEX,MAAM,SAAY,OAAO,MAAM,CAAC,CAAA,GAAI,SAAS,CAAA,GAAA,OAAA,kBAAkB,EAAC,SAAS;IAEzE,MAAM,YAAY,SAAS,aAAa,QAAQ;IAChD,8EAA8E;IAC9E,MAAM,UAAU,SAAS;IAEzB,IAAI,CAAC,SAAS,iBAAiB;QAC7B,MAAM,cAAc,eAAA,WAAW,CAAC,WAAW,CAAC,YAAY,QAAQ;QAChE,IAAI,aAAa;YACf,OAAO,WAAW,GAAG;QACvB;QAEA,IAAI,eAAe,gBAAA,YAAY,CAAC,WAAW,CAAC,YAAY,QAAQ;QAChE,IAAI,cAAc;YAChB,IAAI,aAAa,MAAM;gBACrB,eAAe,gBAAA,YAAY,CAAC,WAAW,CAAC;oBACtC,cAAc;wBACZ,GAAG,YAAY;wBACf,UAAU;wBACV,YAAY;;;YAGlB;YACA,OAAO,YAAY,GAAG;QACxB;IACF;IAEA,OAAO,SAAS,GAAG;IAEnB,MAAM,iBAAiB,kBAAA,cAAc,CAAC,WAAW,CAAC,YAAY,QAAQ;IACtE,IAAI,gBAAgB;QAClB,OAAO,cAAc,GAAG;IAC1B;IAEA,MAAM,0BAA0B,SAAS,YAAY,SAAS,kBAAkB;IAChF,IAAI,2BAA2B,SAAS,aAAa,MAAM;QACzD,MAAM,IAAI,QAAA,yBAAyB,CACjC;IAEJ;IAEA,OAAO;AACT;AAEA,SAAgB,WAAW,GAAqB,EAAE,MAAwB;IACxE,MAAM,MAAM,OAAO,CAAC,OAAO,IAAI,IAAI,OAAO;IAC1C,SAAS,MAAM,OAAO,CAAC,UAAU,IAAI,IAAI,UAAU;IACnD,KAAK,MAAM,QAAQ,OAAQ;QACzB,IAAI,CAAC,IAAI,GAAG,CAAC,OAAO;YAClB,OAAO;QACT;IACF;IACA,OAAO;AACT;AAEA;;;IAIA,SAAgB,QAAQ,GAAa;IACnC,OAAO,GAAG,CAAC,YAAA,oBAAoB,CAAC,IAAI,IAAI,KAAK,GAAG,OAAO;AACzD;AAEA,gDAAA,GACA,SAAgB,cAAiB,IAAiB,EAAE,IAAiB;IACnE,MAAM,aAAa,IAAI,IAAO;IAC9B,KAAK,MAAM,QAAQ,KAAM;QACvB,WAAW,MAAM,CAAC;IACpB;IACA,OAAO;AACT;AAEA,MAAM,UAAU,CAAC,QAAiB,OAChC,OAAO,SAAS,CAAC,cAAc,CAAC,IAAI,CAAC,QAAQ;AAO/C,SAAgB,SACd,KAAc,EACd,eAAqC,SAAS;IAE9C,IAAI,CAAC,SAAS,QAAQ;QACpB,OAAO;IACT;IAEA,MAAM,OAAQ,MAAc,WAAW;IACvC,IAAI,QAAQ,KAAK,SAAS,EAAE;QAC1B,IAAI,CAAC,SAAS,KAAK,SAAS,GAAG;YAC7B,OAAO;QACT;QAEA,4DAA4D;QAC5D,IAAI,CAAC,QAAQ,KAAK,SAAS,EAAE,kBAAkB;YAC7C,OAAO;QACT;IACF;IAEA,IAAI,cAAc;QAChB,MAAM,OAAO,OAAO,IAAI,CAAC;QACzB,OAAO,WAAW,MAAM;IAC1B;IAEA,OAAO;AACT;AAwBA;;;;;;;;IASA,MAAa;IAIX,IAAI,SAAM;QACR,OAAO,IAAI,CAAC,KAAK;IACnB;IAEA,IAAI,CAAC,OAAO,WAAW,CAAC,GAAA;QACtB,OAAO;IACT;IAEA,aAAA;QACE,IAAI,CAAC,KAAK,GAAG;QAEb,6BAA6B;QAC7B,oDAAoD;QACpD,oDAAoD;QACpD,IAAI,CAAC,IAAI,GAAG;YACV,MAAM;YACN,MAAM;YACN,OAAO;;QAET,IAAI,CAAC,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI;QAC1B,IAAI,CAAC,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI;IAC5B;IAEA,UAAO;QACL,OAAO,MAAM,IAAI,CAAC,IAAI;IACxB;IAEA,WAAQ;QACN,OAAO,CAAA,SAAA,EAAY,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,SAAQ,SAAA,CAAW;IAC5D;IAEA,CAAC,CAAC,OAAO,QAAQ,CAAC,GAAA;QAChB,KAAK,MAAM,QAAQ,IAAI,CAAC,KAAK,GAAI;YAC/B,MAAM,KAAK,KAAK;QAClB;IACF;IAEQ,CAAC,QAAK;QACZ,IAAI,MAA6C,IAAI,CAAC,IAAI,CAAC,IAAI;QAC/D,MAAO,QAAQ,IAAI,CAAC,IAAI,CAAE;YACxB,2EAA2E;YAC3E,MAAM,EAAE,IAAI,EAAE,GAAG;YACjB,MAAM;YACN,MAAM;QACR;IACF;IAEA,0BAAA,GACA,KAAK,KAAQ,EAAA;QACX,IAAI,CAAC,KAAK,IAAI;QACd,MAAM,UAAuB;YAC3B,MAAM,IAAI,CAAC,IAAmB;YAC9B,MAAM,IAAI,CAAC,IAAI,CAAC,IAAmB;YACnC;;QAEF,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,GAAG;QACtB,IAAI,CAAC,IAAI,CAAC,IAAI,GAAG;IACnB;IAEA,yEAAA,GACA,SAAS,QAAqB,EAAA;QAC5B,KAAK,MAAM,SAAS,SAAU;YAC5B,IAAI,CAAC,IAAI,CAAC;QACZ;IACF;IAEA,4BAAA,GACA,QAAQ,KAAQ,EAAA;QACd,IAAI,CAAC,KAAK,IAAI;QACd,MAAM,UAAuB;YAC3B,MAAM,IAAI,CAAC,IAAI,CAAC,IAAmB;YACnC,MAAM,IAAI,CAAC,IAAmB;YAC9B;;QAEF,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,GAAG;QACtB,IAAI,CAAC,IAAI,CAAC,IAAI,GAAG;IACnB;IAEQ,OAAO,IAA6B,EAAA;QAC1C,IAAI,SAAS,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,MAAM,KAAK,GAAG;YAC3C,OAAO;QACT;QAEA,IAAI,CAAC,KAAK,IAAI;QAEd,MAAM,WAAW,KAAK,IAAI;QAC1B,MAAM,WAAW,KAAK,IAAI;QAC1B,SAAS,IAAI,GAAG;QAChB,SAAS,IAAI,GAAG;QAEhB,OAAO,KAAK,KAAK;IACnB;IAEA,oDAAA,GACA,QAAK;QACH,OAAO,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI;IACnC;IAEA,iDAAA,GACA,MAAG;QACD,OAAO,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI;IACnC;IAEA,0EAAA,GACA,MAAM,MAA6B,EAAA;QACjC,KAAK,MAAM,QAAQ,IAAI,CAAC,KAAK,GAAI;YAC/B,IAAI,OAAO,KAAK,KAAK,GAAG;gBACtB,IAAI,CAAC,MAAM,CAAC;YACd;QACF;IACF;IAEA,QAAK;QACH,IAAI,CAAC,KAAK,GAAG;QACb,IAAI,CAAC,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAiB;QACvC,IAAI,CAAC,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAiB;IACzC;IAEA,wDAAA,GACA,QAAK;QACH,sDAAsD;QACtD,OAAO,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK;IAC7B;IAEA,uDAAA,GACA,OAAI;QACF,sDAAsD;QACtD,OAAO,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK;IAC7B;;AApIF,QAAA,IAAA,GAAA;AAuIA;;;IAIA,MAAa;IAIX,aAAA;QACE,IAAI,CAAC,OAAO,GAAG,IAAI;QACnB,IAAI,CAAC,eAAe,GAAG;IACzB;IAEA,IAAI,SAAM;QACR,OAAO,IAAI,CAAC,eAAe;IAC7B;IAEA,mDAAA,GACA,OAAO,MAAc,EAAA;QACnB,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC;QAClB,IAAI,CAAC,eAAe,IAAI,OAAO,MAAM;IACvC;IAEA;;;QAIA,WAAQ;QACN,IAAI,IAAI,CAAC,eAAe,GAAG,GAAG;YAC5B,OAAO;QACT;QACA,MAAM,cAAc,IAAI,CAAC,OAAO,CAAC,KAAK;QACtC,IAAI,eAAe,QAAQ,YAAY,UAAU,IAAI,GAAG;YACtD,OAAO,YAAY,WAAW,CAAC;QACjC;QAEA,mDAAmD;QACnD,mDAAmD;QACnD,MAAM,YAAY,IAAI,CAAC,IAAI,CAAC;QAC5B,MAAM,QAAQ,UAAU,WAAW,CAAC;QAEpC,eAAe;QACf,IAAI,CAAC,eAAe,IAAI;QACxB,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC;QAErB,OAAO;IACT;IAEA,mEAAA,GACA,KAAK,IAAY,EAAA;QACf,IAAI,OAAO,SAAS,YAAY,OAAO,GAAG;YACxC,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,yCAAyC;QACzC,IAAI,OAAO,IAAI,CAAC,eAAe,EAAE;YAC/B,OAAO,OAAO,KAAK,CAAC;QACtB;QAEA,4EAA4E;QAC5E,+DAA+D;QAC/D,MAAM,SAAS,OAAO,WAAW,CAAC;QAElC,IAAK,IAAI,YAAY,GAAG,YAAY,MAAQ;YAC1C,MAAM,SAAS,IAAI,CAAC,OAAO,CAAC,KAAK;YACjC,IAAI,UAAU,MAAM;gBAClB;YACF;YACA,MAAM,iBAAiB,OAAO;YAC9B,MAAM,gBAAgB,KAAK,GAAG,CAAC,gBAAgB,OAAO,UAAU;YAChE,MAAM,QAAQ,OAAO,QAAQ,CAAC,GAAG;YAEjC,OAAO,GAAG,CAAC,OAAO;YAElB,aAAa;YACb,IAAI,CAAC,eAAe,IAAI;YACxB,IAAI,gBAAgB,OAAO,UAAU,EAAE;gBACrC,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,QAAQ,CAAC;YACvC;QACF;QAEA,OAAO;IACT;;AA9EF,QAAA,UAAA,GAAA;AAiFA,YAAA,GACA,MAAa;IAMX,YAAY,UAAkB,CAAA;QAL9B,IAAA,CAAA,IAAI,GAAuB;QAC3B,IAAA,CAAA,IAAI,GAAuB;QAC3B,IAAA,CAAA,UAAU,GAAuB;QACjC,IAAA,CAAA,MAAM,GAAG;QAGP,MAAM,cAAc,WAAW,KAAK,CAAC,KAAK,IAAI,CAAC,QAAQ,uCAAuC;QAE9F,IAAI,YAAY,QAAQ,CAAC,UAAU;YACjC,gEAAgE;YAChE,IAAI,CAAC,UAAU,GAAG,mBAAmB;YACrC;QACF;QAEA,MAAM,YAAY,CAAA,UAAA,EAAa,YAAW,CAAE;QAC5C,IAAI;QACJ,IAAI;YACF,MAAM,IAAI,MAAA,GAAG,CAAC;QAChB,EAAE,OAAO,UAAU;YACjB,MAAM,eAAe,IAAI,QAAA,iBAAiB,CAAC,CAAA,gBAAA,EAAmB,YAAW,SAAA,CAAW;YACpF,aAAa,KAAK,GAAG;YACrB,MAAM;QACR;QAEA,MAAM,WAAW,IAAI,QAAQ;QAC7B,MAAM,OAAO,IAAI,IAAI;QAErB,IAAI,aAAa,mBAAmB,UAAU,WAAW;QACzD,IAAI,WAAW,UAAU,CAAC,QAAQ,WAAW,QAAQ,CAAC,MAAM;YAC1D,IAAI,CAAC,MAAM,GAAG;YACd,aAAa,WAAW,SAAS,CAAC,GAAG,SAAS,MAAM,GAAG;QACzD;QAEA,IAAI,CAAC,IAAI,GAAG,WAAW,WAAW;QAElC,IAAI,OAAO,SAAS,UAAU;YAC5B,IAAI,CAAC,IAAI,GAAG;QACd,OAAO,IAAI,OAAO,SAAS,YAAY,SAAS,IAAI;YAClD,IAAI,CAAC,IAAI,GAAG,OAAO,QAAQ,CAAC,MAAM;QACpC,OAAO;YACL,IAAI,CAAC,IAAI,GAAG;QACd;QAEA,IAAI,IAAI,CAAC,IAAI,KAAK,GAAG;YACnB,MAAM,IAAI,QAAA,eAAe,CAAC;QAC5B;QACA,OAAO,MAAM,CAAC,IAAI;IACpB;IAEA,CAAC,OAAO,GAAG,CAAC,8BAA8B,GAAA;QACxC,OAAO,IAAI,CAAC,OAAO;IACrB;IAEA,UAAO;QACL,OAAO,CAAA,iBAAA,EAAoB,IAAI,CAAC,QAAQ,GAAE,EAAA,CAAI;IAChD;IAEA,WAAQ;QACN,IAAI,OAAO,IAAI,CAAC,IAAI,KAAK,UAAU;YACjC,IAAI,IAAI,CAAC,MAAM,EAAE;gBACf,OAAO,CAAA,CAAA,EAAI,IAAI,CAAC,IAAI,CAAA,EAAA,EAAK,IAAI,CAAC,IAAI,CAAA,CAAE;YACtC;YACA,OAAO,CAAA,EAAG,IAAI,CAAC,IAAI,CAAA,CAAA,EAAI,IAAI,CAAC,IAAI,CAAA,CAAE;QACpC;QACA,OAAO,CAAA,EAAG,IAAI,CAAC,UAAU,CAAA,CAAE;IAC7B;IAEA,OAAO,WAAuB,CAAS,EAAA;QACrC,OAAO,IAAI,YAAY;IACzB;IAEA,OAAO,aAAa,IAAY,EAAE,IAAY,EAAA;QAC5C,IAAI,KAAK,QAAQ,CAAC,MAAM;YACtB,OAAO,CAAA,CAAA,EAAI,KAAI,CAAA,CAAG,EAAE,eAAe;QACrC;QACA,OAAO,YAAY,UAAU,CAAC,CAAA,EAAG,KAAI,CAAA,EAAI,KAAI,CAAE;IACjD;IAEA,OAAO,cAAc,EAAE,IAAI,EAAE,IAAI,EAAa,EAAA;QAC5C,OAAO,YAAY,YAAY,CAAC,MAAM;IACxC;IAEA,aAAU;QACR,IAAI,IAAI,CAAC,UAAU,EAAE;YACnB,OAAO;gBAAE,MAAM,IAAI,CAAC,UAAU;gBAAE,MAAM;YAAC;QACzC;QAEA,MAAM,OAAO,IAAI,CAAC,IAAI,IAAI;QAC1B,MAAM,OAAO,IAAI,CAAC,IAAI,IAAI;QAC1B,OAAO;YAAE;YAAM;QAAI;IACrB;;AA3FF,QAAA,WAAA,GAAA;AA8Fa,QAAA,kBAAkB,GAAG;IAChC,6DAA6D;IAC7D;QACE,OAAO,IAAI,OAAA,QAAQ;IACrB;;AAGF;;;;;;;;;;IAWa,QAAA,oBAAoB,GAAG;AAEpC,cAAA,GACA,SAAgB,YAAY,OAAe;IACzC,OAAO,QAAQ,WAAW,CAAC,SAAS;QAAE,MAAM,QAAA,oBAAoB;IAAA;AAClE;AAEA,MAAM,kBAAkB,IAAI;AAC5B;;;;;IAMA,SAAgB,gBAAgB,OAAe;IAC7C,IAAI,CAAC,gBAAgB,GAAG,CAAC,UAAU;QACjC,gBAAgB,GAAG,CAAC;QACpB,OAAO,YAAY;IACrB;AACF;AAEA;;IAGA,SAAgB,aAAa,EAA2B;IACtD,OAAO,OAAO,MAAM,CAAC,IAAI,IAAI,CAAC;AAChC;AAEA;;;;IAKA,SAAgB,wBAAwB,MAAe;IACrD,IAAI,CAAC,QAAQ;QACX,OAAO;IACT;IAEA,IAAI,OAAO,YAAY,EAAE;QACvB,2DAA2D;QAC3D,OAAO;IACT;IAEA,IAAI,OAAO,WAAW,CAAC,4BAA4B,IAAI,MAAM;QAC3D,yBAAyB;QACzB,IAAI,OAAO,WAAW,CAAC,IAAI,KAAK,SAAA,UAAU,CAAC,UAAU,EAAE;YACrD,+BAA+B;YAC/B,OAAO;QACT;IACF;IAEA,OAAO;AACT;AAEA;;;;;;IAOA,SAAgB,QAAW,QAAqB,EAAE,QAAQ,CAAC;IACzD,MAAM,QAAQ,MAAM,IAAI,CAAC,WAAW,mDAAmD;IAEvF,IAAI,QAAQ,MAAM,MAAM,EAAE;QACxB,MAAM,IAAI,QAAA,iBAAiB,CAAC;IAC9B;IAEA,IAAI,0BAA0B,MAAM,MAAM;IAC1C,MAAM,aAAa,QAAQ,MAAM,MAAM,KAAK,IAAI,IAAI,MAAM,MAAM,GAAG;IACnE,MAAO,0BAA0B,WAAY;QAC3C,2BAA2B;QAC3B,MAAM,cAAc,KAAK,KAAK,CAAC,KAAK,MAAM,KAAK;QAC/C,2BAA2B;QAE3B,uCAAuC;QACvC,MAAM,WAAW,KAAK,CAAC,wBAAwB;QAC/C,KAAK,CAAC,wBAAwB,GAAG,KAAK,CAAC,YAAY;QACnD,KAAK,CAAC,YAAY,GAAG;IACvB;IAEA,OAAO,QAAQ,MAAM,MAAM,KAAK,IAAI,QAAQ,MAAM,KAAK,CAAC;AAC1D;AAEA;;;;IAKA,SAAgB,2BAA2B,OAAiB;IAC1D,IAAI,QAAQ,SAAS,IAAI,QAAQ,KAAK,IAAI,QAAQ,QAAQ,IAAI,QAAQ,IAAI,IAAI,QAAQ,OAAO,EAAE;QAC7F,OAAO;IACT;IAEA,OAAO;AACT;AAEA;;;;;IAMA,SAAgB,gBAAgB,IAAsB,EAAE,IAAsB;IAC5E,IAAI,QAAQ,QAAQ,QAAQ,MAAM;QAChC,OAAO;IACT;IAEA,IAAI,QAAQ,MAAM;QAChB,OAAO,CAAC;IACV;IAEA,IAAI,QAAQ,MAAM;QAChB,OAAO;IACT;IAEA,OAAO,QAAA,SAAS,CAAC,OAAO,CAAC,KAAK,EAAE,EAAE,KAAK,EAAE;AAC3C;AAEA,SAAgB,aAAa,KAAc;IACzC,IAAI,OAAO,UAAU,UAAU,OAAO,KAAK,KAAK,CAAC;IACjD,MAAM,cAAc,OAAO,QAAQ,CAAC,OAAO,QAAQ;IAEnD,OAAO,OAAO,KAAK,CAAC,eAAe,OAAO;AAC5C;AAEA,SAAgB,qBAAqB,KAAc;IACjD,MAAM,YAAY,aAAa;IAE/B,OAAO,aAAa,QAAQ,aAAa,IAAI,YAAY;AAC3D;AAEA;;;;;;;;;;;IAYA,SAAgB,uBAAuB,OAAe,EAAE,OAAe;IACrE,mFAAmF;IACnF,MAAM,oBAAoB,QAAQ,QAAQ,CAAC,OAAO,QAAQ,KAAK,CAAC,GAAG,QAAQ,MAAM,GAAG,KAAK;IACzF,MAAM,oBAAoB,QAAQ,QAAQ,CAAC,OAAO,QAAQ,KAAK,CAAC,GAAG,QAAQ,MAAM,GAAG,KAAK;IAEzF,MAAM,6BAA6B;IACnC,MAAM,0BAA0B,kBAAkB,KAAK,CAAC,KAAK,MAAM,GAAG;IACtE,yCAAyC;IACzC,oCAAoC;IACpC,uCAAuC;IACvC,yEAAyE;IACzE,MAAM,gBAAgB,CAAA,CAAA,EAAI,kBAAkB,OAAO,CAAC,4BAA4B,IAAG,CAAE;IACrF,IAAI,gBAAgB,0BAChB,oBACA,CAAA,CAAA,EAAI,kBAAkB,OAAO,CAAC,4BAA4B,IAAG,CAAE;IAEnE,IAAI,CAAC,cAAc,UAAU,CAAC,MAAM;QAClC,gBAAgB,MAAM;IACxB;IACA,IACE,2BACA,kBAAkB,KAAK,CAAC,KAAK,MAAM,IAAI,kBAAkB,KAAK,CAAC,KAAK,MAAM,EAC1E;QACA,MAAM,IAAI,QAAA,aAAa,CACrB;IAEJ;IACA,IAAI,CAAC,cAAc,QAAQ,CAAC,gBAAgB;QAC1C,MAAM,IAAI,QAAA,aAAa,CAAC;IAC1B;AACF;AASA;;;IAIA,SAAgB,IACd,GAAiB,EACjB,UAA+B,CAAA,CAAE;IAEjC,OAAO,IAAI,QAAQ,CAAC,SAAS;QAC3B,+BAAA,GACA,IAAI;QACJ,MAAM,UAAU,KACb,GAAG,CAAC,KAAK,SAAS,CAAA;YACjB,SAAS,WAAW,CAAC;YACrB,IAAI,OAAO;YACX,SAAS,EAAE,CAAC,QAAQ,CAAA,QAAU,QAAQ;YACtC,SAAS,EAAE,CAAC,OAAO;gBACjB,CAAA,GAAA,SAAA,YAAY,EAAC;gBACb,QAAQ;oBAAE,QAAQ,SAAS,UAAU;oBAAE;gBAAI;YAC7C;QACF,GACC,EAAE,CAAC,SAAS,CAAA;YACX,CAAA,GAAA,SAAA,YAAY,EAAC;YACb,OAAO;QACT,GACC,GAAG;QACN,YAAY,CAAA,GAAA,SAAA,UAAU,EAAC;YACrB,QAAQ,OAAO,CAAC,IAAI,QAAA,wBAAwB,CAAC,CAAA,kCAAA,CAAoC;QACnF,GAAG;IACL;AACF;AAWO,eAAe,QACpB,GAAW,EACX,UAA0B,CAAA,CAAE;IAE5B,OAAO,MAAM,IAAI,QAAsC,CAAC,SAAS;QAC/D,MAAM,iBAAiB;YACrB,QAAQ;YACR,SAAS;YACT,MAAM;YACN,GAAG,IAAI,KAAK,CAAC,IAAI;YACjB,GAAG,OAAO;;QAGZ,MAAM,MAAM,KAAK,OAAO,CAAC,gBAAgB,CAAA;YACvC,IAAI,WAAW,CAAC;YAEhB,IAAI,OAAO;YACX,IAAI,EAAE,CAAC,QAAQ,CAAA;gBACb,QAAQ;YACV;YAEA,IAAI,IAAI,CAAC,OAAO;gBACd,IAAI,QAAQ,IAAI,KAAK,OAAO;oBAC1B,QAAQ;oBACR;gBACF;gBAEA,IAAI;oBACF,MAAM,SAAS,KAAK,KAAK,CAAC;oBAC1B,QAAQ;gBACV,EAAE,OAAM;oBACN,kBAAkB;oBAClB,OAAO,IAAI,QAAA,iBAAiB,CAAC,CAAA,wBAAA,EAA2B,KAAI,CAAA,CAAG;gBACjE;YACF;QACF;QAEA,IAAI,IAAI,CAAC,WAAW,IAClB,IAAI,OAAO,CACT,IAAI,QAAA,wBAAwB,CAC1B,CAAA,mBAAA,EAAsB,IAAG,iBAAA,EAAoB,QAAQ,OAAO,CAAA,GAAA,CAAK;QAIvE,IAAI,IAAI,CAAC,SAAS,CAAA,QAAS,OAAO;QAClC,IAAI,GAAG;IACT;AACF;AAEA,cAAA,GACa,QAAA,iBAAiB,GAAG;AACjC,cAAA,GACa,QAAA,eAAe,GAAG;AAE/B,cAAA,GACa,QAAA,eAAe,GAC1B;AACF,cAAA,GACa,QAAA,aAAa,GACxB;AAEF,cAAA,GACA,SAAgB,YAAY,KAAa,EAAE,IAAa;IACtD,OAAO,QAAQ,MAAM,IAAI,CAAC,KAAK,WAAW,MAAM,OAAO;AACzD;AAEA,SAAgB;IAKd,IAAI;IACJ,IAAI;IACJ,MAAM,UAAU,IAAI,QAAW,SAAS,sBAAsB,cAAc,EAAE,aAAa;QACzF,UAAU;QACV,SAAS;IACX;IACA,OAAO;QAAE;QAAS;QAAS;IAAM;AACnC;AAEA;;;;;;;;;IAUA,SAAgB,YAAY,MAAe;IACzC;AACF;AAEa,QAAA,WAAW,GAAG,CAAA,GAAA,OAAA,SAAS,EAAC,OAAO,WAAW;AAEvD;;;;;;;IAQO,eAAe,KAAQ,EAAgB,EAAE,IAAY,EAAE,OAAmB;IAC/E,SAAS,QAAQ;IAEjB,MAAM,EAAE,OAAO,EAAE,OAAO,EAAE,MAAM,EAAE,GAAG;IACrC,MAAM,UAAU,CAAC,OAAY,QAAQ;IACrC,MAAM,UAAU,CAAC,QAAiB,OAAO;IACzC,MAAM,gBAAgB,iBAAiB,SAAS,QAAQ;QACtD,OAAO,IAAI,CAAC,MAAM;IACpB;IAEA,GAAG,IAAI,CAAC,MAAM,SAAS,IAAI,CAAC,SAAS;IAErC,IAAI;QACF,OAAO,MAAM;IACf,SAAU;QACR,GAAG,GAAG,CAAC,MAAM;QACb,GAAG,GAAG,CAAC,SAAS;QAChB,eAAe,CAAC,QAAA,QAAQ,CAAC;IAC3B;AACF;AAYA,SAAgB,sBACd,IAAgB,EAChB,SAAgC,EAChC,OAA0C;IAE1C,MAAM,sBACJ,OAAO,QAAQ,mBAAmB,KAAK,YACnC,QAAQ,mBAAmB,GAC3B,KAAK,CAAC,CAAC,EAAE,CAAC,OAAO,EAAE;IAEzB,yDAAyD;IACzD,IAAI,wBAAwB,MAAM;QAChC,OAAO;IACT;IAEA,MAAM,YAAY,CAAC;QACjB,IAAI,IAAI,GAAG,IAAI,MAAM;YACnB,IAAI,GAAG,GAAG,KAAK,CAAC,CAAC,SAAS,CAAC,QAAQ;QACrC;QAEA,OAAO;IACT;IACA,OAAO,MAAM,OAAO,CAAC,aAAa,UAAU,GAAG,CAAC,aAAa,UAAU;AACzE;AAEO,eAAe,iBAAiB,QAAgB,EAAE,IAAa;IACpE,IAAI;QACF,MAAM,KAAA,QAAE,CAAC,MAAM,CAAC,UAAU;QAC1B,OAAO;IACT,EAAE,OAAM;QACN,OAAO;IACT;AACF;AAEA,SAAgB,QAAQ,SAAiB,EAAE,SAAiB;IAC1D,IAAI,cAAc,GAAG,OAAO;IAC5B,IAAI,cAAc,GAAG,OAAO;IAC5B,OAAO,KAAK,GAAG,CAAC,WAAW;AAC7B;AAEA,SAAgB;IACd;AACF;AAEA;;;;;;;IAQA,SAAgB,yBACd,SAA0D,EAC1D,QAAkB,EAClB,yBAAyB,IAAI;IAE7B,IAAI,wBAAwB;QAC1B,yEAAyE;QACzE,IAAI,OAAO,QAAQ,CAAC,WAAW;YAC7B,WAAW,CAAA,GAAA,OAAA,WAAW,EAAC;QACzB;QACA,IAAI,OAAO,QAAQ,CAAC,YAAY;YAC9B,MAAM,IAAI,QAAA,iBAAiB,CAAC;QAC9B;IACF;IAEA,IAAI,CAAC,aAAa,OAAO,cAAc,UAAU;IACjD,KAAK,MAAM,KAAK,OAAO,IAAI,CAAC,WAAY;QACtC,MAAM,gBAAgB,QAAQ,CAAC,EAAE;QAEjC,iEAAiE;QACjE,uCAAuC;QACvC,IAAI,iBAAiB,cAAc,SAAS,KAAK,YAAY,cAAc,QAAQ,KAAK,GAAG;YACzF,IAAI,CAAC,SAAS,CAAC,YAAA,cAAc,CAAC,EAAE;gBAC9B,OAAO,cAAc,CAAC,WAAW,YAAA,cAAc,EAAE;oBAC/C,OAAO,EAAE;oBACT,cAAc;oBACd,YAAY;oBACZ,UAAU;;YAEd;YACA,gDAAgD;YAChD,oEAAoE;YACpE,SAAS,CAAC,YAAA,cAAc,CAAE,CAAC,IAAI,CAAC;YAGhC;QACF;QAEA,yBAAyB,SAAS,CAAC,EAAE,EAAE,eAAe;IACxD;AACF;AAEA,cAAA,GACa,QAAA,QAAQ,GAAmB,OAAO,OAAe,IAAI,OAAO;AAOzE;;;;;;;;;;;;;IAcA,SAAgB,iBACd,MAAsC,EACtC,QAAmD;IAEnD,IAAI,UAAU,MAAM;IACpB,OAAO,gBAAgB,CAAC,SAAS,UAAU;QAAE,MAAM;IAAI;IACvD,OAAO;QAAE,CAAC,QAAA,QAAQ,CAAC,EAAE,IAAM,OAAO,mBAAmB,CAAC,SAAS;IAAS;AAC1E;AAEA;;;;;;;;;;;;IAaO,eAAe,UACpB,OAAmB,EACnB,EAAE,MAAM,EAA4B;IAEpC,IAAI,UAAU,MAAM;QAClB,OAAO,MAAM;IACf;IAEA,MAAM,EAAE,SAAS,OAAO,EAAE,MAAM,EAAE,GAAG;IAErC,MAAM,gBAAgB,OAAO,OAAO,GAChC,OAAO,OAAO,MAAM,IACpB,iBAAiB,QAAQ;QACvB,OAAO,IAAI,CAAC,MAAM;IACpB;IAEJ,IAAI;QACF,OAAO,MAAM,QAAQ,IAAI,CAAC;YAAC;YAAS;SAAQ;IAC9C,SAAU;QACR,eAAe,CAAC,QAAA,QAAQ,CAAC;IAC3B;AACF"}},
    {"offset": {"line": 3118, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 3122, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/timeout.ts"],"sourcesContent":["import { clearTimeout, setTimeout } from 'timers';\n\nimport { type Document } from './bson';\nimport { MongoInvalidArgumentError, MongoOperationTimeoutError, MongoRuntimeError } from './error';\nimport { type ClientSession } from './sessions';\nimport { csotMin, noop, squashError } from './utils';\n\n/** @internal */\nexport class TimeoutError extends Error {\n  duration: number;\n  override get name(): 'TimeoutError' {\n    return 'TimeoutError';\n  }\n\n  constructor(message: string, options: { cause?: Error; duration: number }) {\n    super(message, options);\n    this.duration = options.duration;\n  }\n\n  static is(error: unknown): error is TimeoutError {\n    return (\n      error != null && typeof error === 'object' && 'name' in error && error.name === 'TimeoutError'\n    );\n  }\n}\n\ntype Executor = ConstructorParameters<typeof Promise<never>>[0];\ntype Reject = Parameters<ConstructorParameters<typeof Promise<never>>[0]>[1];\n/**\n * @internal\n * This class is an abstraction over timeouts\n * The Timeout class can only be in the pending or rejected states. It is guaranteed not to resolve\n * if interacted with exclusively through its public API\n * */\nexport class Timeout extends Promise<never> {\n  private id?: NodeJS.Timeout;\n\n  public readonly start: number;\n  public ended: number | null = null;\n  public duration: number;\n  private timedOut = false;\n  public cleared = false;\n\n  get remainingTime(): number {\n    if (this.timedOut) return 0;\n    if (this.duration === 0) return Infinity;\n    return this.start + this.duration - Math.trunc(performance.now());\n  }\n\n  get timeElapsed(): number {\n    return Math.trunc(performance.now()) - this.start;\n  }\n\n  /** Create a new timeout that expires in `duration` ms */\n  private constructor(\n    executor: Executor = () => null,\n    options?: { duration: number; unref?: true; rejection?: Error }\n  ) {\n    const duration = options?.duration ?? 0;\n    const unref = !!options?.unref;\n    const rejection = options?.rejection;\n\n    if (duration < 0) {\n      throw new MongoInvalidArgumentError('Cannot create a Timeout with a negative duration');\n    }\n\n    let reject!: Reject;\n    super((_, promiseReject) => {\n      reject = promiseReject;\n\n      executor(noop, promiseReject);\n    });\n\n    this.duration = duration;\n    this.start = Math.trunc(performance.now());\n\n    if (rejection == null && this.duration > 0) {\n      this.id = setTimeout(() => {\n        this.ended = Math.trunc(performance.now());\n        this.timedOut = true;\n        reject(new TimeoutError(`Expired after ${duration}ms`, { duration }));\n      }, this.duration);\n      if (typeof this.id.unref === 'function' && unref) {\n        // Ensure we do not keep the Node.js event loop running\n        this.id.unref();\n      }\n    } else if (rejection != null) {\n      this.ended = Math.trunc(performance.now());\n      this.timedOut = true;\n      reject(rejection);\n    }\n  }\n\n  /**\n   * Clears the underlying timeout. This method is idempotent\n   */\n  clear(): void {\n    clearTimeout(this.id);\n    this.id = undefined;\n    this.timedOut = false;\n    this.cleared = true;\n  }\n\n  throwIfExpired(): void {\n    if (this.timedOut) {\n      // This method is invoked when someone wants to throw immediately instead of await the result of this promise\n      // Since they won't be handling the rejection from the promise (because we're about to throw here)\n      // attach handling to prevent this from bubbling up to Node.js\n      this.then(undefined, squashError);\n      throw new TimeoutError('Timed out', { duration: this.duration });\n    }\n  }\n\n  public static expires(duration: number, unref?: true): Timeout {\n    return new Timeout(undefined, { duration, unref });\n  }\n\n  static override reject(rejection?: Error): Timeout {\n    return new Timeout(undefined, { duration: 0, unref: true, rejection });\n  }\n}\n\n/** @internal */\nexport type TimeoutContextOptions = (LegacyTimeoutContextOptions | CSOTTimeoutContextOptions) & {\n  session?: ClientSession;\n};\n\n/** @internal */\nexport type LegacyTimeoutContextOptions = {\n  serverSelectionTimeoutMS: number;\n  waitQueueTimeoutMS: number;\n  socketTimeoutMS?: number;\n};\n\n/** @internal */\nexport type CSOTTimeoutContextOptions = {\n  timeoutMS: number;\n  serverSelectionTimeoutMS: number;\n  socketTimeoutMS?: number;\n};\n\nfunction isLegacyTimeoutContextOptions(v: unknown): v is LegacyTimeoutContextOptions {\n  return (\n    v != null &&\n    typeof v === 'object' &&\n    'serverSelectionTimeoutMS' in v &&\n    typeof v.serverSelectionTimeoutMS === 'number' &&\n    'waitQueueTimeoutMS' in v &&\n    typeof v.waitQueueTimeoutMS === 'number'\n  );\n}\n\nfunction isCSOTTimeoutContextOptions(v: unknown): v is CSOTTimeoutContextOptions {\n  return (\n    v != null &&\n    typeof v === 'object' &&\n    'serverSelectionTimeoutMS' in v &&\n    typeof v.serverSelectionTimeoutMS === 'number' &&\n    'timeoutMS' in v &&\n    typeof v.timeoutMS === 'number'\n  );\n}\n\n/** @internal */\nexport abstract class TimeoutContext {\n  static create(options: TimeoutContextOptions): TimeoutContext {\n    if (options.session?.timeoutContext != null) return options.session?.timeoutContext;\n    if (isCSOTTimeoutContextOptions(options)) return new CSOTTimeoutContext(options);\n    else if (isLegacyTimeoutContextOptions(options)) return new LegacyTimeoutContext(options);\n    else throw new MongoRuntimeError('Unrecognized options');\n  }\n\n  abstract get maxTimeMS(): number | null;\n\n  abstract get serverSelectionTimeout(): Timeout | null;\n\n  abstract get connectionCheckoutTimeout(): Timeout | null;\n\n  abstract get clearServerSelectionTimeout(): boolean;\n\n  abstract get timeoutForSocketWrite(): Timeout | null;\n\n  abstract get timeoutForSocketRead(): Timeout | null;\n\n  abstract csotEnabled(): this is CSOTTimeoutContext;\n\n  abstract refresh(): void;\n\n  abstract clear(): void;\n\n  /** Returns a new instance of the TimeoutContext, with all timeouts refreshed and restarted. */\n  abstract refreshed(): TimeoutContext;\n\n  abstract addMaxTimeMSToCommand(command: Document, options: { omitMaxTimeMS?: boolean }): void;\n\n  abstract getSocketTimeoutMS(): number | undefined;\n}\n\n/** @internal */\nexport class CSOTTimeoutContext extends TimeoutContext {\n  timeoutMS: number;\n  serverSelectionTimeoutMS: number;\n  socketTimeoutMS?: number;\n\n  clearServerSelectionTimeout: boolean;\n\n  private _serverSelectionTimeout?: Timeout | null;\n  private _connectionCheckoutTimeout?: Timeout | null;\n  public minRoundTripTime = 0;\n  public start: number;\n\n  constructor(options: CSOTTimeoutContextOptions) {\n    super();\n    this.start = Math.trunc(performance.now());\n\n    this.timeoutMS = options.timeoutMS;\n\n    this.serverSelectionTimeoutMS = options.serverSelectionTimeoutMS;\n\n    this.socketTimeoutMS = options.socketTimeoutMS;\n\n    this.clearServerSelectionTimeout = false;\n  }\n\n  get maxTimeMS(): number {\n    return this.remainingTimeMS - this.minRoundTripTime;\n  }\n\n  get remainingTimeMS() {\n    const timePassed = Math.trunc(performance.now()) - this.start;\n    return this.timeoutMS <= 0 ? Infinity : this.timeoutMS - timePassed;\n  }\n\n  csotEnabled(): this is CSOTTimeoutContext {\n    return true;\n  }\n\n  get serverSelectionTimeout(): Timeout | null {\n    // check for undefined\n    if (typeof this._serverSelectionTimeout !== 'object' || this._serverSelectionTimeout?.cleared) {\n      const { remainingTimeMS, serverSelectionTimeoutMS } = this;\n      if (remainingTimeMS <= 0)\n        return Timeout.reject(\n          new MongoOperationTimeoutError(`Timed out in server selection after ${this.timeoutMS}ms`)\n        );\n      const usingServerSelectionTimeoutMS =\n        serverSelectionTimeoutMS !== 0 &&\n        csotMin(remainingTimeMS, serverSelectionTimeoutMS) === serverSelectionTimeoutMS;\n      if (usingServerSelectionTimeoutMS) {\n        this._serverSelectionTimeout = Timeout.expires(serverSelectionTimeoutMS);\n      } else {\n        if (remainingTimeMS > 0 && Number.isFinite(remainingTimeMS)) {\n          this._serverSelectionTimeout = Timeout.expires(remainingTimeMS);\n        } else {\n          this._serverSelectionTimeout = null;\n        }\n      }\n    }\n\n    return this._serverSelectionTimeout;\n  }\n\n  get connectionCheckoutTimeout(): Timeout | null {\n    if (\n      typeof this._connectionCheckoutTimeout !== 'object' ||\n      this._connectionCheckoutTimeout?.cleared\n    ) {\n      if (typeof this._serverSelectionTimeout === 'object') {\n        // null or Timeout\n        this._connectionCheckoutTimeout = this._serverSelectionTimeout;\n      } else {\n        throw new MongoRuntimeError(\n          'Unreachable. If you are seeing this error, please file a ticket on the NODE driver project on Jira'\n        );\n      }\n    }\n    return this._connectionCheckoutTimeout;\n  }\n\n  get timeoutForSocketWrite(): Timeout | null {\n    const { remainingTimeMS } = this;\n    if (!Number.isFinite(remainingTimeMS)) return null;\n    if (remainingTimeMS > 0) return Timeout.expires(remainingTimeMS);\n    return Timeout.reject(new MongoOperationTimeoutError('Timed out before socket write'));\n  }\n\n  get timeoutForSocketRead(): Timeout | null {\n    const { remainingTimeMS } = this;\n    if (!Number.isFinite(remainingTimeMS)) return null;\n    if (remainingTimeMS > 0) return Timeout.expires(remainingTimeMS);\n    return Timeout.reject(new MongoOperationTimeoutError('Timed out before socket read'));\n  }\n\n  refresh(): void {\n    this.start = Math.trunc(performance.now());\n    this.minRoundTripTime = 0;\n    this._serverSelectionTimeout?.clear();\n    this._connectionCheckoutTimeout?.clear();\n  }\n\n  clear(): void {\n    this._serverSelectionTimeout?.clear();\n    this._connectionCheckoutTimeout?.clear();\n  }\n\n  /**\n   * @internal\n   * Throws a MongoOperationTimeoutError if the context has expired.\n   * If the context has not expired, returns the `remainingTimeMS`\n   **/\n  getRemainingTimeMSOrThrow(message?: string): number {\n    const { remainingTimeMS } = this;\n    if (remainingTimeMS <= 0)\n      throw new MongoOperationTimeoutError(message ?? `Expired after ${this.timeoutMS}ms`);\n    return remainingTimeMS;\n  }\n\n  /**\n   * @internal\n   * This method is intended to be used in situations where concurrent operation are on the same deadline, but cannot share a single `TimeoutContext` instance.\n   * Returns a new instance of `CSOTTimeoutContext` constructed with identical options, but setting the `start` property to `this.start`.\n   */\n  clone(): CSOTTimeoutContext {\n    const timeoutContext = new CSOTTimeoutContext({\n      timeoutMS: this.timeoutMS,\n      serverSelectionTimeoutMS: this.serverSelectionTimeoutMS\n    });\n    timeoutContext.start = this.start;\n    return timeoutContext;\n  }\n\n  override refreshed(): CSOTTimeoutContext {\n    return new CSOTTimeoutContext(this);\n  }\n\n  override addMaxTimeMSToCommand(command: Document, options: { omitMaxTimeMS?: boolean }): void {\n    if (options.omitMaxTimeMS) return;\n    const maxTimeMS = this.remainingTimeMS - this.minRoundTripTime;\n    if (maxTimeMS > 0 && Number.isFinite(maxTimeMS)) command.maxTimeMS = maxTimeMS;\n  }\n\n  override getSocketTimeoutMS(): number | undefined {\n    return 0;\n  }\n}\n\n/** @internal */\nexport class LegacyTimeoutContext extends TimeoutContext {\n  options: LegacyTimeoutContextOptions;\n  clearServerSelectionTimeout: boolean;\n\n  constructor(options: LegacyTimeoutContextOptions) {\n    super();\n    this.options = options;\n    this.clearServerSelectionTimeout = true;\n  }\n\n  csotEnabled(): this is CSOTTimeoutContext {\n    return false;\n  }\n\n  get serverSelectionTimeout(): Timeout | null {\n    if (this.options.serverSelectionTimeoutMS != null && this.options.serverSelectionTimeoutMS > 0)\n      return Timeout.expires(this.options.serverSelectionTimeoutMS);\n    return null;\n  }\n\n  get connectionCheckoutTimeout(): Timeout | null {\n    if (this.options.waitQueueTimeoutMS != null && this.options.waitQueueTimeoutMS > 0)\n      return Timeout.expires(this.options.waitQueueTimeoutMS);\n    return null;\n  }\n\n  get timeoutForSocketWrite(): Timeout | null {\n    return null;\n  }\n\n  get timeoutForSocketRead(): Timeout | null {\n    return null;\n  }\n\n  refresh(): void {\n    return;\n  }\n\n  clear(): void {\n    return;\n  }\n\n  get maxTimeMS() {\n    return null;\n  }\n\n  override refreshed(): LegacyTimeoutContext {\n    return new LegacyTimeoutContext(this.options);\n  }\n\n  override addMaxTimeMSToCommand(_command: Document, _options: { omitMaxTimeMS?: boolean }): void {\n    // No max timeMS is added to commands in legacy timeout mode.\n  }\n\n  override getSocketTimeoutMS(): number | undefined {\n    return this.options.socketTimeoutMS;\n  }\n}\n"],"names":[],"mappings":";;;;;AAAA,MAAA;AAGA,MAAA;AAEA,MAAA;AAEA,cAAA,GACA,MAAa,qBAAqB;IAEhC,IAAa,OAAI;QACf,OAAO;IACT;IAEA,YAAY,OAAe,EAAE,OAA4C,CAAA;QACvE,KAAK,CAAC,SAAS;QACf,IAAI,CAAC,QAAQ,GAAG,QAAQ,QAAQ;IAClC;IAEA,OAAO,GAAG,KAAc,EAAA;QACtB,OACE,SAAS,QAAQ,OAAO,UAAU,YAAY,UAAU,SAAS,MAAM,IAAI,KAAK;IAEpF;;AAfF,QAAA,YAAA,GAAA;AAoBA;;;;;MAMA,MAAa,gBAAgB;IAS3B,IAAI,gBAAa;QACf,IAAI,IAAI,CAAC,QAAQ,EAAE,OAAO;QAC1B,IAAI,IAAI,CAAC,QAAQ,KAAK,GAAG,OAAO;QAChC,OAAO,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,QAAQ,GAAG,KAAK,KAAK,CAAC,YAAY,GAAG;IAChE;IAEA,IAAI,cAAW;QACb,OAAO,KAAK,KAAK,CAAC,YAAY,GAAG,MAAM,IAAI,CAAC,KAAK;IACnD;IAEA,uDAAA,GACA,YACE,WAAqB,IAAM,IAAI,EAC/B,OAA+D,CAAA;QAE/D,MAAM,WAAW,SAAS,YAAY;QACtC,MAAM,QAAQ,CAAC,CAAC,SAAS;QACzB,MAAM,YAAY,SAAS;QAE3B,IAAI,WAAW,GAAG;YAChB,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,IAAI;QACJ,KAAK,CAAC,CAAC,GAAG;YACR,SAAS;YAET,SAAS,QAAA,IAAI,EAAE;QACjB;QAjCK,IAAA,CAAA,KAAK,GAAkB;QAEtB,IAAA,CAAA,QAAQ,GAAG;QACZ,IAAA,CAAA,OAAO,GAAG;QAgCf,IAAI,CAAC,QAAQ,GAAG;QAChB,IAAI,CAAC,KAAK,GAAG,KAAK,KAAK,CAAC,YAAY,GAAG;QAEvC,IAAI,aAAa,QAAQ,IAAI,CAAC,QAAQ,GAAG,GAAG;YAC1C,IAAI,CAAC,EAAE,GAAG,CAAA,GAAA,SAAA,UAAU,EAAC;gBACnB,IAAI,CAAC,KAAK,GAAG,KAAK,KAAK,CAAC,YAAY,GAAG;gBACvC,IAAI,CAAC,QAAQ,GAAG;gBAChB,OAAO,IAAI,aAAa,CAAA,cAAA,EAAiB,SAAQ,EAAA,CAAI,EAAE;oBAAE;gBAAQ;YACnE,GAAG,IAAI,CAAC,QAAQ;YAChB,IAAI,OAAO,IAAI,CAAC,EAAE,CAAC,KAAK,KAAK,cAAc,OAAO;gBAChD,uDAAuD;gBACvD,IAAI,CAAC,EAAE,CAAC,KAAK;YACf;QACF,OAAO,IAAI,aAAa,MAAM;YAC5B,IAAI,CAAC,KAAK,GAAG,KAAK,KAAK,CAAC,YAAY,GAAG;YACvC,IAAI,CAAC,QAAQ,GAAG;YAChB,OAAO;QACT;IACF;IAEA;;QAGA,QAAK;QACH,CAAA,GAAA,SAAA,YAAY,EAAC,IAAI,CAAC,EAAE;QACpB,IAAI,CAAC,EAAE,GAAG;QACV,IAAI,CAAC,QAAQ,GAAG;QAChB,IAAI,CAAC,OAAO,GAAG;IACjB;IAEA,iBAAc;QACZ,IAAI,IAAI,CAAC,QAAQ,EAAE;YACjB,6GAA6G;YAC7G,kGAAkG;YAClG,8DAA8D;YAC9D,IAAI,CAAC,IAAI,CAAC,WAAW,QAAA,WAAW;YAChC,MAAM,IAAI,aAAa,aAAa;gBAAE,UAAU,IAAI,CAAC,QAAQ;YAAA;QAC/D;IACF;IAEO,OAAO,QAAQ,QAAgB,EAAE,KAAY,EAAA;QAClD,OAAO,IAAI,QAAQ,WAAW;YAAE;YAAU;QAAK;IACjD;IAEA,OAAgB,OAAO,SAAiB,EAAA;QACtC,OAAO,IAAI,QAAQ,WAAW;YAAE,UAAU;YAAG,OAAO;YAAM;QAAS;IACrE;;AArFF,QAAA,OAAA,GAAA;AA2GA,SAAS,8BAA8B,CAAU;IAC/C,OACE,KAAK,QACL,OAAO,MAAM,YACb,8BAA8B,KAC9B,OAAO,EAAE,wBAAwB,KAAK,YACtC,wBAAwB,KACxB,OAAO,EAAE,kBAAkB,KAAK;AAEpC;AAEA,SAAS,4BAA4B,CAAU;IAC7C,OACE,KAAK,QACL,OAAO,MAAM,YACb,8BAA8B,KAC9B,OAAO,EAAE,wBAAwB,KAAK,YACtC,eAAe,KACf,OAAO,EAAE,SAAS,KAAK;AAE3B;AAEA,cAAA,GACA,MAAsB;IACpB,OAAO,OAAO,OAA8B,EAAA;QAC1C,IAAI,QAAQ,OAAO,EAAE,kBAAkB,MAAM,OAAO,QAAQ,OAAO,EAAE;QACrE,IAAI,4BAA4B,UAAU,OAAO,IAAI,mBAAmB;aACnE,IAAI,8BAA8B,UAAU,OAAO,IAAI,qBAAqB;aAC5E,MAAM,IAAI,QAAA,iBAAiB,CAAC;IACnC;;AANF,QAAA,cAAA,GAAA;AAkCA,cAAA,GACA,MAAa,2BAA2B;IAYtC,YAAY,OAAkC,CAAA;QAC5C,KAAK;QAJA,IAAA,CAAA,gBAAgB,GAAG;QAKxB,IAAI,CAAC,KAAK,GAAG,KAAK,KAAK,CAAC,YAAY,GAAG;QAEvC,IAAI,CAAC,SAAS,GAAG,QAAQ,SAAS;QAElC,IAAI,CAAC,wBAAwB,GAAG,QAAQ,wBAAwB;QAEhE,IAAI,CAAC,eAAe,GAAG,QAAQ,eAAe;QAE9C,IAAI,CAAC,2BAA2B,GAAG;IACrC;IAEA,IAAI,YAAS;QACX,OAAO,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC,gBAAgB;IACrD;IAEA,IAAI,kBAAe;QACjB,MAAM,aAAa,KAAK,KAAK,CAAC,YAAY,GAAG,MAAM,IAAI,CAAC,KAAK;QAC7D,OAAO,IAAI,CAAC,SAAS,IAAI,IAAI,WAAW,IAAI,CAAC,SAAS,GAAG;IAC3D;IAEA,cAAW;QACT,OAAO;IACT;IAEA,IAAI,yBAAsB;QACxB,sBAAsB;QACtB,IAAI,OAAO,IAAI,CAAC,uBAAuB,KAAK,YAAY,IAAI,CAAC,uBAAuB,EAAE,SAAS;YAC7F,MAAM,EAAE,eAAe,EAAE,wBAAwB,EAAE,GAAG,IAAI;YAC1D,IAAI,mBAAmB,GACrB,OAAO,QAAQ,MAAM,CACnB,IAAI,QAAA,0BAA0B,CAAC,CAAA,oCAAA,EAAuC,IAAI,CAAC,SAAS,CAAA,EAAA,CAAI;YAE5F,MAAM,gCACJ,6BAA6B,KAC7B,CAAA,GAAA,QAAA,OAAO,EAAC,iBAAiB,8BAA8B;YACzD,IAAI,+BAA+B;gBACjC,IAAI,CAAC,uBAAuB,GAAG,QAAQ,OAAO,CAAC;YACjD,OAAO;gBACL,IAAI,kBAAkB,KAAK,OAAO,QAAQ,CAAC,kBAAkB;oBAC3D,IAAI,CAAC,uBAAuB,GAAG,QAAQ,OAAO,CAAC;gBACjD,OAAO;oBACL,IAAI,CAAC,uBAAuB,GAAG;gBACjC;YACF;QACF;QAEA,OAAO,IAAI,CAAC,uBAAuB;IACrC;IAEA,IAAI,4BAAyB;QAC3B,IACE,OAAO,IAAI,CAAC,0BAA0B,KAAK,YAC3C,IAAI,CAAC,0BAA0B,EAAE,SACjC;YACA,IAAI,OAAO,IAAI,CAAC,uBAAuB,KAAK,UAAU;gBACpD,kBAAkB;gBAClB,IAAI,CAAC,0BAA0B,GAAG,IAAI,CAAC,uBAAuB;YAChE,OAAO;gBACL,MAAM,IAAI,QAAA,iBAAiB,CACzB;YAEJ;QACF;QACA,OAAO,IAAI,CAAC,0BAA0B;IACxC;IAEA,IAAI,wBAAqB;QACvB,MAAM,EAAE,eAAe,EAAE,GAAG,IAAI;QAChC,IAAI,CAAC,OAAO,QAAQ,CAAC,kBAAkB,OAAO;QAC9C,IAAI,kBAAkB,GAAG,OAAO,QAAQ,OAAO,CAAC;QAChD,OAAO,QAAQ,MAAM,CAAC,IAAI,QAAA,0BAA0B,CAAC;IACvD;IAEA,IAAI,uBAAoB;QACtB,MAAM,EAAE,eAAe,EAAE,GAAG,IAAI;QAChC,IAAI,CAAC,OAAO,QAAQ,CAAC,kBAAkB,OAAO;QAC9C,IAAI,kBAAkB,GAAG,OAAO,QAAQ,OAAO,CAAC;QAChD,OAAO,QAAQ,MAAM,CAAC,IAAI,QAAA,0BAA0B,CAAC;IACvD;IAEA,UAAO;QACL,IAAI,CAAC,KAAK,GAAG,KAAK,KAAK,CAAC,YAAY,GAAG;QACvC,IAAI,CAAC,gBAAgB,GAAG;QACxB,IAAI,CAAC,uBAAuB,EAAE;QAC9B,IAAI,CAAC,0BAA0B,EAAE;IACnC;IAEA,QAAK;QACH,IAAI,CAAC,uBAAuB,EAAE;QAC9B,IAAI,CAAC,0BAA0B,EAAE;IACnC;IAEA;;;;SAKA,0BAA0B,OAAgB,EAAA;QACxC,MAAM,EAAE,eAAe,EAAE,GAAG,IAAI;QAChC,IAAI,mBAAmB,GACrB,MAAM,IAAI,QAAA,0BAA0B,CAAC,WAAW,CAAA,cAAA,EAAiB,IAAI,CAAC,SAAS,CAAA,EAAA,CAAI;QACrF,OAAO;IACT;IAEA;;;;QAKA,QAAK;QACH,MAAM,iBAAiB,IAAI,mBAAmB;YAC5C,WAAW,IAAI,CAAC,SAAS;YACzB,0BAA0B,IAAI,CAAC,wBAAwB;;QAEzD,eAAe,KAAK,GAAG,IAAI,CAAC,KAAK;QACjC,OAAO;IACT;IAES,YAAS;QAChB,OAAO,IAAI,mBAAmB,IAAI;IACpC;IAES,sBAAsB,OAAiB,EAAE,OAAoC,EAAA;QACpF,IAAI,QAAQ,aAAa,EAAE;QAC3B,MAAM,YAAY,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC,gBAAgB;QAC9D,IAAI,YAAY,KAAK,OAAO,QAAQ,CAAC,YAAY,QAAQ,SAAS,GAAG;IACvE;IAES,qBAAkB;QACzB,OAAO;IACT;;AAhJF,QAAA,kBAAA,GAAA;AAmJA,cAAA,GACA,MAAa,6BAA6B;IAIxC,YAAY,OAAoC,CAAA;QAC9C,KAAK;QACL,IAAI,CAAC,OAAO,GAAG;QACf,IAAI,CAAC,2BAA2B,GAAG;IACrC;IAEA,cAAW;QACT,OAAO;IACT;IAEA,IAAI,yBAAsB;QACxB,IAAI,IAAI,CAAC,OAAO,CAAC,wBAAwB,IAAI,QAAQ,IAAI,CAAC,OAAO,CAAC,wBAAwB,GAAG,GAC3F,OAAO,QAAQ,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC,wBAAwB;QAC9D,OAAO;IACT;IAEA,IAAI,4BAAyB;QAC3B,IAAI,IAAI,CAAC,OAAO,CAAC,kBAAkB,IAAI,QAAQ,IAAI,CAAC,OAAO,CAAC,kBAAkB,GAAG,GAC/E,OAAO,QAAQ,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC,kBAAkB;QACxD,OAAO;IACT;IAEA,IAAI,wBAAqB;QACvB,OAAO;IACT;IAEA,IAAI,uBAAoB;QACtB,OAAO;IACT;IAEA,UAAO;QACL;IACF;IAEA,QAAK;QACH;IACF;IAEA,IAAI,YAAS;QACX,OAAO;IACT;IAES,YAAS;QAChB,OAAO,IAAI,qBAAqB,IAAI,CAAC,OAAO;IAC9C;IAES,sBAAsB,QAAkB,EAAE,QAAqC,EAAA;IACtF,6DAA6D;IAC/D;IAES,qBAAkB;QACzB,OAAO,IAAI,CAAC,OAAO,CAAC,eAAe;IACrC;;AAxDF,QAAA,oBAAA,GAAA"}},
    {"offset": {"line": 3389, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 3393, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/mongo_logger.ts"],"sourcesContent":["import { inspect, promisify } from 'util';\n\nimport {\n  type Binary,\n  type BSONRegExp,\n  type BSONSymbol,\n  type Code,\n  type DBRef,\n  type Decimal128,\n  type Document,\n  type Double,\n  EJSON,\n  type EJSONOptions,\n  type Int32,\n  type Long,\n  type MaxKey,\n  type MinKey,\n  type ObjectId,\n  type Timestamp\n} from './bson';\nimport type { CommandStartedEvent } from './cmap/command_monitoring_events';\nimport type {\n  ConnectionCheckedInEvent,\n  ConnectionCheckedOutEvent,\n  ConnectionCheckOutFailedEvent,\n  ConnectionCheckOutStartedEvent,\n  ConnectionClosedEvent,\n  ConnectionCreatedEvent,\n  ConnectionPoolClearedEvent,\n  ConnectionPoolClosedEvent,\n  ConnectionPoolCreatedEvent,\n  ConnectionPoolReadyEvent,\n  ConnectionReadyEvent\n} from './cmap/connection_pool_events';\nimport {\n  COMMAND_FAILED,\n  COMMAND_STARTED,\n  COMMAND_SUCCEEDED,\n  CONNECTION_CHECK_OUT_FAILED,\n  CONNECTION_CHECK_OUT_STARTED,\n  CONNECTION_CHECKED_IN,\n  CONNECTION_CHECKED_OUT,\n  CONNECTION_CLOSED,\n  CONNECTION_CREATED,\n  CONNECTION_POOL_CLEARED,\n  CONNECTION_POOL_CLOSED,\n  CONNECTION_POOL_CREATED,\n  CONNECTION_POOL_READY,\n  CONNECTION_READY,\n  SERVER_CLOSED,\n  SERVER_HEARTBEAT_FAILED,\n  SERVER_HEARTBEAT_STARTED,\n  SERVER_HEARTBEAT_SUCCEEDED,\n  SERVER_OPENING,\n  SERVER_SELECTION_FAILED,\n  SERVER_SELECTION_STARTED,\n  SERVER_SELECTION_SUCCEEDED,\n  TOPOLOGY_CLOSED,\n  TOPOLOGY_DESCRIPTION_CHANGED,\n  TOPOLOGY_OPENING,\n  WAITING_FOR_SUITABLE_SERVER\n} from './constants';\nimport type {\n  ServerClosedEvent,\n  ServerOpeningEvent,\n  TopologyClosedEvent,\n  TopologyDescriptionChangedEvent,\n  TopologyOpeningEvent\n} from './sdam/events';\nimport type {\n  ServerSelectionEvent,\n  ServerSelectionFailedEvent,\n  ServerSelectionStartedEvent,\n  ServerSelectionSucceededEvent,\n  WaitingForSuitableServerEvent\n} from './sdam/server_selection_events';\nimport { HostAddress, isPromiseLike, isUint8Array, parseUnsignedInteger } from './utils';\n\n/**\n * @public\n * Severity levels align with unix syslog.\n * Most typical driver functions will log to debug.\n */\nexport const SeverityLevel = Object.freeze({\n  EMERGENCY: 'emergency',\n  ALERT: 'alert',\n  CRITICAL: 'critical',\n  ERROR: 'error',\n  WARNING: 'warn',\n  NOTICE: 'notice',\n  INFORMATIONAL: 'info',\n  DEBUG: 'debug',\n  TRACE: 'trace',\n  OFF: 'off'\n} as const);\n\n/** @internal */\nexport const DEFAULT_MAX_DOCUMENT_LENGTH = 1000;\n/** @public */\nexport type SeverityLevel = (typeof SeverityLevel)[keyof typeof SeverityLevel];\n\n/** @internal */\nclass SeverityLevelMap extends Map<SeverityLevel | number, SeverityLevel | number> {\n  constructor(entries: [SeverityLevel | number, SeverityLevel | number][]) {\n    const newEntries: [number | SeverityLevel, SeverityLevel | number][] = [];\n    for (const [level, value] of entries) {\n      newEntries.push([value, level]);\n    }\n\n    newEntries.push(...entries);\n    super(newEntries);\n  }\n\n  getNumericSeverityLevel(severity: SeverityLevel): number {\n    return this.get(severity) as number;\n  }\n\n  getSeverityLevelName(level: number): SeverityLevel | undefined {\n    return this.get(level) as SeverityLevel | undefined;\n  }\n}\n\n/** @internal */\nexport const SEVERITY_LEVEL_MAP = new SeverityLevelMap([\n  [SeverityLevel.OFF, -Infinity],\n  [SeverityLevel.EMERGENCY, 0],\n  [SeverityLevel.ALERT, 1],\n  [SeverityLevel.CRITICAL, 2],\n  [SeverityLevel.ERROR, 3],\n  [SeverityLevel.WARNING, 4],\n  [SeverityLevel.NOTICE, 5],\n  [SeverityLevel.INFORMATIONAL, 6],\n  [SeverityLevel.DEBUG, 7],\n  [SeverityLevel.TRACE, 8]\n]);\n\n/** @public */\nexport const MongoLoggableComponent = Object.freeze({\n  COMMAND: 'command',\n  TOPOLOGY: 'topology',\n  SERVER_SELECTION: 'serverSelection',\n  CONNECTION: 'connection',\n  CLIENT: 'client'\n} as const);\n\n/** @public */\nexport type MongoLoggableComponent =\n  (typeof MongoLoggableComponent)[keyof typeof MongoLoggableComponent];\n\n/** @internal */\nexport interface MongoLoggerEnvOptions {\n  /** Severity level for command component */\n  MONGODB_LOG_COMMAND?: string;\n  /** Severity level for topology component */\n  MONGODB_LOG_TOPOLOGY?: string;\n  /** Severity level for server selection component */\n  MONGODB_LOG_SERVER_SELECTION?: string;\n  /** Severity level for CMAP */\n  MONGODB_LOG_CONNECTION?: string;\n  /** Severity level for client */\n  MONGODB_LOG_CLIENT?: string;\n  /** Default severity level to be if any of the above are unset */\n  MONGODB_LOG_ALL?: string;\n  /** Max length of embedded EJSON docs. Setting to 0 disables truncation. Defaults to 1000. */\n  MONGODB_LOG_MAX_DOCUMENT_LENGTH?: string;\n  /** Destination for log messages. Must be 'stderr', 'stdout'. Defaults to 'stderr'. */\n  MONGODB_LOG_PATH?: string;\n}\n\n/** @public */\nexport interface LogComponentSeveritiesClientOptions {\n  /** Optional severity level for command component */\n  command?: SeverityLevel;\n  /** Optional severity level for topology component */\n  topology?: SeverityLevel;\n  /** Optional severity level for server selection component */\n  serverSelection?: SeverityLevel;\n  /** Optional severity level for connection component */\n  connection?: SeverityLevel;\n  /** Optional severity level for client component */\n  client?: SeverityLevel;\n  /** Optional default severity level to be used if any of the above are unset */\n  default?: SeverityLevel;\n}\n\n/** @internal */\nexport interface MongoLoggerMongoClientOptions {\n  /** Destination for log messages */\n  mongodbLogPath?: 'stdout' | 'stderr' | MongoDBLogWritable;\n  /** Severity levels for logger components */\n  mongodbLogComponentSeverities?: LogComponentSeveritiesClientOptions;\n  /** Max length of embedded EJSON docs. Setting to 0 disables truncation. Defaults to 1000. */\n  mongodbLogMaxDocumentLength?: number;\n}\n\n/** @internal */\nexport interface MongoLoggerOptions {\n  componentSeverities: {\n    /** Severity level for command component */\n    command: SeverityLevel;\n    /** Severity level for topology component */\n    topology: SeverityLevel;\n    /** Severity level for server selection component */\n    serverSelection: SeverityLevel;\n    /** Severity level for connection component */\n    connection: SeverityLevel;\n    /** Severity level for client component */\n    client: SeverityLevel;\n    /** Default severity level to be used if any of the above are unset */\n    default: SeverityLevel;\n  };\n  /** Max length of embedded EJSON docs. Setting to 0 disables truncation. Defaults to 1000. */\n  maxDocumentLength: number;\n  /** Destination for log messages. */\n  logDestination: MongoDBLogWritable;\n  /** For internal check to see if error should stop logging. */\n  logDestinationIsStdErr: boolean;\n}\n\n/**\n * Parses a string as one of SeverityLevel\n * @internal\n *\n * @param s - the value to be parsed\n * @returns one of SeverityLevel if value can be parsed as such, otherwise null\n */\nexport function parseSeverityFromString(s?: string): SeverityLevel | null {\n  const validSeverities: string[] = Object.values(SeverityLevel);\n  const lowerSeverity = s?.toLowerCase();\n\n  if (lowerSeverity != null && validSeverities.includes(lowerSeverity)) {\n    return lowerSeverity as SeverityLevel;\n  }\n\n  return null;\n}\n\n/** @internal */\nexport function createStdioLogger(stream: {\n  write: NodeJS.WriteStream['write'];\n}): MongoDBLogWritable {\n  return {\n    write: promisify((log: Log, cb: (error?: Error) => void): unknown => {\n      const logLine = inspect(log, { compact: true, breakLength: Infinity });\n      stream.write(`${logLine}\\n`, 'utf-8', cb);\n      return;\n    })\n  };\n}\n\n/**\n * resolves the MONGODB_LOG_PATH and mongodbLogPath options from the environment and the\n * mongo client options respectively. The mongodbLogPath can be either 'stdout', 'stderr', a NodeJS\n * Writable or an object which has a `write` method with the signature:\n * ```ts\n * write(log: Log): void\n * ```\n *\n * @returns the MongoDBLogWritable object to write logs to\n */\nfunction resolveLogPath(\n  { MONGODB_LOG_PATH }: MongoLoggerEnvOptions,\n  { mongodbLogPath }: MongoLoggerMongoClientOptions\n): { mongodbLogPath: MongoDBLogWritable; mongodbLogPathIsStdErr: boolean } {\n  if (typeof mongodbLogPath === 'string' && /^stderr$/i.test(mongodbLogPath)) {\n    return { mongodbLogPath: createStdioLogger(process.stderr), mongodbLogPathIsStdErr: true };\n  }\n  if (typeof mongodbLogPath === 'string' && /^stdout$/i.test(mongodbLogPath)) {\n    return { mongodbLogPath: createStdioLogger(process.stdout), mongodbLogPathIsStdErr: false };\n  }\n\n  if (typeof mongodbLogPath === 'object' && typeof mongodbLogPath?.write === 'function') {\n    return { mongodbLogPath: mongodbLogPath, mongodbLogPathIsStdErr: false };\n  }\n\n  if (MONGODB_LOG_PATH && /^stderr$/i.test(MONGODB_LOG_PATH)) {\n    return { mongodbLogPath: createStdioLogger(process.stderr), mongodbLogPathIsStdErr: true };\n  }\n  if (MONGODB_LOG_PATH && /^stdout$/i.test(MONGODB_LOG_PATH)) {\n    return { mongodbLogPath: createStdioLogger(process.stdout), mongodbLogPathIsStdErr: false };\n  }\n\n  return { mongodbLogPath: createStdioLogger(process.stderr), mongodbLogPathIsStdErr: true };\n}\n\nfunction resolveSeverityConfiguration(\n  clientOption: string | undefined,\n  environmentOption: string | undefined,\n  defaultSeverity: SeverityLevel\n): SeverityLevel {\n  return (\n    parseSeverityFromString(clientOption) ??\n    parseSeverityFromString(environmentOption) ??\n    defaultSeverity\n  );\n}\n\n/** @public */\nexport interface Log extends Record<string, any> {\n  t: Date;\n  c: MongoLoggableComponent;\n  s: SeverityLevel;\n  message?: string;\n}\n\n/**\n * @public\n *\n * A custom destination for structured logging messages.\n */\nexport interface MongoDBLogWritable {\n  /**\n   * This function will be called for every enabled log message.\n   *\n   * It can be sync or async:\n   * - If it is synchronous it will block the driver from proceeding until this method returns.\n   * - If it is asynchronous the driver will not await the returned promise. It will attach fulfillment handling (`.then`).\n   *   If the promise rejects the logger will write an error message to stderr and stop functioning.\n   *   If the promise resolves the driver proceeds to the next log message (or waits for new ones to occur).\n   *\n   * Tips:\n   * - We recommend writing an async `write` function that _never_ rejects.\n   *   Instead handle logging errors as necessary to your use case and make the write function a noop, until it can be recovered.\n   * - The Log messages are structured but **subject to change** since the intended purpose is informational.\n   *   Program against this defensively and err on the side of stringifying whatever is passed in to write in some form or another.\n   *\n   */\n  write(log: Log): PromiseLike<unknown> | unknown;\n}\n\nfunction compareSeverity(s0: SeverityLevel, s1: SeverityLevel): 1 | 0 | -1 {\n  const s0Num = SEVERITY_LEVEL_MAP.getNumericSeverityLevel(s0);\n  const s1Num = SEVERITY_LEVEL_MAP.getNumericSeverityLevel(s1);\n\n  return s0Num < s1Num ? -1 : s0Num > s1Num ? 1 : 0;\n}\n\n/**\n * @internal\n * Must be separate from Events API due to differences in spec requirements for logging a command success\n */\nexport type LoggableCommandSucceededEvent = {\n  address: string;\n  connectionId?: string | number;\n  requestId: number;\n  duration: number;\n  commandName: string;\n  reply: Document | undefined;\n  serviceId?: ObjectId;\n  name: typeof COMMAND_SUCCEEDED;\n  serverConnectionId: bigint | null;\n  databaseName: string;\n};\n\n/**\n * @internal\n * Must be separate from Events API due to differences in spec requirements for logging a command failure\n */\nexport type LoggableCommandFailedEvent = {\n  address: string;\n  connectionId?: string | number;\n  requestId: number;\n  duration: number;\n  commandName: string;\n  failure: Error;\n  serviceId?: ObjectId;\n  name: typeof COMMAND_FAILED;\n  serverConnectionId: bigint | null;\n  databaseName: string;\n};\n\n/**\n * @internal\n * Must be separate from Events API due to differences in spec requirements for logging server heartbeat beginning\n */\nexport type LoggableServerHeartbeatStartedEvent = {\n  topologyId: number;\n  awaited: boolean;\n  connectionId: string;\n  name: typeof SERVER_HEARTBEAT_STARTED;\n};\n\n/**\n * @internal\n * Must be separate from Events API due to differences in spec requirements for logging server heartbeat success\n */\nexport type LoggableServerHeartbeatSucceededEvent = {\n  topologyId: number;\n  awaited: boolean;\n  connectionId: string;\n  reply: Document;\n  serverConnectionId: number | '<monitor>';\n  duration: number;\n  name: typeof SERVER_HEARTBEAT_SUCCEEDED;\n};\n\n/**\n * @internal\n * Must be separate from Events API due to differences in spec requirements for logging server heartbeat failure\n */\nexport type LoggableServerHeartbeatFailedEvent = {\n  topologyId: number;\n  awaited: boolean;\n  connectionId: string;\n  failure: Error;\n  duration: number;\n  name: typeof SERVER_HEARTBEAT_FAILED;\n};\n\ntype SDAMLoggableEvent =\n  | ServerClosedEvent\n  | LoggableServerHeartbeatFailedEvent\n  | LoggableServerHeartbeatStartedEvent\n  | LoggableServerHeartbeatSucceededEvent\n  | ServerOpeningEvent\n  | TopologyClosedEvent\n  | TopologyDescriptionChangedEvent\n  | TopologyOpeningEvent;\n\n/** @internal */\nexport type LoggableEvent =\n  | ServerSelectionStartedEvent\n  | ServerSelectionFailedEvent\n  | ServerSelectionSucceededEvent\n  | WaitingForSuitableServerEvent\n  | CommandStartedEvent\n  | LoggableCommandSucceededEvent\n  | LoggableCommandFailedEvent\n  | ConnectionPoolCreatedEvent\n  | ConnectionPoolReadyEvent\n  | ConnectionPoolClosedEvent\n  | ConnectionPoolClearedEvent\n  | ConnectionCreatedEvent\n  | ConnectionReadyEvent\n  | ConnectionClosedEvent\n  | ConnectionCheckedInEvent\n  | ConnectionCheckedOutEvent\n  | ConnectionCheckOutStartedEvent\n  | ConnectionCheckOutFailedEvent\n  | ServerClosedEvent\n  | LoggableServerHeartbeatFailedEvent\n  | LoggableServerHeartbeatStartedEvent\n  | LoggableServerHeartbeatSucceededEvent\n  | ServerOpeningEvent\n  | TopologyClosedEvent\n  | TopologyDescriptionChangedEvent\n  | TopologyOpeningEvent;\n\n/** @internal */\nexport interface LogConvertible extends Record<string, any> {\n  toLog(): Record<string, any>;\n}\n\ntype BSONObject =\n  | BSONRegExp\n  | BSONSymbol\n  | Code\n  | DBRef\n  | Decimal128\n  | Double\n  | Int32\n  | Long\n  | MaxKey\n  | MinKey\n  | ObjectId\n  | Timestamp\n  | Binary;\n/** @internal */\nexport function stringifyWithMaxLen(\n  value: any,\n  maxDocumentLength: number,\n  options: EJSONOptions = {}\n): string {\n  let strToTruncate = '';\n\n  let currentLength = 0;\n  const maxDocumentLengthEnsurer = function maxDocumentLengthEnsurer(key: string, value: any) {\n    if (currentLength >= maxDocumentLength) {\n      return undefined;\n    }\n    // Account for root document\n    if (key === '') {\n      // Account for starting brace\n      currentLength += 1;\n      return value;\n    }\n\n    // +4 accounts for 2 quotation marks, colon and comma after value\n    // Note that this potentially undercounts since it does not account for escape sequences which\n    // will have an additional backslash added to them once passed through JSON.stringify.\n    currentLength += key.length + 4;\n\n    if (value == null) return value;\n\n    switch (typeof value) {\n      case 'string':\n        // +2 accounts for quotes\n        // Note that this potentially undercounts similarly to the key length calculation\n        currentLength += value.length + 2;\n        break;\n      case 'number':\n      case 'bigint':\n        currentLength += String(value).length;\n        break;\n      case 'boolean':\n        currentLength += value ? 4 : 5;\n        break;\n      case 'object':\n        if (isUint8Array(value)) {\n          // '{\"$binary\":{\"base64\":\"<base64 string>\",\"subType\":\"XX\"}}'\n          // This is an estimate based on the fact that the base64 is approximately 1.33x the length of\n          // the actual binary sequence https://en.wikipedia.org/wiki/Base64\n          currentLength += (22 + value.byteLength + value.byteLength * 0.33 + 18) | 0;\n        } else if ('_bsontype' in value) {\n          const v = value as BSONObject;\n          switch (v._bsontype) {\n            case 'Int32':\n              currentLength += String(v.value).length;\n              break;\n            case 'Double':\n              // Account for representing integers as <value>.0\n              currentLength +=\n                (v.value | 0) === v.value ? String(v.value).length + 2 : String(v.value).length;\n              break;\n            case 'Long':\n              currentLength += v.toString().length;\n              break;\n            case 'ObjectId':\n              // '{\"$oid\":\"XXXXXXXXXXXXXXXXXXXXXXXX\"}'\n              currentLength += 35;\n              break;\n            case 'MaxKey':\n            case 'MinKey':\n              // '{\"$maxKey\":1}' or '{\"$minKey\":1}'\n              currentLength += 13;\n              break;\n            case 'Binary':\n              // '{\"$binary\":{\"base64\":\"<base64 string>\",\"subType\":\"XX\"}}'\n              // This is an estimate based on the fact that the base64 is approximately 1.33x the length of\n              // the actual binary sequence https://en.wikipedia.org/wiki/Base64\n              currentLength += (22 + value.position + value.position * 0.33 + 18) | 0;\n              break;\n            case 'Timestamp':\n              // '{\"$timestamp\":{\"t\":<t>,\"i\":<i>}}'\n              currentLength += 19 + String(v.t).length + 5 + String(v.i).length + 2;\n              break;\n            case 'Code':\n              // '{\"$code\":\"<code>\"}' or '{\"$code\":\"<code>\",\"$scope\":<scope>}'\n              if (v.scope == null) {\n                currentLength += v.code.length + 10 + 2;\n              } else {\n                // Ignoring actual scope object, so this undercounts by a significant amount\n                currentLength += v.code.length + 10 + 11;\n              }\n              break;\n            case 'BSONRegExp':\n              // '{\"$regularExpression\":{\"pattern\":\"<pattern>\",\"options\":\"<options>\"}}'\n              currentLength += 34 + v.pattern.length + 13 + v.options.length + 3;\n              break;\n          }\n        }\n    }\n    return value;\n  };\n\n  if (typeof value === 'string') {\n    strToTruncate = value;\n  } else if (typeof value === 'function') {\n    strToTruncate = value.name;\n  } else {\n    try {\n      if (maxDocumentLength !== 0) {\n        strToTruncate = EJSON.stringify(value, maxDocumentLengthEnsurer, 0, options);\n      } else {\n        strToTruncate = EJSON.stringify(value, options);\n      }\n    } catch (e) {\n      strToTruncate = `Extended JSON serialization failed with: ${e.message}`;\n    }\n  }\n\n  // handle truncation that occurs in the middle of multi-byte codepoints\n  if (\n    maxDocumentLength !== 0 &&\n    strToTruncate.length > maxDocumentLength &&\n    strToTruncate.charCodeAt(maxDocumentLength - 1) !==\n      strToTruncate.codePointAt(maxDocumentLength - 1)\n  ) {\n    maxDocumentLength--;\n    if (maxDocumentLength === 0) {\n      return '';\n    }\n  }\n\n  return maxDocumentLength !== 0 && strToTruncate.length > maxDocumentLength\n    ? `${strToTruncate.slice(0, maxDocumentLength)}...`\n    : strToTruncate;\n}\n\n/** @internal */\nexport type Loggable = LoggableEvent | LogConvertible;\n\nfunction isLogConvertible(obj: Loggable): obj is LogConvertible {\n  const objAsLogConvertible = obj as LogConvertible;\n  // eslint-disable-next-line no-restricted-syntax\n  return objAsLogConvertible.toLog !== undefined && typeof objAsLogConvertible.toLog === 'function';\n}\n\nfunction attachServerSelectionFields(\n  log: Record<string, any>,\n  serverSelectionEvent: ServerSelectionEvent,\n  maxDocumentLength: number = DEFAULT_MAX_DOCUMENT_LENGTH\n) {\n  const { selector, operation, topologyDescription, message } = serverSelectionEvent;\n  log.selector = stringifyWithMaxLen(selector, maxDocumentLength);\n  log.operation = operation;\n  log.topologyDescription = stringifyWithMaxLen(topologyDescription, maxDocumentLength);\n  log.message = message;\n\n  return log;\n}\n\nfunction attachCommandFields(\n  log: Record<string, any>,\n  commandEvent: CommandStartedEvent | LoggableCommandSucceededEvent | LoggableCommandFailedEvent\n) {\n  log.commandName = commandEvent.commandName;\n  log.requestId = commandEvent.requestId;\n  log.driverConnectionId = commandEvent.connectionId;\n  const { host, port } = HostAddress.fromString(commandEvent.address).toHostPort();\n  log.serverHost = host;\n  log.serverPort = port;\n  if (commandEvent?.serviceId) {\n    log.serviceId = commandEvent.serviceId.toHexString();\n  }\n  log.databaseName = commandEvent.databaseName;\n  log.serverConnectionId = commandEvent.serverConnectionId;\n\n  return log;\n}\n\nfunction attachConnectionFields(log: Record<string, any>, event: any) {\n  const { host, port } = HostAddress.fromString(event.address).toHostPort();\n  log.serverHost = host;\n  log.serverPort = port;\n\n  return log;\n}\n\nfunction attachSDAMFields(log: Record<string, any>, sdamEvent: SDAMLoggableEvent) {\n  log.topologyId = sdamEvent.topologyId;\n  return log;\n}\n\nfunction attachServerHeartbeatFields(\n  log: Record<string, any>,\n  serverHeartbeatEvent:\n    | LoggableServerHeartbeatFailedEvent\n    | LoggableServerHeartbeatStartedEvent\n    | LoggableServerHeartbeatSucceededEvent\n) {\n  const { awaited, connectionId } = serverHeartbeatEvent;\n  log.awaited = awaited;\n  log.driverConnectionId = serverHeartbeatEvent.connectionId;\n  const { host, port } = HostAddress.fromString(connectionId).toHostPort();\n  log.serverHost = host;\n  log.serverPort = port;\n  return log;\n}\n\n/** @internal */\nexport function defaultLogTransform(\n  logObject: LoggableEvent | Record<string, any>,\n  maxDocumentLength: number = DEFAULT_MAX_DOCUMENT_LENGTH\n): Omit<Log, 's' | 't' | 'c'> {\n  let log: Omit<Log, 's' | 't' | 'c'> = Object.create(null);\n\n  switch (logObject.name) {\n    case SERVER_SELECTION_STARTED:\n      log = attachServerSelectionFields(log, logObject, maxDocumentLength);\n      return log;\n    case SERVER_SELECTION_FAILED:\n      log = attachServerSelectionFields(log, logObject, maxDocumentLength);\n      log.failure = logObject.failure?.message;\n      return log;\n    case SERVER_SELECTION_SUCCEEDED:\n      log = attachServerSelectionFields(log, logObject, maxDocumentLength);\n      log.serverHost = logObject.serverHost;\n      log.serverPort = logObject.serverPort;\n      return log;\n    case WAITING_FOR_SUITABLE_SERVER:\n      log = attachServerSelectionFields(log, logObject, maxDocumentLength);\n      log.remainingTimeMS = logObject.remainingTimeMS;\n      return log;\n    case COMMAND_STARTED:\n      log = attachCommandFields(log, logObject);\n      log.message = 'Command started';\n      log.command = stringifyWithMaxLen(logObject.command, maxDocumentLength, { relaxed: true });\n      log.databaseName = logObject.databaseName;\n      return log;\n    case COMMAND_SUCCEEDED:\n      log = attachCommandFields(log, logObject);\n      log.message = 'Command succeeded';\n      log.durationMS = logObject.duration;\n      log.reply = stringifyWithMaxLen(logObject.reply, maxDocumentLength, { relaxed: true });\n      return log;\n    case COMMAND_FAILED:\n      log = attachCommandFields(log, logObject);\n      log.message = 'Command failed';\n      log.durationMS = logObject.duration;\n      log.failure = logObject.failure?.message ?? '(redacted)';\n      return log;\n    case CONNECTION_POOL_CREATED:\n      log = attachConnectionFields(log, logObject);\n      log.message = 'Connection pool created';\n      if (logObject.options) {\n        const { maxIdleTimeMS, minPoolSize, maxPoolSize, maxConnecting, waitQueueTimeoutMS } =\n          logObject.options;\n        log = {\n          ...log,\n          maxIdleTimeMS,\n          minPoolSize,\n          maxPoolSize,\n          maxConnecting,\n          waitQueueTimeoutMS\n        };\n      }\n      return log;\n    case CONNECTION_POOL_READY:\n      log = attachConnectionFields(log, logObject);\n      log.message = 'Connection pool ready';\n      return log;\n    case CONNECTION_POOL_CLEARED:\n      log = attachConnectionFields(log, logObject);\n      log.message = 'Connection pool cleared';\n      if (logObject.serviceId?._bsontype === 'ObjectId') {\n        log.serviceId = logObject.serviceId?.toHexString();\n      }\n      return log;\n    case CONNECTION_POOL_CLOSED:\n      log = attachConnectionFields(log, logObject);\n      log.message = 'Connection pool closed';\n      return log;\n    case CONNECTION_CREATED:\n      log = attachConnectionFields(log, logObject);\n      log.message = 'Connection created';\n      log.driverConnectionId = logObject.connectionId;\n      return log;\n    case CONNECTION_READY:\n      log = attachConnectionFields(log, logObject);\n      log.message = 'Connection ready';\n      log.driverConnectionId = logObject.connectionId;\n      log.durationMS = logObject.durationMS;\n      return log;\n    case CONNECTION_CLOSED:\n      log = attachConnectionFields(log, logObject);\n      log.message = 'Connection closed';\n      log.driverConnectionId = logObject.connectionId;\n      switch (logObject.reason) {\n        case 'stale':\n          log.reason = 'Connection became stale because the pool was cleared';\n          break;\n        case 'idle':\n          log.reason =\n            'Connection has been available but unused for longer than the configured max idle time';\n          break;\n        case 'error':\n          log.reason = 'An error occurred while using the connection';\n          if (logObject.error) {\n            log.error = logObject.error;\n          }\n          break;\n        case 'poolClosed':\n          log.reason = 'Connection pool was closed';\n          break;\n        default:\n          log.reason = `Unknown close reason: ${logObject.reason}`;\n      }\n      return log;\n    case CONNECTION_CHECK_OUT_STARTED:\n      log = attachConnectionFields(log, logObject);\n      log.message = 'Connection checkout started';\n      return log;\n    case CONNECTION_CHECK_OUT_FAILED:\n      log = attachConnectionFields(log, logObject);\n      log.message = 'Connection checkout failed';\n      switch (logObject.reason) {\n        case 'poolClosed':\n          log.reason = 'Connection pool was closed';\n          break;\n        case 'timeout':\n          log.reason = 'Wait queue timeout elapsed without a connection becoming available';\n          break;\n        case 'connectionError':\n          log.reason = 'An error occurred while trying to establish a new connection';\n          if (logObject.error) {\n            log.error = logObject.error;\n          }\n          break;\n        default:\n          log.reason = `Unknown close reason: ${logObject.reason}`;\n      }\n      log.durationMS = logObject.durationMS;\n      return log;\n    case CONNECTION_CHECKED_OUT:\n      log = attachConnectionFields(log, logObject);\n      log.message = 'Connection checked out';\n      log.driverConnectionId = logObject.connectionId;\n      log.durationMS = logObject.durationMS;\n      return log;\n    case CONNECTION_CHECKED_IN:\n      log = attachConnectionFields(log, logObject);\n      log.message = 'Connection checked in';\n      log.driverConnectionId = logObject.connectionId;\n      return log;\n    case SERVER_OPENING:\n      log = attachSDAMFields(log, logObject);\n      log = attachConnectionFields(log, logObject);\n      log.message = 'Starting server monitoring';\n      return log;\n    case SERVER_CLOSED:\n      log = attachSDAMFields(log, logObject);\n      log = attachConnectionFields(log, logObject);\n      log.message = 'Stopped server monitoring';\n      return log;\n    case SERVER_HEARTBEAT_STARTED:\n      log = attachSDAMFields(log, logObject);\n      log = attachServerHeartbeatFields(log, logObject);\n      log.message = 'Server heartbeat started';\n      return log;\n    case SERVER_HEARTBEAT_SUCCEEDED:\n      log = attachSDAMFields(log, logObject);\n      log = attachServerHeartbeatFields(log, logObject);\n      log.message = 'Server heartbeat succeeded';\n      log.durationMS = logObject.duration;\n      log.serverConnectionId = logObject.serverConnectionId;\n      log.reply = stringifyWithMaxLen(logObject.reply, maxDocumentLength, { relaxed: true });\n      return log;\n    case SERVER_HEARTBEAT_FAILED:\n      log = attachSDAMFields(log, logObject);\n      log = attachServerHeartbeatFields(log, logObject);\n      log.message = 'Server heartbeat failed';\n      log.durationMS = logObject.duration;\n      log.failure = logObject.failure?.message;\n      return log;\n    case TOPOLOGY_OPENING:\n      log = attachSDAMFields(log, logObject);\n      log.message = 'Starting topology monitoring';\n      return log;\n    case TOPOLOGY_CLOSED:\n      log = attachSDAMFields(log, logObject);\n      log.message = 'Stopped topology monitoring';\n      return log;\n    case TOPOLOGY_DESCRIPTION_CHANGED:\n      log = attachSDAMFields(log, logObject);\n      log.message = 'Topology description changed';\n      log.previousDescription = log.reply = stringifyWithMaxLen(\n        logObject.previousDescription,\n        maxDocumentLength\n      );\n      log.newDescription = log.reply = stringifyWithMaxLen(\n        logObject.newDescription,\n        maxDocumentLength\n      );\n      return log;\n    default:\n      for (const [key, value] of Object.entries(logObject)) {\n        if (value != null) log[key] = value;\n      }\n  }\n  return log;\n}\n\n/** @internal */\nexport class MongoLogger {\n  componentSeverities: Record<MongoLoggableComponent, SeverityLevel>;\n  maxDocumentLength: number;\n  logDestination: MongoDBLogWritable;\n  logDestinationIsStdErr: boolean;\n  pendingLog: PromiseLike<unknown> | unknown = null;\n  private severities: Record<MongoLoggableComponent, Record<SeverityLevel, boolean>>;\n\n  /**\n   * This method should be used when logging errors that do not have a public driver API for\n   * reporting errors.\n   */\n  error = this.log.bind(this, 'error');\n  /**\n   * This method should be used to log situations where undesirable application behaviour might\n   * occur. For example, failing to end sessions on `MongoClient.close`.\n   */\n  warn = this.log.bind(this, 'warn');\n  /**\n   * This method should be used to report high-level information about normal driver behaviour.\n   * For example, the creation of a `MongoClient`.\n   */\n  info = this.log.bind(this, 'info');\n  /**\n   * This method should be used to report information that would be helpful when debugging an\n   * application. For example, a command starting, succeeding or failing.\n   */\n  debug = this.log.bind(this, 'debug');\n  /**\n   * This method should be used to report fine-grained details related to logic flow. For example,\n   * entering and exiting a function body.\n   */\n  trace = this.log.bind(this, 'trace');\n\n  constructor(options: MongoLoggerOptions) {\n    this.componentSeverities = options.componentSeverities;\n    this.maxDocumentLength = options.maxDocumentLength;\n    this.logDestination = options.logDestination;\n    this.logDestinationIsStdErr = options.logDestinationIsStdErr;\n    this.severities = this.createLoggingSeverities();\n  }\n\n  createLoggingSeverities(): Record<MongoLoggableComponent, Record<SeverityLevel, boolean>> {\n    const severities = Object();\n    for (const component of Object.values(MongoLoggableComponent)) {\n      severities[component] = {};\n      for (const severityLevel of Object.values(SeverityLevel)) {\n        severities[component][severityLevel] =\n          compareSeverity(severityLevel, this.componentSeverities[component]) <= 0;\n      }\n    }\n    return severities;\n  }\n\n  turnOffSeverities() {\n    for (const component of Object.values(MongoLoggableComponent)) {\n      this.componentSeverities[component] = SeverityLevel.OFF;\n      for (const severityLevel of Object.values(SeverityLevel)) {\n        this.severities[component][severityLevel] = false;\n      }\n    }\n  }\n\n  private logWriteFailureHandler(error: Error) {\n    if (this.logDestinationIsStdErr) {\n      this.turnOffSeverities();\n      this.clearPendingLog();\n      return;\n    }\n    this.logDestination = createStdioLogger(process.stderr);\n    this.logDestinationIsStdErr = true;\n    this.clearPendingLog();\n    this.error(MongoLoggableComponent.CLIENT, {\n      toLog: function () {\n        return {\n          message: 'User input for mongodbLogPath is now invalid. Logging is halted.',\n          error: error.message\n        };\n      }\n    });\n    this.turnOffSeverities();\n    this.clearPendingLog();\n  }\n\n  private clearPendingLog() {\n    this.pendingLog = null;\n  }\n\n  willLog(component: MongoLoggableComponent, severity: SeverityLevel): boolean {\n    if (severity === SeverityLevel.OFF) return false;\n    return this.severities[component][severity];\n  }\n\n  private log(\n    severity: SeverityLevel,\n    component: MongoLoggableComponent,\n    message: Loggable | string\n  ): void {\n    if (!this.willLog(component, severity)) return;\n\n    let logMessage: Log = { t: new Date(), c: component, s: severity };\n    if (typeof message === 'string') {\n      logMessage.message = message;\n    } else if (typeof message === 'object') {\n      if (isLogConvertible(message)) {\n        logMessage = { ...logMessage, ...message.toLog() };\n      } else {\n        logMessage = { ...logMessage, ...defaultLogTransform(message, this.maxDocumentLength) };\n      }\n    }\n\n    if (isPromiseLike(this.pendingLog)) {\n      this.pendingLog = this.pendingLog\n\n        .then(() => this.logDestination.write(logMessage))\n\n        .then(this.clearPendingLog.bind(this), this.logWriteFailureHandler.bind(this));\n      return;\n    }\n\n    try {\n      const logResult = this.logDestination.write(logMessage);\n      if (isPromiseLike(logResult)) {\n        this.pendingLog = logResult.then(\n          this.clearPendingLog.bind(this),\n          this.logWriteFailureHandler.bind(this)\n        );\n      }\n    } catch (error) {\n      this.logWriteFailureHandler(error);\n    }\n  }\n\n  /**\n   * Merges options set through environment variables and the MongoClient, preferring environment\n   * variables when both are set, and substituting defaults for values not set. Options set in\n   * constructor take precedence over both environment variables and MongoClient options.\n   *\n   * @remarks\n   * When parsing component severity levels, invalid values are treated as unset and replaced with\n   * the default severity.\n   *\n   * @param envOptions - options set for the logger from the environment\n   * @param clientOptions - options set for the logger in the MongoClient options\n   * @returns a MongoLoggerOptions object to be used when instantiating a new MongoLogger\n   */\n  static resolveOptions(\n    envOptions: MongoLoggerEnvOptions,\n    clientOptions: MongoLoggerMongoClientOptions\n  ): MongoLoggerOptions {\n    // client options take precedence over env options\n    const resolvedLogPath = resolveLogPath(envOptions, clientOptions);\n    const combinedOptions = {\n      ...envOptions,\n      ...clientOptions,\n      mongodbLogPath: resolvedLogPath.mongodbLogPath,\n      mongodbLogPathIsStdErr: resolvedLogPath.mongodbLogPathIsStdErr\n    };\n    const defaultSeverity = resolveSeverityConfiguration(\n      combinedOptions.mongodbLogComponentSeverities?.default,\n      combinedOptions.MONGODB_LOG_ALL,\n      SeverityLevel.OFF\n    );\n\n    return {\n      componentSeverities: {\n        command: resolveSeverityConfiguration(\n          combinedOptions.mongodbLogComponentSeverities?.command,\n          combinedOptions.MONGODB_LOG_COMMAND,\n          defaultSeverity\n        ),\n        topology: resolveSeverityConfiguration(\n          combinedOptions.mongodbLogComponentSeverities?.topology,\n          combinedOptions.MONGODB_LOG_TOPOLOGY,\n          defaultSeverity\n        ),\n        serverSelection: resolveSeverityConfiguration(\n          combinedOptions.mongodbLogComponentSeverities?.serverSelection,\n          combinedOptions.MONGODB_LOG_SERVER_SELECTION,\n          defaultSeverity\n        ),\n        connection: resolveSeverityConfiguration(\n          combinedOptions.mongodbLogComponentSeverities?.connection,\n          combinedOptions.MONGODB_LOG_CONNECTION,\n          defaultSeverity\n        ),\n        client: resolveSeverityConfiguration(\n          combinedOptions.mongodbLogComponentSeverities?.client,\n          combinedOptions.MONGODB_LOG_CLIENT,\n          defaultSeverity\n        ),\n        default: defaultSeverity\n      },\n      maxDocumentLength:\n        combinedOptions.mongodbLogMaxDocumentLength ??\n        parseUnsignedInteger(combinedOptions.MONGODB_LOG_MAX_DOCUMENT_LENGTH) ??\n        1000,\n      logDestination: combinedOptions.mongodbLogPath,\n      logDestinationIsStdErr: combinedOptions.mongodbLogPathIsStdErr\n    };\n  }\n}\n"],"names":[],"mappings":";;;;;AAkOA,QAAA,uBAAA,GAAA;AAYA,QAAA,iBAAA,GAAA;AAsOA,QAAA,mBAAA,GAAA;AA2MA,QAAA,mBAAA,GAAA;AA/pBA,MAAA;AAEA,MAAA;AAgCA,MAAA;AA0CA,MAAA;AAEA;;;;IAKa,QAAA,aAAa,GAAG,OAAO,MAAM,CAAC;IACzC,WAAW;IACX,OAAO;IACP,UAAU;IACV,OAAO;IACP,SAAS;IACT,QAAQ;IACR,eAAe;IACf,OAAO;IACP,OAAO;IACP,KAAK;;AAGP,cAAA,GACa,QAAA,2BAA2B,GAAG;AAI3C,cAAA,GACA,MAAM,yBAAyB;IAC7B,YAAY,OAA2D,CAAA;QACrE,MAAM,aAAiE,EAAE;QACzE,KAAK,MAAM,CAAC,OAAO,MAAM,IAAI,QAAS;YACpC,WAAW,IAAI,CAAC;gBAAC;gBAAO;aAAM;QAChC;QAEA,WAAW,IAAI,IAAI;QACnB,KAAK,CAAC;IACR;IAEA,wBAAwB,QAAuB,EAAA;QAC7C,OAAO,IAAI,CAAC,GAAG,CAAC;IAClB;IAEA,qBAAqB,KAAa,EAAA;QAChC,OAAO,IAAI,CAAC,GAAG,CAAC;IAClB;;AAGF,cAAA,GACa,QAAA,kBAAkB,GAAG,IAAI,iBAAiB;IACrD;QAAC,QAAA,aAAa,CAAC,GAAG;QAAE,CAAC;KAAS;IAC9B;QAAC,QAAA,aAAa,CAAC,SAAS;QAAE;KAAE;IAC5B;QAAC,QAAA,aAAa,CAAC,KAAK;QAAE;KAAE;IACxB;QAAC,QAAA,aAAa,CAAC,QAAQ;QAAE;KAAE;IAC3B;QAAC,QAAA,aAAa,CAAC,KAAK;QAAE;KAAE;IACxB;QAAC,QAAA,aAAa,CAAC,OAAO;QAAE;KAAE;IAC1B;QAAC,QAAA,aAAa,CAAC,MAAM;QAAE;KAAE;IACzB;QAAC,QAAA,aAAa,CAAC,aAAa;QAAE;KAAE;IAChC;QAAC,QAAA,aAAa,CAAC,KAAK;QAAE;KAAE;IACxB;QAAC,QAAA,aAAa,CAAC,KAAK;QAAE;KAAE;CACzB;AAED,YAAA,GACa,QAAA,sBAAsB,GAAG,OAAO,MAAM,CAAC;IAClD,SAAS;IACT,UAAU;IACV,kBAAkB;IAClB,YAAY;IACZ,QAAQ;;AA6EV;;;;;;IAOA,SAAgB,wBAAwB,CAAU;IAChD,MAAM,kBAA4B,OAAO,MAAM,CAAC,QAAA,aAAa;IAC7D,MAAM,gBAAgB,GAAG;IAEzB,IAAI,iBAAiB,QAAQ,gBAAgB,QAAQ,CAAC,gBAAgB;QACpE,OAAO;IACT;IAEA,OAAO;AACT;AAEA,cAAA,GACA,SAAgB,kBAAkB,MAEjC;IACC,OAAO;QACL,OAAO,CAAA,GAAA,OAAA,SAAS,EAAC,CAAC,KAAU;YAC1B,MAAM,UAAU,CAAA,GAAA,OAAA,OAAO,EAAC,KAAK;gBAAE,SAAS;gBAAM,aAAa;YAAQ;YACnE,OAAO,KAAK,CAAC,CAAA,EAAG,QAAO,EAAA,CAAI,EAAE,SAAS;YACtC;QACF;;AAEJ;AAEA;;;;;;;;;IAUA,SAAS,eACP,EAAE,gBAAgB,EAAyB,EAC3C,EAAE,cAAc,EAAiC;IAEjD,IAAI,OAAO,mBAAmB,YAAY,YAAY,IAAI,CAAC,iBAAiB;QAC1E,OAAO;YAAE,gBAAgB,kBAAkB,QAAQ,MAAM;YAAG,wBAAwB;QAAI;IAC1F;IACA,IAAI,OAAO,mBAAmB,YAAY,YAAY,IAAI,CAAC,iBAAiB;QAC1E,OAAO;YAAE,gBAAgB,kBAAkB,QAAQ,MAAM;YAAG,wBAAwB;QAAK;IAC3F;IAEA,IAAI,OAAO,mBAAmB,YAAY,OAAO,gBAAgB,UAAU,YAAY;QACrF,OAAO;YAAE,gBAAgB;YAAgB,wBAAwB;QAAK;IACxE;IAEA,IAAI,oBAAoB,YAAY,IAAI,CAAC,mBAAmB;QAC1D,OAAO;YAAE,gBAAgB,kBAAkB,QAAQ,MAAM;YAAG,wBAAwB;QAAI;IAC1F;IACA,IAAI,oBAAoB,YAAY,IAAI,CAAC,mBAAmB;QAC1D,OAAO;YAAE,gBAAgB,kBAAkB,QAAQ,MAAM;YAAG,wBAAwB;QAAK;IAC3F;IAEA,OAAO;QAAE,gBAAgB,kBAAkB,QAAQ,MAAM;QAAG,wBAAwB;IAAI;AAC1F;AAEA,SAAS,6BACP,YAAgC,EAChC,iBAAqC,EACrC,eAA8B;IAE9B,OACE,wBAAwB,iBACxB,wBAAwB,sBACxB;AAEJ;AAmCA,SAAS,gBAAgB,EAAiB,EAAE,EAAiB;IAC3D,MAAM,QAAQ,QAAA,kBAAkB,CAAC,uBAAuB,CAAC;IACzD,MAAM,QAAQ,QAAA,kBAAkB,CAAC,uBAAuB,CAAC;IAEzD,OAAO,QAAQ,QAAQ,CAAC,IAAI,QAAQ,QAAQ,IAAI;AAClD;AAoIA,cAAA,GACA,SAAgB,oBACd,KAAU,EACV,iBAAyB,EACzB,UAAwB,CAAA,CAAE;IAE1B,IAAI,gBAAgB;IAEpB,IAAI,gBAAgB;IACpB,MAAM,2BAA2B,SAAS,yBAAyB,GAAW,EAAE,KAAU;QACxF,IAAI,iBAAiB,mBAAmB;YACtC,OAAO;QACT;QACA,4BAA4B;QAC5B,IAAI,QAAQ,IAAI;YACd,6BAA6B;YAC7B,iBAAiB;YACjB,OAAO;QACT;QAEA,iEAAiE;QACjE,8FAA8F;QAC9F,sFAAsF;QACtF,iBAAiB,IAAI,MAAM,GAAG;QAE9B,IAAI,SAAS,MAAM,OAAO;QAE1B,OAAQ,OAAO;YACb,KAAK;gBACH,yBAAyB;gBACzB,iFAAiF;gBACjF,iBAAiB,MAAM,MAAM,GAAG;gBAChC;YACF,KAAK;YACL,KAAK;gBACH,iBAAiB,OAAO,OAAO,MAAM;gBACrC;YACF,KAAK;gBACH,iBAAiB,QAAQ,IAAI;gBAC7B;YACF,KAAK;gBACH,IAAI,CAAA,GAAA,QAAA,YAAY,EAAC,QAAQ;oBACvB,4DAA4D;oBAC5D,6FAA6F;oBAC7F,kEAAkE;oBAClE,iBAAiB,AAAC,KAAK,MAAM,UAAU,GAAG,MAAM,UAAU,GAAG,OAAO,KAAM;gBAC5E,OAAO,IAAI,eAAe,OAAO;oBAC/B,MAAM,IAAI;oBACV,OAAQ,EAAE,SAAS;wBACjB,KAAK;4BACH,iBAAiB,OAAO,EAAE,KAAK,EAAE,MAAM;4BACvC;wBACF,KAAK;4BACH,iDAAiD;4BACjD,iBACE,CAAC,EAAE,KAAK,GAAG,CAAC,MAAM,EAAE,KAAK,GAAG,OAAO,EAAE,KAAK,EAAE,MAAM,GAAG,IAAI,OAAO,EAAE,KAAK,EAAE,MAAM;4BACjF;wBACF,KAAK;4BACH,iBAAiB,EAAE,QAAQ,GAAG,MAAM;4BACpC;wBACF,KAAK;4BACH,wCAAwC;4BACxC,iBAAiB;4BACjB;wBACF,KAAK;wBACL,KAAK;4BACH,qCAAqC;4BACrC,iBAAiB;4BACjB;wBACF,KAAK;4BACH,4DAA4D;4BAC5D,6FAA6F;4BAC7F,kEAAkE;4BAClE,iBAAiB,AAAC,KAAK,MAAM,QAAQ,GAAG,MAAM,QAAQ,GAAG,OAAO,KAAM;4BACtE;wBACF,KAAK;4BACH,qCAAqC;4BACrC,iBAAiB,KAAK,OAAO,EAAE,CAAC,EAAE,MAAM,GAAG,IAAI,OAAO,EAAE,CAAC,EAAE,MAAM,GAAG;4BACpE;wBACF,KAAK;4BACH,gEAAgE;4BAChE,IAAI,EAAE,KAAK,IAAI,MAAM;gCACnB,iBAAiB,EAAE,IAAI,CAAC,MAAM,GAAG,KAAK;4BACxC,OAAO;gCACL,4EAA4E;gCAC5E,iBAAiB,EAAE,IAAI,CAAC,MAAM,GAAG,KAAK;4BACxC;4BACA;wBACF,KAAK;4BACH,yEAAyE;4BACzE,iBAAiB,KAAK,EAAE,OAAO,CAAC,MAAM,GAAG,KAAK,EAAE,OAAO,CAAC,MAAM,GAAG;4BACjE;oBACJ;gBACF;QACJ;QACA,OAAO;IACT;IAEA,IAAI,OAAO,UAAU,UAAU;QAC7B,gBAAgB;IAClB,OAAO,IAAI,OAAO,UAAU,YAAY;QACtC,gBAAgB,MAAM,IAAI;IAC5B,OAAO;QACL,IAAI;YACF,IAAI,sBAAsB,GAAG;gBAC3B,gBAAgB,OAAA,KAAK,CAAC,SAAS,CAAC,OAAO,0BAA0B,GAAG;YACtE,OAAO;gBACL,gBAAgB,OAAA,KAAK,CAAC,SAAS,CAAC,OAAO;YACzC;QACF,EAAE,OAAO,GAAG;YACV,gBAAgB,CAAA,yCAAA,EAA4C,EAAE,OAAO,CAAA,CAAE;QACzE;IACF;IAEA,uEAAuE;IACvE,IACE,sBAAsB,KACtB,cAAc,MAAM,GAAG,qBACvB,cAAc,UAAU,CAAC,oBAAoB,OAC3C,cAAc,WAAW,CAAC,oBAAoB,IAChD;QACA;QACA,IAAI,sBAAsB,GAAG;YAC3B,OAAO;QACT;IACF;IAEA,OAAO,sBAAsB,KAAK,cAAc,MAAM,GAAG,oBACrD,CAAA,EAAG,cAAc,KAAK,CAAC,GAAG,mBAAkB,GAAA,CAAK,GACjD;AACN;AAKA,SAAS,iBAAiB,GAAa;IACrC,MAAM,sBAAsB;IAC5B,gDAAgD;IAChD,OAAO,oBAAoB,KAAK,KAAK,aAAa,OAAO,oBAAoB,KAAK,KAAK;AACzF;AAEA,SAAS,4BACP,GAAwB,EACxB,oBAA0C,EAC1C,oBAA4B,QAAA,2BAA2B;IAEvD,MAAM,EAAE,QAAQ,EAAE,SAAS,EAAE,mBAAmB,EAAE,OAAO,EAAE,GAAG;IAC9D,IAAI,QAAQ,GAAG,oBAAoB,UAAU;IAC7C,IAAI,SAAS,GAAG;IAChB,IAAI,mBAAmB,GAAG,oBAAoB,qBAAqB;IACnE,IAAI,OAAO,GAAG;IAEd,OAAO;AACT;AAEA,SAAS,oBACP,GAAwB,EACxB,YAA8F;IAE9F,IAAI,WAAW,GAAG,aAAa,WAAW;IAC1C,IAAI,SAAS,GAAG,aAAa,SAAS;IACtC,IAAI,kBAAkB,GAAG,aAAa,YAAY;IAClD,MAAM,EAAE,IAAI,EAAE,IAAI,EAAE,GAAG,QAAA,WAAW,CAAC,UAAU,CAAC,aAAa,OAAO,EAAE,UAAU;IAC9E,IAAI,UAAU,GAAG;IACjB,IAAI,UAAU,GAAG;IACjB,IAAI,cAAc,WAAW;QAC3B,IAAI,SAAS,GAAG,aAAa,SAAS,CAAC,WAAW;IACpD;IACA,IAAI,YAAY,GAAG,aAAa,YAAY;IAC5C,IAAI,kBAAkB,GAAG,aAAa,kBAAkB;IAExD,OAAO;AACT;AAEA,SAAS,uBAAuB,GAAwB,EAAE,KAAU;IAClE,MAAM,EAAE,IAAI,EAAE,IAAI,EAAE,GAAG,QAAA,WAAW,CAAC,UAAU,CAAC,MAAM,OAAO,EAAE,UAAU;IACvE,IAAI,UAAU,GAAG;IACjB,IAAI,UAAU,GAAG;IAEjB,OAAO;AACT;AAEA,SAAS,iBAAiB,GAAwB,EAAE,SAA4B;IAC9E,IAAI,UAAU,GAAG,UAAU,UAAU;IACrC,OAAO;AACT;AAEA,SAAS,4BACP,GAAwB,EACxB,oBAGyC;IAEzC,MAAM,EAAE,OAAO,EAAE,YAAY,EAAE,GAAG;IAClC,IAAI,OAAO,GAAG;IACd,IAAI,kBAAkB,GAAG,qBAAqB,YAAY;IAC1D,MAAM,EAAE,IAAI,EAAE,IAAI,EAAE,GAAG,QAAA,WAAW,CAAC,UAAU,CAAC,cAAc,UAAU;IACtE,IAAI,UAAU,GAAG;IACjB,IAAI,UAAU,GAAG;IACjB,OAAO;AACT;AAEA,cAAA,GACA,SAAgB,oBACd,SAA8C,EAC9C,oBAA4B,QAAA,2BAA2B;IAEvD,IAAI,MAAkC,OAAO,MAAM,CAAC;IAEpD,OAAQ,UAAU,IAAI;QACpB,KAAK,YAAA,wBAAwB;YAC3B,MAAM,4BAA4B,KAAK,WAAW;YAClD,OAAO;QACT,KAAK,YAAA,uBAAuB;YAC1B,MAAM,4BAA4B,KAAK,WAAW;YAClD,IAAI,OAAO,GAAG,UAAU,OAAO,EAAE;YACjC,OAAO;QACT,KAAK,YAAA,0BAA0B;YAC7B,MAAM,4BAA4B,KAAK,WAAW;YAClD,IAAI,UAAU,GAAG,UAAU,UAAU;YACrC,IAAI,UAAU,GAAG,UAAU,UAAU;YACrC,OAAO;QACT,KAAK,YAAA,2BAA2B;YAC9B,MAAM,4BAA4B,KAAK,WAAW;YAClD,IAAI,eAAe,GAAG,UAAU,eAAe;YAC/C,OAAO;QACT,KAAK,YAAA,eAAe;YAClB,MAAM,oBAAoB,KAAK;YAC/B,IAAI,OAAO,GAAG;YACd,IAAI,OAAO,GAAG,oBAAoB,UAAU,OAAO,EAAE,mBAAmB;gBAAE,SAAS;YAAI;YACvF,IAAI,YAAY,GAAG,UAAU,YAAY;YACzC,OAAO;QACT,KAAK,YAAA,iBAAiB;YACpB,MAAM,oBAAoB,KAAK;YAC/B,IAAI,OAAO,GAAG;YACd,IAAI,UAAU,GAAG,UAAU,QAAQ;YACnC,IAAI,KAAK,GAAG,oBAAoB,UAAU,KAAK,EAAE,mBAAmB;gBAAE,SAAS;YAAI;YACnF,OAAO;QACT,KAAK,YAAA,cAAc;YACjB,MAAM,oBAAoB,KAAK;YAC/B,IAAI,OAAO,GAAG;YACd,IAAI,UAAU,GAAG,UAAU,QAAQ;YACnC,IAAI,OAAO,GAAG,UAAU,OAAO,EAAE,WAAW;YAC5C,OAAO;QACT,KAAK,YAAA,uBAAuB;YAC1B,MAAM,uBAAuB,KAAK;YAClC,IAAI,OAAO,GAAG;YACd,IAAI,UAAU,OAAO,EAAE;gBACrB,MAAM,EAAE,aAAa,EAAE,WAAW,EAAE,WAAW,EAAE,aAAa,EAAE,kBAAkB,EAAE,GAClF,UAAU,OAAO;gBACnB,MAAM;oBACJ,GAAG,GAAG;oBACN;oBACA;oBACA;oBACA;oBACA;;YAEJ;YACA,OAAO;QACT,KAAK,YAAA,qBAAqB;YACxB,MAAM,uBAAuB,KAAK;YAClC,IAAI,OAAO,GAAG;YACd,OAAO;QACT,KAAK,YAAA,uBAAuB;YAC1B,MAAM,uBAAuB,KAAK;YAClC,IAAI,OAAO,GAAG;YACd,IAAI,UAAU,SAAS,EAAE,cAAc,YAAY;gBACjD,IAAI,SAAS,GAAG,UAAU,SAAS,EAAE;YACvC;YACA,OAAO;QACT,KAAK,YAAA,sBAAsB;YACzB,MAAM,uBAAuB,KAAK;YAClC,IAAI,OAAO,GAAG;YACd,OAAO;QACT,KAAK,YAAA,kBAAkB;YACrB,MAAM,uBAAuB,KAAK;YAClC,IAAI,OAAO,GAAG;YACd,IAAI,kBAAkB,GAAG,UAAU,YAAY;YAC/C,OAAO;QACT,KAAK,YAAA,gBAAgB;YACnB,MAAM,uBAAuB,KAAK;YAClC,IAAI,OAAO,GAAG;YACd,IAAI,kBAAkB,GAAG,UAAU,YAAY;YAC/C,IAAI,UAAU,GAAG,UAAU,UAAU;YACrC,OAAO;QACT,KAAK,YAAA,iBAAiB;YACpB,MAAM,uBAAuB,KAAK;YAClC,IAAI,OAAO,GAAG;YACd,IAAI,kBAAkB,GAAG,UAAU,YAAY;YAC/C,OAAQ,UAAU,MAAM;gBACtB,KAAK;oBACH,IAAI,MAAM,GAAG;oBACb;gBACF,KAAK;oBACH,IAAI,MAAM,GACR;oBACF;gBACF,KAAK;oBACH,IAAI,MAAM,GAAG;oBACb,IAAI,UAAU,KAAK,EAAE;wBACnB,IAAI,KAAK,GAAG,UAAU,KAAK;oBAC7B;oBACA;gBACF,KAAK;oBACH,IAAI,MAAM,GAAG;oBACb;gBACF;oBACE,IAAI,MAAM,GAAG,CAAA,sBAAA,EAAyB,UAAU,MAAM,CAAA,CAAE;YAC5D;YACA,OAAO;QACT,KAAK,YAAA,4BAA4B;YAC/B,MAAM,uBAAuB,KAAK;YAClC,IAAI,OAAO,GAAG;YACd,OAAO;QACT,KAAK,YAAA,2BAA2B;YAC9B,MAAM,uBAAuB,KAAK;YAClC,IAAI,OAAO,GAAG;YACd,OAAQ,UAAU,MAAM;gBACtB,KAAK;oBACH,IAAI,MAAM,GAAG;oBACb;gBACF,KAAK;oBACH,IAAI,MAAM,GAAG;oBACb;gBACF,KAAK;oBACH,IAAI,MAAM,GAAG;oBACb,IAAI,UAAU,KAAK,EAAE;wBACnB,IAAI,KAAK,GAAG,UAAU,KAAK;oBAC7B;oBACA;gBACF;oBACE,IAAI,MAAM,GAAG,CAAA,sBAAA,EAAyB,UAAU,MAAM,CAAA,CAAE;YAC5D;YACA,IAAI,UAAU,GAAG,UAAU,UAAU;YACrC,OAAO;QACT,KAAK,YAAA,sBAAsB;YACzB,MAAM,uBAAuB,KAAK;YAClC,IAAI,OAAO,GAAG;YACd,IAAI,kBAAkB,GAAG,UAAU,YAAY;YAC/C,IAAI,UAAU,GAAG,UAAU,UAAU;YACrC,OAAO;QACT,KAAK,YAAA,qBAAqB;YACxB,MAAM,uBAAuB,KAAK;YAClC,IAAI,OAAO,GAAG;YACd,IAAI,kBAAkB,GAAG,UAAU,YAAY;YAC/C,OAAO;QACT,KAAK,YAAA,cAAc;YACjB,MAAM,iBAAiB,KAAK;YAC5B,MAAM,uBAAuB,KAAK;YAClC,IAAI,OAAO,GAAG;YACd,OAAO;QACT,KAAK,YAAA,aAAa;YAChB,MAAM,iBAAiB,KAAK;YAC5B,MAAM,uBAAuB,KAAK;YAClC,IAAI,OAAO,GAAG;YACd,OAAO;QACT,KAAK,YAAA,wBAAwB;YAC3B,MAAM,iBAAiB,KAAK;YAC5B,MAAM,4BAA4B,KAAK;YACvC,IAAI,OAAO,GAAG;YACd,OAAO;QACT,KAAK,YAAA,0BAA0B;YAC7B,MAAM,iBAAiB,KAAK;YAC5B,MAAM,4BAA4B,KAAK;YACvC,IAAI,OAAO,GAAG;YACd,IAAI,UAAU,GAAG,UAAU,QAAQ;YACnC,IAAI,kBAAkB,GAAG,UAAU,kBAAkB;YACrD,IAAI,KAAK,GAAG,oBAAoB,UAAU,KAAK,EAAE,mBAAmB;gBAAE,SAAS;YAAI;YACnF,OAAO;QACT,KAAK,YAAA,uBAAuB;YAC1B,MAAM,iBAAiB,KAAK;YAC5B,MAAM,4BAA4B,KAAK;YACvC,IAAI,OAAO,GAAG;YACd,IAAI,UAAU,GAAG,UAAU,QAAQ;YACnC,IAAI,OAAO,GAAG,UAAU,OAAO,EAAE;YACjC,OAAO;QACT,KAAK,YAAA,gBAAgB;YACnB,MAAM,iBAAiB,KAAK;YAC5B,IAAI,OAAO,GAAG;YACd,OAAO;QACT,KAAK,YAAA,eAAe;YAClB,MAAM,iBAAiB,KAAK;YAC5B,IAAI,OAAO,GAAG;YACd,OAAO;QACT,KAAK,YAAA,4BAA4B;YAC/B,MAAM,iBAAiB,KAAK;YAC5B,IAAI,OAAO,GAAG;YACd,IAAI,mBAAmB,GAAG,IAAI,KAAK,GAAG,oBACpC,UAAU,mBAAmB,EAC7B;YAEF,IAAI,cAAc,GAAG,IAAI,KAAK,GAAG,oBAC/B,UAAU,cAAc,EACxB;YAEF,OAAO;QACT;YACE,KAAK,MAAM,CAAC,KAAK,MAAM,IAAI,OAAO,OAAO,CAAC,WAAY;gBACpD,IAAI,SAAS,MAAM,GAAG,CAAC,IAAI,GAAG;YAChC;IACJ;IACA,OAAO;AACT;AAEA,cAAA,GACA,MAAa;IAkCX,YAAY,OAA2B,CAAA;QA7BvC,IAAA,CAAA,UAAU,GAAmC;QAG7C;;;YAIA,IAAA,CAAA,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,EAAE;QAC5B;;;YAIA,IAAA,CAAA,IAAI,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,EAAE;QAC3B;;;YAIA,IAAA,CAAA,IAAI,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,EAAE;QAC3B;;;YAIA,IAAA,CAAA,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,EAAE;QAC5B;;;YAIA,IAAA,CAAA,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,EAAE;QAG1B,IAAI,CAAC,mBAAmB,GAAG,QAAQ,mBAAmB;QACtD,IAAI,CAAC,iBAAiB,GAAG,QAAQ,iBAAiB;QAClD,IAAI,CAAC,cAAc,GAAG,QAAQ,cAAc;QAC5C,IAAI,CAAC,sBAAsB,GAAG,QAAQ,sBAAsB;QAC5D,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,uBAAuB;IAChD;IAEA,0BAAuB;QACrB,MAAM,aAAa;QACnB,KAAK,MAAM,aAAa,OAAO,MAAM,CAAC,QAAA,sBAAsB,EAAG;YAC7D,UAAU,CAAC,UAAU,GAAG,CAAA;YACxB,KAAK,MAAM,iBAAiB,OAAO,MAAM,CAAC,QAAA,aAAa,EAAG;gBACxD,UAAU,CAAC,UAAU,CAAC,cAAc,GAClC,gBAAgB,eAAe,IAAI,CAAC,mBAAmB,CAAC,UAAU,KAAK;YAC3E;QACF;QACA,OAAO;IACT;IAEA,oBAAiB;QACf,KAAK,MAAM,aAAa,OAAO,MAAM,CAAC,QAAA,sBAAsB,EAAG;YAC7D,IAAI,CAAC,mBAAmB,CAAC,UAAU,GAAG,QAAA,aAAa,CAAC,GAAG;YACvD,KAAK,MAAM,iBAAiB,OAAO,MAAM,CAAC,QAAA,aAAa,EAAG;gBACxD,IAAI,CAAC,UAAU,CAAC,UAAU,CAAC,cAAc,GAAG;YAC9C;QACF;IACF;IAEQ,uBAAuB,KAAY,EAAA;QACzC,IAAI,IAAI,CAAC,sBAAsB,EAAE;YAC/B,IAAI,CAAC,iBAAiB;YACtB,IAAI,CAAC,eAAe;YACpB;QACF;QACA,IAAI,CAAC,cAAc,GAAG,kBAAkB,QAAQ,MAAM;QACtD,IAAI,CAAC,sBAAsB,GAAG;QAC9B,IAAI,CAAC,eAAe;QACpB,IAAI,CAAC,KAAK,CAAC,QAAA,sBAAsB,CAAC,MAAM,EAAE;YACxC,OAAO;gBACL,OAAO;oBACL,SAAS;oBACT,OAAO,MAAM,OAAO;;YAExB;;QAEF,IAAI,CAAC,iBAAiB;QACtB,IAAI,CAAC,eAAe;IACtB;IAEQ,kBAAe;QACrB,IAAI,CAAC,UAAU,GAAG;IACpB;IAEA,QAAQ,SAAiC,EAAE,QAAuB,EAAA;QAChE,IAAI,aAAa,QAAA,aAAa,CAAC,GAAG,EAAE,OAAO;QAC3C,OAAO,IAAI,CAAC,UAAU,CAAC,UAAU,CAAC,SAAS;IAC7C;IAEQ,IACN,QAAuB,EACvB,SAAiC,EACjC,OAA0B,EAAA;QAE1B,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,WAAW,WAAW;QAExC,IAAI,aAAkB;YAAE,GAAG,IAAI;YAAQ,GAAG;YAAW,GAAG;QAAQ;QAChE,IAAI,OAAO,YAAY,UAAU;YAC/B,WAAW,OAAO,GAAG;QACvB,OAAO,IAAI,OAAO,YAAY,UAAU;YACtC,IAAI,iBAAiB,UAAU;gBAC7B,aAAa;oBAAE,GAAG,UAAU;oBAAE,GAAG,QAAQ,KAAK,EAAE;gBAAA;YAClD,OAAO;gBACL,aAAa;oBAAE,GAAG,UAAU;oBAAE,GAAG,oBAAoB,SAAS,IAAI,CAAC,iBAAiB,CAAC;gBAAA;YACvF;QACF;QAEA,IAAI,CAAA,GAAA,QAAA,aAAa,EAAC,IAAI,CAAC,UAAU,GAAG;YAClC,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,UAAU,CAE9B,IAAI,CAAC,IAAM,IAAI,CAAC,cAAc,CAAC,KAAK,CAAC,aAErC,IAAI,CAAC,IAAI,CAAC,eAAe,CAAC,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,sBAAsB,CAAC,IAAI,CAAC,IAAI;YAC9E;QACF;QAEA,IAAI;YACF,MAAM,YAAY,IAAI,CAAC,cAAc,CAAC,KAAK,CAAC;YAC5C,IAAI,CAAA,GAAA,QAAA,aAAa,EAAC,YAAY;gBAC5B,IAAI,CAAC,UAAU,GAAG,UAAU,IAAI,CAC9B,IAAI,CAAC,eAAe,CAAC,IAAI,CAAC,IAAI,GAC9B,IAAI,CAAC,sBAAsB,CAAC,IAAI,CAAC,IAAI;YAEzC;QACF,EAAE,OAAO,OAAO;YACd,IAAI,CAAC,sBAAsB,CAAC;QAC9B;IACF;IAEA;;;;;;;;;;;;QAaA,OAAO,eACL,UAAiC,EACjC,aAA4C,EAAA;QAE5C,kDAAkD;QAClD,MAAM,kBAAkB,eAAe,YAAY;QACnD,MAAM,kBAAkB;YACtB,GAAG,UAAU;YACb,GAAG,aAAa;YAChB,gBAAgB,gBAAgB,cAAc;YAC9C,wBAAwB,gBAAgB,sBAAsB;;QAEhE,MAAM,kBAAkB,6BACtB,gBAAgB,6BAA6B,EAAE,SAC/C,gBAAgB,eAAe,EAC/B,QAAA,aAAa,CAAC,GAAG;QAGnB,OAAO;YACL,qBAAqB;gBACnB,SAAS,6BACP,gBAAgB,6BAA6B,EAAE,SAC/C,gBAAgB,mBAAmB,EACnC;gBAEF,UAAU,6BACR,gBAAgB,6BAA6B,EAAE,UAC/C,gBAAgB,oBAAoB,EACpC;gBAEF,iBAAiB,6BACf,gBAAgB,6BAA6B,EAAE,iBAC/C,gBAAgB,4BAA4B,EAC5C;gBAEF,YAAY,6BACV,gBAAgB,6BAA6B,EAAE,YAC/C,gBAAgB,sBAAsB,EACtC;gBAEF,QAAQ,6BACN,gBAAgB,6BAA6B,EAAE,QAC/C,gBAAgB,kBAAkB,EAClC;gBAEF,SAAS;;YAEX,mBACE,gBAAgB,2BAA2B,IAC3C,CAAA,GAAA,QAAA,oBAAoB,EAAC,gBAAgB,+BAA+B,KACpE;YACF,gBAAgB,gBAAgB,cAAc;YAC9C,wBAAwB,gBAAgB,sBAAsB;;IAElE;;AAxMF,QAAA,WAAA,GAAA"}},
    {"offset": {"line": 4069, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 4073, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/mongo_types.ts"],"sourcesContent":["import { EventEmitter } from 'events';\n\nimport type {\n  Binary,\n  BSONRegExp,\n  BSONType,\n  Decimal128,\n  Document,\n  Double,\n  Int32,\n  Long,\n  ObjectId,\n  ObjectIdLike,\n  Timestamp\n} from './bson';\nimport { type CommandStartedEvent } from './cmap/command_monitoring_events';\nimport {\n  type LoggableCommandFailedEvent,\n  type LoggableCommandSucceededEvent,\n  type LoggableServerHeartbeatFailedEvent,\n  type LoggableServerHeartbeatStartedEvent,\n  type LoggableServerHeartbeatSucceededEvent,\n  MongoLoggableComponent,\n  type MongoLogger\n} from './mongo_logger';\nimport type { Sort } from './sort';\nimport { noop } from './utils';\n\n/** @internal */\nexport type TODO_NODE_3286 = any;\n\n/** Given an object shaped type, return the type of the _id field or default to ObjectId @public */\nexport type InferIdType<TSchema> = TSchema extends { _id: infer IdType }\n  ? // user has defined a type for _id\n    Record<any, never> extends IdType\n    ? never // explicitly forbid empty objects as the type of _id\n    : IdType\n  : TSchema extends { _id?: infer IdType }\n    ? // optional _id defined - return ObjectId | IdType\n      unknown extends IdType\n      ? ObjectId // infer the _id type as ObjectId if the type of _id is unknown\n      : IdType\n    : ObjectId; // user has not defined _id on schema\n\n/** Add an _id field to an object shaped type @public */\nexport type WithId<TSchema> = EnhancedOmit<TSchema, '_id'> & { _id: InferIdType<TSchema> };\n\n/**\n * Add an optional _id field to an object shaped type\n * @public\n */\nexport type OptionalId<TSchema> = EnhancedOmit<TSchema, '_id'> & { _id?: InferIdType<TSchema> };\n\n/**\n * Adds an optional _id field to an object shaped type, unless the _id field is required on that type.\n * In the case _id is required, this method continues to require_id.\n *\n * @public\n *\n * @privateRemarks\n * `ObjectId extends TSchema['_id']` is a confusing ordering at first glance. Rather than ask\n * `TSchema['_id'] extends ObjectId` which translated to \"Is the _id property ObjectId?\"\n * we instead ask \"Does ObjectId look like (have the same shape) as the _id?\"\n */\nexport type OptionalUnlessRequiredId<TSchema> = TSchema extends { _id: any }\n  ? TSchema\n  : OptionalId<TSchema>;\n\n/** TypeScript Omit (Exclude to be specific) does not work for objects with an \"any\" indexed type, and breaks discriminated unions @public */\nexport type EnhancedOmit<TRecordOrUnion, KeyUnion> = string extends keyof TRecordOrUnion\n  ? TRecordOrUnion // TRecordOrUnion has indexed type e.g. { _id: string; [k: string]: any; } or it is \"any\"\n  : TRecordOrUnion extends any\n    ? Pick<TRecordOrUnion, Exclude<keyof TRecordOrUnion, KeyUnion>> // discriminated unions\n    : never;\n\n/** Remove the _id field from an object shaped type @public */\nexport type WithoutId<TSchema> = Omit<TSchema, '_id'>;\n\n/** A MongoDB filter can be some portion of the schema or a set of operators @public */\nexport type Filter<TSchema> = {\n  [P in keyof WithId<TSchema>]?: Condition<WithId<TSchema>[P]>;\n} & RootFilterOperators<WithId<TSchema>>;\n\n/** @public */\nexport type Condition<T> = AlternativeType<T> | FilterOperators<AlternativeType<T>>;\n\n/**\n * It is possible to search using alternative types in mongodb e.g.\n * string types can be searched using a regex in mongo\n * array types can be searched using their element type\n * @public\n */\nexport type AlternativeType<T> =\n  T extends ReadonlyArray<infer U> ? T | RegExpOrString<U> : RegExpOrString<T>;\n\n/** @public */\nexport type RegExpOrString<T> = T extends string ? BSONRegExp | RegExp | T : T;\n\n/** @public */\nexport interface RootFilterOperators<TSchema> extends Document {\n  $and?: Filter<TSchema>[];\n  $nor?: Filter<TSchema>[];\n  $or?: Filter<TSchema>[];\n  $text?: {\n    $search: string;\n    $language?: string;\n    $caseSensitive?: boolean;\n    $diacriticSensitive?: boolean;\n  };\n  $where?: string | ((this: TSchema) => boolean);\n  $comment?: string | Document;\n}\n\n/**\n * @public\n * A type that extends Document but forbids anything that \"looks like\" an object id.\n */\nexport type NonObjectIdLikeDocument = {\n  [key in keyof ObjectIdLike]?: never;\n} & Document;\n\n/** @public */\nexport interface FilterOperators<TValue> extends NonObjectIdLikeDocument {\n  // Comparison\n  $eq?: TValue;\n  $gt?: TValue;\n  $gte?: TValue;\n  $in?: ReadonlyArray<TValue>;\n  $lt?: TValue;\n  $lte?: TValue;\n  $ne?: TValue;\n  $nin?: ReadonlyArray<TValue>;\n  // Logical\n  $not?: TValue extends string ? FilterOperators<TValue> | RegExp : FilterOperators<TValue>;\n  // Element\n  /**\n   * When `true`, `$exists` matches the documents that contain the field,\n   * including documents where the field value is null.\n   */\n  $exists?: boolean;\n  $type?: BSONType | BSONTypeAlias;\n  // Evaluation\n  $expr?: Record<string, any>;\n  $jsonSchema?: Record<string, any>;\n  $mod?: TValue extends number ? [number, number] : never;\n  $regex?: TValue extends string ? RegExp | BSONRegExp | string : never;\n  $options?: TValue extends string ? string : never;\n  // Geospatial\n  $geoIntersects?: { $geometry: Document };\n  $geoWithin?: Document;\n  $near?: Document;\n  $nearSphere?: Document;\n  $maxDistance?: number;\n  // Array\n  $all?: ReadonlyArray<any>;\n  $elemMatch?: Document;\n  $size?: TValue extends ReadonlyArray<any> ? number : never;\n  // Bitwise\n  $bitsAllClear?: BitwiseFilter;\n  $bitsAllSet?: BitwiseFilter;\n  $bitsAnyClear?: BitwiseFilter;\n  $bitsAnySet?: BitwiseFilter;\n  $rand?: Record<string, never>;\n}\n\n/** @public */\nexport type BitwiseFilter =\n  | number /** numeric bit mask */\n  | Binary /** BinData bit mask */\n  | ReadonlyArray<number>; /** `[ <position1>, <position2>, ... ]` */\n\n/** @public */\nexport type BSONTypeAlias = keyof typeof BSONType;\n\n/** @public */\nexport type IsAny<Type, ResultIfAny, ResultIfNotAny> = true extends false & Type\n  ? ResultIfAny\n  : ResultIfNotAny;\n\n/** @public */\nexport type Flatten<Type> = Type extends ReadonlyArray<infer Item> ? Item : Type;\n\n/** @public */\nexport type ArrayElement<Type> = Type extends ReadonlyArray<infer Item> ? Item : never;\n\n/** @public */\nexport type SchemaMember<T, V> = { [P in keyof T]?: V } | { [key: string]: V };\n\n/** @public */\nexport type IntegerType = number | Int32 | Long | bigint;\n\n/** @public */\nexport type NumericType = IntegerType | Decimal128 | Double;\n\n/** @public */\nexport type FilterOperations<T> =\n  T extends Record<string, any>\n    ? { [key in keyof T]?: FilterOperators<T[key]> }\n    : FilterOperators<T>;\n\n/** @public */\nexport type KeysOfAType<TSchema, Type> = {\n  [key in keyof TSchema]: NonNullable<TSchema[key]> extends Type ? key : never;\n}[keyof TSchema];\n\n/** @public */\nexport type KeysOfOtherType<TSchema, Type> = {\n  [key in keyof TSchema]: NonNullable<TSchema[key]> extends Type ? never : key;\n}[keyof TSchema];\n\n/** @public */\nexport type AcceptedFields<TSchema, FieldType, AssignableType> = {\n  readonly [key in KeysOfAType<TSchema, FieldType>]?: AssignableType;\n};\n\n/** It avoids using fields with not acceptable types @public */\nexport type NotAcceptedFields<TSchema, FieldType> = {\n  readonly [key in KeysOfOtherType<TSchema, FieldType>]?: never;\n};\n\n/** @public */\nexport type OnlyFieldsOfType<TSchema, FieldType = any, AssignableType = FieldType> = IsAny<\n  TSchema[keyof TSchema],\n  AssignableType extends FieldType ? Record<string, FieldType> : Record<string, AssignableType>,\n  AcceptedFields<TSchema, FieldType, AssignableType> &\n    NotAcceptedFields<TSchema, FieldType> &\n    Record<string, AssignableType>\n>;\n\n/** @public */\nexport type MatchKeysAndValues<TSchema> = Readonly<Partial<TSchema>> & Record<string, any>;\n\n/** @public */\nexport type AddToSetOperators<Type> = {\n  $each?: Array<Flatten<Type>>;\n};\n\n/** @public */\nexport type ArrayOperator<Type> = {\n  $each?: Array<Flatten<Type>>;\n  $slice?: number;\n  $position?: number;\n  $sort?: Sort;\n};\n\n/** @public */\nexport type SetFields<TSchema> = ({\n  readonly [key in KeysOfAType<TSchema, ReadonlyArray<any> | undefined>]?:\n    | OptionalId<Flatten<TSchema[key]>>\n    | AddToSetOperators<Array<OptionalId<Flatten<TSchema[key]>>>>;\n} & IsAny<\n  TSchema[keyof TSchema],\n  object,\n  NotAcceptedFields<TSchema, ReadonlyArray<any> | undefined>\n>) & {\n  readonly [key: string]: AddToSetOperators<any> | any;\n};\n\n/** @public */\nexport type PushOperator<TSchema> = ({\n  readonly [key in KeysOfAType<TSchema, ReadonlyArray<any>>]?:\n    | Flatten<TSchema[key]>\n    | ArrayOperator<Array<Flatten<TSchema[key]>>>;\n} & NotAcceptedFields<TSchema, ReadonlyArray<any>>) & {\n  readonly [key: string]: ArrayOperator<any> | any;\n};\n\n/** @public */\nexport type PullOperator<TSchema> = ({\n  readonly [key in KeysOfAType<TSchema, ReadonlyArray<any>>]?:\n    | Partial<Flatten<TSchema[key]>>\n    | FilterOperations<Flatten<TSchema[key]>>;\n} & NotAcceptedFields<TSchema, ReadonlyArray<any>>) & {\n  readonly [key: string]: FilterOperators<any> | any;\n};\n\n/** @public */\nexport type PullAllOperator<TSchema> = ({\n  readonly [key in KeysOfAType<TSchema, ReadonlyArray<any>>]?: TSchema[key];\n} & NotAcceptedFields<TSchema, ReadonlyArray<any>>) & {\n  readonly [key: string]: ReadonlyArray<any>;\n};\n\n/** @public */\nexport type UpdateFilter<TSchema> = {\n  $currentDate?: OnlyFieldsOfType<\n    TSchema,\n    Date | Timestamp,\n    true | { $type: 'date' | 'timestamp' }\n  >;\n  $inc?: OnlyFieldsOfType<TSchema, NumericType | undefined>;\n  $min?: MatchKeysAndValues<TSchema>;\n  $max?: MatchKeysAndValues<TSchema>;\n  $mul?: OnlyFieldsOfType<TSchema, NumericType | undefined>;\n  $rename?: Record<string, string>;\n  $set?: MatchKeysAndValues<TSchema>;\n  $setOnInsert?: MatchKeysAndValues<TSchema>;\n  $unset?: OnlyFieldsOfType<TSchema, any, '' | true | 1>;\n  $addToSet?: SetFields<TSchema>;\n  $pop?: OnlyFieldsOfType<TSchema, ReadonlyArray<any>, 1 | -1>;\n  $pull?: PullOperator<TSchema>;\n  $push?: PushOperator<TSchema>;\n  $pullAll?: PullAllOperator<TSchema>;\n  $bit?: OnlyFieldsOfType<\n    TSchema,\n    NumericType | undefined,\n    { and: IntegerType } | { or: IntegerType } | { xor: IntegerType }\n  >;\n} & Document;\n\n/** @public */\nexport type Nullable<AnyType> = AnyType | null | undefined;\n\n/** @public */\nexport type OneOrMore<T> = T | ReadonlyArray<T>;\n\n/** @public */\nexport type GenericListener = (...args: any[]) => void;\n\n/**\n * Event description type\n * @public\n */\nexport type EventsDescription = Record<string, GenericListener>;\n\n/** @public */\nexport type CommonEvents = 'newListener' | 'removeListener';\n\n/**\n * Typescript type safe event emitter\n * @public\n */\nexport declare interface TypedEventEmitter<Events extends EventsDescription> extends EventEmitter {\n  addListener<EventKey extends keyof Events>(event: EventKey, listener: Events[EventKey]): this;\n  addListener(\n    event: CommonEvents,\n    listener: (eventName: string | symbol, listener: GenericListener) => void\n  ): this;\n  addListener(event: string | symbol, listener: GenericListener): this;\n\n  on<EventKey extends keyof Events>(event: EventKey, listener: Events[EventKey]): this;\n  on(\n    event: CommonEvents,\n    listener: (eventName: string | symbol, listener: GenericListener) => void\n  ): this;\n  on(event: string | symbol, listener: GenericListener): this;\n\n  once<EventKey extends keyof Events>(event: EventKey, listener: Events[EventKey]): this;\n  once(\n    event: CommonEvents,\n    listener: (eventName: string | symbol, listener: GenericListener) => void\n  ): this;\n  once(event: string | symbol, listener: GenericListener): this;\n\n  removeListener<EventKey extends keyof Events>(event: EventKey, listener: Events[EventKey]): this;\n  removeListener(\n    event: CommonEvents,\n    listener: (eventName: string | symbol, listener: GenericListener) => void\n  ): this;\n  removeListener(event: string | symbol, listener: GenericListener): this;\n\n  off<EventKey extends keyof Events>(event: EventKey, listener: Events[EventKey]): this;\n  off(\n    event: CommonEvents,\n    listener: (eventName: string | symbol, listener: GenericListener) => void\n  ): this;\n  off(event: string | symbol, listener: GenericListener): this;\n\n  removeAllListeners<EventKey extends keyof Events>(\n    event?: EventKey | CommonEvents | symbol | string\n  ): this;\n\n  listeners<EventKey extends keyof Events>(\n    event: EventKey | CommonEvents | symbol | string\n  ): Events[EventKey][];\n\n  rawListeners<EventKey extends keyof Events>(\n    event: EventKey | CommonEvents | symbol | string\n  ): Events[EventKey][];\n\n  emit<EventKey extends keyof Events>(\n    event: EventKey | symbol,\n    ...args: Parameters<Events[EventKey]>\n  ): boolean;\n\n  listenerCount<EventKey extends keyof Events>(\n    type: EventKey | CommonEvents | symbol | string\n  ): number;\n\n  prependListener<EventKey extends keyof Events>(event: EventKey, listener: Events[EventKey]): this;\n  prependListener(\n    event: CommonEvents,\n    listener: (eventName: string | symbol, listener: GenericListener) => void\n  ): this;\n  prependListener(event: string | symbol, listener: GenericListener): this;\n\n  prependOnceListener<EventKey extends keyof Events>(\n    event: EventKey,\n    listener: Events[EventKey]\n  ): this;\n  prependOnceListener(\n    event: CommonEvents,\n    listener: (eventName: string | symbol, listener: GenericListener) => void\n  ): this;\n  prependOnceListener(event: string | symbol, listener: GenericListener): this;\n\n  eventNames(): string[];\n  getMaxListeners(): number;\n  setMaxListeners(n: number): this;\n}\n\n/**\n * Typescript type safe event emitter\n * @public\n */\n\n// eslint-disable-next-line @typescript-eslint/no-unsafe-declaration-merging\nexport class TypedEventEmitter<Events extends EventsDescription> extends EventEmitter {\n  /** @internal */\n  protected mongoLogger?: MongoLogger;\n  /** @internal */\n  protected component?: MongoLoggableComponent;\n  /** @internal */\n  emitAndLog<EventKey extends keyof Events>(\n    event: EventKey | symbol,\n    ...args: Parameters<Events[EventKey]>\n  ): void {\n    this.emit(event, ...args);\n    if (this.component) this.mongoLogger?.debug(this.component, args[0]);\n  }\n  /** @internal */\n  emitAndLogHeartbeat<EventKey extends keyof Events>(\n    event: EventKey | symbol,\n    topologyId: number,\n    serverConnectionId?: number | '<monitor>',\n    ...args: Parameters<Events[EventKey]>\n  ): void {\n    this.emit(event, ...args);\n    if (this.component) {\n      const loggableHeartbeatEvent:\n        | LoggableServerHeartbeatFailedEvent\n        | LoggableServerHeartbeatSucceededEvent\n        | LoggableServerHeartbeatStartedEvent = {\n        topologyId: topologyId,\n        serverConnectionId: serverConnectionId ?? null,\n        ...args[0]\n      };\n      this.mongoLogger?.debug(this.component, loggableHeartbeatEvent);\n    }\n  }\n  /** @internal */\n  emitAndLogCommand<EventKey extends keyof Events>(\n    monitorCommands: boolean,\n    event: EventKey | symbol,\n    databaseName: string,\n    connectionEstablished: boolean,\n    ...args: Parameters<Events[EventKey]>\n  ): void {\n    if (monitorCommands) {\n      this.emit(event, ...args);\n    }\n    if (connectionEstablished) {\n      const loggableCommandEvent:\n        | CommandStartedEvent\n        | LoggableCommandFailedEvent\n        | LoggableCommandSucceededEvent = {\n        databaseName: databaseName,\n        ...args[0]\n      };\n      this.mongoLogger?.debug(MongoLoggableComponent.COMMAND, loggableCommandEvent);\n    }\n  }\n}\n\n/** @public */\nexport class CancellationToken extends TypedEventEmitter<{ cancel(): void }> {\n  constructor(...args: any[]) {\n    super(...args);\n    this.on('error', noop);\n  }\n}\n\n/** @public */\nexport type Abortable = {\n  /**\n   * @experimental\n   * When provided, the corresponding `AbortController` can be used to abort an asynchronous action.\n   *\n   * The `signal.reason` value is used as the error thrown.\n   *\n   * @remarks\n   * **NOTE:** If an abort signal aborts an operation while the driver is writing to the underlying\n   * socket or reading the response from the server, the socket will be closed.\n   * If signals are aborted at a high rate during socket read/writes this can lead to a high rate of connection reestablishment.\n   *\n   * We plan to mitigate this in a future release, please follow NODE-6062 (`timeoutMS` expiration suffers the same limitation).\n   *\n   * AbortSignals are likely a best fit for human interactive interruption (ex. ctrl-C) where the frequency\n   * of cancellation is reasonably low. If a signal is programmatically aborted for 100s of operations you can empty\n   * the driver's connection pool.\n   *\n   * @example\n   * ```js\n   * const controller = new AbortController();\n   * const { signal } = controller;\n   * process.on('SIGINT', () => controller.abort(new Error('^C pressed')));\n   *\n   * try {\n   *   const res = await fetch('...', { signal });\n   *   await collection.findOne(await res.json(), { signal });\n   * catch (error) {\n   *   if (error === signal.reason) {\n   *     // signal abort error handling\n   *   }\n   * }\n   * ```\n   */\n  signal?: AbortSignal | undefined;\n};\n\n/**\n * Helper types for dot-notation filter attributes\n */\n\n/** @public */\nexport type Join<T extends unknown[], D extends string> = T extends []\n  ? ''\n  : T extends [string | number]\n    ? `${T[0]}`\n    : T extends [string | number, ...infer R]\n      ? `${T[0]}${D}${Join<R, D>}`\n      : string;\n\n/** @public */\nexport type PropertyType<Type, Property extends string> = string extends Property\n  ? unknown\n  : Property extends keyof Type\n    ? Type[Property]\n    : Property extends `${number}`\n      ? Type extends ReadonlyArray<infer ArrayType>\n        ? ArrayType\n        : unknown\n      : Property extends `${infer Key}.${infer Rest}`\n        ? Key extends `${number}`\n          ? Type extends ReadonlyArray<infer ArrayType>\n            ? PropertyType<ArrayType, Rest>\n            : unknown\n          : Key extends keyof Type\n            ? Type[Key] extends Map<string, infer MapType>\n              ? MapType\n              : PropertyType<Type[Key], Rest>\n            : unknown\n        : unknown;\n\n/**\n * @public\n * returns tuple of strings (keys to be joined on '.') that represent every path into a schema\n * https://www.mongodb.com/docs/manual/tutorial/query-embedded-documents/\n *\n * @remarks\n * Through testing we determined that a depth of 8 is safe for the typescript compiler\n * and provides reasonable compilation times. This number is otherwise not special and\n * should be changed if issues are found with this level of checking. Beyond this\n * depth any helpers that make use of NestedPaths should devolve to not asserting any\n * type safety on the input.\n */\nexport type NestedPaths<Type, Depth extends number[]> = Depth['length'] extends 8\n  ? []\n  : Type extends\n        | string\n        | number\n        | bigint\n        | boolean\n        | Date\n        | RegExp\n        | Buffer\n        | Uint8Array\n        | ((...args: any[]) => any)\n        | { _bsontype: string }\n    ? []\n    : Type extends ReadonlyArray<infer ArrayType>\n      ? [] | [number, ...NestedPaths<ArrayType, [...Depth, 1]>]\n      : Type extends Map<string, any>\n        ? [string]\n        : Type extends object\n          ? {\n              [Key in Extract<keyof Type, string>]: Type[Key] extends Type // type of value extends the parent\n                ? [Key]\n                : // for a recursive union type, the child will never extend the parent type.\n                  // but the parent will still extend the child\n                  Type extends Type[Key]\n                  ? [Key]\n                  : Type[Key] extends ReadonlyArray<infer ArrayType> // handling recursive types with arrays\n                    ? Type extends ArrayType // is the type of the parent the same as the type of the array?\n                      ? [Key] // yes, it's a recursive array type\n                      : // for unions, the child type extends the parent\n                        ArrayType extends Type\n                        ? [Key] // we have a recursive array union\n                        : // child is an array, but it's not a recursive array\n                          [Key, ...NestedPaths<Type[Key], [...Depth, 1]>]\n                    : // child is not structured the same as the parent\n                      [Key, ...NestedPaths<Type[Key], [...Depth, 1]>] | [Key];\n            }[Extract<keyof Type, string>]\n          : [];\n\n/**\n * @public\n * returns keys (strings) for every path into a schema with a value of type\n * https://www.mongodb.com/docs/manual/tutorial/query-embedded-documents/\n */\nexport type NestedPathsOfType<TSchema, Type> = KeysOfAType<\n  {\n    [Property in Join<NestedPaths<TSchema, []>, '.'>]: PropertyType<TSchema, Property>;\n  },\n  Type\n>;\n\n/**\n * @public\n * @experimental\n */\nexport type StrictFilter<TSchema> =\n  | Partial<TSchema>\n  | ({\n      [Property in Join<NestedPaths<WithId<TSchema>, []>, '.'>]?: Condition<\n        PropertyType<WithId<TSchema>, Property>\n      >;\n    } & RootFilterOperators<WithId<TSchema>>);\n\n/**\n * @public\n * @experimental\n */\nexport type StrictUpdateFilter<TSchema> = {\n  $currentDate?: OnlyFieldsOfType<\n    TSchema,\n    Date | Timestamp,\n    true | { $type: 'date' | 'timestamp' }\n  >;\n  $inc?: OnlyFieldsOfType<TSchema, NumericType | undefined>;\n  $min?: StrictMatchKeysAndValues<TSchema>;\n  $max?: StrictMatchKeysAndValues<TSchema>;\n  $mul?: OnlyFieldsOfType<TSchema, NumericType | undefined>;\n  $rename?: Record<string, string>;\n  $set?: StrictMatchKeysAndValues<TSchema>;\n  $setOnInsert?: StrictMatchKeysAndValues<TSchema>;\n  $unset?: OnlyFieldsOfType<TSchema, any, '' | true | 1>;\n  $addToSet?: SetFields<TSchema>;\n  $pop?: OnlyFieldsOfType<TSchema, ReadonlyArray<any>, 1 | -1>;\n  $pull?: PullOperator<TSchema>;\n  $push?: PushOperator<TSchema>;\n  $pullAll?: PullAllOperator<TSchema>;\n  $bit?: OnlyFieldsOfType<\n    TSchema,\n    NumericType | undefined,\n    { and: IntegerType } | { or: IntegerType } | { xor: IntegerType }\n  >;\n} & Document;\n\n/**\n * @public\n * @experimental\n */\nexport type StrictMatchKeysAndValues<TSchema> = Readonly<\n  {\n    [Property in Join<NestedPaths<TSchema, []>, '.'>]?: PropertyType<TSchema, Property>;\n  } & {\n    [Property in `${NestedPathsOfType<TSchema, any[]>}.$${`[${string}]` | ''}`]?: ArrayElement<\n      PropertyType<TSchema, Property extends `${infer Key}.$${string}` ? Key : never>\n    >;\n  } & {\n    [Property in `${NestedPathsOfType<TSchema, Record<string, any>[]>}.$${\n      | `[${string}]`\n      | ''}.${string}`]?: any; // Could be further narrowed\n  } & Document\n>;\n"],"names":[],"mappings":";;;;;AAAA,MAAA;AAgBA,MAAA;AAUA,MAAA;AAiYA;;;IAKA,4EAA4E;AAC5E,MAAa,0BAA4D,SAAA,YAAY;IAKnF,cAAA,GACA,WACE,KAAwB,EACxB,GAAG,IAAkC,EAAA;QAErC,IAAI,CAAC,IAAI,CAAC,UAAU;QACpB,IAAI,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,WAAW,EAAE,MAAM,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,EAAE;IACrE;IACA,cAAA,GACA,oBACE,KAAwB,EACxB,UAAkB,EAClB,kBAAyC,EACzC,GAAG,IAAkC,EAAA;QAErC,IAAI,CAAC,IAAI,CAAC,UAAU;QACpB,IAAI,IAAI,CAAC,SAAS,EAAE;YAClB,MAAM,yBAGoC;gBACxC,YAAY;gBACZ,oBAAoB,sBAAsB;gBAC1C,GAAG,IAAI,CAAC,EAAE;;YAEZ,IAAI,CAAC,WAAW,EAAE,MAAM,IAAI,CAAC,SAAS,EAAE;QAC1C;IACF;IACA,cAAA,GACA,kBACE,eAAwB,EACxB,KAAwB,EACxB,YAAoB,EACpB,qBAA8B,EAC9B,GAAG,IAAkC,EAAA;QAErC,IAAI,iBAAiB;YACnB,IAAI,CAAC,IAAI,CAAC,UAAU;QACtB;QACA,IAAI,uBAAuB;YACzB,MAAM,uBAG8B;gBAClC,cAAc;gBACd,GAAG,IAAI,CAAC,EAAE;;YAEZ,IAAI,CAAC,WAAW,EAAE,MAAM,eAAA,sBAAsB,CAAC,OAAO,EAAE;QAC1D;IACF;;AAtDF,QAAA,iBAAA,GAAA;AAyDA,YAAA,GACA,MAAa,0BAA0B;IACrC,YAAY,GAAG,IAAW,CAAA;QACxB,KAAK,IAAI;QACT,IAAI,CAAC,EAAE,CAAC,SAAS,QAAA,IAAI;IACvB;;AAJF,QAAA,iBAAA,GAAA"}},
    {"offset": {"line": 4122, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 4126, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/sort.ts"],"sourcesContent":["import { MongoInvalidArgumentError } from './error';\n\n/** @public */\nexport type SortDirection =\n  | 1\n  | -1\n  | 'asc'\n  | 'desc'\n  | 'ascending'\n  | 'descending'\n  | { readonly $meta: string };\n\n/** @public */\nexport type Sort =\n  | string\n  | Exclude<SortDirection, { readonly $meta: string }>\n  | ReadonlyArray<string>\n  | { readonly [key: string]: SortDirection }\n  | ReadonlyMap<string, SortDirection>\n  | ReadonlyArray<readonly [string, SortDirection]>\n  | readonly [string, SortDirection];\n\n/** Below stricter types were created for sort that correspond with type that the cmd takes  */\n\n/** @public */\nexport type SortDirectionForCmd = 1 | -1 | { $meta: string };\n\n/** @public */\nexport type SortForCmd = Map<string, SortDirectionForCmd>;\n\n/** @internal */\ntype SortPairForCmd = [string, SortDirectionForCmd];\n\n/** @internal */\nfunction prepareDirection(direction: any = 1): SortDirectionForCmd {\n  const value = `${direction}`.toLowerCase();\n  if (isMeta(direction)) return direction;\n  switch (value) {\n    case 'ascending':\n    case 'asc':\n    case '1':\n      return 1;\n    case 'descending':\n    case 'desc':\n    case '-1':\n      return -1;\n    default:\n      throw new MongoInvalidArgumentError(`Invalid sort direction: ${JSON.stringify(direction)}`);\n  }\n}\n\n/** @internal */\nfunction isMeta(t: SortDirection): t is { $meta: string } {\n  return typeof t === 'object' && t != null && '$meta' in t && typeof t.$meta === 'string';\n}\n\n/** @internal */\nfunction isPair(t: Sort): t is readonly [string, SortDirection] {\n  if (Array.isArray(t) && t.length === 2) {\n    try {\n      prepareDirection(t[1]);\n      return true;\n    } catch {\n      return false;\n    }\n  }\n  return false;\n}\n\nfunction isDeep(t: Sort): t is ReadonlyArray<readonly [string, SortDirection]> {\n  return Array.isArray(t) && Array.isArray(t[0]);\n}\n\nfunction isMap(t: Sort): t is ReadonlyMap<string, SortDirection> {\n  return t instanceof Map && t.size > 0;\n}\n\nfunction isReadonlyArray<T>(value: any): value is readonly T[] {\n  return Array.isArray(value);\n}\n\n/** @internal */\nfunction pairToMap(v: readonly [string, SortDirection]): SortForCmd {\n  return new Map([[`${v[0]}`, prepareDirection([v[1]])]]);\n}\n\n/** @internal */\nfunction deepToMap(t: ReadonlyArray<readonly [string, SortDirection]>): SortForCmd {\n  const sortEntries: SortPairForCmd[] = t.map(([k, v]) => [`${k}`, prepareDirection(v)]);\n  return new Map(sortEntries);\n}\n\n/** @internal */\nfunction stringsToMap(t: ReadonlyArray<string>): SortForCmd {\n  const sortEntries: SortPairForCmd[] = t.map(key => [`${key}`, 1]);\n  return new Map(sortEntries);\n}\n\n/** @internal */\nfunction objectToMap(t: { readonly [key: string]: SortDirection }): SortForCmd {\n  const sortEntries: SortPairForCmd[] = Object.entries(t).map(([k, v]) => [\n    `${k}`,\n    prepareDirection(v)\n  ]);\n  return new Map(sortEntries);\n}\n\n/** @internal */\nfunction mapToMap(t: ReadonlyMap<string, SortDirection>): SortForCmd {\n  const sortEntries: SortPairForCmd[] = Array.from(t).map(([k, v]) => [\n    `${k}`,\n    prepareDirection(v)\n  ]);\n  return new Map(sortEntries);\n}\n\n/** converts a Sort type into a type that is valid for the server (SortForCmd) */\nexport function formatSort(\n  sort: Sort | undefined,\n  direction?: SortDirection\n): SortForCmd | undefined {\n  if (sort == null) return undefined;\n\n  if (typeof sort === 'string') return new Map([[sort, prepareDirection(direction)]]); // 'fieldName'\n\n  if (typeof sort !== 'object') {\n    throw new MongoInvalidArgumentError(\n      `Invalid sort format: ${JSON.stringify(sort)} Sort must be a valid object`\n    );\n  }\n\n  if (!isReadonlyArray(sort)) {\n    if (isMap(sort)) return mapToMap(sort); // Map<fieldName, SortDirection>\n    if (Object.keys(sort).length) return objectToMap(sort); // { [fieldName: string]: SortDirection }\n    return undefined;\n  }\n  if (!sort.length) return undefined;\n  if (isDeep(sort)) return deepToMap(sort); // [ [fieldName, sortDir], [fieldName, sortDir] ... ]\n  if (isPair(sort)) return pairToMap(sort); // [ fieldName, sortDir ]\n  return stringsToMap(sort); // [ fieldName, fieldName ]\n}\n"],"names":[],"mappings":";;;;AAqHA,QAAA,UAAA,GAAA;AArHA,MAAA;AAiCA,cAAA,GACA,SAAS,iBAAiB,YAAiB,CAAC;IAC1C,MAAM,QAAQ,CAAA,EAAG,UAAS,CAAE,CAAC,WAAW;IACxC,IAAI,OAAO,YAAY,OAAO;IAC9B,OAAQ;QACN,KAAK;QACL,KAAK;QACL,KAAK;YACH,OAAO;QACT,KAAK;QACL,KAAK;QACL,KAAK;YACH,OAAO,CAAC;QACV;YACE,MAAM,IAAI,QAAA,yBAAyB,CAAC,CAAA,wBAAA,EAA2B,KAAK,SAAS,CAAC,WAAU,CAAE;IAC9F;AACF;AAEA,cAAA,GACA,SAAS,OAAO,CAAgB;IAC9B,OAAO,OAAO,MAAM,YAAY,KAAK,QAAQ,WAAW,KAAK,OAAO,EAAE,KAAK,KAAK;AAClF;AAEA,cAAA,GACA,SAAS,OAAO,CAAO;IACrB,IAAI,MAAM,OAAO,CAAC,MAAM,EAAE,MAAM,KAAK,GAAG;QACtC,IAAI;YACF,iBAAiB,CAAC,CAAC,EAAE;YACrB,OAAO;QACT,EAAE,OAAM;YACN,OAAO;QACT;IACF;IACA,OAAO;AACT;AAEA,SAAS,OAAO,CAAO;IACrB,OAAO,MAAM,OAAO,CAAC,MAAM,MAAM,OAAO,CAAC,CAAC,CAAC,EAAE;AAC/C;AAEA,SAAS,MAAM,CAAO;IACpB,OAAO,aAAa,OAAO,EAAE,IAAI,GAAG;AACtC;AAEA,SAAS,gBAAmB,KAAU;IACpC,OAAO,MAAM,OAAO,CAAC;AACvB;AAEA,cAAA,GACA,SAAS,UAAU,CAAmC;IACpD,OAAO,IAAI,IAAI;QAAC;YAAC,CAAA,EAAG,CAAC,CAAC,EAAE,CAAA,CAAE;YAAE,iBAAiB;gBAAC,CAAC,CAAC,EAAE;aAAC;SAAE;KAAC;AACxD;AAEA,cAAA,GACA,SAAS,UAAU,CAAkD;IACnE,MAAM,cAAgC,EAAE,GAAG,CAAC,CAAC,CAAC,GAAG,EAAE,GAAK;YAAC,CAAA,EAAG,EAAC,CAAE;YAAE,iBAAiB;SAAG;IACrF,OAAO,IAAI,IAAI;AACjB;AAEA,cAAA,GACA,SAAS,aAAa,CAAwB;IAC5C,MAAM,cAAgC,EAAE,GAAG,CAAC,CAAA,MAAO;YAAC,CAAA,EAAG,IAAG,CAAE;YAAE;SAAE;IAChE,OAAO,IAAI,IAAI;AACjB;AAEA,cAAA,GACA,SAAS,YAAY,CAA4C;IAC/D,MAAM,cAAgC,OAAO,OAAO,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,GAAG,EAAE,GAAK;YACtE,CAAA,EAAG,EAAC,CAAE;YACN,iBAAiB;SAClB;IACD,OAAO,IAAI,IAAI;AACjB;AAEA,cAAA,GACA,SAAS,SAAS,CAAqC;IACrD,MAAM,cAAgC,MAAM,IAAI,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,GAAG,EAAE,GAAK;YAClE,CAAA,EAAG,EAAC,CAAE;YACN,iBAAiB;SAClB;IACD,OAAO,IAAI,IAAI;AACjB;AAEA,+EAAA,GACA,SAAgB,WACd,IAAsB,EACtB,SAAyB;IAEzB,IAAI,QAAQ,MAAM,OAAO;IAEzB,IAAI,OAAO,SAAS,UAAU,OAAO,IAAI,IAAI;QAAC;YAAC;YAAM,iBAAiB;SAAW;KAAC,GAAG,cAAc;IAEnG,IAAI,OAAO,SAAS,UAAU;QAC5B,MAAM,IAAI,QAAA,yBAAyB,CACjC,CAAA,qBAAA,EAAwB,KAAK,SAAS,CAAC,MAAK,4BAAA,CAA8B;IAE9E;IAEA,IAAI,CAAC,gBAAgB,OAAO;QAC1B,IAAI,MAAM,OAAO,OAAO,SAAS,OAAO,gCAAgC;QACxE,IAAI,OAAO,IAAI,CAAC,MAAM,MAAM,EAAE,OAAO,YAAY,OAAO,yCAAyC;QACjG,OAAO;IACT;IACA,IAAI,CAAC,KAAK,MAAM,EAAE,OAAO;IACzB,IAAI,OAAO,OAAO,OAAO,UAAU,OAAO,qDAAqD;IAC/F,IAAI,OAAO,OAAO,OAAO,UAAU,OAAO,yBAAyB;IACnE,OAAO,aAAa,OAAO,2BAA2B;AACxD"}},
    {"offset": {"line": 4230, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 4234, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/bulk/common.ts"],"sourcesContent":["import { type BSONSerializeOptions, type Document, EJSON, resolveBSONOptions } from '../bson';\nimport type { Collection } from '../collection';\nimport {\n  type AnyError,\n  MongoBatchReExecutionError,\n  MONGODB_ERROR_CODES,\n  MongoInvalidArgumentError,\n  MongoRuntimeError,\n  MongoServerError,\n  MongoWriteConcernError\n} from '../error';\nimport type { Filter, OneOrMore, OptionalId, UpdateFilter, WithoutId } from '../mongo_types';\nimport type { CollationOptions, CommandOperationOptions } from '../operations/command';\nimport { DeleteOperation, type DeleteStatement, makeDeleteStatement } from '../operations/delete';\nimport { executeOperation } from '../operations/execute_operation';\nimport { InsertOperation } from '../operations/insert';\nimport { AbstractOperation, type Hint } from '../operations/operation';\nimport { makeUpdateStatement, UpdateOperation, type UpdateStatement } from '../operations/update';\nimport type { Server } from '../sdam/server';\nimport type { Topology } from '../sdam/topology';\nimport type { ClientSession } from '../sessions';\nimport { type Sort } from '../sort';\nimport { type TimeoutContext } from '../timeout';\nimport {\n  applyRetryableWrites,\n  getTopology,\n  hasAtomicOperators,\n  maybeAddIdToDocuments,\n  type MongoDBNamespace,\n  resolveOptions\n} from '../utils';\nimport { WriteConcern } from '../write_concern';\n\n/** @public */\nexport const BatchType = Object.freeze({\n  INSERT: 1,\n  UPDATE: 2,\n  DELETE: 3\n} as const);\n\n/** @public */\nexport type BatchType = (typeof BatchType)[keyof typeof BatchType];\n\n/** @public */\nexport interface InsertOneModel<TSchema extends Document = Document> {\n  /** The document to insert. */\n  document: OptionalId<TSchema>;\n}\n\n/** @public */\nexport interface DeleteOneModel<TSchema extends Document = Document> {\n  /** The filter to limit the deleted documents. */\n  filter: Filter<TSchema>;\n  /** Specifies a collation. */\n  collation?: CollationOptions;\n  /** The index to use. If specified, then the query system will only consider plans using the hinted index. */\n  hint?: Hint;\n}\n\n/** @public */\nexport interface DeleteManyModel<TSchema extends Document = Document> {\n  /** The filter to limit the deleted documents. */\n  filter: Filter<TSchema>;\n  /** Specifies a collation. */\n  collation?: CollationOptions;\n  /** The index to use. If specified, then the query system will only consider plans using the hinted index. */\n  hint?: Hint;\n}\n\n/** @public */\nexport interface ReplaceOneModel<TSchema extends Document = Document> {\n  /** The filter that specifies which document to replace. In the case of multiple matches, the first document matched is replaced. */\n  filter: Filter<TSchema>;\n  /** The document with which to replace the matched document. */\n  replacement: WithoutId<TSchema>;\n  /** Specifies a collation. */\n  collation?: CollationOptions;\n  /** The index to use. If specified, then the query system will only consider plans using the hinted index. */\n  hint?: Hint;\n  /** When true, creates a new document if no document matches the query. */\n  upsert?: boolean;\n  /** Specifies the sort order for the documents matched by the filter. */\n  sort?: Sort;\n}\n\n/** @public */\nexport interface UpdateOneModel<TSchema extends Document = Document> {\n  /** The filter that specifies which document to update. In the case of multiple matches, the first document matched is updated. */\n  filter: Filter<TSchema>;\n  /**\n   * The modifications to apply. The value can be either:\n   * UpdateFilter<TSchema> - A document that contains update operator expressions,\n   * Document[] - an aggregation pipeline.\n   */\n  update: UpdateFilter<TSchema> | Document[];\n  /** A set of filters specifying to which array elements an update should apply. */\n  arrayFilters?: Document[];\n  /** Specifies a collation. */\n  collation?: CollationOptions;\n  /** The index to use. If specified, then the query system will only consider plans using the hinted index. */\n  hint?: Hint;\n  /** When true, creates a new document if no document matches the query. */\n  upsert?: boolean;\n  /** Specifies the sort order for the documents matched by the filter. */\n  sort?: Sort;\n}\n\n/** @public */\nexport interface UpdateManyModel<TSchema extends Document = Document> {\n  /** The filter to limit the updated documents. */\n  filter: Filter<TSchema>;\n  /**\n   * The modifications to apply. The value can be either:\n   * UpdateFilter<TSchema> - A document that contains update operator expressions,\n   * Document[] - an aggregation pipeline.\n   */\n  update: UpdateFilter<TSchema> | Document[];\n  /** A set of filters specifying to which array elements an update should apply. */\n  arrayFilters?: Document[];\n  /** Specifies a collation. */\n  collation?: CollationOptions;\n  /** The index to use. If specified, then the query system will only consider plans using the hinted index. */\n  hint?: Hint;\n  /** When true, creates a new document if no document matches the query. */\n  upsert?: boolean;\n}\n\n/** @public */\nexport type AnyBulkWriteOperation<TSchema extends Document = Document> =\n  | { insertOne: InsertOneModel<TSchema> }\n  | { replaceOne: ReplaceOneModel<TSchema> }\n  | { updateOne: UpdateOneModel<TSchema> }\n  | { updateMany: UpdateManyModel<TSchema> }\n  | { deleteOne: DeleteOneModel<TSchema> }\n  | { deleteMany: DeleteManyModel<TSchema> };\n\n/** @internal */\nexport interface BulkResult {\n  ok: number;\n  writeErrors: WriteError[];\n  writeConcernErrors: WriteConcernError[];\n  insertedIds: Document[];\n  nInserted: number;\n  nUpserted: number;\n  nMatched: number;\n  nModified: number;\n  nRemoved: number;\n  upserted: Document[];\n}\n\n/**\n * Keeps the state of a unordered batch so we can rewrite the results\n * correctly after command execution\n *\n * @public\n */\nexport class Batch<T = Document> {\n  originalZeroIndex: number;\n  currentIndex: number;\n  originalIndexes: number[];\n  batchType: BatchType;\n  operations: T[];\n  size: number;\n  sizeBytes: number;\n\n  constructor(batchType: BatchType, originalZeroIndex: number) {\n    this.originalZeroIndex = originalZeroIndex;\n    this.currentIndex = 0;\n    this.originalIndexes = [];\n    this.batchType = batchType;\n    this.operations = [];\n    this.size = 0;\n    this.sizeBytes = 0;\n  }\n}\n\n/**\n * @public\n * The result of a bulk write.\n */\nexport class BulkWriteResult {\n  private readonly result: BulkResult;\n  /** Number of documents inserted. */\n  readonly insertedCount: number;\n  /** Number of documents matched for update. */\n  readonly matchedCount: number;\n  /** Number of documents modified. */\n  readonly modifiedCount: number;\n  /** Number of documents deleted. */\n  readonly deletedCount: number;\n  /** Number of documents upserted. */\n  readonly upsertedCount: number;\n  /** Upserted document generated Id's, hash key is the index of the originating operation */\n  readonly upsertedIds: { [key: number]: any };\n  /** Inserted document generated Id's, hash key is the index of the originating operation */\n  readonly insertedIds: { [key: number]: any };\n\n  private static generateIdMap(ids: Document[]): { [key: number]: any } {\n    const idMap: { [index: number]: any } = {};\n    for (const doc of ids) {\n      idMap[doc.index] = doc._id;\n    }\n    return idMap;\n  }\n\n  /**\n   * Create a new BulkWriteResult instance\n   * @internal\n   */\n  constructor(bulkResult: BulkResult, isOrdered: boolean) {\n    this.result = bulkResult;\n    this.insertedCount = this.result.nInserted ?? 0;\n    this.matchedCount = this.result.nMatched ?? 0;\n    this.modifiedCount = this.result.nModified ?? 0;\n    this.deletedCount = this.result.nRemoved ?? 0;\n    this.upsertedCount = this.result.upserted.length ?? 0;\n    this.upsertedIds = BulkWriteResult.generateIdMap(this.result.upserted);\n    this.insertedIds = BulkWriteResult.generateIdMap(\n      this.getSuccessfullyInsertedIds(bulkResult, isOrdered)\n    );\n    Object.defineProperty(this, 'result', { value: this.result, enumerable: false });\n  }\n\n  /** Evaluates to true if the bulk operation correctly executes */\n  get ok(): number {\n    return this.result.ok;\n  }\n\n  /**\n   * Returns document_ids that were actually inserted\n   * @internal\n   */\n  private getSuccessfullyInsertedIds(bulkResult: BulkResult, isOrdered: boolean): Document[] {\n    if (bulkResult.writeErrors.length === 0) return bulkResult.insertedIds;\n\n    if (isOrdered) {\n      return bulkResult.insertedIds.slice(0, bulkResult.writeErrors[0].index);\n    }\n\n    return bulkResult.insertedIds.filter(\n      ({ index }) => !bulkResult.writeErrors.some(writeError => index === writeError.index)\n    );\n  }\n\n  /** Returns the upserted id at the given index */\n  getUpsertedIdAt(index: number): Document | undefined {\n    return this.result.upserted[index];\n  }\n\n  /** Returns raw internal result */\n  getRawResponse(): Document {\n    return this.result;\n  }\n\n  /** Returns true if the bulk operation contains a write error */\n  hasWriteErrors(): boolean {\n    return this.result.writeErrors.length > 0;\n  }\n\n  /** Returns the number of write errors from the bulk operation */\n  getWriteErrorCount(): number {\n    return this.result.writeErrors.length;\n  }\n\n  /** Returns a specific write error object */\n  getWriteErrorAt(index: number): WriteError | undefined {\n    return index < this.result.writeErrors.length ? this.result.writeErrors[index] : undefined;\n  }\n\n  /** Retrieve all write errors */\n  getWriteErrors(): WriteError[] {\n    return this.result.writeErrors;\n  }\n\n  /** Retrieve the write concern error if one exists */\n  getWriteConcernError(): WriteConcernError | undefined {\n    if (this.result.writeConcernErrors.length === 0) {\n      return;\n    } else if (this.result.writeConcernErrors.length === 1) {\n      // Return the error\n      return this.result.writeConcernErrors[0];\n    } else {\n      // Combine the errors\n      let errmsg = '';\n      for (let i = 0; i < this.result.writeConcernErrors.length; i++) {\n        const err = this.result.writeConcernErrors[i];\n        errmsg = errmsg + err.errmsg;\n\n        // TODO: Something better\n        if (i === 0) errmsg = errmsg + ' and ';\n      }\n\n      return new WriteConcernError({ errmsg, code: MONGODB_ERROR_CODES.WriteConcernTimeout });\n    }\n  }\n\n  toString(): string {\n    return `BulkWriteResult(${EJSON.stringify(this.result)})`;\n  }\n\n  isOk(): boolean {\n    return this.result.ok === 1;\n  }\n}\n\n/** @public */\nexport interface WriteConcernErrorData {\n  code: number;\n  errmsg: string;\n  errInfo?: Document;\n}\n\n/**\n * An error representing a failure by the server to apply the requested write concern to the bulk operation.\n * @public\n * @category Error\n */\nexport class WriteConcernError {\n  /** @internal */\n  private serverError: WriteConcernErrorData;\n\n  constructor(error: WriteConcernErrorData) {\n    this.serverError = error;\n  }\n\n  /** Write concern error code. */\n  get code(): number | undefined {\n    return this.serverError.code;\n  }\n\n  /** Write concern error message. */\n  get errmsg(): string | undefined {\n    return this.serverError.errmsg;\n  }\n\n  /** Write concern error info. */\n  get errInfo(): Document | undefined {\n    return this.serverError.errInfo;\n  }\n\n  toJSON(): WriteConcernErrorData {\n    return this.serverError;\n  }\n\n  toString(): string {\n    return `WriteConcernError(${this.errmsg})`;\n  }\n}\n\n/** @public */\nexport interface BulkWriteOperationError {\n  index: number;\n  code: number;\n  errmsg: string;\n  errInfo: Document;\n  op: Document | UpdateStatement | DeleteStatement;\n}\n\n/**\n * An error that occurred during a BulkWrite on the server.\n * @public\n * @category Error\n */\nexport class WriteError {\n  err: BulkWriteOperationError;\n\n  constructor(err: BulkWriteOperationError) {\n    this.err = err;\n  }\n\n  /** WriteError code. */\n  get code(): number {\n    return this.err.code;\n  }\n\n  /** WriteError original bulk operation index. */\n  get index(): number {\n    return this.err.index;\n  }\n\n  /** WriteError message. */\n  get errmsg(): string | undefined {\n    return this.err.errmsg;\n  }\n\n  /** WriteError details. */\n  get errInfo(): Document | undefined {\n    return this.err.errInfo;\n  }\n\n  /** Returns the underlying operation that caused the error */\n  getOperation(): Document {\n    return this.err.op;\n  }\n\n  toJSON(): { code: number; index: number; errmsg?: string; op: Document } {\n    return { code: this.err.code, index: this.err.index, errmsg: this.err.errmsg, op: this.err.op };\n  }\n\n  toString(): string {\n    return `WriteError(${JSON.stringify(this.toJSON())})`;\n  }\n}\n\n/** Merges results into shared data structure */\nexport function mergeBatchResults(\n  batch: Batch,\n  bulkResult: BulkResult,\n  err?: AnyError,\n  result?: Document\n): void {\n  // If we have an error set the result to be the err object\n  if (err) {\n    result = err;\n  } else if (result && result.result) {\n    result = result.result;\n  }\n\n  if (result == null) {\n    return;\n  }\n\n  // Do we have a top level error stop processing and return\n  if (result.ok === 0 && bulkResult.ok === 1) {\n    bulkResult.ok = 0;\n\n    const writeError = {\n      index: 0,\n      code: result.code || 0,\n      errmsg: result.message,\n      errInfo: result.errInfo,\n      op: batch.operations[0]\n    };\n\n    bulkResult.writeErrors.push(new WriteError(writeError));\n    return;\n  } else if (result.ok === 0 && bulkResult.ok === 0) {\n    return;\n  }\n\n  // If we have an insert Batch type\n  if (isInsertBatch(batch) && result.n) {\n    bulkResult.nInserted = bulkResult.nInserted + result.n;\n  }\n\n  // If we have an insert Batch type\n  if (isDeleteBatch(batch) && result.n) {\n    bulkResult.nRemoved = bulkResult.nRemoved + result.n;\n  }\n\n  let nUpserted = 0;\n\n  // We have an array of upserted values, we need to rewrite the indexes\n  if (Array.isArray(result.upserted)) {\n    nUpserted = result.upserted.length;\n\n    for (let i = 0; i < result.upserted.length; i++) {\n      bulkResult.upserted.push({\n        index: result.upserted[i].index + batch.originalZeroIndex,\n        _id: result.upserted[i]._id\n      });\n    }\n  } else if (result.upserted) {\n    nUpserted = 1;\n\n    bulkResult.upserted.push({\n      index: batch.originalZeroIndex,\n      _id: result.upserted\n    });\n  }\n\n  // If we have an update Batch type\n  if (isUpdateBatch(batch) && result.n) {\n    const nModified = result.nModified;\n    bulkResult.nUpserted = bulkResult.nUpserted + nUpserted;\n    bulkResult.nMatched = bulkResult.nMatched + (result.n - nUpserted);\n\n    if (typeof nModified === 'number') {\n      bulkResult.nModified = bulkResult.nModified + nModified;\n    } else {\n      bulkResult.nModified = 0;\n    }\n  }\n\n  if (Array.isArray(result.writeErrors)) {\n    for (let i = 0; i < result.writeErrors.length; i++) {\n      const writeError = {\n        index: batch.originalIndexes[result.writeErrors[i].index],\n        code: result.writeErrors[i].code,\n        errmsg: result.writeErrors[i].errmsg,\n        errInfo: result.writeErrors[i].errInfo,\n        op: batch.operations[result.writeErrors[i].index]\n      };\n\n      bulkResult.writeErrors.push(new WriteError(writeError));\n    }\n  }\n\n  if (result.writeConcernError) {\n    bulkResult.writeConcernErrors.push(new WriteConcernError(result.writeConcernError));\n  }\n}\n\nasync function executeCommands(\n  bulkOperation: BulkOperationBase,\n  options: BulkWriteOptions & { timeoutContext?: TimeoutContext | null }\n): Promise<BulkWriteResult> {\n  if (bulkOperation.s.batches.length === 0) {\n    return new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered);\n  }\n\n  for (const batch of bulkOperation.s.batches) {\n    const finalOptions = resolveOptions(bulkOperation, {\n      ...options,\n      ordered: bulkOperation.isOrdered\n    });\n\n    if (finalOptions.bypassDocumentValidation !== true) {\n      delete finalOptions.bypassDocumentValidation;\n    }\n\n    // Is the bypassDocumentValidation options specific\n    if (bulkOperation.s.bypassDocumentValidation === true) {\n      finalOptions.bypassDocumentValidation = true;\n    }\n\n    // Is the checkKeys option disabled\n    if (bulkOperation.s.checkKeys === false) {\n      finalOptions.checkKeys = false;\n    }\n\n    if (finalOptions.retryWrites) {\n      if (isUpdateBatch(batch)) {\n        finalOptions.retryWrites =\n          finalOptions.retryWrites && !batch.operations.some(op => op.multi);\n      }\n\n      if (isDeleteBatch(batch)) {\n        finalOptions.retryWrites =\n          finalOptions.retryWrites && !batch.operations.some(op => op.limit === 0);\n      }\n    }\n\n    const operation = isInsertBatch(batch)\n      ? new InsertOperation(bulkOperation.s.namespace, batch.operations, finalOptions)\n      : isUpdateBatch(batch)\n        ? new UpdateOperation(bulkOperation.s.namespace, batch.operations, finalOptions)\n        : isDeleteBatch(batch)\n          ? new DeleteOperation(bulkOperation.s.namespace, batch.operations, finalOptions)\n          : null;\n\n    if (operation == null) throw new MongoRuntimeError(`Unknown batchType: ${batch.batchType}`);\n\n    let thrownError = null;\n    let result;\n    try {\n      result = await executeOperation(\n        bulkOperation.s.collection.client,\n        operation,\n        finalOptions.timeoutContext\n      );\n    } catch (error) {\n      thrownError = error;\n    }\n\n    if (thrownError != null) {\n      if (thrownError instanceof MongoWriteConcernError) {\n        mergeBatchResults(batch, bulkOperation.s.bulkResult, thrownError, result);\n        const writeResult = new BulkWriteResult(\n          bulkOperation.s.bulkResult,\n          bulkOperation.isOrdered\n        );\n\n        throw new MongoBulkWriteError(\n          {\n            message: thrownError.result.writeConcernError.errmsg,\n            code: thrownError.result.writeConcernError.code\n          },\n          writeResult\n        );\n      } else {\n        // Error is a driver related error not a bulk op error, return early\n        throw new MongoBulkWriteError(\n          thrownError,\n          new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered)\n        );\n      }\n    }\n\n    mergeBatchResults(batch, bulkOperation.s.bulkResult, thrownError, result);\n    const writeResult = new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered);\n    bulkOperation.handleWriteError(writeResult);\n  }\n\n  bulkOperation.s.batches.length = 0;\n\n  const writeResult = new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered);\n  bulkOperation.handleWriteError(writeResult);\n  return writeResult;\n}\n\n/**\n * An error indicating an unsuccessful Bulk Write\n * @public\n * @category Error\n */\nexport class MongoBulkWriteError extends MongoServerError {\n  result: BulkWriteResult;\n  writeErrors: OneOrMore<WriteError> = [];\n  err?: WriteConcernError;\n\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(\n    error:\n      | { message: string; code: number; writeErrors?: WriteError[] }\n      | WriteConcernError\n      | AnyError,\n    result: BulkWriteResult\n  ) {\n    super(error);\n\n    if (error instanceof WriteConcernError) this.err = error;\n    else if (!(error instanceof Error)) {\n      this.message = error.message;\n      this.code = error.code;\n      this.writeErrors = error.writeErrors ?? [];\n    }\n\n    this.result = result;\n    Object.assign(this, error);\n  }\n\n  override get name(): string {\n    return 'MongoBulkWriteError';\n  }\n\n  /** Number of documents inserted. */\n  get insertedCount(): number {\n    return this.result.insertedCount;\n  }\n  /** Number of documents matched for update. */\n  get matchedCount(): number {\n    return this.result.matchedCount;\n  }\n  /** Number of documents modified. */\n  get modifiedCount(): number {\n    return this.result.modifiedCount;\n  }\n  /** Number of documents deleted. */\n  get deletedCount(): number {\n    return this.result.deletedCount;\n  }\n  /** Number of documents upserted. */\n  get upsertedCount(): number {\n    return this.result.upsertedCount;\n  }\n  /** Inserted document generated Id's, hash key is the index of the originating operation */\n  get insertedIds(): { [key: number]: any } {\n    return this.result.insertedIds;\n  }\n  /** Upserted document generated Id's, hash key is the index of the originating operation */\n  get upsertedIds(): { [key: number]: any } {\n    return this.result.upsertedIds;\n  }\n}\n\n/**\n * A builder object that is returned from {@link BulkOperationBase#find}.\n * Is used to build a write operation that involves a query filter.\n *\n * @public\n */\nexport class FindOperators {\n  bulkOperation: BulkOperationBase;\n\n  /**\n   * Creates a new FindOperators object.\n   * @internal\n   */\n  constructor(bulkOperation: BulkOperationBase) {\n    this.bulkOperation = bulkOperation;\n  }\n\n  /** Add a multiple update operation to the bulk operation */\n  update(updateDocument: Document | Document[]): BulkOperationBase {\n    const currentOp = buildCurrentOp(this.bulkOperation);\n    return this.bulkOperation.addToOperationsList(\n      BatchType.UPDATE,\n      makeUpdateStatement(currentOp.selector, updateDocument, {\n        ...currentOp,\n        multi: true\n      })\n    );\n  }\n\n  /** Add a single update operation to the bulk operation */\n  updateOne(updateDocument: Document | Document[]): BulkOperationBase {\n    if (!hasAtomicOperators(updateDocument, this.bulkOperation.bsonOptions)) {\n      throw new MongoInvalidArgumentError('Update document requires atomic operators');\n    }\n\n    const currentOp = buildCurrentOp(this.bulkOperation);\n    return this.bulkOperation.addToOperationsList(\n      BatchType.UPDATE,\n      makeUpdateStatement(currentOp.selector, updateDocument, { ...currentOp, multi: false })\n    );\n  }\n\n  /** Add a replace one operation to the bulk operation */\n  replaceOne(replacement: Document): BulkOperationBase {\n    if (hasAtomicOperators(replacement)) {\n      throw new MongoInvalidArgumentError('Replacement document must not use atomic operators');\n    }\n\n    const currentOp = buildCurrentOp(this.bulkOperation);\n    return this.bulkOperation.addToOperationsList(\n      BatchType.UPDATE,\n      makeUpdateStatement(currentOp.selector, replacement, { ...currentOp, multi: false })\n    );\n  }\n\n  /** Add a delete one operation to the bulk operation */\n  deleteOne(): BulkOperationBase {\n    const currentOp = buildCurrentOp(this.bulkOperation);\n    return this.bulkOperation.addToOperationsList(\n      BatchType.DELETE,\n      makeDeleteStatement(currentOp.selector, { ...currentOp, limit: 1 })\n    );\n  }\n\n  /** Add a delete many operation to the bulk operation */\n  delete(): BulkOperationBase {\n    const currentOp = buildCurrentOp(this.bulkOperation);\n    return this.bulkOperation.addToOperationsList(\n      BatchType.DELETE,\n      makeDeleteStatement(currentOp.selector, { ...currentOp, limit: 0 })\n    );\n  }\n\n  /** Upsert modifier for update bulk operation, noting that this operation is an upsert. */\n  upsert(): this {\n    if (!this.bulkOperation.s.currentOp) {\n      this.bulkOperation.s.currentOp = {};\n    }\n\n    this.bulkOperation.s.currentOp.upsert = true;\n    return this;\n  }\n\n  /** Specifies the collation for the query condition. */\n  collation(collation: CollationOptions): this {\n    if (!this.bulkOperation.s.currentOp) {\n      this.bulkOperation.s.currentOp = {};\n    }\n\n    this.bulkOperation.s.currentOp.collation = collation;\n    return this;\n  }\n\n  /** Specifies arrayFilters for UpdateOne or UpdateMany bulk operations. */\n  arrayFilters(arrayFilters: Document[]): this {\n    if (!this.bulkOperation.s.currentOp) {\n      this.bulkOperation.s.currentOp = {};\n    }\n\n    this.bulkOperation.s.currentOp.arrayFilters = arrayFilters;\n    return this;\n  }\n\n  /** Specifies hint for the bulk operation. */\n  hint(hint: Hint): this {\n    if (!this.bulkOperation.s.currentOp) {\n      this.bulkOperation.s.currentOp = {};\n    }\n\n    this.bulkOperation.s.currentOp.hint = hint;\n    return this;\n  }\n}\n\n/** @internal */\nexport interface BulkOperationPrivate {\n  bulkResult: BulkResult;\n  currentBatch?: Batch;\n  currentIndex: number;\n  // ordered specific\n  currentBatchSize: number;\n  currentBatchSizeBytes: number;\n  // unordered specific\n  currentInsertBatch?: Batch;\n  currentUpdateBatch?: Batch;\n  currentRemoveBatch?: Batch;\n  batches: Batch[];\n  // Write concern\n  writeConcern?: WriteConcern;\n  // Max batch size options\n  maxBsonObjectSize: number;\n  maxBatchSizeBytes: number;\n  maxWriteBatchSize: number;\n  maxKeySize: number;\n  // Namespace\n  namespace: MongoDBNamespace;\n  // Topology\n  topology: Topology;\n  // Options\n  options: BulkWriteOptions;\n  // BSON options\n  bsonOptions: BSONSerializeOptions;\n  // Document used to build a bulk operation\n  currentOp?: Document;\n  // Executed\n  executed: boolean;\n  // Collection\n  collection: Collection;\n  // Fundamental error\n  err?: AnyError;\n  // check keys\n  checkKeys: boolean;\n  bypassDocumentValidation?: boolean;\n}\n\n/** @public */\nexport interface BulkWriteOptions extends CommandOperationOptions {\n  /**\n   * Allow driver to bypass schema validation.\n   * @defaultValue `false` - documents will be validated by default\n   **/\n  bypassDocumentValidation?: boolean;\n  /**\n   * If true, when an insert fails, don't execute the remaining writes.\n   * If false, continue with remaining inserts when one fails.\n   * @defaultValue `true` - inserts are ordered by default\n   */\n  ordered?: boolean;\n  /**\n   * Force server to assign _id values instead of driver.\n   * @defaultValue `false` - the driver generates `_id` fields by default\n   **/\n  forceServerObjectId?: boolean;\n  /** Map of parameter names and values that can be accessed using $$var (requires MongoDB 5.0). */\n  let?: Document;\n\n  /** @internal */\n  timeoutContext?: TimeoutContext;\n}\n\n/**\n * TODO(NODE-4063)\n * BulkWrites merge complexity is implemented in executeCommands\n * This provides a vehicle to treat bulkOperations like any other operation (hence \"shim\")\n * We would like this logic to simply live inside the BulkWriteOperation class\n * @internal\n */\nexport class BulkWriteShimOperation extends AbstractOperation {\n  bulkOperation: BulkOperationBase;\n  constructor(bulkOperation: BulkOperationBase, options: BulkWriteOptions) {\n    super(options);\n    this.bulkOperation = bulkOperation;\n  }\n\n  get commandName(): string {\n    return 'bulkWrite' as const;\n  }\n\n  async execute(\n    _server: Server,\n    session: ClientSession | undefined,\n    timeoutContext: TimeoutContext\n  ): Promise<any> {\n    if (this.options.session == null) {\n      // An implicit session could have been created by 'executeOperation'\n      // So if we stick it on finalOptions here, each bulk operation\n      // will use this same session, it'll be passed in the same way\n      // an explicit session would be\n      this.options.session = session;\n    }\n    return await executeCommands(this.bulkOperation, { ...this.options, timeoutContext });\n  }\n}\n\n/** @public */\nexport abstract class BulkOperationBase {\n  isOrdered: boolean;\n  /** @internal */\n  s: BulkOperationPrivate;\n  operationId?: number;\n\n  /**\n   * Create a new OrderedBulkOperation or UnorderedBulkOperation instance\n   * @internal\n   */\n  constructor(\n    private collection: Collection,\n    options: BulkWriteOptions,\n    isOrdered: boolean\n  ) {\n    // determine whether bulkOperation is ordered or unordered\n    this.isOrdered = isOrdered;\n\n    const topology = getTopology(collection);\n    options = options == null ? {} : options;\n    // TODO Bring from driver information in hello\n    // Get the namespace for the write operations\n    const namespace = collection.s.namespace;\n    // Used to mark operation as executed\n    const executed = false;\n\n    // Current item\n    const currentOp = undefined;\n\n    // Set max byte size\n    const hello = topology.lastHello();\n\n    // If we have autoEncryption on, batch-splitting must be done on 2mb chunks, but single documents\n    // over 2mb are still allowed\n    const usingAutoEncryption = !!(topology.s.options && topology.s.options.autoEncrypter);\n    const maxBsonObjectSize =\n      hello && hello.maxBsonObjectSize ? hello.maxBsonObjectSize : 1024 * 1024 * 16;\n    const maxBatchSizeBytes = usingAutoEncryption ? 1024 * 1024 * 2 : maxBsonObjectSize;\n    const maxWriteBatchSize = hello && hello.maxWriteBatchSize ? hello.maxWriteBatchSize : 1000;\n\n    // Calculates the largest possible size of an Array key, represented as a BSON string\n    // element. This calculation:\n    //     1 byte for BSON type\n    //     # of bytes = length of (string representation of (maxWriteBatchSize - 1))\n    //   + 1 bytes for null terminator\n    const maxKeySize = (maxWriteBatchSize - 1).toString(10).length + 2;\n\n    // Final options for retryable writes\n    let finalOptions = Object.assign({}, options);\n    finalOptions = applyRetryableWrites(finalOptions, collection.s.db);\n\n    // Final results\n    const bulkResult: BulkResult = {\n      ok: 1,\n      writeErrors: [],\n      writeConcernErrors: [],\n      insertedIds: [],\n      nInserted: 0,\n      nUpserted: 0,\n      nMatched: 0,\n      nModified: 0,\n      nRemoved: 0,\n      upserted: []\n    };\n\n    // Internal state\n    this.s = {\n      // Final result\n      bulkResult,\n      // Current batch state\n      currentBatch: undefined,\n      currentIndex: 0,\n      // ordered specific\n      currentBatchSize: 0,\n      currentBatchSizeBytes: 0,\n      // unordered specific\n      currentInsertBatch: undefined,\n      currentUpdateBatch: undefined,\n      currentRemoveBatch: undefined,\n      batches: [],\n      // Write concern\n      writeConcern: WriteConcern.fromOptions(options),\n      // Max batch size options\n      maxBsonObjectSize,\n      maxBatchSizeBytes,\n      maxWriteBatchSize,\n      maxKeySize,\n      // Namespace\n      namespace,\n      // Topology\n      topology,\n      // Options\n      options: finalOptions,\n      // BSON options\n      bsonOptions: resolveBSONOptions(options),\n      // Current operation\n      currentOp,\n      // Executed\n      executed,\n      // Collection\n      collection,\n      // Fundamental error\n      err: undefined,\n      // check keys\n      checkKeys: typeof options.checkKeys === 'boolean' ? options.checkKeys : false\n    };\n\n    // bypass Validation\n    if (options.bypassDocumentValidation === true) {\n      this.s.bypassDocumentValidation = true;\n    }\n  }\n\n  /**\n   * Add a single insert document to the bulk operation\n   *\n   * @example\n   * ```ts\n   * const bulkOp = collection.initializeOrderedBulkOp();\n   *\n   * // Adds three inserts to the bulkOp.\n   * bulkOp\n   *   .insert({ a: 1 })\n   *   .insert({ b: 2 })\n   *   .insert({ c: 3 });\n   * await bulkOp.execute();\n   * ```\n   */\n  insert(document: Document): BulkOperationBase {\n    maybeAddIdToDocuments(this.collection, document, {\n      forceServerObjectId: this.shouldForceServerObjectId()\n    });\n\n    return this.addToOperationsList(BatchType.INSERT, document);\n  }\n\n  /**\n   * Builds a find operation for an update/updateOne/delete/deleteOne/replaceOne.\n   * Returns a builder object used to complete the definition of the operation.\n   *\n   * @example\n   * ```ts\n   * const bulkOp = collection.initializeOrderedBulkOp();\n   *\n   * // Add an updateOne to the bulkOp\n   * bulkOp.find({ a: 1 }).updateOne({ $set: { b: 2 } });\n   *\n   * // Add an updateMany to the bulkOp\n   * bulkOp.find({ c: 3 }).update({ $set: { d: 4 } });\n   *\n   * // Add an upsert\n   * bulkOp.find({ e: 5 }).upsert().updateOne({ $set: { f: 6 } });\n   *\n   * // Add a deletion\n   * bulkOp.find({ g: 7 }).deleteOne();\n   *\n   * // Add a multi deletion\n   * bulkOp.find({ h: 8 }).delete();\n   *\n   * // Add a replaceOne\n   * bulkOp.find({ i: 9 }).replaceOne({writeConcern: { j: 10 }});\n   *\n   * // Update using a pipeline (requires Mongodb 4.2 or higher)\n   * bulk.find({ k: 11, y: { $exists: true }, z: { $exists: true } }).updateOne([\n   *   { $set: { total: { $sum: [ '$y', '$z' ] } } }\n   * ]);\n   *\n   * // All of the ops will now be executed\n   * await bulkOp.execute();\n   * ```\n   */\n  find(selector: Document): FindOperators {\n    if (!selector) {\n      throw new MongoInvalidArgumentError('Bulk find operation must specify a selector');\n    }\n\n    // Save a current selector\n    this.s.currentOp = {\n      selector: selector\n    };\n\n    return new FindOperators(this);\n  }\n\n  /** Specifies a raw operation to perform in the bulk write. */\n  raw(op: AnyBulkWriteOperation): this {\n    if (op == null || typeof op !== 'object') {\n      throw new MongoInvalidArgumentError('Operation must be an object with an operation key');\n    }\n    if ('insertOne' in op) {\n      const forceServerObjectId = this.shouldForceServerObjectId();\n      const document =\n        op.insertOne && op.insertOne.document == null\n          ? // TODO(NODE-6003): remove support for omitting the `documents` subdocument in bulk inserts\n            (op.insertOne as Document)\n          : op.insertOne.document;\n\n      maybeAddIdToDocuments(this.collection, document, { forceServerObjectId });\n\n      return this.addToOperationsList(BatchType.INSERT, document);\n    }\n\n    if ('replaceOne' in op || 'updateOne' in op || 'updateMany' in op) {\n      if ('replaceOne' in op) {\n        if ('q' in op.replaceOne) {\n          throw new MongoInvalidArgumentError('Raw operations are not allowed');\n        }\n        const updateStatement = makeUpdateStatement(\n          op.replaceOne.filter,\n          op.replaceOne.replacement,\n          { ...op.replaceOne, multi: false }\n        );\n        if (hasAtomicOperators(updateStatement.u)) {\n          throw new MongoInvalidArgumentError('Replacement document must not use atomic operators');\n        }\n        return this.addToOperationsList(BatchType.UPDATE, updateStatement);\n      }\n\n      if ('updateOne' in op) {\n        if ('q' in op.updateOne) {\n          throw new MongoInvalidArgumentError('Raw operations are not allowed');\n        }\n        const updateStatement = makeUpdateStatement(op.updateOne.filter, op.updateOne.update, {\n          ...op.updateOne,\n          multi: false\n        });\n        if (!hasAtomicOperators(updateStatement.u, this.bsonOptions)) {\n          throw new MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n        return this.addToOperationsList(BatchType.UPDATE, updateStatement);\n      }\n\n      if ('updateMany' in op) {\n        if ('q' in op.updateMany) {\n          throw new MongoInvalidArgumentError('Raw operations are not allowed');\n        }\n        const updateStatement = makeUpdateStatement(op.updateMany.filter, op.updateMany.update, {\n          ...op.updateMany,\n          multi: true\n        });\n        if (!hasAtomicOperators(updateStatement.u, this.bsonOptions)) {\n          throw new MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n        return this.addToOperationsList(BatchType.UPDATE, updateStatement);\n      }\n    }\n\n    if ('deleteOne' in op) {\n      if ('q' in op.deleteOne) {\n        throw new MongoInvalidArgumentError('Raw operations are not allowed');\n      }\n      return this.addToOperationsList(\n        BatchType.DELETE,\n        makeDeleteStatement(op.deleteOne.filter, { ...op.deleteOne, limit: 1 })\n      );\n    }\n\n    if ('deleteMany' in op) {\n      if ('q' in op.deleteMany) {\n        throw new MongoInvalidArgumentError('Raw operations are not allowed');\n      }\n      return this.addToOperationsList(\n        BatchType.DELETE,\n        makeDeleteStatement(op.deleteMany.filter, { ...op.deleteMany, limit: 0 })\n      );\n    }\n\n    // otherwise an unknown operation was provided\n    throw new MongoInvalidArgumentError(\n      'bulkWrite only supports insertOne, updateOne, updateMany, deleteOne, deleteMany'\n    );\n  }\n\n  get length(): number {\n    return this.s.currentIndex;\n  }\n\n  get bsonOptions(): BSONSerializeOptions {\n    return this.s.bsonOptions;\n  }\n\n  get writeConcern(): WriteConcern | undefined {\n    return this.s.writeConcern;\n  }\n\n  get batches(): Batch[] {\n    const batches = [...this.s.batches];\n    if (this.isOrdered) {\n      if (this.s.currentBatch) batches.push(this.s.currentBatch);\n    } else {\n      if (this.s.currentInsertBatch) batches.push(this.s.currentInsertBatch);\n      if (this.s.currentUpdateBatch) batches.push(this.s.currentUpdateBatch);\n      if (this.s.currentRemoveBatch) batches.push(this.s.currentRemoveBatch);\n    }\n    return batches;\n  }\n\n  async execute(options: BulkWriteOptions = {}): Promise<BulkWriteResult> {\n    if (this.s.executed) {\n      throw new MongoBatchReExecutionError();\n    }\n\n    const writeConcern = WriteConcern.fromOptions(options);\n    if (writeConcern) {\n      this.s.writeConcern = writeConcern;\n    }\n\n    // If we have current batch\n    if (this.isOrdered) {\n      if (this.s.currentBatch) this.s.batches.push(this.s.currentBatch);\n    } else {\n      if (this.s.currentInsertBatch) this.s.batches.push(this.s.currentInsertBatch);\n      if (this.s.currentUpdateBatch) this.s.batches.push(this.s.currentUpdateBatch);\n      if (this.s.currentRemoveBatch) this.s.batches.push(this.s.currentRemoveBatch);\n    }\n    // If we have no operations in the bulk raise an error\n    if (this.s.batches.length === 0) {\n      throw new MongoInvalidArgumentError('Invalid BulkOperation, Batch cannot be empty');\n    }\n\n    this.s.executed = true;\n    const finalOptions = { ...this.s.options, ...options };\n    const operation = new BulkWriteShimOperation(this, finalOptions);\n\n    return await executeOperation(this.s.collection.client, operation, finalOptions.timeoutContext);\n  }\n\n  /**\n   * Handles the write error before executing commands\n   * @internal\n   */\n  handleWriteError(writeResult: BulkWriteResult): void {\n    if (this.s.bulkResult.writeErrors.length > 0) {\n      const msg = this.s.bulkResult.writeErrors[0].errmsg\n        ? this.s.bulkResult.writeErrors[0].errmsg\n        : 'write operation failed';\n\n      throw new MongoBulkWriteError(\n        {\n          message: msg,\n          code: this.s.bulkResult.writeErrors[0].code,\n          writeErrors: this.s.bulkResult.writeErrors\n        },\n        writeResult\n      );\n    }\n\n    const writeConcernError = writeResult.getWriteConcernError();\n    if (writeConcernError) {\n      throw new MongoBulkWriteError(writeConcernError, writeResult);\n    }\n  }\n\n  abstract addToOperationsList(\n    batchType: BatchType,\n    document: Document | UpdateStatement | DeleteStatement\n  ): this;\n\n  private shouldForceServerObjectId(): boolean {\n    return (\n      this.s.options.forceServerObjectId === true ||\n      this.s.collection.s.db.options?.forceServerObjectId === true\n    );\n  }\n}\n\nfunction isInsertBatch(batch: Batch): boolean {\n  return batch.batchType === BatchType.INSERT;\n}\n\nfunction isUpdateBatch(batch: Batch): batch is Batch<UpdateStatement> {\n  return batch.batchType === BatchType.UPDATE;\n}\n\nfunction isDeleteBatch(batch: Batch): batch is Batch<DeleteStatement> {\n  return batch.batchType === BatchType.DELETE;\n}\n\nfunction buildCurrentOp(bulkOp: BulkOperationBase): Document {\n  let { currentOp } = bulkOp.s;\n  bulkOp.s.currentOp = undefined;\n  if (!currentOp) currentOp = {};\n  return currentOp;\n}\n"],"names":[],"mappings":";;;;;AAqZA,QAAA,iBAAA,GAAA;AArZA,MAAA;AAEA,MAAA;AAWA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAMA,MAAA;AAQA,MAAA;AAEA,YAAA,GACa,QAAA,SAAS,GAAG,OAAO,MAAM,CAAC;IACrC,QAAQ;IACR,QAAQ;IACR,QAAQ;;AAiHV;;;;;IAMA,MAAa;IASX,YAAY,SAAoB,EAAE,iBAAyB,CAAA;QACzD,IAAI,CAAC,iBAAiB,GAAG;QACzB,IAAI,CAAC,YAAY,GAAG;QACpB,IAAI,CAAC,eAAe,GAAG,EAAE;QACzB,IAAI,CAAC,SAAS,GAAG;QACjB,IAAI,CAAC,UAAU,GAAG,EAAE;QACpB,IAAI,CAAC,IAAI,GAAG;QACZ,IAAI,CAAC,SAAS,GAAG;IACnB;;AAjBF,QAAA,KAAA,GAAA;AAoBA;;;IAIA,MAAa;IAiBH,OAAO,cAAc,GAAe,EAAA;QAC1C,MAAM,QAAkC,CAAA;QACxC,KAAK,MAAM,OAAO,IAAK;YACrB,KAAK,CAAC,IAAI,KAAK,CAAC,GAAG,IAAI,GAAG;QAC5B;QACA,OAAO;IACT;IAEA;;;QAIA,YAAY,UAAsB,EAAE,SAAkB,CAAA;QACpD,IAAI,CAAC,MAAM,GAAG;QACd,IAAI,CAAC,aAAa,GAAG,IAAI,CAAC,MAAM,CAAC,SAAS,IAAI;QAC9C,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC,MAAM,CAAC,QAAQ,IAAI;QAC5C,IAAI,CAAC,aAAa,GAAG,IAAI,CAAC,MAAM,CAAC,SAAS,IAAI;QAC9C,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC,MAAM,CAAC,QAAQ,IAAI;QAC5C,IAAI,CAAC,aAAa,GAAG,IAAI,CAAC,MAAM,CAAC,QAAQ,CAAC,MAAM,IAAI;QACpD,IAAI,CAAC,WAAW,GAAG,gBAAgB,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,QAAQ;QACrE,IAAI,CAAC,WAAW,GAAG,gBAAgB,aAAa,CAC9C,IAAI,CAAC,0BAA0B,CAAC,YAAY;QAE9C,OAAO,cAAc,CAAC,IAAI,EAAE,UAAU;YAAE,OAAO,IAAI,CAAC,MAAM;YAAE,YAAY;QAAK;IAC/E;IAEA,+DAAA,GACA,IAAI,KAAE;QACJ,OAAO,IAAI,CAAC,MAAM,CAAC,EAAE;IACvB;IAEA;;;QAIQ,2BAA2B,UAAsB,EAAE,SAAkB,EAAA;QAC3E,IAAI,WAAW,WAAW,CAAC,MAAM,KAAK,GAAG,OAAO,WAAW,WAAW;QAEtE,IAAI,WAAW;YACb,OAAO,WAAW,WAAW,CAAC,KAAK,CAAC,GAAG,WAAW,WAAW,CAAC,EAAE,CAAC,KAAK;QACxE;QAEA,OAAO,WAAW,WAAW,CAAC,MAAM,CAClC,CAAC,EAAE,KAAK,EAAE,GAAK,CAAC,WAAW,WAAW,CAAC,IAAI,CAAC,CAAA,aAAc,UAAU,WAAW,KAAK;IAExF;IAEA,+CAAA,GACA,gBAAgB,KAAa,EAAA;QAC3B,OAAO,IAAI,CAAC,MAAM,CAAC,QAAQ,CAAC,MAAM;IACpC;IAEA,gCAAA,GACA,iBAAc;QACZ,OAAO,IAAI,CAAC,MAAM;IACpB;IAEA,8DAAA,GACA,iBAAc;QACZ,OAAO,IAAI,CAAC,MAAM,CAAC,WAAW,CAAC,MAAM,GAAG;IAC1C;IAEA,+DAAA,GACA,qBAAkB;QAChB,OAAO,IAAI,CAAC,MAAM,CAAC,WAAW,CAAC,MAAM;IACvC;IAEA,0CAAA,GACA,gBAAgB,KAAa,EAAA;QAC3B,OAAO,QAAQ,IAAI,CAAC,MAAM,CAAC,WAAW,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,WAAW,CAAC,MAAM,GAAG;IACnF;IAEA,8BAAA,GACA,iBAAc;QACZ,OAAO,IAAI,CAAC,MAAM,CAAC,WAAW;IAChC;IAEA,mDAAA,GACA,uBAAoB;QAClB,IAAI,IAAI,CAAC,MAAM,CAAC,kBAAkB,CAAC,MAAM,KAAK,GAAG;YAC/C;QACF,OAAO,IAAI,IAAI,CAAC,MAAM,CAAC,kBAAkB,CAAC,MAAM,KAAK,GAAG;YACtD,mBAAmB;YACnB,OAAO,IAAI,CAAC,MAAM,CAAC,kBAAkB,CAAC,EAAE;QAC1C,OAAO;YACL,qBAAqB;YACrB,IAAI,SAAS;YACb,IAAK,IAAI,IAAI,GAAG,IAAI,IAAI,CAAC,MAAM,CAAC,kBAAkB,CAAC,MAAM,EAAE,IAAK;gBAC9D,MAAM,MAAM,IAAI,CAAC,MAAM,CAAC,kBAAkB,CAAC,EAAE;gBAC7C,SAAS,SAAS,IAAI,MAAM;gBAE5B,yBAAyB;gBACzB,IAAI,MAAM,GAAG,SAAS,SAAS;YACjC;YAEA,OAAO,IAAI,kBAAkB;gBAAE;gBAAQ,MAAM,QAAA,mBAAmB,CAAC,mBAAmB;YAAA;QACtF;IACF;IAEA,WAAQ;QACN,OAAO,CAAA,gBAAA,EAAmB,OAAA,KAAK,CAAC,SAAS,CAAC,IAAI,CAAC,MAAM,EAAC,CAAA,CAAG;IAC3D;IAEA,OAAI;QACF,OAAO,IAAI,CAAC,MAAM,CAAC,EAAE,KAAK;IAC5B;;AA1HF,QAAA,eAAA,GAAA;AAoIA;;;;IAKA,MAAa;IAIX,YAAY,KAA4B,CAAA;QACtC,IAAI,CAAC,WAAW,GAAG;IACrB;IAEA,8BAAA,GACA,IAAI,OAAI;QACN,OAAO,IAAI,CAAC,WAAW,CAAC,IAAI;IAC9B;IAEA,iCAAA,GACA,IAAI,SAAM;QACR,OAAO,IAAI,CAAC,WAAW,CAAC,MAAM;IAChC;IAEA,8BAAA,GACA,IAAI,UAAO;QACT,OAAO,IAAI,CAAC,WAAW,CAAC,OAAO;IACjC;IAEA,SAAM;QACJ,OAAO,IAAI,CAAC,WAAW;IACzB;IAEA,WAAQ;QACN,OAAO,CAAA,kBAAA,EAAqB,IAAI,CAAC,MAAM,CAAA,CAAA,CAAG;IAC5C;;AA7BF,QAAA,iBAAA,GAAA;AAyCA;;;;IAKA,MAAa;IAGX,YAAY,GAA4B,CAAA;QACtC,IAAI,CAAC,GAAG,GAAG;IACb;IAEA,qBAAA,GACA,IAAI,OAAI;QACN,OAAO,IAAI,CAAC,GAAG,CAAC,IAAI;IACtB;IAEA,8CAAA,GACA,IAAI,QAAK;QACP,OAAO,IAAI,CAAC,GAAG,CAAC,KAAK;IACvB;IAEA,wBAAA,GACA,IAAI,SAAM;QACR,OAAO,IAAI,CAAC,GAAG,CAAC,MAAM;IACxB;IAEA,wBAAA,GACA,IAAI,UAAO;QACT,OAAO,IAAI,CAAC,GAAG,CAAC,OAAO;IACzB;IAEA,2DAAA,GACA,eAAY;QACV,OAAO,IAAI,CAAC,GAAG,CAAC,EAAE;IACpB;IAEA,SAAM;QACJ,OAAO;YAAE,MAAM,IAAI,CAAC,GAAG,CAAC,IAAI;YAAE,OAAO,IAAI,CAAC,GAAG,CAAC,KAAK;YAAE,QAAQ,IAAI,CAAC,GAAG,CAAC,MAAM;YAAE,IAAI,IAAI,CAAC,GAAG,CAAC,EAAE;QAAA;IAC/F;IAEA,WAAQ;QACN,OAAO,CAAA,WAAA,EAAc,KAAK,SAAS,CAAC,IAAI,CAAC,MAAM,IAAG,CAAA,CAAG;IACvD;;AAtCF,QAAA,UAAA,GAAA;AAyCA,8CAAA,GACA,SAAgB,kBACd,KAAY,EACZ,UAAsB,EACtB,GAAc,EACd,MAAiB;IAEjB,0DAA0D;IAC1D,IAAI,KAAK;QACP,SAAS;IACX,OAAO,IAAI,UAAU,OAAO,MAAM,EAAE;QAClC,SAAS,OAAO,MAAM;IACxB;IAEA,IAAI,UAAU,MAAM;QAClB;IACF;IAEA,0DAA0D;IAC1D,IAAI,OAAO,EAAE,KAAK,KAAK,WAAW,EAAE,KAAK,GAAG;QAC1C,WAAW,EAAE,GAAG;QAEhB,MAAM,aAAa;YACjB,OAAO;YACP,MAAM,OAAO,IAAI,IAAI;YACrB,QAAQ,OAAO,OAAO;YACtB,SAAS,OAAO,OAAO;YACvB,IAAI,MAAM,UAAU,CAAC,EAAE;;QAGzB,WAAW,WAAW,CAAC,IAAI,CAAC,IAAI,WAAW;QAC3C;IACF,OAAO,IAAI,OAAO,EAAE,KAAK,KAAK,WAAW,EAAE,KAAK,GAAG;QACjD;IACF;IAEA,kCAAkC;IAClC,IAAI,cAAc,UAAU,OAAO,CAAC,EAAE;QACpC,WAAW,SAAS,GAAG,WAAW,SAAS,GAAG,OAAO,CAAC;IACxD;IAEA,kCAAkC;IAClC,IAAI,cAAc,UAAU,OAAO,CAAC,EAAE;QACpC,WAAW,QAAQ,GAAG,WAAW,QAAQ,GAAG,OAAO,CAAC;IACtD;IAEA,IAAI,YAAY;IAEhB,sEAAsE;IACtE,IAAI,MAAM,OAAO,CAAC,OAAO,QAAQ,GAAG;QAClC,YAAY,OAAO,QAAQ,CAAC,MAAM;QAElC,IAAK,IAAI,IAAI,GAAG,IAAI,OAAO,QAAQ,CAAC,MAAM,EAAE,IAAK;YAC/C,WAAW,QAAQ,CAAC,IAAI,CAAC;gBACvB,OAAO,OAAO,QAAQ,CAAC,EAAE,CAAC,KAAK,GAAG,MAAM,iBAAiB;gBACzD,KAAK,OAAO,QAAQ,CAAC,EAAE,CAAC,GAAG;;QAE/B;IACF,OAAO,IAAI,OAAO,QAAQ,EAAE;QAC1B,YAAY;QAEZ,WAAW,QAAQ,CAAC,IAAI,CAAC;YACvB,OAAO,MAAM,iBAAiB;YAC9B,KAAK,OAAO,QAAQ;;IAExB;IAEA,kCAAkC;IAClC,IAAI,cAAc,UAAU,OAAO,CAAC,EAAE;QACpC,MAAM,YAAY,OAAO,SAAS;QAClC,WAAW,SAAS,GAAG,WAAW,SAAS,GAAG;QAC9C,WAAW,QAAQ,GAAG,WAAW,QAAQ,GAAG,CAAC,OAAO,CAAC,GAAG,SAAS;QAEjE,IAAI,OAAO,cAAc,UAAU;YACjC,WAAW,SAAS,GAAG,WAAW,SAAS,GAAG;QAChD,OAAO;YACL,WAAW,SAAS,GAAG;QACzB;IACF;IAEA,IAAI,MAAM,OAAO,CAAC,OAAO,WAAW,GAAG;QACrC,IAAK,IAAI,IAAI,GAAG,IAAI,OAAO,WAAW,CAAC,MAAM,EAAE,IAAK;YAClD,MAAM,aAAa;gBACjB,OAAO,MAAM,eAAe,CAAC,OAAO,WAAW,CAAC,EAAE,CAAC,KAAK,CAAC;gBACzD,MAAM,OAAO,WAAW,CAAC,EAAE,CAAC,IAAI;gBAChC,QAAQ,OAAO,WAAW,CAAC,EAAE,CAAC,MAAM;gBACpC,SAAS,OAAO,WAAW,CAAC,EAAE,CAAC,OAAO;gBACtC,IAAI,MAAM,UAAU,CAAC,OAAO,WAAW,CAAC,EAAE,CAAC,KAAK,CAAC;;YAGnD,WAAW,WAAW,CAAC,IAAI,CAAC,IAAI,WAAW;QAC7C;IACF;IAEA,IAAI,OAAO,iBAAiB,EAAE;QAC5B,WAAW,kBAAkB,CAAC,IAAI,CAAC,IAAI,kBAAkB,OAAO,iBAAiB;IACnF;AACF;AAEA,eAAe,gBACb,aAAgC,EAChC,OAAsE;IAEtE,IAAI,cAAc,CAAC,CAAC,OAAO,CAAC,MAAM,KAAK,GAAG;QACxC,OAAO,IAAI,gBAAgB,cAAc,CAAC,CAAC,UAAU,EAAE,cAAc,SAAS;IAChF;IAEA,KAAK,MAAM,SAAS,cAAc,CAAC,CAAC,OAAO,CAAE;QAC3C,MAAM,eAAe,CAAA,GAAA,QAAA,cAAc,EAAC,eAAe;YACjD,GAAG,OAAO;YACV,SAAS,cAAc,SAAS;;QAGlC,IAAI,aAAa,wBAAwB,KAAK,MAAM;YAClD,OAAO,aAAa,wBAAwB;QAC9C;QAEA,mDAAmD;QACnD,IAAI,cAAc,CAAC,CAAC,wBAAwB,KAAK,MAAM;YACrD,aAAa,wBAAwB,GAAG;QAC1C;QAEA,mCAAmC;QACnC,IAAI,cAAc,CAAC,CAAC,SAAS,KAAK,OAAO;YACvC,aAAa,SAAS,GAAG;QAC3B;QAEA,IAAI,aAAa,WAAW,EAAE;YAC5B,IAAI,cAAc,QAAQ;gBACxB,aAAa,WAAW,GACtB,aAAa,WAAW,IAAI,CAAC,MAAM,UAAU,CAAC,IAAI,CAAC,CAAA,KAAM,GAAG,KAAK;YACrE;YAEA,IAAI,cAAc,QAAQ;gBACxB,aAAa,WAAW,GACtB,aAAa,WAAW,IAAI,CAAC,MAAM,UAAU,CAAC,IAAI,CAAC,CAAA,KAAM,GAAG,KAAK,KAAK;YAC1E;QACF;QAEA,MAAM,YAAY,cAAc,SAC5B,IAAI,SAAA,eAAe,CAAC,cAAc,CAAC,CAAC,SAAS,EAAE,MAAM,UAAU,EAAE,gBACjE,cAAc,SACZ,IAAI,SAAA,eAAe,CAAC,cAAc,CAAC,CAAC,SAAS,EAAE,MAAM,UAAU,EAAE,gBACjE,cAAc,SACZ,IAAI,SAAA,eAAe,CAAC,cAAc,CAAC,CAAC,SAAS,EAAE,MAAM,UAAU,EAAE,gBACjE;QAER,IAAI,aAAa,MAAM,MAAM,IAAI,QAAA,iBAAiB,CAAC,CAAA,mBAAA,EAAsB,MAAM,SAAS,CAAA,CAAE;QAE1F,IAAI,cAAc;QAClB,IAAI;QACJ,IAAI;YACF,SAAS,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC7B,cAAc,CAAC,CAAC,UAAU,CAAC,MAAM,EACjC,WACA,aAAa,cAAc;QAE/B,EAAE,OAAO,OAAO;YACd,cAAc;QAChB;QAEA,IAAI,eAAe,MAAM;YACvB,IAAI,uBAAuB,QAAA,sBAAsB,EAAE;gBACjD,kBAAkB,OAAO,cAAc,CAAC,CAAC,UAAU,EAAE,aAAa;gBAClE,MAAM,cAAc,IAAI,gBACtB,cAAc,CAAC,CAAC,UAAU,EAC1B,cAAc,SAAS;gBAGzB,MAAM,IAAI,oBACR;oBACE,SAAS,YAAY,MAAM,CAAC,iBAAiB,CAAC,MAAM;oBACpD,MAAM,YAAY,MAAM,CAAC,iBAAiB,CAAC,IAAI;mBAEjD;YAEJ,OAAO;gBACL,oEAAoE;gBACpE,MAAM,IAAI,oBACR,aACA,IAAI,gBAAgB,cAAc,CAAC,CAAC,UAAU,EAAE,cAAc,SAAS;YAE3E;QACF;QAEA,kBAAkB,OAAO,cAAc,CAAC,CAAC,UAAU,EAAE,aAAa;QAClE,MAAM,cAAc,IAAI,gBAAgB,cAAc,CAAC,CAAC,UAAU,EAAE,cAAc,SAAS;QAC3F,cAAc,gBAAgB,CAAC;IACjC;IAEA,cAAc,CAAC,CAAC,OAAO,CAAC,MAAM,GAAG;IAEjC,MAAM,cAAc,IAAI,gBAAgB,cAAc,CAAC,CAAC,UAAU,EAAE,cAAc,SAAS;IAC3F,cAAc,gBAAgB,CAAC;IAC/B,OAAO;AACT;AAEA;;;;IAKA,MAAa,4BAA4B,QAAA,gBAAgB;IAKvD;;;;;;;;;;SAWA,YACE,KAGY,EACZ,MAAuB,CAAA;QAEvB,KAAK,CAAC;QArBR,IAAA,CAAA,WAAW,GAA0B,EAAE;QAuBrC,IAAI,iBAAiB,mBAAmB,IAAI,CAAC,GAAG,GAAG;aAC9C,IAAI,CAAC,CAAC,iBAAiB,KAAK,GAAG;YAClC,IAAI,CAAC,OAAO,GAAG,MAAM,OAAO;YAC5B,IAAI,CAAC,IAAI,GAAG,MAAM,IAAI;YACtB,IAAI,CAAC,WAAW,GAAG,MAAM,WAAW,IAAI,EAAE;QAC5C;QAEA,IAAI,CAAC,MAAM,GAAG;QACd,OAAO,MAAM,CAAC,IAAI,EAAE;IACtB;IAEA,IAAa,OAAI;QACf,OAAO;IACT;IAEA,kCAAA,GACA,IAAI,gBAAa;QACf,OAAO,IAAI,CAAC,MAAM,CAAC,aAAa;IAClC;IACA,4CAAA,GACA,IAAI,eAAY;QACd,OAAO,IAAI,CAAC,MAAM,CAAC,YAAY;IACjC;IACA,kCAAA,GACA,IAAI,gBAAa;QACf,OAAO,IAAI,CAAC,MAAM,CAAC,aAAa;IAClC;IACA,iCAAA,GACA,IAAI,eAAY;QACd,OAAO,IAAI,CAAC,MAAM,CAAC,YAAY;IACjC;IACA,kCAAA,GACA,IAAI,gBAAa;QACf,OAAO,IAAI,CAAC,MAAM,CAAC,aAAa;IAClC;IACA,yFAAA,GACA,IAAI,cAAW;QACb,OAAO,IAAI,CAAC,MAAM,CAAC,WAAW;IAChC;IACA,yFAAA,GACA,IAAI,cAAW;QACb,OAAO,IAAI,CAAC,MAAM,CAAC,WAAW;IAChC;;AAnEF,QAAA,mBAAA,GAAA;AAsEA;;;;;IAMA,MAAa;IAGX;;;QAIA,YAAY,aAAgC,CAAA;QAC1C,IAAI,CAAC,aAAa,GAAG;IACvB;IAEA,0DAAA,GACA,OAAO,cAAqC,EAAA;QAC1C,MAAM,YAAY,eAAe,IAAI,CAAC,aAAa;QACnD,OAAO,IAAI,CAAC,aAAa,CAAC,mBAAmB,CAC3C,QAAA,SAAS,CAAC,MAAM,EAChB,CAAA,GAAA,SAAA,mBAAmB,EAAC,UAAU,QAAQ,EAAE,gBAAgB;YACtD,GAAG,SAAS;YACZ,OAAO;;IAGb;IAEA,wDAAA,GACA,UAAU,cAAqC,EAAA;QAC7C,IAAI,CAAC,CAAA,GAAA,QAAA,kBAAkB,EAAC,gBAAgB,IAAI,CAAC,aAAa,CAAC,WAAW,GAAG;YACvE,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,MAAM,YAAY,eAAe,IAAI,CAAC,aAAa;QACnD,OAAO,IAAI,CAAC,aAAa,CAAC,mBAAmB,CAC3C,QAAA,SAAS,CAAC,MAAM,EAChB,CAAA,GAAA,SAAA,mBAAmB,EAAC,UAAU,QAAQ,EAAE,gBAAgB;YAAE,GAAG,SAAS;YAAE,OAAO;QAAK;IAExF;IAEA,sDAAA,GACA,WAAW,WAAqB,EAAA;QAC9B,IAAI,CAAA,GAAA,QAAA,kBAAkB,EAAC,cAAc;YACnC,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,MAAM,YAAY,eAAe,IAAI,CAAC,aAAa;QACnD,OAAO,IAAI,CAAC,aAAa,CAAC,mBAAmB,CAC3C,QAAA,SAAS,CAAC,MAAM,EAChB,CAAA,GAAA,SAAA,mBAAmB,EAAC,UAAU,QAAQ,EAAE,aAAa;YAAE,GAAG,SAAS;YAAE,OAAO;QAAK;IAErF;IAEA,qDAAA,GACA,YAAS;QACP,MAAM,YAAY,eAAe,IAAI,CAAC,aAAa;QACnD,OAAO,IAAI,CAAC,aAAa,CAAC,mBAAmB,CAC3C,QAAA,SAAS,CAAC,MAAM,EAChB,CAAA,GAAA,SAAA,mBAAmB,EAAC,UAAU,QAAQ,EAAE;YAAE,GAAG,SAAS;YAAE,OAAO;QAAC;IAEpE;IAEA,sDAAA,GACA,SAAM;QACJ,MAAM,YAAY,eAAe,IAAI,CAAC,aAAa;QACnD,OAAO,IAAI,CAAC,aAAa,CAAC,mBAAmB,CAC3C,QAAA,SAAS,CAAC,MAAM,EAChB,CAAA,GAAA,SAAA,mBAAmB,EAAC,UAAU,QAAQ,EAAE;YAAE,GAAG,SAAS;YAAE,OAAO;QAAC;IAEpE;IAEA,wFAAA,GACA,SAAM;QACJ,IAAI,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,SAAS,EAAE;YACnC,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,SAAS,GAAG,CAAA;QACnC;QAEA,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,SAAS,CAAC,MAAM,GAAG;QACxC,OAAO,IAAI;IACb;IAEA,qDAAA,GACA,UAAU,SAA2B,EAAA;QACnC,IAAI,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,SAAS,EAAE;YACnC,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,SAAS,GAAG,CAAA;QACnC;QAEA,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,SAAS,CAAC,SAAS,GAAG;QAC3C,OAAO,IAAI;IACb;IAEA,wEAAA,GACA,aAAa,YAAwB,EAAA;QACnC,IAAI,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,SAAS,EAAE;YACnC,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,SAAS,GAAG,CAAA;QACnC;QAEA,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,SAAS,CAAC,YAAY,GAAG;QAC9C,OAAO,IAAI;IACb;IAEA,2CAAA,GACA,KAAK,IAAU,EAAA;QACb,IAAI,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,SAAS,EAAE;YACnC,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,SAAS,GAAG,CAAA;QACnC;QAEA,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,SAAS,CAAC,IAAI,GAAG;QACtC,OAAO,IAAI;IACb;;AAzGF,QAAA,aAAA,GAAA;AA8KA;;;;;;IAOA,MAAa,+BAA+B,YAAA,iBAAiB;IAE3D,YAAY,aAAgC,EAAE,OAAyB,CAAA;QACrE,KAAK,CAAC;QACN,IAAI,CAAC,aAAa,GAAG;IACvB;IAEA,IAAI,cAAW;QACb,OAAO;IACT;IAEA,MAAM,QACJ,OAAe,EACf,OAAkC,EAClC,cAA8B,EAAA;QAE9B,IAAI,IAAI,CAAC,OAAO,CAAC,OAAO,IAAI,MAAM;YAChC,oEAAoE;YACpE,8DAA8D;YAC9D,8DAA8D;YAC9D,+BAA+B;YAC/B,IAAI,CAAC,OAAO,CAAC,OAAO,GAAG;QACzB;QACA,OAAO,MAAM,gBAAgB,IAAI,CAAC,aAAa,EAAE;YAAE,GAAG,IAAI,CAAC,OAAO;YAAE;QAAc;IACpF;;AAxBF,QAAA,sBAAA,GAAA;AA2BA,YAAA,GACA,MAAsB;IAMpB;;;QAIA,YACU,UAAsB,EAC9B,OAAyB,EACzB,SAAkB,CAAA;QAFV,IAAA,CAAA,UAAU,GAAV;QAIR,0DAA0D;QAC1D,IAAI,CAAC,SAAS,GAAG;QAEjB,MAAM,WAAW,CAAA,GAAA,QAAA,WAAW,EAAC;QAC7B,UAAU,WAAW,OAAO,CAAA,IAAK;QACjC,8CAA8C;QAC9C,6CAA6C;QAC7C,MAAM,YAAY,WAAW,CAAC,CAAC,SAAS;QACxC,qCAAqC;QACrC,MAAM,WAAW;QAEjB,eAAe;QACf,MAAM,YAAY;QAElB,oBAAoB;QACpB,MAAM,QAAQ,SAAS,SAAS;QAEhC,iGAAiG;QACjG,6BAA6B;QAC7B,MAAM,sBAAsB,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,OAAO,IAAI,SAAS,CAAC,CAAC,OAAO,CAAC,aAAa;QACrF,MAAM,oBACJ,SAAS,MAAM,iBAAiB,GAAG,MAAM,iBAAiB,GAAG,OAAO,OAAO;QAC7E,MAAM,oBAAoB,sBAAsB,OAAO,OAAO,IAAI;QAClE,MAAM,oBAAoB,SAAS,MAAM,iBAAiB,GAAG,MAAM,iBAAiB,GAAG;QAEvF,qFAAqF;QACrF,6BAA6B;QAC7B,2BAA2B;QAC3B,gFAAgF;QAChF,kCAAkC;QAClC,MAAM,aAAa,CAAC,oBAAoB,CAAC,EAAE,QAAQ,CAAC,IAAI,MAAM,GAAG;QAEjE,qCAAqC;QACrC,IAAI,eAAe,OAAO,MAAM,CAAC,CAAA,GAAI;QACrC,eAAe,CAAA,GAAA,QAAA,oBAAoB,EAAC,cAAc,WAAW,CAAC,CAAC,EAAE;QAEjE,gBAAgB;QAChB,MAAM,aAAyB;YAC7B,IAAI;YACJ,aAAa,EAAE;YACf,oBAAoB,EAAE;YACtB,aAAa,EAAE;YACf,WAAW;YACX,WAAW;YACX,UAAU;YACV,WAAW;YACX,UAAU;YACV,UAAU,EAAE;;QAGd,iBAAiB;QACjB,IAAI,CAAC,CAAC,GAAG;YACP,eAAe;YACf;YACA,sBAAsB;YACtB,cAAc;YACd,cAAc;YACd,mBAAmB;YACnB,kBAAkB;YAClB,uBAAuB;YACvB,qBAAqB;YACrB,oBAAoB;YACpB,oBAAoB;YACpB,oBAAoB;YACpB,SAAS,EAAE;YACX,gBAAgB;YAChB,cAAc,gBAAA,YAAY,CAAC,WAAW,CAAC;YACvC,yBAAyB;YACzB;YACA;YACA;YACA;YACA,YAAY;YACZ;YACA,WAAW;YACX;YACA,UAAU;YACV,SAAS;YACT,eAAe;YACf,aAAa,CAAA,GAAA,OAAA,kBAAkB,EAAC;YAChC,oBAAoB;YACpB;YACA,WAAW;YACX;YACA,aAAa;YACb;YACA,oBAAoB;YACpB,KAAK;YACL,aAAa;YACb,WAAW,OAAO,QAAQ,SAAS,KAAK,YAAY,QAAQ,SAAS,GAAG;;QAG1E,oBAAoB;QACpB,IAAI,QAAQ,wBAAwB,KAAK,MAAM;YAC7C,IAAI,CAAC,CAAC,CAAC,wBAAwB,GAAG;QACpC;IACF;IAEA;;;;;;;;;;;;;;QAeA,OAAO,QAAkB,EAAA;QACvB,CAAA,GAAA,QAAA,qBAAqB,EAAC,IAAI,CAAC,UAAU,EAAE,UAAU;YAC/C,qBAAqB,IAAI,CAAC,yBAAyB;;QAGrD,OAAO,IAAI,CAAC,mBAAmB,CAAC,QAAA,SAAS,CAAC,MAAM,EAAE;IACpD;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;QAmCA,KAAK,QAAkB,EAAA;QACrB,IAAI,CAAC,UAAU;YACb,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,0BAA0B;QAC1B,IAAI,CAAC,CAAC,CAAC,SAAS,GAAG;YACjB,UAAU;;QAGZ,OAAO,IAAI,cAAc,IAAI;IAC/B;IAEA,4DAAA,GACA,IAAI,EAAyB,EAAA;QAC3B,IAAI,MAAM,QAAQ,OAAO,OAAO,UAAU;YACxC,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QACA,IAAI,eAAe,IAAI;YACrB,MAAM,sBAAsB,IAAI,CAAC,yBAAyB;YAC1D,MAAM,WACJ,GAAG,SAAS,IAAI,GAAG,SAAS,CAAC,QAAQ,IAAI,OAEpC,GAAG,SAAsB,GAC1B,GAAG,SAAS,CAAC,QAAQ;YAE3B,CAAA,GAAA,QAAA,qBAAqB,EAAC,IAAI,CAAC,UAAU,EAAE,UAAU;gBAAE;YAAmB;YAEtE,OAAO,IAAI,CAAC,mBAAmB,CAAC,QAAA,SAAS,CAAC,MAAM,EAAE;QACpD;QAEA,IAAI,gBAAgB,MAAM,eAAe,MAAM,gBAAgB,IAAI;YACjE,IAAI,gBAAgB,IAAI;gBACtB,IAAI,OAAO,GAAG,UAAU,EAAE;oBACxB,MAAM,IAAI,QAAA,yBAAyB,CAAC;gBACtC;gBACA,MAAM,kBAAkB,CAAA,GAAA,SAAA,mBAAmB,EACzC,GAAG,UAAU,CAAC,MAAM,EACpB,GAAG,UAAU,CAAC,WAAW,EACzB;oBAAE,GAAG,GAAG,UAAU;oBAAE,OAAO;gBAAK;gBAElC,IAAI,CAAA,GAAA,QAAA,kBAAkB,EAAC,gBAAgB,CAAC,GAAG;oBACzC,MAAM,IAAI,QAAA,yBAAyB,CAAC;gBACtC;gBACA,OAAO,IAAI,CAAC,mBAAmB,CAAC,QAAA,SAAS,CAAC,MAAM,EAAE;YACpD;YAEA,IAAI,eAAe,IAAI;gBACrB,IAAI,OAAO,GAAG,SAAS,EAAE;oBACvB,MAAM,IAAI,QAAA,yBAAyB,CAAC;gBACtC;gBACA,MAAM,kBAAkB,CAAA,GAAA,SAAA,mBAAmB,EAAC,GAAG,SAAS,CAAC,MAAM,EAAE,GAAG,SAAS,CAAC,MAAM,EAAE;oBACpF,GAAG,GAAG,SAAS;oBACf,OAAO;;gBAET,IAAI,CAAC,CAAA,GAAA,QAAA,kBAAkB,EAAC,gBAAgB,CAAC,EAAE,IAAI,CAAC,WAAW,GAAG;oBAC5D,MAAM,IAAI,QAAA,yBAAyB,CAAC;gBACtC;gBACA,OAAO,IAAI,CAAC,mBAAmB,CAAC,QAAA,SAAS,CAAC,MAAM,EAAE;YACpD;YAEA,IAAI,gBAAgB,IAAI;gBACtB,IAAI,OAAO,GAAG,UAAU,EAAE;oBACxB,MAAM,IAAI,QAAA,yBAAyB,CAAC;gBACtC;gBACA,MAAM,kBAAkB,CAAA,GAAA,SAAA,mBAAmB,EAAC,GAAG,UAAU,CAAC,MAAM,EAAE,GAAG,UAAU,CAAC,MAAM,EAAE;oBACtF,GAAG,GAAG,UAAU;oBAChB,OAAO;;gBAET,IAAI,CAAC,CAAA,GAAA,QAAA,kBAAkB,EAAC,gBAAgB,CAAC,EAAE,IAAI,CAAC,WAAW,GAAG;oBAC5D,MAAM,IAAI,QAAA,yBAAyB,CAAC;gBACtC;gBACA,OAAO,IAAI,CAAC,mBAAmB,CAAC,QAAA,SAAS,CAAC,MAAM,EAAE;YACpD;QACF;QAEA,IAAI,eAAe,IAAI;YACrB,IAAI,OAAO,GAAG,SAAS,EAAE;gBACvB,MAAM,IAAI,QAAA,yBAAyB,CAAC;YACtC;YACA,OAAO,IAAI,CAAC,mBAAmB,CAC7B,QAAA,SAAS,CAAC,MAAM,EAChB,CAAA,GAAA,SAAA,mBAAmB,EAAC,GAAG,SAAS,CAAC,MAAM,EAAE;gBAAE,GAAG,GAAG,SAAS;gBAAE,OAAO;YAAC;QAExE;QAEA,IAAI,gBAAgB,IAAI;YACtB,IAAI,OAAO,GAAG,UAAU,EAAE;gBACxB,MAAM,IAAI,QAAA,yBAAyB,CAAC;YACtC;YACA,OAAO,IAAI,CAAC,mBAAmB,CAC7B,QAAA,SAAS,CAAC,MAAM,EAChB,CAAA,GAAA,SAAA,mBAAmB,EAAC,GAAG,UAAU,CAAC,MAAM,EAAE;gBAAE,GAAG,GAAG,UAAU;gBAAE,OAAO;YAAC;QAE1E;QAEA,8CAA8C;QAC9C,MAAM,IAAI,QAAA,yBAAyB,CACjC;IAEJ;IAEA,IAAI,SAAM;QACR,OAAO,IAAI,CAAC,CAAC,CAAC,YAAY;IAC5B;IAEA,IAAI,cAAW;QACb,OAAO,IAAI,CAAC,CAAC,CAAC,WAAW;IAC3B;IAEA,IAAI,eAAY;QACd,OAAO,IAAI,CAAC,CAAC,CAAC,YAAY;IAC5B;IAEA,IAAI,UAAO;QACT,MAAM,UAAU;eAAI,IAAI,CAAC,CAAC,CAAC,OAAO;SAAC;QACnC,IAAI,IAAI,CAAC,SAAS,EAAE;YAClB,IAAI,IAAI,CAAC,CAAC,CAAC,YAAY,EAAE,QAAQ,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,YAAY;QAC3D,OAAO;YACL,IAAI,IAAI,CAAC,CAAC,CAAC,kBAAkB,EAAE,QAAQ,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,kBAAkB;YACrE,IAAI,IAAI,CAAC,CAAC,CAAC,kBAAkB,EAAE,QAAQ,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,kBAAkB;YACrE,IAAI,IAAI,CAAC,CAAC,CAAC,kBAAkB,EAAE,QAAQ,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,kBAAkB;QACvE;QACA,OAAO;IACT;IAEA,MAAM,QAAQ,UAA4B,CAAA,CAAE,EAAA;QAC1C,IAAI,IAAI,CAAC,CAAC,CAAC,QAAQ,EAAE;YACnB,MAAM,IAAI,QAAA,0BAA0B;QACtC;QAEA,MAAM,eAAe,gBAAA,YAAY,CAAC,WAAW,CAAC;QAC9C,IAAI,cAAc;YAChB,IAAI,CAAC,CAAC,CAAC,YAAY,GAAG;QACxB;QAEA,2BAA2B;QAC3B,IAAI,IAAI,CAAC,SAAS,EAAE;YAClB,IAAI,IAAI,CAAC,CAAC,CAAC,YAAY,EAAE,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,YAAY;QAClE,OAAO;YACL,IAAI,IAAI,CAAC,CAAC,CAAC,kBAAkB,EAAE,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,kBAAkB;YAC5E,IAAI,IAAI,CAAC,CAAC,CAAC,kBAAkB,EAAE,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,kBAAkB;YAC5E,IAAI,IAAI,CAAC,CAAC,CAAC,kBAAkB,EAAE,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,kBAAkB;QAC9E;QACA,sDAAsD;QACtD,IAAI,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,MAAM,KAAK,GAAG;YAC/B,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,IAAI,CAAC,CAAC,CAAC,QAAQ,GAAG;QAClB,MAAM,eAAe;YAAE,GAAG,IAAI,CAAC,CAAC,CAAC,OAAO;YAAE,GAAG,OAAO;QAAA;QACpD,MAAM,YAAY,IAAI,uBAAuB,IAAI,EAAE;QAEnD,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAAC,IAAI,CAAC,CAAC,CAAC,UAAU,CAAC,MAAM,EAAE,WAAW,aAAa,cAAc;IAChG;IAEA;;;QAIA,iBAAiB,WAA4B,EAAA;QAC3C,IAAI,IAAI,CAAC,CAAC,CAAC,UAAU,CAAC,WAAW,CAAC,MAAM,GAAG,GAAG;YAC5C,MAAM,MAAM,IAAI,CAAC,CAAC,CAAC,UAAU,CAAC,WAAW,CAAC,EAAE,CAAC,MAAM,GAC/C,IAAI,CAAC,CAAC,CAAC,UAAU,CAAC,WAAW,CAAC,EAAE,CAAC,MAAM,GACvC;YAEJ,MAAM,IAAI,oBACR;gBACE,SAAS;gBACT,MAAM,IAAI,CAAC,CAAC,CAAC,UAAU,CAAC,WAAW,CAAC,EAAE,CAAC,IAAI;gBAC3C,aAAa,IAAI,CAAC,CAAC,CAAC,UAAU,CAAC,WAAW;eAE5C;QAEJ;QAEA,MAAM,oBAAoB,YAAY,oBAAoB;QAC1D,IAAI,mBAAmB;YACrB,MAAM,IAAI,oBAAoB,mBAAmB;QACnD;IACF;IAOQ,4BAAyB;QAC/B,OACE,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,mBAAmB,KAAK,QACvC,IAAI,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,CAAC,OAAO,EAAE,wBAAwB;IAE5D;;AA3WF,QAAA,iBAAA,GAAA;AA8WA,SAAS,cAAc,KAAY;IACjC,OAAO,MAAM,SAAS,KAAK,QAAA,SAAS,CAAC,MAAM;AAC7C;AAEA,SAAS,cAAc,KAAY;IACjC,OAAO,MAAM,SAAS,KAAK,QAAA,SAAS,CAAC,MAAM;AAC7C;AAEA,SAAS,cAAc,KAAY;IACjC,OAAO,MAAM,SAAS,KAAK,QAAA,SAAS,CAAC,MAAM;AAC7C;AAEA,SAAS,eAAe,MAAyB;IAC/C,IAAI,EAAE,SAAS,EAAE,GAAG,OAAO,CAAC;IAC5B,OAAO,CAAC,CAAC,SAAS,GAAG;IACrB,IAAI,CAAC,WAAW,YAAY,CAAA;IAC5B,OAAO;AACT"}},
    {"offset": {"line": 5039, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5043, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/bulk/ordered.ts"],"sourcesContent":["import type { Document } from '../bson';\nimport * as BSON from '../bson';\nimport type { Collection } from '../collection';\nimport { MongoInvalidArgumentError } from '../error';\nimport type { DeleteStatement } from '../operations/delete';\nimport type { UpdateStatement } from '../operations/update';\nimport { Batch, BatchType, BulkOperationBase, type BulkWriteOptions } from './common';\n\n/** @public */\nexport class OrderedBulkOperation extends BulkOperationBase {\n  /** @internal */\n  constructor(collection: Collection, options: BulkWriteOptions) {\n    super(collection, options, true);\n  }\n\n  addToOperationsList(\n    batchType: BatchType,\n    document: Document | UpdateStatement | DeleteStatement\n  ): this {\n    // Get the bsonSize\n    const bsonSize = BSON.calculateObjectSize(document, {\n      checkKeys: false,\n      // Since we don't know what the user selected for BSON options here,\n      // err on the safe side, and check the size with ignoreUndefined: false.\n      ignoreUndefined: false\n    } as any);\n\n    // Throw error if the doc is bigger than the max BSON size\n    if (bsonSize >= this.s.maxBsonObjectSize)\n      // TODO(NODE-3483): Change this to MongoBSONError\n      throw new MongoInvalidArgumentError(\n        `Document is larger than the maximum size ${this.s.maxBsonObjectSize}`\n      );\n\n    // Create a new batch object if we don't have a current one\n    if (this.s.currentBatch == null) {\n      this.s.currentBatch = new Batch(batchType, this.s.currentIndex);\n    }\n\n    const maxKeySize = this.s.maxKeySize;\n\n    // Check if we need to create a new batch\n    if (\n      // New batch if we exceed the max batch op size\n      this.s.currentBatchSize + 1 >= this.s.maxWriteBatchSize ||\n      // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\n      // since we can't sent an empty batch\n      (this.s.currentBatchSize > 0 &&\n        this.s.currentBatchSizeBytes + maxKeySize + bsonSize >= this.s.maxBatchSizeBytes) ||\n      // New batch if the new op does not have the same op type as the current batch\n      this.s.currentBatch.batchType !== batchType\n    ) {\n      // Save the batch to the execution stack\n      this.s.batches.push(this.s.currentBatch);\n\n      // Create a new batch\n      this.s.currentBatch = new Batch(batchType, this.s.currentIndex);\n\n      // Reset the current size trackers\n      this.s.currentBatchSize = 0;\n      this.s.currentBatchSizeBytes = 0;\n    }\n\n    if (batchType === BatchType.INSERT) {\n      this.s.bulkResult.insertedIds.push({\n        index: this.s.currentIndex,\n        _id: (document as Document)._id\n      });\n    }\n\n    // We have an array of documents\n    if (Array.isArray(document)) {\n      throw new MongoInvalidArgumentError('Operation passed in cannot be an Array');\n    }\n\n    this.s.currentBatch.originalIndexes.push(this.s.currentIndex);\n    this.s.currentBatch.operations.push(document);\n    this.s.currentBatchSize += 1;\n    this.s.currentBatchSizeBytes += maxKeySize + bsonSize;\n    this.s.currentIndex += 1;\n    return this;\n  }\n}\n"],"names":[],"mappings":";;;;;AACA,MAAA;AAEA,MAAA;AAGA,MAAA;AAEA,YAAA,GACA,MAAa,6BAA6B,SAAA,iBAAiB;IACzD,cAAA,GACA,YAAY,UAAsB,EAAE,OAAyB,CAAA;QAC3D,KAAK,CAAC,YAAY,SAAS;IAC7B;IAEA,oBACE,SAAoB,EACpB,QAAsD,EAAA;QAEtD,mBAAmB;QACnB,MAAM,WAAW,KAAK,mBAAmB,CAAC,UAAU;YAClD,WAAW;YACX,oEAAoE;YACpE,wEAAwE;YACxE,iBAAiB;;QAGnB,0DAA0D;QAC1D,IAAI,YAAY,IAAI,CAAC,CAAC,CAAC,iBAAiB,EACtC,iDAAiD;QACjD,MAAM,IAAI,QAAA,yBAAyB,CACjC,CAAA,yCAAA,EAA4C,IAAI,CAAC,CAAC,CAAC,iBAAiB,CAAA,CAAE;QAG1E,2DAA2D;QAC3D,IAAI,IAAI,CAAC,CAAC,CAAC,YAAY,IAAI,MAAM;YAC/B,IAAI,CAAC,CAAC,CAAC,YAAY,GAAG,IAAI,SAAA,KAAK,CAAC,WAAW,IAAI,CAAC,CAAC,CAAC,YAAY;QAChE;QAEA,MAAM,aAAa,IAAI,CAAC,CAAC,CAAC,UAAU;QAEpC,yCAAyC;QACzC,IACE,+CAA+C;QAC/C,IAAI,CAAC,CAAC,CAAC,gBAAgB,GAAG,KAAK,IAAI,CAAC,CAAC,CAAC,iBAAiB,IAGtD,IAAI,CAAC,CAAC,CAAC,gBAAgB,GAAG,KACzB,IAAI,CAAC,CAAC,CAAC,qBAAqB,GAAG,aAAa,YAAY,IAAI,CAAC,CAAC,CAAC,iBAAiB,IAClF,8EAA8E;QAC9E,IAAI,CAAC,CAAC,CAAC,YAAY,CAAC,SAAS,KAAK,WAClC;YACA,wCAAwC;YACxC,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,YAAY;YAEvC,qBAAqB;YACrB,IAAI,CAAC,CAAC,CAAC,YAAY,GAAG,IAAI,SAAA,KAAK,CAAC,WAAW,IAAI,CAAC,CAAC,CAAC,YAAY;YAE9D,kCAAkC;YAClC,IAAI,CAAC,CAAC,CAAC,gBAAgB,GAAG;YAC1B,IAAI,CAAC,CAAC,CAAC,qBAAqB,GAAG;QACjC;QAEA,IAAI,cAAc,SAAA,SAAS,CAAC,MAAM,EAAE;YAClC,IAAI,CAAC,CAAC,CAAC,UAAU,CAAC,WAAW,CAAC,IAAI,CAAC;gBACjC,OAAO,IAAI,CAAC,CAAC,CAAC,YAAY;gBAC1B,KAAM,SAAsB,GAAG;;QAEnC;QAEA,gCAAgC;QAChC,IAAI,MAAM,OAAO,CAAC,WAAW;YAC3B,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,IAAI,CAAC,CAAC,CAAC,YAAY,CAAC,eAAe,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,YAAY;QAC5D,IAAI,CAAC,CAAC,CAAC,YAAY,CAAC,UAAU,CAAC,IAAI,CAAC;QACpC,IAAI,CAAC,CAAC,CAAC,gBAAgB,IAAI;QAC3B,IAAI,CAAC,CAAC,CAAC,qBAAqB,IAAI,aAAa;QAC7C,IAAI,CAAC,CAAC,CAAC,YAAY,IAAI;QACvB,OAAO,IAAI;IACb;;AAxEF,QAAA,oBAAA,GAAA"}},
    {"offset": {"line": 5102, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5106, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/bulk/unordered.ts"],"sourcesContent":["import type { Document } from '../bson';\nimport * as BSON from '../bson';\nimport type { Collection } from '../collection';\nimport { MongoInvalidArgumentError } from '../error';\nimport type { DeleteStatement } from '../operations/delete';\nimport type { UpdateStatement } from '../operations/update';\nimport {\n  Batch,\n  BatchType,\n  BulkOperationBase,\n  type BulkWriteOptions,\n  type BulkWriteResult\n} from './common';\n\n/** @public */\nexport class UnorderedBulkOperation extends BulkOperationBase {\n  /** @internal */\n  constructor(collection: Collection, options: BulkWriteOptions) {\n    super(collection, options, false);\n  }\n\n  override handleWriteError(writeResult: BulkWriteResult): void {\n    if (this.s.batches.length) {\n      return;\n    }\n\n    return super.handleWriteError(writeResult);\n  }\n\n  addToOperationsList(\n    batchType: BatchType,\n    document: Document | UpdateStatement | DeleteStatement\n  ): this {\n    // Get the bsonSize\n    const bsonSize = BSON.calculateObjectSize(document, {\n      checkKeys: false,\n\n      // Since we don't know what the user selected for BSON options here,\n      // err on the safe side, and check the size with ignoreUndefined: false.\n      ignoreUndefined: false\n    } as any);\n\n    // Throw error if the doc is bigger than the max BSON size\n    if (bsonSize >= this.s.maxBsonObjectSize) {\n      // TODO(NODE-3483): Change this to MongoBSONError\n      throw new MongoInvalidArgumentError(\n        `Document is larger than the maximum size ${this.s.maxBsonObjectSize}`\n      );\n    }\n\n    // Holds the current batch\n    this.s.currentBatch = undefined;\n    // Get the right type of batch\n    if (batchType === BatchType.INSERT) {\n      this.s.currentBatch = this.s.currentInsertBatch;\n    } else if (batchType === BatchType.UPDATE) {\n      this.s.currentBatch = this.s.currentUpdateBatch;\n    } else if (batchType === BatchType.DELETE) {\n      this.s.currentBatch = this.s.currentRemoveBatch;\n    }\n\n    const maxKeySize = this.s.maxKeySize;\n\n    // Create a new batch object if we don't have a current one\n    if (this.s.currentBatch == null) {\n      this.s.currentBatch = new Batch(batchType, this.s.currentIndex);\n    }\n\n    // Check if we need to create a new batch\n    if (\n      // New batch if we exceed the max batch op size\n      this.s.currentBatch.size + 1 >= this.s.maxWriteBatchSize ||\n      // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\n      // since we can't sent an empty batch\n      (this.s.currentBatch.size > 0 &&\n        this.s.currentBatch.sizeBytes + maxKeySize + bsonSize >= this.s.maxBatchSizeBytes) ||\n      // New batch if the new op does not have the same op type as the current batch\n      this.s.currentBatch.batchType !== batchType\n    ) {\n      // Save the batch to the execution stack\n      this.s.batches.push(this.s.currentBatch);\n\n      // Create a new batch\n      this.s.currentBatch = new Batch(batchType, this.s.currentIndex);\n    }\n\n    // We have an array of documents\n    if (Array.isArray(document)) {\n      throw new MongoInvalidArgumentError('Operation passed in cannot be an Array');\n    }\n\n    this.s.currentBatch.operations.push(document);\n    this.s.currentBatch.originalIndexes.push(this.s.currentIndex);\n    this.s.currentIndex = this.s.currentIndex + 1;\n\n    // Save back the current Batch to the right type\n    if (batchType === BatchType.INSERT) {\n      this.s.currentInsertBatch = this.s.currentBatch;\n      this.s.bulkResult.insertedIds.push({\n        index: this.s.bulkResult.insertedIds.length,\n        _id: (document as Document)._id\n      });\n    } else if (batchType === BatchType.UPDATE) {\n      this.s.currentUpdateBatch = this.s.currentBatch;\n    } else if (batchType === BatchType.DELETE) {\n      this.s.currentRemoveBatch = this.s.currentBatch;\n    }\n\n    // Update current batch size\n    this.s.currentBatch.size += 1;\n    this.s.currentBatch.sizeBytes += maxKeySize + bsonSize;\n\n    return this;\n  }\n}\n"],"names":[],"mappings":";;;;;AACA,MAAA;AAEA,MAAA;AAGA,MAAA;AAQA,YAAA,GACA,MAAa,+BAA+B,SAAA,iBAAiB;IAC3D,cAAA,GACA,YAAY,UAAsB,EAAE,OAAyB,CAAA;QAC3D,KAAK,CAAC,YAAY,SAAS;IAC7B;IAES,iBAAiB,WAA4B,EAAA;QACpD,IAAI,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,MAAM,EAAE;YACzB;QACF;QAEA,OAAO,KAAK,CAAC,iBAAiB;IAChC;IAEA,oBACE,SAAoB,EACpB,QAAsD,EAAA;QAEtD,mBAAmB;QACnB,MAAM,WAAW,KAAK,mBAAmB,CAAC,UAAU;YAClD,WAAW;YAEX,oEAAoE;YACpE,wEAAwE;YACxE,iBAAiB;;QAGnB,0DAA0D;QAC1D,IAAI,YAAY,IAAI,CAAC,CAAC,CAAC,iBAAiB,EAAE;YACxC,iDAAiD;YACjD,MAAM,IAAI,QAAA,yBAAyB,CACjC,CAAA,yCAAA,EAA4C,IAAI,CAAC,CAAC,CAAC,iBAAiB,CAAA,CAAE;QAE1E;QAEA,0BAA0B;QAC1B,IAAI,CAAC,CAAC,CAAC,YAAY,GAAG;QACtB,8BAA8B;QAC9B,IAAI,cAAc,SAAA,SAAS,CAAC,MAAM,EAAE;YAClC,IAAI,CAAC,CAAC,CAAC,YAAY,GAAG,IAAI,CAAC,CAAC,CAAC,kBAAkB;QACjD,OAAO,IAAI,cAAc,SAAA,SAAS,CAAC,MAAM,EAAE;YACzC,IAAI,CAAC,CAAC,CAAC,YAAY,GAAG,IAAI,CAAC,CAAC,CAAC,kBAAkB;QACjD,OAAO,IAAI,cAAc,SAAA,SAAS,CAAC,MAAM,EAAE;YACzC,IAAI,CAAC,CAAC,CAAC,YAAY,GAAG,IAAI,CAAC,CAAC,CAAC,kBAAkB;QACjD;QAEA,MAAM,aAAa,IAAI,CAAC,CAAC,CAAC,UAAU;QAEpC,2DAA2D;QAC3D,IAAI,IAAI,CAAC,CAAC,CAAC,YAAY,IAAI,MAAM;YAC/B,IAAI,CAAC,CAAC,CAAC,YAAY,GAAG,IAAI,SAAA,KAAK,CAAC,WAAW,IAAI,CAAC,CAAC,CAAC,YAAY;QAChE;QAEA,yCAAyC;QACzC,IACE,+CAA+C;QAC/C,IAAI,CAAC,CAAC,CAAC,YAAY,CAAC,IAAI,GAAG,KAAK,IAAI,CAAC,CAAC,CAAC,iBAAiB,IAGvD,IAAI,CAAC,CAAC,CAAC,YAAY,CAAC,IAAI,GAAG,KAC1B,IAAI,CAAC,CAAC,CAAC,YAAY,CAAC,SAAS,GAAG,aAAa,YAAY,IAAI,CAAC,CAAC,CAAC,iBAAiB,IACnF,8EAA8E;QAC9E,IAAI,CAAC,CAAC,CAAC,YAAY,CAAC,SAAS,KAAK,WAClC;YACA,wCAAwC;YACxC,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,YAAY;YAEvC,qBAAqB;YACrB,IAAI,CAAC,CAAC,CAAC,YAAY,GAAG,IAAI,SAAA,KAAK,CAAC,WAAW,IAAI,CAAC,CAAC,CAAC,YAAY;QAChE;QAEA,gCAAgC;QAChC,IAAI,MAAM,OAAO,CAAC,WAAW;YAC3B,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,IAAI,CAAC,CAAC,CAAC,YAAY,CAAC,UAAU,CAAC,IAAI,CAAC;QACpC,IAAI,CAAC,CAAC,CAAC,YAAY,CAAC,eAAe,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,YAAY;QAC5D,IAAI,CAAC,CAAC,CAAC,YAAY,GAAG,IAAI,CAAC,CAAC,CAAC,YAAY,GAAG;QAE5C,gDAAgD;QAChD,IAAI,cAAc,SAAA,SAAS,CAAC,MAAM,EAAE;YAClC,IAAI,CAAC,CAAC,CAAC,kBAAkB,GAAG,IAAI,CAAC,CAAC,CAAC,YAAY;YAC/C,IAAI,CAAC,CAAC,CAAC,UAAU,CAAC,WAAW,CAAC,IAAI,CAAC;gBACjC,OAAO,IAAI,CAAC,CAAC,CAAC,UAAU,CAAC,WAAW,CAAC,MAAM;gBAC3C,KAAM,SAAsB,GAAG;;QAEnC,OAAO,IAAI,cAAc,SAAA,SAAS,CAAC,MAAM,EAAE;YACzC,IAAI,CAAC,CAAC,CAAC,kBAAkB,GAAG,IAAI,CAAC,CAAC,CAAC,YAAY;QACjD,OAAO,IAAI,cAAc,SAAA,SAAS,CAAC,MAAM,EAAE;YACzC,IAAI,CAAC,CAAC,CAAC,kBAAkB,GAAG,IAAI,CAAC,CAAC,CAAC,YAAY;QACjD;QAEA,4BAA4B;QAC5B,IAAI,CAAC,CAAC,CAAC,YAAY,CAAC,IAAI,IAAI;QAC5B,IAAI,CAAC,CAAC,CAAC,YAAY,CAAC,SAAS,IAAI,aAAa;QAE9C,OAAO,IAAI;IACb;;AAlGF,QAAA,sBAAA,GAAA"}},
    {"offset": {"line": 5187, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5191, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/cursor/aggregation_cursor.ts"],"sourcesContent":["import type { Document } from '../bson';\nimport { MongoAPIError } from '../error';\nimport {\n  Explain,\n  ExplainableCursor,\n  type ExplainCommandOptions,\n  type ExplainVerbosityLike,\n  validateExplainTimeoutOptions\n} from '../explain';\nimport type { MongoClient } from '../mongo_client';\nimport { type Abortable } from '../mongo_types';\nimport { AggregateOperation, type AggregateOptions } from '../operations/aggregate';\nimport { executeOperation } from '../operations/execute_operation';\nimport type { ClientSession } from '../sessions';\nimport type { Sort } from '../sort';\nimport { mergeOptions, type MongoDBNamespace } from '../utils';\nimport {\n  type AbstractCursorOptions,\n  CursorTimeoutMode,\n  type InitialCursorResponse\n} from './abstract_cursor';\n\n/** @public */\nexport interface AggregationCursorOptions extends AbstractCursorOptions, AggregateOptions {}\n\n/**\n * The **AggregationCursor** class is an internal class that embodies an aggregation cursor on MongoDB\n * allowing for iteration over the results returned from the underlying query. It supports\n * one by one document iteration, conversion to an array or can be iterated as a Node 4.X\n * or higher stream\n * @public\n */\nexport class AggregationCursor<TSchema = any> extends ExplainableCursor<TSchema> {\n  public readonly pipeline: Document[];\n  /** @internal */\n  private aggregateOptions: AggregateOptions & Abortable;\n\n  /** @internal */\n  constructor(\n    client: MongoClient,\n    namespace: MongoDBNamespace,\n    pipeline: Document[] = [],\n    options: AggregateOptions & Abortable = {}\n  ) {\n    super(client, namespace, options);\n\n    this.pipeline = pipeline;\n    this.aggregateOptions = options;\n\n    const lastStage: Document | undefined = this.pipeline[this.pipeline.length - 1];\n\n    if (\n      this.cursorOptions.timeoutMS != null &&\n      this.cursorOptions.timeoutMode === CursorTimeoutMode.ITERATION &&\n      (lastStage?.$merge != null || lastStage?.$out != null)\n    )\n      throw new MongoAPIError('Cannot use $out or $merge stage with ITERATION timeoutMode');\n  }\n\n  clone(): AggregationCursor<TSchema> {\n    const clonedOptions = mergeOptions({}, this.aggregateOptions);\n    delete clonedOptions.session;\n    return new AggregationCursor(this.client, this.namespace, this.pipeline, {\n      ...clonedOptions\n    });\n  }\n\n  override map<T>(transform: (doc: TSchema) => T): AggregationCursor<T> {\n    return super.map(transform) as AggregationCursor<T>;\n  }\n\n  /** @internal */\n  async _initialize(session: ClientSession): Promise<InitialCursorResponse> {\n    const options = {\n      ...this.aggregateOptions,\n      ...this.cursorOptions,\n      session,\n      signal: this.signal\n    };\n    if (options.explain) {\n      try {\n        validateExplainTimeoutOptions(options, Explain.fromOptions(options));\n      } catch {\n        throw new MongoAPIError(\n          'timeoutMS cannot be used with explain when explain is specified in aggregateOptions'\n        );\n      }\n    }\n\n    const aggregateOperation = new AggregateOperation(this.namespace, this.pipeline, options);\n\n    const response = await executeOperation(this.client, aggregateOperation, this.timeoutContext);\n\n    return { server: aggregateOperation.server, session, response };\n  }\n\n  /** Execute the explain for the cursor */\n  async explain(): Promise<Document>;\n  async explain(verbosity: ExplainVerbosityLike | ExplainCommandOptions): Promise<Document>;\n  async explain(options: { timeoutMS?: number }): Promise<Document>;\n  async explain(\n    verbosity: ExplainVerbosityLike | ExplainCommandOptions,\n    options: { timeoutMS?: number }\n  ): Promise<Document>;\n  async explain(\n    verbosity?: ExplainVerbosityLike | ExplainCommandOptions | { timeoutMS?: number },\n    options?: { timeoutMS?: number }\n  ): Promise<Document> {\n    const { explain, timeout } = this.resolveExplainTimeoutOptions(verbosity, options);\n    return (\n      await executeOperation(\n        this.client,\n        new AggregateOperation(this.namespace, this.pipeline, {\n          ...this.aggregateOptions, // NOTE: order matters here, we may need to refine this\n          ...this.cursorOptions,\n          ...timeout,\n          explain: explain ?? true\n        })\n      )\n    ).shift(this.deserializationOptions);\n  }\n\n  /** Add a stage to the aggregation pipeline\n   * @example\n   * ```\n   * const documents = await users.aggregate().addStage({ $match: { name: /Mike/ } }).toArray();\n   * ```\n   * @example\n   * ```\n   * const documents = await users.aggregate()\n   *   .addStage<{ name: string }>({ $project: { name: true } })\n   *   .toArray(); // type of documents is { name: string }[]\n   * ```\n   */\n  addStage(stage: Document): this;\n  addStage<T = Document>(stage: Document): AggregationCursor<T>;\n  addStage<T = Document>(stage: Document): AggregationCursor<T> {\n    this.throwIfInitialized();\n    if (\n      this.cursorOptions.timeoutMS != null &&\n      this.cursorOptions.timeoutMode === CursorTimeoutMode.ITERATION &&\n      (stage.$out != null || stage.$merge != null)\n    ) {\n      throw new MongoAPIError('Cannot use $out or $merge stage with ITERATION timeoutMode');\n    }\n    this.pipeline.push(stage);\n    return this as unknown as AggregationCursor<T>;\n  }\n\n  /** Add a group stage to the aggregation pipeline */\n  group<T = TSchema>($group: Document): AggregationCursor<T>;\n  group($group: Document): this {\n    return this.addStage({ $group });\n  }\n\n  /** Add a limit stage to the aggregation pipeline */\n  limit($limit: number): this {\n    return this.addStage({ $limit });\n  }\n\n  /** Add a match stage to the aggregation pipeline */\n  match($match: Document): this {\n    return this.addStage({ $match });\n  }\n\n  /** Add an out stage to the aggregation pipeline */\n  out($out: { db: string; coll: string } | string): this {\n    return this.addStage({ $out });\n  }\n\n  /**\n   * Add a project stage to the aggregation pipeline\n   *\n   * @remarks\n   * In order to strictly type this function you must provide an interface\n   * that represents the effect of your projection on the result documents.\n   *\n   * By default chaining a projection to your cursor changes the returned type to the generic {@link Document} type.\n   * You should specify a parameterized type to have assertions on your final results.\n   *\n   * @example\n   * ```typescript\n   * // Best way\n   * const docs: AggregationCursor<{ a: number }> = cursor.project<{ a: number }>({ _id: 0, a: true });\n   * // Flexible way\n   * const docs: AggregationCursor<Document> = cursor.project({ _id: 0, a: true });\n   * ```\n   *\n   * @remarks\n   * In order to strictly type this function you must provide an interface\n   * that represents the effect of your projection on the result documents.\n   *\n   * **Note for Typescript Users:** adding a transform changes the return type of the iteration of this cursor,\n   * it **does not** return a new instance of a cursor. This means when calling project,\n   * you should always assign the result to a new variable in order to get a correctly typed cursor variable.\n   * Take note of the following example:\n   *\n   * @example\n   * ```typescript\n   * const cursor: AggregationCursor<{ a: number; b: string }> = coll.aggregate([]);\n   * const projectCursor = cursor.project<{ a: number }>({ _id: 0, a: true });\n   * const aPropOnlyArray: {a: number}[] = await projectCursor.toArray();\n   *\n   * // or always use chaining and save the final cursor\n   *\n   * const cursor = coll.aggregate().project<{ a: string }>({\n   *   _id: 0,\n   *   a: { $convert: { input: '$a', to: 'string' }\n   * }});\n   * ```\n   */\n  project<T extends Document = Document>($project: Document): AggregationCursor<T> {\n    return this.addStage<T>({ $project });\n  }\n\n  /** Add a lookup stage to the aggregation pipeline */\n  lookup($lookup: Document): this {\n    return this.addStage({ $lookup });\n  }\n\n  /** Add a redact stage to the aggregation pipeline */\n  redact($redact: Document): this {\n    return this.addStage({ $redact });\n  }\n\n  /** Add a skip stage to the aggregation pipeline */\n  skip($skip: number): this {\n    return this.addStage({ $skip });\n  }\n\n  /** Add a sort stage to the aggregation pipeline */\n  sort($sort: Sort): this {\n    return this.addStage({ $sort });\n  }\n\n  /** Add a unwind stage to the aggregation pipeline */\n  unwind($unwind: Document | string): this {\n    return this.addStage({ $unwind });\n  }\n\n  /** Add a geoNear stage to the aggregation pipeline */\n  geoNear($geoNear: Document): this {\n    return this.addStage({ $geoNear });\n  }\n}\n"],"names":[],"mappings":";;;;;AACA,MAAA;AACA,MAAA;AASA,MAAA;AACA,MAAA;AAGA,MAAA;AACA,MAAA;AASA;;;;;;IAOA,MAAa,0BAAyC,UAAA,iBAA0B;IAK9E,cAAA,GACA,YACE,MAAmB,EACnB,SAA2B,EAC3B,WAAuB,EAAE,EACzB,UAAwC,CAAA,CAAE,CAAA;QAE1C,KAAK,CAAC,QAAQ,WAAW;QAEzB,IAAI,CAAC,QAAQ,GAAG;QAChB,IAAI,CAAC,gBAAgB,GAAG;QAExB,MAAM,YAAkC,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,QAAQ,CAAC,MAAM,GAAG,EAAE;QAE/E,IACE,IAAI,CAAC,aAAa,CAAC,SAAS,IAAI,QAChC,IAAI,CAAC,aAAa,CAAC,WAAW,KAAK,kBAAA,iBAAiB,CAAC,SAAS,IAC9D,CAAC,WAAW,UAAU,QAAQ,WAAW,QAAQ,IAAI,GAErD,MAAM,IAAI,QAAA,aAAa,CAAC;IAC5B;IAEA,QAAK;QACH,MAAM,gBAAgB,CAAA,GAAA,QAAA,YAAY,EAAC,CAAA,GAAI,IAAI,CAAC,gBAAgB;QAC5D,OAAO,cAAc,OAAO;QAC5B,OAAO,IAAI,kBAAkB,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,QAAQ,EAAE;YACvE,GAAG,aAAa;;IAEpB;IAES,IAAO,SAA8B,EAAA;QAC5C,OAAO,KAAK,CAAC,IAAI;IACnB;IAEA,cAAA,GACA,MAAM,YAAY,OAAsB,EAAA;QACtC,MAAM,UAAU;YACd,GAAG,IAAI,CAAC,gBAAgB;YACxB,GAAG,IAAI,CAAC,aAAa;YACrB;YACA,QAAQ,IAAI,CAAC,MAAM;;QAErB,IAAI,QAAQ,OAAO,EAAE;YACnB,IAAI;gBACF,CAAA,GAAA,UAAA,6BAA6B,EAAC,SAAS,UAAA,OAAO,CAAC,WAAW,CAAC;YAC7D,EAAE,OAAM;gBACN,MAAM,IAAI,QAAA,aAAa,CACrB;YAEJ;QACF;QAEA,MAAM,qBAAqB,IAAI,YAAA,kBAAkB,CAAC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,QAAQ,EAAE;QAEjF,MAAM,WAAW,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAAC,IAAI,CAAC,MAAM,EAAE,oBAAoB,IAAI,CAAC,cAAc;QAE5F,OAAO;YAAE,QAAQ,mBAAmB,MAAM;YAAE;YAAS;QAAQ;IAC/D;IAUA,MAAM,QACJ,SAAiF,EACjF,OAAgC,EAAA;QAEhC,MAAM,EAAE,OAAO,EAAE,OAAO,EAAE,GAAG,IAAI,CAAC,4BAA4B,CAAC,WAAW;QAC1E,OAAO,CACL,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EACpB,IAAI,CAAC,MAAM,EACX,IAAI,YAAA,kBAAkB,CAAC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,QAAQ,EAAE;YACpD,GAAG,IAAI,CAAC,gBAAgB;YACxB,GAAG,IAAI,CAAC,aAAa;YACrB,GAAG,OAAO;YACV,SAAS,WAAW;WAEvB,EACD,KAAK,CAAC,IAAI,CAAC,sBAAsB;IACrC;IAgBA,SAAuB,KAAe,EAAA;QACpC,IAAI,CAAC,kBAAkB;QACvB,IACE,IAAI,CAAC,aAAa,CAAC,SAAS,IAAI,QAChC,IAAI,CAAC,aAAa,CAAC,WAAW,KAAK,kBAAA,iBAAiB,CAAC,SAAS,IAC9D,CAAC,MAAM,IAAI,IAAI,QAAQ,MAAM,MAAM,IAAI,IAAI,GAC3C;YACA,MAAM,IAAI,QAAA,aAAa,CAAC;QAC1B;QACA,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC;QACnB,OAAO,IAAuC;IAChD;IAIA,MAAM,MAAgB,EAAA;QACpB,OAAO,IAAI,CAAC,QAAQ,CAAC;YAAE;QAAM;IAC/B;IAEA,kDAAA,GACA,MAAM,MAAc,EAAA;QAClB,OAAO,IAAI,CAAC,QAAQ,CAAC;YAAE;QAAM;IAC/B;IAEA,kDAAA,GACA,MAAM,MAAgB,EAAA;QACpB,OAAO,IAAI,CAAC,QAAQ,CAAC;YAAE;QAAM;IAC/B;IAEA,iDAAA,GACA,IAAI,IAA2C,EAAA;QAC7C,OAAO,IAAI,CAAC,QAAQ,CAAC;YAAE;QAAI;IAC7B;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;QAyCA,QAAuC,QAAkB,EAAA;QACvD,OAAO,IAAI,CAAC,QAAQ,CAAI;YAAE;QAAQ;IACpC;IAEA,mDAAA,GACA,OAAO,OAAiB,EAAA;QACtB,OAAO,IAAI,CAAC,QAAQ,CAAC;YAAE;QAAO;IAChC;IAEA,mDAAA,GACA,OAAO,OAAiB,EAAA;QACtB,OAAO,IAAI,CAAC,QAAQ,CAAC;YAAE;QAAO;IAChC;IAEA,iDAAA,GACA,KAAK,KAAa,EAAA;QAChB,OAAO,IAAI,CAAC,QAAQ,CAAC;YAAE;QAAK;IAC9B;IAEA,iDAAA,GACA,KAAK,KAAW,EAAA;QACd,OAAO,IAAI,CAAC,QAAQ,CAAC;YAAE;QAAK;IAC9B;IAEA,mDAAA,GACA,OAAO,OAA0B,EAAA;QAC/B,OAAO,IAAI,CAAC,QAAQ,CAAC;YAAE;QAAO;IAChC;IAEA,oDAAA,GACA,QAAQ,QAAkB,EAAA;QACxB,OAAO,IAAI,CAAC,QAAQ,CAAC;YAAE;QAAQ;IACjC;;AAnNF,QAAA,iBAAA,GAAA"}},
    {"offset": {"line": 5362, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5366, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/cursor/find_cursor.ts"],"sourcesContent":["import { type Document } from '../bson';\nimport { CursorResponse } from '../cmap/wire_protocol/responses';\nimport { MongoAPIError, MongoInvalidArgumentError, MongoTailableCursorError } from '../error';\nimport {\n  Explain,\n  ExplainableCursor,\n  type ExplainCommandOptions,\n  type ExplainVerbosityLike,\n  validateExplainTimeoutOptions\n} from '../explain';\nimport type { MongoClient } from '../mongo_client';\nimport { type Abortable } from '../mongo_types';\nimport type { CollationOptions } from '../operations/command';\nimport { CountOperation, type CountOptions } from '../operations/count';\nimport { executeOperation } from '../operations/execute_operation';\nimport { FindOperation, type FindOptions } from '../operations/find';\nimport type { Hint } from '../operations/operation';\nimport type { ClientSession } from '../sessions';\nimport { formatSort, type Sort, type SortDirection } from '../sort';\nimport { emitWarningOnce, mergeOptions, type MongoDBNamespace, squashError } from '../utils';\nimport { type InitialCursorResponse } from './abstract_cursor';\n\n/** @public Flags allowed for cursor */\nexport const FLAGS = [\n  'tailable',\n  'oplogReplay',\n  'noCursorTimeout',\n  'awaitData',\n  'exhaust',\n  'partial'\n] as const;\n\n/** @public */\nexport class FindCursor<TSchema = any> extends ExplainableCursor<TSchema> {\n  /** @internal */\n  private cursorFilter: Document;\n  /** @internal */\n  private numReturned = 0;\n  /** @internal */\n  private readonly findOptions: FindOptions & Abortable;\n\n  /** @internal */\n  constructor(\n    client: MongoClient,\n    namespace: MongoDBNamespace,\n    filter: Document = {},\n    options: FindOptions & Abortable = {}\n  ) {\n    super(client, namespace, options);\n\n    this.cursorFilter = filter;\n    this.findOptions = options;\n\n    if (options.sort != null) {\n      this.findOptions.sort = formatSort(options.sort);\n    }\n  }\n\n  clone(): FindCursor<TSchema> {\n    const clonedOptions = mergeOptions({}, this.findOptions);\n    delete clonedOptions.session;\n    return new FindCursor(this.client, this.namespace, this.cursorFilter, {\n      ...clonedOptions\n    });\n  }\n\n  override map<T>(transform: (doc: TSchema) => T): FindCursor<T> {\n    return super.map(transform) as FindCursor<T>;\n  }\n\n  /** @internal */\n  async _initialize(session: ClientSession): Promise<InitialCursorResponse> {\n    const options = {\n      ...this.findOptions, // NOTE: order matters here, we may need to refine this\n      ...this.cursorOptions,\n      session,\n      signal: this.signal\n    };\n\n    if (options.explain) {\n      try {\n        validateExplainTimeoutOptions(options, Explain.fromOptions(options));\n      } catch {\n        throw new MongoAPIError(\n          'timeoutMS cannot be used with explain when explain is specified in findOptions'\n        );\n      }\n    }\n\n    const findOperation = new FindOperation(this.namespace, this.cursorFilter, options);\n\n    const response = await executeOperation(this.client, findOperation, this.timeoutContext);\n\n    // the response is not a cursor when `explain` is enabled\n    this.numReturned = response.batchSize;\n\n    return { server: findOperation.server, session, response };\n  }\n\n  /** @internal */\n  override async getMore(batchSize: number): Promise<CursorResponse> {\n    const numReturned = this.numReturned;\n    if (numReturned) {\n      // TODO(DRIVERS-1448): Remove logic to enforce `limit` in the driver\n      const limit = this.findOptions.limit;\n      batchSize =\n        limit && limit > 0 && numReturned + batchSize > limit ? limit - numReturned : batchSize;\n\n      if (batchSize <= 0) {\n        try {\n          await this.close();\n        } catch (error) {\n          squashError(error);\n          // this is an optimization for the special case of a limit for a find command to avoid an\n          // extra getMore when the limit has been reached and the limit is a multiple of the batchSize.\n          // This is a consequence of the new query engine in 5.0 having no knowledge of the limit as it\n          // produces results for the find command.  Once a batch is filled up, it is returned and only\n          // on the subsequent getMore will the query framework consider the limit, determine the cursor\n          // is exhausted and return a cursorId of zero.\n          // instead, if we determine there are no more documents to request from the server, we preemptively\n          // close the cursor\n        }\n        return CursorResponse.emptyGetMore;\n      }\n    }\n\n    const response = await super.getMore(batchSize);\n    // TODO: wrap this in some logic to prevent it from happening if we don't need this support\n    this.numReturned = this.numReturned + response.batchSize;\n\n    return response;\n  }\n\n  /**\n   * Get the count of documents for this cursor\n   * @deprecated Use `collection.estimatedDocumentCount` or `collection.countDocuments` instead\n   */\n  async count(options?: CountOptions): Promise<number> {\n    emitWarningOnce(\n      'cursor.count is deprecated and will be removed in the next major version, please use `collection.estimatedDocumentCount` or `collection.countDocuments` instead '\n    );\n    if (typeof options === 'boolean') {\n      throw new MongoInvalidArgumentError('Invalid first parameter to count');\n    }\n    return await executeOperation(\n      this.client,\n      new CountOperation(this.namespace, this.cursorFilter, {\n        ...this.findOptions, // NOTE: order matters here, we may need to refine this\n        ...this.cursorOptions,\n        ...options\n      })\n    );\n  }\n\n  /** Execute the explain for the cursor */\n  async explain(): Promise<Document>;\n  async explain(verbosity: ExplainVerbosityLike | ExplainCommandOptions): Promise<Document>;\n  async explain(options: { timeoutMS?: number }): Promise<Document>;\n  async explain(\n    verbosity: ExplainVerbosityLike | ExplainCommandOptions,\n    options: { timeoutMS?: number }\n  ): Promise<Document>;\n  async explain(\n    verbosity?: ExplainVerbosityLike | ExplainCommandOptions | { timeoutMS?: number },\n    options?: { timeoutMS?: number }\n  ): Promise<Document> {\n    const { explain, timeout } = this.resolveExplainTimeoutOptions(verbosity, options);\n\n    return (\n      await executeOperation(\n        this.client,\n        new FindOperation(this.namespace, this.cursorFilter, {\n          ...this.findOptions, // NOTE: order matters here, we may need to refine this\n          ...this.cursorOptions,\n          ...timeout,\n          explain: explain ?? true\n        })\n      )\n    ).shift(this.deserializationOptions);\n  }\n\n  /** Set the cursor query */\n  filter(filter: Document): this {\n    this.throwIfInitialized();\n    this.cursorFilter = filter;\n    return this;\n  }\n\n  /**\n   * Set the cursor hint\n   *\n   * @param hint - If specified, then the query system will only consider plans using the hinted index.\n   */\n  hint(hint: Hint): this {\n    this.throwIfInitialized();\n    this.findOptions.hint = hint;\n    return this;\n  }\n\n  /**\n   * Set the cursor min\n   *\n   * @param min - Specify a $min value to specify the inclusive lower bound for a specific index in order to constrain the results of find(). The $min specifies the lower bound for all keys of a specific index in order.\n   */\n  min(min: Document): this {\n    this.throwIfInitialized();\n    this.findOptions.min = min;\n    return this;\n  }\n\n  /**\n   * Set the cursor max\n   *\n   * @param max - Specify a $max value to specify the exclusive upper bound for a specific index in order to constrain the results of find(). The $max specifies the upper bound for all keys of a specific index in order.\n   */\n  max(max: Document): this {\n    this.throwIfInitialized();\n    this.findOptions.max = max;\n    return this;\n  }\n\n  /**\n   * Set the cursor returnKey.\n   * If set to true, modifies the cursor to only return the index field or fields for the results of the query, rather than documents.\n   * If set to true and the query does not use an index to perform the read operation, the returned documents will not contain any fields.\n   *\n   * @param value - the returnKey value.\n   */\n  returnKey(value: boolean): this {\n    this.throwIfInitialized();\n    this.findOptions.returnKey = value;\n    return this;\n  }\n\n  /**\n   * Modifies the output of a query by adding a field $recordId to matching documents. $recordId is the internal key which uniquely identifies a document in a collection.\n   *\n   * @param value - The $showDiskLoc option has now been deprecated and replaced with the showRecordId field. $showDiskLoc will still be accepted for OP_QUERY stye find.\n   */\n  showRecordId(value: boolean): this {\n    this.throwIfInitialized();\n    this.findOptions.showRecordId = value;\n    return this;\n  }\n\n  /**\n   * Add a query modifier to the cursor query\n   *\n   * @param name - The query modifier (must start with $, such as $orderby etc)\n   * @param value - The modifier value.\n   */\n  addQueryModifier(name: string, value: string | boolean | number | Document): this {\n    this.throwIfInitialized();\n    if (name[0] !== '$') {\n      throw new MongoInvalidArgumentError(`${name} is not a valid query modifier`);\n    }\n\n    // Strip of the $\n    const field = name.substr(1);\n\n    // NOTE: consider some TS magic for this\n    switch (field) {\n      case 'comment':\n        this.findOptions.comment = value as string | Document;\n        break;\n\n      case 'explain':\n        this.findOptions.explain = value as boolean;\n        break;\n\n      case 'hint':\n        this.findOptions.hint = value as string | Document;\n        break;\n\n      case 'max':\n        this.findOptions.max = value as Document;\n        break;\n\n      case 'maxTimeMS':\n        this.findOptions.maxTimeMS = value as number;\n        break;\n\n      case 'min':\n        this.findOptions.min = value as Document;\n        break;\n\n      case 'orderby':\n        this.findOptions.sort = formatSort(value as string | Document);\n        break;\n\n      case 'query':\n        this.cursorFilter = value as Document;\n        break;\n\n      case 'returnKey':\n        this.findOptions.returnKey = value as boolean;\n        break;\n\n      case 'showDiskLoc':\n        this.findOptions.showRecordId = value as boolean;\n        break;\n\n      default:\n        throw new MongoInvalidArgumentError(`Invalid query modifier: ${name}`);\n    }\n\n    return this;\n  }\n\n  /**\n   * Add a comment to the cursor query allowing for tracking the comment in the log.\n   *\n   * @param value - The comment attached to this query.\n   */\n  comment(value: string): this {\n    this.throwIfInitialized();\n    this.findOptions.comment = value;\n    return this;\n  }\n\n  /**\n   * Set a maxAwaitTimeMS on a tailing cursor query to allow to customize the timeout value for the option awaitData (Only supported on MongoDB 3.2 or higher, ignored otherwise)\n   *\n   * @param value - Number of milliseconds to wait before aborting the tailed query.\n   */\n  maxAwaitTimeMS(value: number): this {\n    this.throwIfInitialized();\n    if (typeof value !== 'number') {\n      throw new MongoInvalidArgumentError('Argument for maxAwaitTimeMS must be a number');\n    }\n\n    this.findOptions.maxAwaitTimeMS = value;\n    return this;\n  }\n\n  /**\n   * Set a maxTimeMS on the cursor query, allowing for hard timeout limits on queries (Only supported on MongoDB 2.6 or higher)\n   *\n   * @param value - Number of milliseconds to wait before aborting the query.\n   */\n  override maxTimeMS(value: number): this {\n    this.throwIfInitialized();\n    if (typeof value !== 'number') {\n      throw new MongoInvalidArgumentError('Argument for maxTimeMS must be a number');\n    }\n\n    this.findOptions.maxTimeMS = value;\n    return this;\n  }\n\n  /**\n   * Add a project stage to the aggregation pipeline\n   *\n   * @remarks\n   * In order to strictly type this function you must provide an interface\n   * that represents the effect of your projection on the result documents.\n   *\n   * By default chaining a projection to your cursor changes the returned type to the generic\n   * {@link Document} type.\n   * You should specify a parameterized type to have assertions on your final results.\n   *\n   * @example\n   * ```typescript\n   * // Best way\n   * const docs: FindCursor<{ a: number }> = cursor.project<{ a: number }>({ _id: 0, a: true });\n   * // Flexible way\n   * const docs: FindCursor<Document> = cursor.project({ _id: 0, a: true });\n   * ```\n   *\n   * @remarks\n   *\n   * **Note for Typescript Users:** adding a transform changes the return type of the iteration of this cursor,\n   * it **does not** return a new instance of a cursor. This means when calling project,\n   * you should always assign the result to a new variable in order to get a correctly typed cursor variable.\n   * Take note of the following example:\n   *\n   * @example\n   * ```typescript\n   * const cursor: FindCursor<{ a: number; b: string }> = coll.find();\n   * const projectCursor = cursor.project<{ a: number }>({ _id: 0, a: true });\n   * const aPropOnlyArray: {a: number}[] = await projectCursor.toArray();\n   *\n   * // or always use chaining and save the final cursor\n   *\n   * const cursor = coll.find().project<{ a: string }>({\n   *   _id: 0,\n   *   a: { $convert: { input: '$a', to: 'string' }\n   * }});\n   * ```\n   */\n  project<T extends Document = Document>(value: Document): FindCursor<T> {\n    this.throwIfInitialized();\n    this.findOptions.projection = value;\n    return this as unknown as FindCursor<T>;\n  }\n\n  /**\n   * Sets the sort order of the cursor query.\n   *\n   * @param sort - The key or keys set for the sort.\n   * @param direction - The direction of the sorting (1 or -1).\n   */\n  sort(sort: Sort | string, direction?: SortDirection): this {\n    this.throwIfInitialized();\n    if (this.findOptions.tailable) {\n      throw new MongoTailableCursorError('Tailable cursor does not support sorting');\n    }\n\n    this.findOptions.sort = formatSort(sort, direction);\n    return this;\n  }\n\n  /**\n   * Allows disk use for blocking sort operations exceeding 100MB memory. (MongoDB 3.2 or higher)\n   *\n   * @remarks\n   * {@link https://www.mongodb.com/docs/manual/reference/command/find/#find-cmd-allowdiskuse | find command allowDiskUse documentation}\n   */\n  allowDiskUse(allow = true): this {\n    this.throwIfInitialized();\n\n    if (!this.findOptions.sort) {\n      throw new MongoInvalidArgumentError('Option \"allowDiskUse\" requires a sort specification');\n    }\n\n    // As of 6.0 the default is true. This allows users to get back to the old behavior.\n    if (!allow) {\n      this.findOptions.allowDiskUse = false;\n      return this;\n    }\n\n    this.findOptions.allowDiskUse = true;\n    return this;\n  }\n\n  /**\n   * Set the collation options for the cursor.\n   *\n   * @param value - The cursor collation options (MongoDB 3.4 or higher) settings for update operation (see 3.4 documentation for available fields).\n   */\n  collation(value: CollationOptions): this {\n    this.throwIfInitialized();\n    this.findOptions.collation = value;\n    return this;\n  }\n\n  /**\n   * Set the limit for the cursor.\n   *\n   * @param value - The limit for the cursor query.\n   */\n  limit(value: number): this {\n    this.throwIfInitialized();\n    if (this.findOptions.tailable) {\n      throw new MongoTailableCursorError('Tailable cursor does not support limit');\n    }\n\n    if (typeof value !== 'number') {\n      throw new MongoInvalidArgumentError('Operation \"limit\" requires an integer');\n    }\n\n    this.findOptions.limit = value;\n    return this;\n  }\n\n  /**\n   * Set the skip for the cursor.\n   *\n   * @param value - The skip for the cursor query.\n   */\n  skip(value: number): this {\n    this.throwIfInitialized();\n    if (this.findOptions.tailable) {\n      throw new MongoTailableCursorError('Tailable cursor does not support skip');\n    }\n\n    if (typeof value !== 'number') {\n      throw new MongoInvalidArgumentError('Operation \"skip\" requires an integer');\n    }\n\n    this.findOptions.skip = value;\n    return this;\n  }\n}\n"],"names":[],"mappings":";;;;;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAUA,MAAA;AACA,MAAA;AACA,MAAA;AAGA,MAAA;AACA,MAAA;AAGA,qCAAA,GACa,QAAA,KAAK,GAAG;IACnB;IACA;IACA;IACA;IACA;IACA;CACQ;AAEV,YAAA,GACA,MAAa,mBAAkC,UAAA,iBAA0B;IAQvE,cAAA,GACA,YACE,MAAmB,EACnB,SAA2B,EAC3B,SAAmB,CAAA,CAAE,EACrB,UAAmC,CAAA,CAAE,CAAA;QAErC,KAAK,CAAC,QAAQ,WAAW;QAZ3B,cAAA,GACQ,IAAA,CAAA,WAAW,GAAG;QAapB,IAAI,CAAC,YAAY,GAAG;QACpB,IAAI,CAAC,WAAW,GAAG;QAEnB,IAAI,QAAQ,IAAI,IAAI,MAAM;YACxB,IAAI,CAAC,WAAW,CAAC,IAAI,GAAG,CAAA,GAAA,OAAA,UAAU,EAAC,QAAQ,IAAI;QACjD;IACF;IAEA,QAAK;QACH,MAAM,gBAAgB,CAAA,GAAA,QAAA,YAAY,EAAC,CAAA,GAAI,IAAI,CAAC,WAAW;QACvD,OAAO,cAAc,OAAO;QAC5B,OAAO,IAAI,WAAW,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,YAAY,EAAE;YACpE,GAAG,aAAa;;IAEpB;IAES,IAAO,SAA8B,EAAA;QAC5C,OAAO,KAAK,CAAC,IAAI;IACnB;IAEA,cAAA,GACA,MAAM,YAAY,OAAsB,EAAA;QACtC,MAAM,UAAU;YACd,GAAG,IAAI,CAAC,WAAW;YACnB,GAAG,IAAI,CAAC,aAAa;YACrB;YACA,QAAQ,IAAI,CAAC,MAAM;;QAGrB,IAAI,QAAQ,OAAO,EAAE;YACnB,IAAI;gBACF,CAAA,GAAA,UAAA,6BAA6B,EAAC,SAAS,UAAA,OAAO,CAAC,WAAW,CAAC;YAC7D,EAAE,OAAM;gBACN,MAAM,IAAI,QAAA,aAAa,CACrB;YAEJ;QACF;QAEA,MAAM,gBAAgB,IAAI,OAAA,aAAa,CAAC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,YAAY,EAAE;QAE3E,MAAM,WAAW,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAAC,IAAI,CAAC,MAAM,EAAE,eAAe,IAAI,CAAC,cAAc;QAEvF,yDAAyD;QACzD,IAAI,CAAC,WAAW,GAAG,SAAS,SAAS;QAErC,OAAO;YAAE,QAAQ,cAAc,MAAM;YAAE;YAAS;QAAQ;IAC1D;IAEA,cAAA,GACS,MAAM,QAAQ,SAAiB,EAAA;QACtC,MAAM,cAAc,IAAI,CAAC,WAAW;QACpC,IAAI,aAAa;YACf,oEAAoE;YACpE,MAAM,QAAQ,IAAI,CAAC,WAAW,CAAC,KAAK;YACpC,YACE,SAAS,QAAQ,KAAK,cAAc,YAAY,QAAQ,QAAQ,cAAc;YAEhF,IAAI,aAAa,GAAG;gBAClB,IAAI;oBACF,MAAM,IAAI,CAAC,KAAK;gBAClB,EAAE,OAAO,OAAO;oBACd,CAAA,GAAA,QAAA,WAAW,EAAC;gBACZ,yFAAyF;gBACzF,8FAA8F;gBAC9F,8FAA8F;gBAC9F,6FAA6F;gBAC7F,8FAA8F;gBAC9F,8CAA8C;gBAC9C,mGAAmG;gBACnG,mBAAmB;gBACrB;gBACA,OAAO,YAAA,cAAc,CAAC,YAAY;YACpC;QACF;QAEA,MAAM,WAAW,MAAM,KAAK,CAAC,QAAQ;QACrC,2FAA2F;QAC3F,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC,WAAW,GAAG,SAAS,SAAS;QAExD,OAAO;IACT;IAEA;;;QAIA,MAAM,MAAM,OAAsB,EAAA;QAChC,CAAA,GAAA,QAAA,eAAe,EACb;QAEF,IAAI,OAAO,YAAY,WAAW;YAChC,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QACA,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,QAAA,cAAc,CAAC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,YAAY,EAAE;YACpD,GAAG,IAAI,CAAC,WAAW;YACnB,GAAG,IAAI,CAAC,aAAa;YACrB,GAAG,OAAO;;IAGhB;IAUA,MAAM,QACJ,SAAiF,EACjF,OAAgC,EAAA;QAEhC,MAAM,EAAE,OAAO,EAAE,OAAO,EAAE,GAAG,IAAI,CAAC,4BAA4B,CAAC,WAAW;QAE1E,OAAO,CACL,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EACpB,IAAI,CAAC,MAAM,EACX,IAAI,OAAA,aAAa,CAAC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,YAAY,EAAE;YACnD,GAAG,IAAI,CAAC,WAAW;YACnB,GAAG,IAAI,CAAC,aAAa;YACrB,GAAG,OAAO;YACV,SAAS,WAAW;WAEvB,EACD,KAAK,CAAC,IAAI,CAAC,sBAAsB;IACrC;IAEA,yBAAA,GACA,OAAO,MAAgB,EAAA;QACrB,IAAI,CAAC,kBAAkB;QACvB,IAAI,CAAC,YAAY,GAAG;QACpB,OAAO,IAAI;IACb;IAEA;;;;QAKA,KAAK,IAAU,EAAA;QACb,IAAI,CAAC,kBAAkB;QACvB,IAAI,CAAC,WAAW,CAAC,IAAI,GAAG;QACxB,OAAO,IAAI;IACb;IAEA;;;;QAKA,IAAI,GAAa,EAAA;QACf,IAAI,CAAC,kBAAkB;QACvB,IAAI,CAAC,WAAW,CAAC,GAAG,GAAG;QACvB,OAAO,IAAI;IACb;IAEA;;;;QAKA,IAAI,GAAa,EAAA;QACf,IAAI,CAAC,kBAAkB;QACvB,IAAI,CAAC,WAAW,CAAC,GAAG,GAAG;QACvB,OAAO,IAAI;IACb;IAEA;;;;;;QAOA,UAAU,KAAc,EAAA;QACtB,IAAI,CAAC,kBAAkB;QACvB,IAAI,CAAC,WAAW,CAAC,SAAS,GAAG;QAC7B,OAAO,IAAI;IACb;IAEA;;;;QAKA,aAAa,KAAc,EAAA;QACzB,IAAI,CAAC,kBAAkB;QACvB,IAAI,CAAC,WAAW,CAAC,YAAY,GAAG;QAChC,OAAO,IAAI;IACb;IAEA;;;;;QAMA,iBAAiB,IAAY,EAAE,KAA2C,EAAA;QACxE,IAAI,CAAC,kBAAkB;QACvB,IAAI,IAAI,CAAC,EAAE,KAAK,KAAK;YACnB,MAAM,IAAI,QAAA,yBAAyB,CAAC,CAAA,EAAG,KAAI,8BAAA,CAAgC;QAC7E;QAEA,iBAAiB;QACjB,MAAM,QAAQ,KAAK,MAAM,CAAC;QAE1B,wCAAwC;QACxC,OAAQ;YACN,KAAK;gBACH,IAAI,CAAC,WAAW,CAAC,OAAO,GAAG;gBAC3B;YAEF,KAAK;gBACH,IAAI,CAAC,WAAW,CAAC,OAAO,GAAG;gBAC3B;YAEF,KAAK;gBACH,IAAI,CAAC,WAAW,CAAC,IAAI,GAAG;gBACxB;YAEF,KAAK;gBACH,IAAI,CAAC,WAAW,CAAC,GAAG,GAAG;gBACvB;YAEF,KAAK;gBACH,IAAI,CAAC,WAAW,CAAC,SAAS,GAAG;gBAC7B;YAEF,KAAK;gBACH,IAAI,CAAC,WAAW,CAAC,GAAG,GAAG;gBACvB;YAEF,KAAK;gBACH,IAAI,CAAC,WAAW,CAAC,IAAI,GAAG,CAAA,GAAA,OAAA,UAAU,EAAC;gBACnC;YAEF,KAAK;gBACH,IAAI,CAAC,YAAY,GAAG;gBACpB;YAEF,KAAK;gBACH,IAAI,CAAC,WAAW,CAAC,SAAS,GAAG;gBAC7B;YAEF,KAAK;gBACH,IAAI,CAAC,WAAW,CAAC,YAAY,GAAG;gBAChC;YAEF;gBACE,MAAM,IAAI,QAAA,yBAAyB,CAAC,CAAA,wBAAA,EAA2B,KAAI,CAAE;QACzE;QAEA,OAAO,IAAI;IACb;IAEA;;;;QAKA,QAAQ,KAAa,EAAA;QACnB,IAAI,CAAC,kBAAkB;QACvB,IAAI,CAAC,WAAW,CAAC,OAAO,GAAG;QAC3B,OAAO,IAAI;IACb;IAEA;;;;QAKA,eAAe,KAAa,EAAA;QAC1B,IAAI,CAAC,kBAAkB;QACvB,IAAI,OAAO,UAAU,UAAU;YAC7B,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,IAAI,CAAC,WAAW,CAAC,cAAc,GAAG;QAClC,OAAO,IAAI;IACb;IAEA;;;;QAKS,UAAU,KAAa,EAAA;QAC9B,IAAI,CAAC,kBAAkB;QACvB,IAAI,OAAO,UAAU,UAAU;YAC7B,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,IAAI,CAAC,WAAW,CAAC,SAAS,GAAG;QAC7B,OAAO,IAAI;IACb;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;QAwCA,QAAuC,KAAe,EAAA;QACpD,IAAI,CAAC,kBAAkB;QACvB,IAAI,CAAC,WAAW,CAAC,UAAU,GAAG;QAC9B,OAAO,IAAgC;IACzC;IAEA;;;;;QAMA,KAAK,IAAmB,EAAE,SAAyB,EAAA;QACjD,IAAI,CAAC,kBAAkB;QACvB,IAAI,IAAI,CAAC,WAAW,CAAC,QAAQ,EAAE;YAC7B,MAAM,IAAI,QAAA,wBAAwB,CAAC;QACrC;QAEA,IAAI,CAAC,WAAW,CAAC,IAAI,GAAG,CAAA,GAAA,OAAA,UAAU,EAAC,MAAM;QACzC,OAAO,IAAI;IACb;IAEA;;;;;QAMA,aAAa,QAAQ,IAAI,EAAA;QACvB,IAAI,CAAC,kBAAkB;QAEvB,IAAI,CAAC,IAAI,CAAC,WAAW,CAAC,IAAI,EAAE;YAC1B,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,oFAAoF;QACpF,IAAI,CAAC,OAAO;YACV,IAAI,CAAC,WAAW,CAAC,YAAY,GAAG;YAChC,OAAO,IAAI;QACb;QAEA,IAAI,CAAC,WAAW,CAAC,YAAY,GAAG;QAChC,OAAO,IAAI;IACb;IAEA;;;;QAKA,UAAU,KAAuB,EAAA;QAC/B,IAAI,CAAC,kBAAkB;QACvB,IAAI,CAAC,WAAW,CAAC,SAAS,GAAG;QAC7B,OAAO,IAAI;IACb;IAEA;;;;QAKA,MAAM,KAAa,EAAA;QACjB,IAAI,CAAC,kBAAkB;QACvB,IAAI,IAAI,CAAC,WAAW,CAAC,QAAQ,EAAE;YAC7B,MAAM,IAAI,QAAA,wBAAwB,CAAC;QACrC;QAEA,IAAI,OAAO,UAAU,UAAU;YAC7B,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,IAAI,CAAC,WAAW,CAAC,KAAK,GAAG;QACzB,OAAO,IAAI;IACb;IAEA;;;;QAKA,KAAK,KAAa,EAAA;QAChB,IAAI,CAAC,kBAAkB;QACvB,IAAI,IAAI,CAAC,WAAW,CAAC,QAAQ,EAAE;YAC7B,MAAM,IAAI,QAAA,wBAAwB,CAAC;QACrC;QAEA,IAAI,OAAO,UAAU,UAAU;YAC7B,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,IAAI,CAAC,WAAW,CAAC,IAAI,GAAG;QACxB,OAAO,IAAI;IACb;;AAjcF,QAAA,UAAA,GAAA"}},
    {"offset": {"line": 5732, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5736, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/cursor/list_indexes_cursor.ts"],"sourcesContent":["import type { Collection } from '../collection';\nimport { executeOperation } from '../operations/execute_operation';\nimport { ListIndexesOperation, type ListIndexesOptions } from '../operations/indexes';\nimport type { ClientSession } from '../sessions';\nimport { AbstractCursor, type InitialCursorResponse } from './abstract_cursor';\n\n/** @public */\nexport class ListIndexesCursor extends AbstractCursor {\n  parent: Collection;\n  options?: ListIndexesOptions;\n\n  constructor(collection: Collection, options?: ListIndexesOptions) {\n    super(collection.client, collection.s.namespace, options);\n    this.parent = collection;\n    this.options = options;\n  }\n\n  clone(): ListIndexesCursor {\n    return new ListIndexesCursor(this.parent, {\n      ...this.options,\n      ...this.cursorOptions\n    });\n  }\n\n  /** @internal */\n  async _initialize(session: ClientSession | undefined): Promise<InitialCursorResponse> {\n    const operation = new ListIndexesOperation(this.parent, {\n      ...this.cursorOptions,\n      ...this.options,\n      session\n    });\n\n    const response = await executeOperation(this.parent.client, operation, this.timeoutContext);\n\n    return { server: operation.server, session, response };\n  }\n}\n"],"names":[],"mappings":";;;;;AACA,MAAA;AACA,MAAA;AAEA,MAAA;AAEA,YAAA,GACA,MAAa,0BAA0B,kBAAA,cAAc;IAInD,YAAY,UAAsB,EAAE,OAA4B,CAAA;QAC9D,KAAK,CAAC,WAAW,MAAM,EAAE,WAAW,CAAC,CAAC,SAAS,EAAE;QACjD,IAAI,CAAC,MAAM,GAAG;QACd,IAAI,CAAC,OAAO,GAAG;IACjB;IAEA,QAAK;QACH,OAAO,IAAI,kBAAkB,IAAI,CAAC,MAAM,EAAE;YACxC,GAAG,IAAI,CAAC,OAAO;YACf,GAAG,IAAI,CAAC,aAAa;;IAEzB;IAEA,cAAA,GACA,MAAM,YAAY,OAAkC,EAAA;QAClD,MAAM,YAAY,IAAI,UAAA,oBAAoB,CAAC,IAAI,CAAC,MAAM,EAAE;YACtD,GAAG,IAAI,CAAC,aAAa;YACrB,GAAG,IAAI,CAAC,OAAO;YACf;;QAGF,MAAM,WAAW,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAAC,IAAI,CAAC,MAAM,CAAC,MAAM,EAAE,WAAW,IAAI,CAAC,cAAc;QAE1F,OAAO;YAAE,QAAQ,UAAU,MAAM;YAAE;YAAS;QAAQ;IACtD;;AA5BF,QAAA,iBAAA,GAAA"}},
    {"offset": {"line": 5771, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5775, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/cursor/list_search_indexes_cursor.ts"],"sourcesContent":["import type { Collection } from '../collection';\nimport type { AggregateOptions } from '../operations/aggregate';\nimport { AggregationCursor } from './aggregation_cursor';\n\n/** @public */\nexport type ListSearchIndexesOptions = Omit<AggregateOptions, 'readConcern' | 'writeConcern'>;\n\n/** @public */\nexport class ListSearchIndexesCursor extends AggregationCursor<{ name: string }> {\n  /** @internal */\n  constructor(\n    { fullNamespace: ns, client }: Collection,\n    name: string | null,\n    options: ListSearchIndexesOptions = {}\n  ) {\n    const pipeline =\n      name == null ? [{ $listSearchIndexes: {} }] : [{ $listSearchIndexes: { name } }];\n    super(client, ns, pipeline, options);\n  }\n}\n"],"names":[],"mappings":";;;;;AAEA,MAAA;AAKA,YAAA,GACA,MAAa,gCAAgC,qBAAA,iBAAmC;IAC9E,cAAA,GACA,YACE,EAAE,eAAe,EAAE,EAAE,MAAM,EAAc,EACzC,IAAmB,EACnB,UAAoC,CAAA,CAAE,CAAA;QAEtC,MAAM,WACJ,QAAQ,OAAO;YAAC;gBAAE,oBAAoB,CAAA;YAAE;SAAG,GAAG;YAAC;gBAAE,oBAAoB;oBAAE;gBAAI;YAAE;SAAG;QAClF,KAAK,CAAC,QAAQ,IAAI,UAAU;IAC9B;;AAVF,QAAA,uBAAA,GAAA"}},
    {"offset": {"line": 5798, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5802, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/cursor/change_stream_cursor.ts"],"sourcesContent":["import type { Document } from '../bson';\nimport {\n  ChangeStream,\n  type ChangeStreamDocument,\n  type ChangeStreamEvents,\n  type OperationTime,\n  type ResumeToken\n} from '../change_stream';\nimport { type CursorResponse } from '../cmap/wire_protocol/responses';\nimport { INIT, RESPONSE } from '../constants';\nimport type { MongoClient } from '../mongo_client';\nimport { AggregateOperation } from '../operations/aggregate';\nimport type { CollationOptions } from '../operations/command';\nimport { executeOperation } from '../operations/execute_operation';\nimport type { ClientSession } from '../sessions';\nimport { maxWireVersion, type MongoDBNamespace } from '../utils';\nimport {\n  AbstractCursor,\n  type AbstractCursorOptions,\n  type InitialCursorResponse\n} from './abstract_cursor';\n\n/** @internal */\nexport interface ChangeStreamCursorOptions extends AbstractCursorOptions {\n  startAtOperationTime?: OperationTime;\n  resumeAfter?: ResumeToken;\n  startAfter?: ResumeToken;\n  maxAwaitTimeMS?: number;\n  collation?: CollationOptions;\n  fullDocument?: string;\n}\n\n/** @internal */\nexport class ChangeStreamCursor<\n  TSchema extends Document = Document,\n  TChange extends Document = ChangeStreamDocument<TSchema>\n> extends AbstractCursor<TChange, ChangeStreamEvents> {\n  private _resumeToken: ResumeToken;\n  private startAtOperationTime: OperationTime | null;\n  private hasReceived?: boolean;\n  private readonly changeStreamCursorOptions: ChangeStreamCursorOptions;\n  private postBatchResumeToken?: ResumeToken;\n  private readonly pipeline: Document[];\n\n  /**\n   * @internal\n   *\n   * used to determine change stream resumability\n   */\n  maxWireVersion: number | undefined;\n\n  constructor(\n    client: MongoClient,\n    namespace: MongoDBNamespace,\n    pipeline: Document[] = [],\n    options: ChangeStreamCursorOptions = {}\n  ) {\n    super(client, namespace, { ...options, tailable: true, awaitData: true });\n\n    this.pipeline = pipeline;\n    this.changeStreamCursorOptions = options;\n    this._resumeToken = null;\n    this.startAtOperationTime = options.startAtOperationTime ?? null;\n\n    if (options.startAfter) {\n      this.resumeToken = options.startAfter;\n    } else if (options.resumeAfter) {\n      this.resumeToken = options.resumeAfter;\n    }\n  }\n\n  set resumeToken(token: ResumeToken) {\n    this._resumeToken = token;\n    this.emit(ChangeStream.RESUME_TOKEN_CHANGED, token);\n  }\n\n  get resumeToken(): ResumeToken {\n    return this._resumeToken;\n  }\n\n  get resumeOptions(): ChangeStreamCursorOptions {\n    const options: ChangeStreamCursorOptions = {\n      ...this.changeStreamCursorOptions\n    };\n\n    for (const key of ['resumeAfter', 'startAfter', 'startAtOperationTime'] as const) {\n      delete options[key];\n    }\n\n    if (this.resumeToken != null) {\n      if (this.changeStreamCursorOptions.startAfter && !this.hasReceived) {\n        options.startAfter = this.resumeToken;\n      } else {\n        options.resumeAfter = this.resumeToken;\n      }\n    } else if (this.startAtOperationTime != null && maxWireVersion(this.server) >= 7) {\n      options.startAtOperationTime = this.startAtOperationTime;\n    }\n\n    return options;\n  }\n\n  cacheResumeToken(resumeToken: ResumeToken): void {\n    if (this.bufferedCount() === 0 && this.postBatchResumeToken) {\n      this.resumeToken = this.postBatchResumeToken;\n    } else {\n      this.resumeToken = resumeToken;\n    }\n    this.hasReceived = true;\n  }\n\n  _processBatch(response: CursorResponse): void {\n    const { postBatchResumeToken } = response;\n    if (postBatchResumeToken) {\n      this.postBatchResumeToken = postBatchResumeToken;\n\n      if (response.batchSize === 0) {\n        this.resumeToken = postBatchResumeToken;\n      }\n    }\n  }\n\n  clone(): AbstractCursor<TChange> {\n    return new ChangeStreamCursor(this.client, this.namespace, this.pipeline, {\n      ...this.cursorOptions\n    });\n  }\n\n  async _initialize(session: ClientSession): Promise<InitialCursorResponse> {\n    const aggregateOperation = new AggregateOperation(this.namespace, this.pipeline, {\n      ...this.cursorOptions,\n      ...this.changeStreamCursorOptions,\n      session\n    });\n\n    const response = await executeOperation(\n      session.client,\n      aggregateOperation,\n      this.timeoutContext\n    );\n\n    const server = aggregateOperation.server;\n    this.maxWireVersion = maxWireVersion(server);\n\n    if (\n      this.startAtOperationTime == null &&\n      this.changeStreamCursorOptions.resumeAfter == null &&\n      this.changeStreamCursorOptions.startAfter == null &&\n      this.maxWireVersion >= 7\n    ) {\n      this.startAtOperationTime = response.operationTime;\n    }\n\n    this._processBatch(response);\n\n    this.emit(INIT, response);\n    this.emit(RESPONSE);\n\n    return { server, session, response };\n  }\n\n  override async getMore(batchSize: number): Promise<CursorResponse> {\n    const response = await super.getMore(batchSize);\n\n    this.maxWireVersion = maxWireVersion(this.server);\n    this._processBatch(response);\n\n    this.emit(ChangeStream.MORE, response);\n    this.emit(ChangeStream.RESPONSE);\n    return response;\n  }\n}\n"],"names":[],"mappings":";;;;;AACA,MAAA;AAQA,MAAA;AAEA,MAAA;AAEA,MAAA;AAEA,MAAA;AACA,MAAA;AAgBA,cAAA,GACA,MAAa,2BAGH,kBAAA,cAA2C;IAenD,YACE,MAAmB,EACnB,SAA2B,EAC3B,WAAuB,EAAE,EACzB,UAAqC,CAAA,CAAE,CAAA;QAEvC,KAAK,CAAC,QAAQ,WAAW;YAAE,GAAG,OAAO;YAAE,UAAU;YAAM,WAAW;QAAI;QAEtE,IAAI,CAAC,QAAQ,GAAG;QAChB,IAAI,CAAC,yBAAyB,GAAG;QACjC,IAAI,CAAC,YAAY,GAAG;QACpB,IAAI,CAAC,oBAAoB,GAAG,QAAQ,oBAAoB,IAAI;QAE5D,IAAI,QAAQ,UAAU,EAAE;YACtB,IAAI,CAAC,WAAW,GAAG,QAAQ,UAAU;QACvC,OAAO,IAAI,QAAQ,WAAW,EAAE;YAC9B,IAAI,CAAC,WAAW,GAAG,QAAQ,WAAW;QACxC;IACF;IAEA,IAAI,YAAY,KAAkB,EAAA;QAChC,IAAI,CAAC,YAAY,GAAG;QACpB,IAAI,CAAC,IAAI,CAAC,gBAAA,YAAY,CAAC,oBAAoB,EAAE;IAC/C;IAEA,IAAI,cAAW;QACb,OAAO,IAAI,CAAC,YAAY;IAC1B;IAEA,IAAI,gBAAa;QACf,MAAM,UAAqC;YACzC,GAAG,IAAI,CAAC,yBAAyB;;QAGnC,KAAK,MAAM,OAAO;YAAC;YAAe;YAAc;SAAgC,CAAE;YAChF,OAAO,OAAO,CAAC,IAAI;QACrB;QAEA,IAAI,IAAI,CAAC,WAAW,IAAI,MAAM;YAC5B,IAAI,IAAI,CAAC,yBAAyB,CAAC,UAAU,IAAI,CAAC,IAAI,CAAC,WAAW,EAAE;gBAClE,QAAQ,UAAU,GAAG,IAAI,CAAC,WAAW;YACvC,OAAO;gBACL,QAAQ,WAAW,GAAG,IAAI,CAAC,WAAW;YACxC;QACF,OAAO,IAAI,IAAI,CAAC,oBAAoB,IAAI,QAAQ,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,CAAC,MAAM,KAAK,GAAG;YAChF,QAAQ,oBAAoB,GAAG,IAAI,CAAC,oBAAoB;QAC1D;QAEA,OAAO;IACT;IAEA,iBAAiB,WAAwB,EAAA;QACvC,IAAI,IAAI,CAAC,aAAa,OAAO,KAAK,IAAI,CAAC,oBAAoB,EAAE;YAC3D,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC,oBAAoB;QAC9C,OAAO;YACL,IAAI,CAAC,WAAW,GAAG;QACrB;QACA,IAAI,CAAC,WAAW,GAAG;IACrB;IAEA,cAAc,QAAwB,EAAA;QACpC,MAAM,EAAE,oBAAoB,EAAE,GAAG;QACjC,IAAI,sBAAsB;YACxB,IAAI,CAAC,oBAAoB,GAAG;YAE5B,IAAI,SAAS,SAAS,KAAK,GAAG;gBAC5B,IAAI,CAAC,WAAW,GAAG;YACrB;QACF;IACF;IAEA,QAAK;QACH,OAAO,IAAI,mBAAmB,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,QAAQ,EAAE;YACxE,GAAG,IAAI,CAAC,aAAa;;IAEzB;IAEA,MAAM,YAAY,OAAsB,EAAA;QACtC,MAAM,qBAAqB,IAAI,YAAA,kBAAkB,CAAC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,QAAQ,EAAE;YAC/E,GAAG,IAAI,CAAC,aAAa;YACrB,GAAG,IAAI,CAAC,yBAAyB;YACjC;;QAGF,MAAM,WAAW,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EACrC,QAAQ,MAAM,EACd,oBACA,IAAI,CAAC,cAAc;QAGrB,MAAM,SAAS,mBAAmB,MAAM;QACxC,IAAI,CAAC,cAAc,GAAG,CAAA,GAAA,QAAA,cAAc,EAAC;QAErC,IACE,IAAI,CAAC,oBAAoB,IAAI,QAC7B,IAAI,CAAC,yBAAyB,CAAC,WAAW,IAAI,QAC9C,IAAI,CAAC,yBAAyB,CAAC,UAAU,IAAI,QAC7C,IAAI,CAAC,cAAc,IAAI,GACvB;YACA,IAAI,CAAC,oBAAoB,GAAG,SAAS,aAAa;QACpD;QAEA,IAAI,CAAC,aAAa,CAAC;QAEnB,IAAI,CAAC,IAAI,CAAC,YAAA,IAAI,EAAE;QAChB,IAAI,CAAC,IAAI,CAAC,YAAA,QAAQ;QAElB,OAAO;YAAE;YAAQ;YAAS;QAAQ;IACpC;IAES,MAAM,QAAQ,SAAiB,EAAA;QACtC,MAAM,WAAW,MAAM,KAAK,CAAC,QAAQ;QAErC,IAAI,CAAC,cAAc,GAAG,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,CAAC,MAAM;QAChD,IAAI,CAAC,aAAa,CAAC;QAEnB,IAAI,CAAC,IAAI,CAAC,gBAAA,YAAY,CAAC,IAAI,EAAE;QAC7B,IAAI,CAAC,IAAI,CAAC,gBAAA,YAAY,CAAC,QAAQ;QAC/B,OAAO;IACT;;AAzIF,QAAA,kBAAA,GAAA"}},
    {"offset": {"line": 5912, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5916, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/cursor/list_collections_cursor.ts"],"sourcesContent":["import type { Document } from '../bson';\nimport type { Db } from '../db';\nimport { type Abortable } from '../mongo_types';\nimport { executeOperation } from '../operations/execute_operation';\nimport {\n  type CollectionInfo,\n  ListCollectionsOperation,\n  type ListCollectionsOptions\n} from '../operations/list_collections';\nimport type { ClientSession } from '../sessions';\nimport { AbstractCursor, type InitialCursorResponse } from './abstract_cursor';\n\n/** @public */\nexport class ListCollectionsCursor<\n  T extends Pick<CollectionInfo, 'name' | 'type'> | CollectionInfo =\n    | Pick<CollectionInfo, 'name' | 'type'>\n    | CollectionInfo\n> extends AbstractCursor<T> {\n  parent: Db;\n  filter: Document;\n  options?: ListCollectionsOptions & Abortable;\n\n  constructor(db: Db, filter: Document, options?: ListCollectionsOptions & Abortable) {\n    super(db.client, db.s.namespace, options);\n    this.parent = db;\n    this.filter = filter;\n    this.options = options;\n  }\n\n  clone(): ListCollectionsCursor<T> {\n    return new ListCollectionsCursor(this.parent, this.filter, {\n      ...this.options,\n      ...this.cursorOptions\n    });\n  }\n\n  /** @internal */\n  async _initialize(session: ClientSession | undefined): Promise<InitialCursorResponse> {\n    const operation = new ListCollectionsOperation(this.parent, this.filter, {\n      ...this.cursorOptions,\n      ...this.options,\n      session,\n      signal: this.signal\n    });\n\n    const response = await executeOperation(this.parent.client, operation, this.timeoutContext);\n\n    return { server: operation.server, session, response };\n  }\n}\n"],"names":[],"mappings":";;;;;AAGA,MAAA;AACA,MAAA;AAMA,MAAA;AAEA,YAAA,GACA,MAAa,8BAIH,kBAAA,cAAiB;IAKzB,YAAY,EAAM,EAAE,MAAgB,EAAE,OAA4C,CAAA;QAChF,KAAK,CAAC,GAAG,MAAM,EAAE,GAAG,CAAC,CAAC,SAAS,EAAE;QACjC,IAAI,CAAC,MAAM,GAAG;QACd,IAAI,CAAC,MAAM,GAAG;QACd,IAAI,CAAC,OAAO,GAAG;IACjB;IAEA,QAAK;QACH,OAAO,IAAI,sBAAsB,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,MAAM,EAAE;YACzD,GAAG,IAAI,CAAC,OAAO;YACf,GAAG,IAAI,CAAC,aAAa;;IAEzB;IAEA,cAAA,GACA,MAAM,YAAY,OAAkC,EAAA;QAClD,MAAM,YAAY,IAAI,mBAAA,wBAAwB,CAAC,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,MAAM,EAAE;YACvE,GAAG,IAAI,CAAC,aAAa;YACrB,GAAG,IAAI,CAAC,OAAO;YACf;YACA,QAAQ,IAAI,CAAC,MAAM;;QAGrB,MAAM,WAAW,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAAC,IAAI,CAAC,MAAM,CAAC,MAAM,EAAE,WAAW,IAAI,CAAC,cAAc;QAE1F,OAAO;YAAE,QAAQ,UAAU,MAAM;YAAE;YAAS;QAAQ;IACtD;;AAnCF,QAAA,qBAAA,GAAA"}},
    {"offset": {"line": 5953, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5957, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/cursor/run_command_cursor.ts"],"sourcesContent":["import type { BSONSerializeOptions, Document } from '../bson';\nimport { CursorResponse } from '../cmap/wire_protocol/responses';\nimport type { Db } from '../db';\nimport { MongoAPIError } from '../error';\nimport { executeOperation } from '../operations/execute_operation';\nimport { GetMoreOperation } from '../operations/get_more';\nimport { RunCommandOperation } from '../operations/run_command';\nimport type { ReadConcernLike } from '../read_concern';\nimport type { ReadPreferenceLike } from '../read_preference';\nimport type { ClientSession } from '../sessions';\nimport { ns } from '../utils';\nimport {\n  AbstractCursor,\n  type CursorTimeoutMode,\n  type InitialCursorResponse\n} from './abstract_cursor';\n\n/** @public */\nexport type RunCursorCommandOptions = {\n  readPreference?: ReadPreferenceLike;\n  session?: ClientSession;\n  /**\n   * @experimental\n   * Specifies the time an operation will run until it throws a timeout error. Note that if\n   * `maxTimeMS` is provided in the command in addition to setting `timeoutMS` in the options, then\n   * the original value of `maxTimeMS` will be overwritten.\n   */\n  timeoutMS?: number;\n  /**\n   * @public\n   * @experimental\n   * Specifies how `timeoutMS` is applied to the cursor. Can be either `'cursorLifeTime'` or `'iteration'`\n   * When set to `'iteration'`, the deadline specified by `timeoutMS` applies to each call of\n   * `cursor.next()`.\n   * When set to `'cursorLifetime'`, the deadline applies to the life of the entire cursor.\n   *\n   * Depending on the type of cursor being used, this option has different default values.\n   * For non-tailable cursors, this value defaults to `'cursorLifetime'`\n   * For tailable cursors, this value defaults to `'iteration'` since tailable cursors, by\n   * definition can have an arbitrarily long lifetime.\n   *\n   * @example\n   * ```ts\n   * const cursor = collection.find({}, {timeoutMS: 100, timeoutMode: 'iteration'});\n   * for await (const doc of cursor) {\n   *  // process doc\n   *  // This will throw a timeout error if any of the iterator's `next()` calls takes more than 100ms, but\n   *  // will continue to iterate successfully otherwise, regardless of the number of batches.\n   * }\n   * ```\n   *\n   * @example\n   * ```ts\n   * const cursor = collection.find({}, { timeoutMS: 1000, timeoutMode: 'cursorLifetime' });\n   * const docs = await cursor.toArray(); // This entire line will throw a timeout error if all batches are not fetched and returned within 1000ms.\n   * ```\n   */\n  timeoutMode?: CursorTimeoutMode;\n  tailable?: boolean;\n  awaitData?: boolean;\n} & BSONSerializeOptions;\n\n/** @public */\nexport class RunCommandCursor extends AbstractCursor {\n  public readonly command: Readonly<Record<string, any>>;\n  public readonly getMoreOptions: {\n    comment?: any;\n    maxAwaitTimeMS?: number;\n    batchSize?: number;\n  } = {};\n\n  /**\n   * Controls the `getMore.comment` field\n   * @param comment - any BSON value\n   */\n  public setComment(comment: any): this {\n    this.getMoreOptions.comment = comment;\n    return this;\n  }\n\n  /**\n   * Controls the `getMore.maxTimeMS` field. Only valid when cursor is tailable await\n   * @param maxTimeMS - the number of milliseconds to wait for new data\n   */\n  public setMaxTimeMS(maxTimeMS: number): this {\n    this.getMoreOptions.maxAwaitTimeMS = maxTimeMS;\n    return this;\n  }\n\n  /**\n   * Controls the `getMore.batchSize` field\n   * @param batchSize - the number documents to return in the `nextBatch`\n   */\n  public setBatchSize(batchSize: number): this {\n    this.getMoreOptions.batchSize = batchSize;\n    return this;\n  }\n\n  /** Unsupported for RunCommandCursor */\n  public override clone(): never {\n    throw new MongoAPIError('Clone not supported, create a new cursor with db.runCursorCommand');\n  }\n\n  /** Unsupported for RunCommandCursor: readConcern must be configured directly on command document */\n  public override withReadConcern(_: ReadConcernLike): never {\n    throw new MongoAPIError(\n      'RunCommandCursor does not support readConcern it must be attached to the command being run'\n    );\n  }\n\n  /** Unsupported for RunCommandCursor: various cursor flags must be configured directly on command document */\n  public override addCursorFlag(_: string, __: boolean): never {\n    throw new MongoAPIError(\n      'RunCommandCursor does not support cursor flags, they must be attached to the command being run'\n    );\n  }\n\n  /**\n   * Unsupported for RunCommandCursor: maxTimeMS must be configured directly on command document\n   */\n  public override maxTimeMS(_: number): never {\n    throw new MongoAPIError(\n      'maxTimeMS must be configured on the command document directly, to configure getMore.maxTimeMS use cursor.setMaxTimeMS()'\n    );\n  }\n\n  /** Unsupported for RunCommandCursor: batchSize must be configured directly on command document */\n  public override batchSize(_: number): never {\n    throw new MongoAPIError(\n      'batchSize must be configured on the command document directly, to configure getMore.batchSize use cursor.setBatchSize()'\n    );\n  }\n\n  /** @internal */\n  private db: Db;\n\n  /** @internal */\n  constructor(db: Db, command: Document, options: RunCursorCommandOptions = {}) {\n    super(db.client, ns(db.namespace), options);\n    this.db = db;\n    this.command = Object.freeze({ ...command });\n  }\n\n  /** @internal */\n  protected async _initialize(session: ClientSession): Promise<InitialCursorResponse> {\n    const operation = new RunCommandOperation<CursorResponse>(this.db, this.command, {\n      ...this.cursorOptions,\n      session: session,\n      readPreference: this.cursorOptions.readPreference,\n      responseType: CursorResponse\n    });\n\n    const response = await executeOperation(this.client, operation, this.timeoutContext);\n\n    return {\n      server: operation.server,\n      session,\n      response\n    };\n  }\n\n  /** @internal */\n  override async getMore(_batchSize: number): Promise<CursorResponse> {\n    // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n    const getMoreOperation = new GetMoreOperation(this.namespace, this.id!, this.server!, {\n      ...this.cursorOptions,\n      session: this.session,\n      ...this.getMoreOptions\n    });\n\n    return await executeOperation(this.client, getMoreOperation, this.timeoutContext);\n  }\n}\n"],"names":[],"mappings":";;;;;AACA,MAAA;AAEA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAIA,MAAA;AACA,MAAA;AAmDA,YAAA,GACA,MAAa,yBAAyB,kBAAA,cAAc;IAQlD;;;QAIO,WAAW,OAAY,EAAA;QAC5B,IAAI,CAAC,cAAc,CAAC,OAAO,GAAG;QAC9B,OAAO,IAAI;IACb;IAEA;;;QAIO,aAAa,SAAiB,EAAA;QACnC,IAAI,CAAC,cAAc,CAAC,cAAc,GAAG;QACrC,OAAO,IAAI;IACb;IAEA;;;QAIO,aAAa,SAAiB,EAAA;QACnC,IAAI,CAAC,cAAc,CAAC,SAAS,GAAG;QAChC,OAAO,IAAI;IACb;IAEA,qCAAA,GACgB,QAAK;QACnB,MAAM,IAAI,QAAA,aAAa,CAAC;IAC1B;IAEA,kGAAA,GACgB,gBAAgB,CAAkB,EAAA;QAChD,MAAM,IAAI,QAAA,aAAa,CACrB;IAEJ;IAEA,2GAAA,GACgB,cAAc,CAAS,EAAE,EAAW,EAAA;QAClD,MAAM,IAAI,QAAA,aAAa,CACrB;IAEJ;IAEA;;QAGgB,UAAU,CAAS,EAAA;QACjC,MAAM,IAAI,QAAA,aAAa,CACrB;IAEJ;IAEA,gGAAA,GACgB,UAAU,CAAS,EAAA;QACjC,MAAM,IAAI,QAAA,aAAa,CACrB;IAEJ;IAKA,cAAA,GACA,YAAY,EAAM,EAAE,OAAiB,EAAE,UAAmC,CAAA,CAAE,CAAA;QAC1E,KAAK,CAAC,GAAG,MAAM,EAAE,CAAA,GAAA,QAAA,EAAE,EAAC,GAAG,SAAS,GAAG;QAzErB,IAAA,CAAA,cAAc,GAI1B,CAAA;QAsEF,IAAI,CAAC,EAAE,GAAG;QACV,IAAI,CAAC,OAAO,GAAG,OAAO,MAAM,CAAC;YAAE,GAAG,OAAO;QAAA;IAC3C;IAEA,cAAA,GACU,MAAM,YAAY,OAAsB,EAAA;QAChD,MAAM,YAAY,IAAI,cAAA,mBAAmB,CAAiB,IAAI,CAAC,EAAE,EAAE,IAAI,CAAC,OAAO,EAAE;YAC/E,GAAG,IAAI,CAAC,aAAa;YACrB,SAAS;YACT,gBAAgB,IAAI,CAAC,aAAa,CAAC,cAAc;YACjD,cAAc,YAAA,cAAc;;QAG9B,MAAM,WAAW,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAAC,IAAI,CAAC,MAAM,EAAE,WAAW,IAAI,CAAC,cAAc;QAEnF,OAAO;YACL,QAAQ,UAAU,MAAM;YACxB;YACA;;IAEJ;IAEA,cAAA,GACS,MAAM,QAAQ,UAAkB,EAAA;QACvC,oEAAoE;QACpE,MAAM,mBAAmB,IAAI,WAAA,gBAAgB,CAAC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,EAAG,EAAE,IAAI,CAAC,MAAO,EAAE;YACpF,GAAG,IAAI,CAAC,aAAa;YACrB,SAAS,IAAI,CAAC,OAAO;YACrB,GAAG,IAAI,CAAC,cAAc;;QAGxB,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAAC,IAAI,CAAC,MAAM,EAAE,kBAAkB,IAAI,CAAC,cAAc;IAClF;;AA5GF,QAAA,gBAAA,GAAA"}},
    {"offset": {"line": 6041, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6045, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/cursor/client_bulk_write_cursor.ts"],"sourcesContent":["import { type Document } from '../bson';\nimport { type ClientBulkWriteCursorResponse } from '../cmap/wire_protocol/responses';\nimport type { MongoClient } from '../mongo_client';\nimport { ClientBulkWriteOperation } from '../operations/client_bulk_write/client_bulk_write';\nimport { type ClientBulkWriteCommandBuilder } from '../operations/client_bulk_write/command_builder';\nimport { type ClientBulkWriteOptions } from '../operations/client_bulk_write/common';\nimport { executeOperation } from '../operations/execute_operation';\nimport type { ClientSession } from '../sessions';\nimport { mergeOptions, MongoDBNamespace } from '../utils';\nimport {\n  AbstractCursor,\n  type AbstractCursorOptions,\n  type InitialCursorResponse\n} from './abstract_cursor';\n\n/** @public */\nexport interface ClientBulkWriteCursorOptions\n  extends Omit<AbstractCursorOptions, 'maxAwaitTimeMS' | 'tailable' | 'awaitData'>,\n    ClientBulkWriteOptions {}\n\n/**\n * This is the cursor that handles client bulk write operations. Note this is never\n * exposed directly to the user and is always immediately exhausted.\n * @internal\n */\nexport class ClientBulkWriteCursor extends AbstractCursor {\n  commandBuilder: ClientBulkWriteCommandBuilder;\n  /** @internal */\n  private cursorResponse?: ClientBulkWriteCursorResponse;\n  /** @internal */\n  private clientBulkWriteOptions: ClientBulkWriteOptions;\n\n  /** @internal */\n  constructor(\n    client: MongoClient,\n    commandBuilder: ClientBulkWriteCommandBuilder,\n    options: ClientBulkWriteCursorOptions = {}\n  ) {\n    super(client, new MongoDBNamespace('admin', '$cmd'), options);\n\n    this.commandBuilder = commandBuilder;\n    this.clientBulkWriteOptions = options;\n  }\n\n  /**\n   * We need a way to get the top level cursor response fields for\n   * generating the bulk write result, so we expose this here.\n   */\n  get response(): ClientBulkWriteCursorResponse | null {\n    if (this.cursorResponse) return this.cursorResponse;\n    return null;\n  }\n\n  get operations(): Document[] {\n    return this.commandBuilder.lastOperations;\n  }\n\n  clone(): ClientBulkWriteCursor {\n    const clonedOptions = mergeOptions({}, this.clientBulkWriteOptions);\n    delete clonedOptions.session;\n    return new ClientBulkWriteCursor(this.client, this.commandBuilder, {\n      ...clonedOptions\n    });\n  }\n\n  /** @internal */\n  async _initialize(session: ClientSession): Promise<InitialCursorResponse> {\n    const clientBulkWriteOperation = new ClientBulkWriteOperation(this.commandBuilder, {\n      ...this.clientBulkWriteOptions,\n      ...this.cursorOptions,\n      session\n    });\n\n    const response = await executeOperation(\n      this.client,\n      clientBulkWriteOperation,\n      this.timeoutContext\n    );\n    this.cursorResponse = response;\n\n    return { server: clientBulkWriteOperation.server, session, response };\n  }\n}\n"],"names":[],"mappings":";;;;;AAGA,MAAA;AAGA,MAAA;AAEA,MAAA;AACA,MAAA;AAWA;;;;IAKA,MAAa,8BAA8B,kBAAA,cAAc;IAOvD,cAAA,GACA,YACE,MAAmB,EACnB,cAA6C,EAC7C,UAAwC,CAAA,CAAE,CAAA;QAE1C,KAAK,CAAC,QAAQ,IAAI,QAAA,gBAAgB,CAAC,SAAS,SAAS;QAErD,IAAI,CAAC,cAAc,GAAG;QACtB,IAAI,CAAC,sBAAsB,GAAG;IAChC;IAEA;;;QAIA,IAAI,WAAQ;QACV,IAAI,IAAI,CAAC,cAAc,EAAE,OAAO,IAAI,CAAC,cAAc;QACnD,OAAO;IACT;IAEA,IAAI,aAAU;QACZ,OAAO,IAAI,CAAC,cAAc,CAAC,cAAc;IAC3C;IAEA,QAAK;QACH,MAAM,gBAAgB,CAAA,GAAA,QAAA,YAAY,EAAC,CAAA,GAAI,IAAI,CAAC,sBAAsB;QAClE,OAAO,cAAc,OAAO;QAC5B,OAAO,IAAI,sBAAsB,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,cAAc,EAAE;YACjE,GAAG,aAAa;;IAEpB;IAEA,cAAA,GACA,MAAM,YAAY,OAAsB,EAAA;QACtC,MAAM,2BAA2B,IAAI,oBAAA,wBAAwB,CAAC,IAAI,CAAC,cAAc,EAAE;YACjF,GAAG,IAAI,CAAC,sBAAsB;YAC9B,GAAG,IAAI,CAAC,aAAa;YACrB;;QAGF,MAAM,WAAW,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EACrC,IAAI,CAAC,MAAM,EACX,0BACA,IAAI,CAAC,cAAc;QAErB,IAAI,CAAC,cAAc,GAAG;QAEtB,OAAO;YAAE,QAAQ,yBAAyB,MAAM;YAAE;YAAS;QAAQ;IACrE;;AAxDF,QAAA,qBAAA,GAAA"}},
    {"offset": {"line": 6097, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6101, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/cursor/abstract_cursor.ts"],"sourcesContent":["import { Readable, Transform } from 'stream';\n\nimport { type BSONSerializeOptions, type Document, Long, pluckBSONSerializeOptions } from '../bson';\nimport { type OnDemandDocumentDeserializeOptions } from '../cmap/wire_protocol/on_demand/document';\nimport { type CursorResponse } from '../cmap/wire_protocol/responses';\nimport {\n  MongoAPIError,\n  MongoCursorExhaustedError,\n  MongoCursorInUseError,\n  MongoInvalidArgumentError,\n  MongoRuntimeError,\n  MongoTailableCursorError\n} from '../error';\nimport type { MongoClient } from '../mongo_client';\nimport { type Abortable, TypedEventEmitter } from '../mongo_types';\nimport { executeOperation } from '../operations/execute_operation';\nimport { GetMoreOperation } from '../operations/get_more';\nimport { KillCursorsOperation } from '../operations/kill_cursors';\nimport { ReadConcern, type ReadConcernLike } from '../read_concern';\nimport { ReadPreference, type ReadPreferenceLike } from '../read_preference';\nimport { type AsyncDisposable, configureResourceManagement } from '../resource_management';\nimport type { Server } from '../sdam/server';\nimport { ClientSession, maybeClearPinnedConnection } from '../sessions';\nimport { type CSOTTimeoutContext, type Timeout, TimeoutContext } from '../timeout';\nimport {\n  addAbortListener,\n  type Disposable,\n  kDispose,\n  type MongoDBNamespace,\n  noop,\n  squashError\n} from '../utils';\n\n/**\n * @internal\n * TODO(NODE-2882): A cursor's getMore commands must be run on the same server it was started on\n * and the same session must be used for the lifetime of the cursor. This object serves to get the\n * server and session (along with the response) out of executeOperation back to the AbstractCursor.\n *\n * There may be a better design for communicating these values back to the cursor, currently an operation\n * MUST store the selected server on itself so it can be read after executeOperation has returned.\n */\nexport interface InitialCursorResponse {\n  /** The server selected for the operation */\n  server: Server;\n  /** The session used for this operation, may be implicitly created */\n  session?: ClientSession;\n  /** The raw server response for the operation */\n  response: CursorResponse;\n}\n\n/** @public */\nexport const CURSOR_FLAGS = [\n  'tailable',\n  'oplogReplay',\n  'noCursorTimeout',\n  'awaitData',\n  'exhaust',\n  'partial'\n] as const;\n\n/** @public */\nexport interface CursorStreamOptions {\n  /** A transformation method applied to each document emitted by the stream */\n  transform?(this: void, doc: Document): Document;\n}\n\n/** @public */\nexport type CursorFlag = (typeof CURSOR_FLAGS)[number];\n\nfunction removeActiveCursor(this: AbstractCursor) {\n  this.client.s.activeCursors.delete(this);\n}\n\n/**\n * @public\n * @experimental\n * Specifies how `timeoutMS` is applied to the cursor. Can be either `'cursorLifeTime'` or `'iteration'`\n * When set to `'iteration'`, the deadline specified by `timeoutMS` applies to each call of\n * `cursor.next()`.\n * When set to `'cursorLifetime'`, the deadline applies to the life of the entire cursor.\n *\n * Depending on the type of cursor being used, this option has different default values.\n * For non-tailable cursors, this value defaults to `'cursorLifetime'`\n * For tailable cursors, this value defaults to `'iteration'` since tailable cursors, by\n * definition can have an arbitrarily long lifetime.\n *\n * @example\n * ```ts\n * const cursor = collection.find({}, {timeoutMS: 100, timeoutMode: 'iteration'});\n * for await (const doc of cursor) {\n *  // process doc\n *  // This will throw a timeout error if any of the iterator's `next()` calls takes more than 100ms, but\n *  // will continue to iterate successfully otherwise, regardless of the number of batches.\n * }\n * ```\n *\n * @example\n * ```ts\n * const cursor = collection.find({}, { timeoutMS: 1000, timeoutMode: 'cursorLifetime' });\n * const docs = await cursor.toArray(); // This entire line will throw a timeout error if all batches are not fetched and returned within 1000ms.\n * ```\n */\nexport const CursorTimeoutMode = Object.freeze({\n  ITERATION: 'iteration',\n  LIFETIME: 'cursorLifetime'\n} as const);\n\n/**\n * @public\n * @experimental\n */\nexport type CursorTimeoutMode = (typeof CursorTimeoutMode)[keyof typeof CursorTimeoutMode];\n\n/** @public */\nexport interface AbstractCursorOptions extends BSONSerializeOptions {\n  session?: ClientSession;\n  readPreference?: ReadPreferenceLike;\n  readConcern?: ReadConcernLike;\n  /**\n   * Specifies the number of documents to return in each response from MongoDB\n   */\n  batchSize?: number;\n  /**\n   * When applicable `maxTimeMS` controls the amount of time the initial command\n   * that constructs a cursor should take. (ex. find, aggregate, listCollections)\n   */\n  maxTimeMS?: number;\n  /**\n   * When applicable `maxAwaitTimeMS` controls the amount of time subsequent getMores\n   * that a cursor uses to fetch more data should take. (ex. cursor.next())\n   */\n  maxAwaitTimeMS?: number;\n  /**\n   * Comment to apply to the operation.\n   *\n   * In server versions pre-4.4, 'comment' must be string.  A server\n   * error will be thrown if any other type is provided.\n   *\n   * In server versions 4.4 and above, 'comment' can be any valid BSON type.\n   */\n  comment?: unknown;\n  /**\n   * By default, MongoDB will automatically close a cursor when the\n   * client has exhausted all results in the cursor. However, for [capped collections](https://www.mongodb.com/docs/manual/core/capped-collections)\n   * you may use a Tailable Cursor that remains open after the client exhausts\n   * the results in the initial cursor.\n   */\n  tailable?: boolean;\n  /**\n   * If awaitData is set to true, when the cursor reaches the end of the capped collection,\n   * MongoDB blocks the query thread for a period of time waiting for new data to arrive.\n   * When new data is inserted into the capped collection, the blocked thread is signaled\n   * to wake up and return the next batch to the client.\n   */\n  awaitData?: boolean;\n  noCursorTimeout?: boolean;\n  /** Specifies the time an operation will run until it throws a timeout error. See {@link AbstractCursorOptions.timeoutMode} for more details on how this option applies to cursors. */\n  timeoutMS?: number;\n  /**\n   * @public\n   * @experimental\n   * Specifies how `timeoutMS` is applied to the cursor. Can be either `'cursorLifeTime'` or `'iteration'`\n   * When set to `'iteration'`, the deadline specified by `timeoutMS` applies to each call of\n   * `cursor.next()`.\n   * When set to `'cursorLifetime'`, the deadline applies to the life of the entire cursor.\n   *\n   * Depending on the type of cursor being used, this option has different default values.\n   * For non-tailable cursors, this value defaults to `'cursorLifetime'`\n   * For tailable cursors, this value defaults to `'iteration'` since tailable cursors, by\n   * definition can have an arbitrarily long lifetime.\n   *\n   * @example\n   * ```ts\n   * const cursor = collection.find({}, {timeoutMS: 100, timeoutMode: 'iteration'});\n   * for await (const doc of cursor) {\n   *  // process doc\n   *  // This will throw a timeout error if any of the iterator's `next()` calls takes more than 100ms, but\n   *  // will continue to iterate successfully otherwise, regardless of the number of batches.\n   * }\n   * ```\n   *\n   * @example\n   * ```ts\n   * const cursor = collection.find({}, { timeoutMS: 1000, timeoutMode: 'cursorLifetime' });\n   * const docs = await cursor.toArray(); // This entire line will throw a timeout error if all batches are not fetched and returned within 1000ms.\n   * ```\n   */\n  timeoutMode?: CursorTimeoutMode;\n\n  /**\n   * @internal\n   *\n   * A timeout context to govern the total time the cursor can live.  If provided, the cursor\n   * cannot be used in ITERATION mode.\n   */\n  timeoutContext?: CursorTimeoutContext;\n}\n\n/** @internal */\nexport type InternalAbstractCursorOptions = Omit<AbstractCursorOptions, 'readPreference'> & {\n  // resolved\n  readPreference: ReadPreference;\n  readConcern?: ReadConcern;\n\n  // cursor flags, some are deprecated\n  oplogReplay?: boolean;\n  exhaust?: boolean;\n  partial?: boolean;\n\n  omitMaxTimeMS?: boolean;\n};\n\n/** @public */\nexport type AbstractCursorEvents = {\n  [AbstractCursor.CLOSE](): void;\n};\n\n/** @public */\nexport abstract class AbstractCursor<\n    TSchema = any,\n    CursorEvents extends AbstractCursorEvents = AbstractCursorEvents\n  >\n  extends TypedEventEmitter<CursorEvents>\n  implements AsyncDisposable\n{\n  /** @internal */\n  private cursorId: Long | null;\n  /** @internal */\n  private cursorSession: ClientSession;\n  /** @internal */\n  private selectedServer?: Server;\n  /** @internal */\n  private cursorNamespace: MongoDBNamespace;\n  /** @internal */\n  private documents: CursorResponse | null = null;\n  /** @internal */\n  private cursorClient: MongoClient;\n  /** @internal */\n  private transform?: (doc: TSchema) => any;\n  /**\n   * @internal\n   * This is true whether or not the first command fails. It only indicates whether or not the first\n   * command has been run.\n   */\n  private initialized: boolean;\n  /** @internal */\n  private isClosed: boolean;\n  /** @internal */\n  private isKilled: boolean;\n  /** @internal */\n  protected readonly cursorOptions: InternalAbstractCursorOptions;\n  /** @internal */\n  protected timeoutContext?: CursorTimeoutContext;\n\n  /** @event */\n  static readonly CLOSE = 'close' as const;\n\n  /** @internal */\n  protected deserializationOptions: OnDemandDocumentDeserializeOptions;\n  protected signal: AbortSignal | undefined;\n  private abortListener: Disposable | undefined;\n\n  /** @internal */\n  protected constructor(\n    client: MongoClient,\n    namespace: MongoDBNamespace,\n    options: AbstractCursorOptions & Abortable = {}\n  ) {\n    super();\n    this.on('error', noop);\n\n    if (!client.s.isMongoClient) {\n      throw new MongoRuntimeError('Cursor must be constructed with MongoClient');\n    }\n    this.cursorClient = client;\n    this.cursorNamespace = namespace;\n    this.cursorId = null;\n    this.initialized = false;\n    this.isClosed = false;\n    this.isKilled = false;\n    this.cursorOptions = {\n      readPreference:\n        options.readPreference && options.readPreference instanceof ReadPreference\n          ? options.readPreference\n          : ReadPreference.primary,\n      ...pluckBSONSerializeOptions(options),\n      timeoutMS: options?.timeoutContext?.csotEnabled()\n        ? options.timeoutContext.timeoutMS\n        : options.timeoutMS,\n      tailable: options.tailable,\n      awaitData: options.awaitData\n    };\n\n    if (this.cursorOptions.timeoutMS != null) {\n      if (options.timeoutMode == null) {\n        if (options.tailable) {\n          if (options.awaitData) {\n            if (\n              options.maxAwaitTimeMS != null &&\n              options.maxAwaitTimeMS >= this.cursorOptions.timeoutMS\n            )\n              throw new MongoInvalidArgumentError(\n                'Cannot specify maxAwaitTimeMS >= timeoutMS for a tailable awaitData cursor'\n              );\n          }\n\n          this.cursorOptions.timeoutMode = CursorTimeoutMode.ITERATION;\n        } else {\n          this.cursorOptions.timeoutMode = CursorTimeoutMode.LIFETIME;\n        }\n      } else {\n        if (options.tailable && options.timeoutMode === CursorTimeoutMode.LIFETIME) {\n          throw new MongoInvalidArgumentError(\n            \"Cannot set tailable cursor's timeoutMode to LIFETIME\"\n          );\n        }\n        this.cursorOptions.timeoutMode = options.timeoutMode;\n      }\n    } else {\n      if (options.timeoutMode != null)\n        throw new MongoInvalidArgumentError('Cannot set timeoutMode without setting timeoutMS');\n    }\n\n    // Set for initial command\n    this.cursorOptions.omitMaxTimeMS =\n      this.cursorOptions.timeoutMS != null &&\n      ((this.cursorOptions.timeoutMode === CursorTimeoutMode.ITERATION &&\n        !this.cursorOptions.tailable) ||\n        (this.cursorOptions.tailable && !this.cursorOptions.awaitData));\n\n    const readConcern = ReadConcern.fromOptions(options);\n    if (readConcern) {\n      this.cursorOptions.readConcern = readConcern;\n    }\n\n    if (typeof options.batchSize === 'number') {\n      this.cursorOptions.batchSize = options.batchSize;\n    }\n\n    // we check for undefined specifically here to allow falsy values\n    // eslint-disable-next-line no-restricted-syntax\n    if (options.comment !== undefined) {\n      this.cursorOptions.comment = options.comment;\n    }\n\n    if (typeof options.maxTimeMS === 'number') {\n      this.cursorOptions.maxTimeMS = options.maxTimeMS;\n    }\n\n    if (typeof options.maxAwaitTimeMS === 'number') {\n      this.cursorOptions.maxAwaitTimeMS = options.maxAwaitTimeMS;\n    }\n\n    if (options.session instanceof ClientSession) {\n      this.cursorSession = options.session;\n    } else {\n      this.cursorSession = this.cursorClient.startSession({ owner: this, explicit: false });\n    }\n\n    this.deserializationOptions = {\n      ...this.cursorOptions,\n      validation: {\n        utf8: options?.enableUtf8Validation === false ? false : true\n      }\n    };\n\n    this.timeoutContext = options.timeoutContext;\n    this.signal = options.signal;\n    this.abortListener = addAbortListener(\n      this.signal,\n      () => void this.close().then(undefined, squashError)\n    );\n    this.trackCursor();\n  }\n\n  /**\n   * The cursor has no id until it receives a response from the initial cursor creating command.\n   *\n   * It is non-zero for as long as the database has an open cursor.\n   *\n   * The initiating command may receive a zero id if the entire result is in the `firstBatch`.\n   */\n  get id(): Long | undefined {\n    return this.cursorId ?? undefined;\n  }\n\n  /** @internal */\n  get isDead() {\n    return (this.cursorId?.isZero() ?? false) || this.isClosed || this.isKilled;\n  }\n\n  /** @internal */\n  get client(): MongoClient {\n    return this.cursorClient;\n  }\n\n  /** @internal */\n  get server(): Server | undefined {\n    return this.selectedServer;\n  }\n\n  get namespace(): MongoDBNamespace {\n    return this.cursorNamespace;\n  }\n\n  get readPreference(): ReadPreference {\n    return this.cursorOptions.readPreference;\n  }\n\n  get readConcern(): ReadConcern | undefined {\n    return this.cursorOptions.readConcern;\n  }\n\n  /** @internal */\n  get session(): ClientSession {\n    return this.cursorSession;\n  }\n\n  set session(clientSession: ClientSession) {\n    this.cursorSession = clientSession;\n  }\n\n  /**\n   * The cursor is closed and all remaining locally buffered documents have been iterated.\n   */\n  get closed(): boolean {\n    return this.isClosed && (this.documents?.length ?? 0) === 0;\n  }\n\n  /**\n   * A `killCursors` command was attempted on this cursor.\n   * This is performed if the cursor id is non zero.\n   */\n  get killed(): boolean {\n    return this.isKilled;\n  }\n\n  get loadBalanced(): boolean {\n    return !!this.cursorClient.topology?.loadBalanced;\n  }\n\n  /**\n   * @beta\n   * @experimental\n   * An alias for {@link AbstractCursor.close|AbstractCursor.close()}.\n   */\n  declare [Symbol.asyncDispose]: () => Promise<void>;\n  /** @internal */\n  async asyncDispose() {\n    await this.close();\n  }\n\n  /** Adds cursor to client's tracking so it will be closed by MongoClient.close() */\n  private trackCursor() {\n    this.cursorClient.s.activeCursors.add(this);\n    if (!this.listeners('close').includes(removeActiveCursor)) {\n      this.once('close', removeActiveCursor);\n    }\n  }\n\n  /** Returns current buffered documents length */\n  bufferedCount(): number {\n    return this.documents?.length ?? 0;\n  }\n\n  /** Returns current buffered documents */\n  readBufferedDocuments(number?: number): NonNullable<TSchema>[] {\n    const bufferedDocs: NonNullable<TSchema>[] = [];\n    const documentsToRead = Math.min(\n      number ?? this.documents?.length ?? 0,\n      this.documents?.length ?? 0\n    );\n\n    for (let count = 0; count < documentsToRead; count++) {\n      const document = this.documents?.shift(this.deserializationOptions);\n      if (document != null) {\n        bufferedDocs.push(document);\n      }\n    }\n\n    return bufferedDocs;\n  }\n\n  async *[Symbol.asyncIterator](): AsyncGenerator<TSchema, void, void> {\n    this.signal?.throwIfAborted();\n\n    if (this.closed) {\n      return;\n    }\n\n    try {\n      while (true) {\n        if (this.isKilled) {\n          return;\n        }\n\n        if (this.closed) {\n          return;\n        }\n\n        if (this.cursorId != null && this.isDead && (this.documents?.length ?? 0) === 0) {\n          return;\n        }\n\n        const document = await this.next();\n\n        // eslint-disable-next-line no-restricted-syntax\n        if (document === null) {\n          return;\n        }\n\n        yield document;\n\n        this.signal?.throwIfAborted();\n      }\n    } finally {\n      // Only close the cursor if it has not already been closed. This finally clause handles\n      // the case when a user would break out of a for await of loop early.\n      if (!this.isClosed) {\n        try {\n          await this.close();\n        } catch (error) {\n          squashError(error);\n        }\n      }\n    }\n  }\n\n  stream(options?: CursorStreamOptions): Readable & AsyncIterable<TSchema> {\n    const readable = new ReadableCursorStream(this);\n    const abortListener = addAbortListener(this.signal, function () {\n      readable.destroy(this.reason);\n    });\n    readable.once('end', () => {\n      abortListener?.[kDispose]();\n    });\n\n    if (options?.transform) {\n      const transform = options.transform;\n\n      const transformedStream = readable.pipe(\n        new Transform({\n          objectMode: true,\n          highWaterMark: 1,\n          transform(chunk, _, callback) {\n            try {\n              const transformed = transform(chunk);\n              callback(undefined, transformed);\n            } catch (err) {\n              callback(err);\n            }\n          }\n        })\n      );\n\n      // Bubble errors to transformed stream, because otherwise no way\n      // to handle this error.\n      readable.on('error', err => transformedStream.emit('error', err));\n\n      return transformedStream;\n    }\n\n    return readable;\n  }\n\n  async hasNext(): Promise<boolean> {\n    this.signal?.throwIfAborted();\n\n    if (this.cursorId === Long.ZERO) {\n      return false;\n    }\n\n    if (this.cursorOptions.timeoutMode === CursorTimeoutMode.ITERATION && this.cursorId != null) {\n      this.timeoutContext?.refresh();\n    }\n    try {\n      do {\n        if ((this.documents?.length ?? 0) !== 0) {\n          return true;\n        }\n        await this.fetchBatch();\n      } while (!this.isDead || (this.documents?.length ?? 0) !== 0);\n    } finally {\n      if (this.cursorOptions.timeoutMode === CursorTimeoutMode.ITERATION) {\n        this.timeoutContext?.clear();\n      }\n    }\n\n    return false;\n  }\n\n  /** Get the next available document from the cursor, returns null if no more documents are available. */\n  async next(): Promise<TSchema | null> {\n    this.signal?.throwIfAborted();\n\n    if (this.cursorId === Long.ZERO) {\n      throw new MongoCursorExhaustedError();\n    }\n\n    if (this.cursorOptions.timeoutMode === CursorTimeoutMode.ITERATION && this.cursorId != null) {\n      this.timeoutContext?.refresh();\n    }\n\n    try {\n      do {\n        const doc = this.documents?.shift(this.deserializationOptions);\n        if (doc != null) {\n          if (this.transform != null) return await this.transformDocument(doc);\n          return doc;\n        }\n        await this.fetchBatch();\n      } while (!this.isDead || (this.documents?.length ?? 0) !== 0);\n    } finally {\n      if (this.cursorOptions.timeoutMode === CursorTimeoutMode.ITERATION) {\n        this.timeoutContext?.clear();\n      }\n    }\n\n    return null;\n  }\n\n  /**\n   * Try to get the next available document from the cursor or `null` if an empty batch is returned\n   */\n  async tryNext(): Promise<TSchema | null> {\n    this.signal?.throwIfAborted();\n\n    if (this.cursorId === Long.ZERO) {\n      throw new MongoCursorExhaustedError();\n    }\n\n    if (this.cursorOptions.timeoutMode === CursorTimeoutMode.ITERATION && this.cursorId != null) {\n      this.timeoutContext?.refresh();\n    }\n    try {\n      let doc = this.documents?.shift(this.deserializationOptions);\n      if (doc != null) {\n        if (this.transform != null) return await this.transformDocument(doc);\n        return doc;\n      }\n\n      await this.fetchBatch();\n\n      doc = this.documents?.shift(this.deserializationOptions);\n      if (doc != null) {\n        if (this.transform != null) return await this.transformDocument(doc);\n        return doc;\n      }\n    } finally {\n      if (this.cursorOptions.timeoutMode === CursorTimeoutMode.ITERATION) {\n        this.timeoutContext?.clear();\n      }\n    }\n\n    return null;\n  }\n\n  /**\n   * Iterates over all the documents for this cursor using the iterator, callback pattern.\n   *\n   * If the iterator returns `false`, iteration will stop.\n   *\n   * @param iterator - The iteration callback.\n   * @deprecated - Will be removed in a future release. Use for await...of instead.\n   */\n  async forEach(iterator: (doc: TSchema) => boolean | void): Promise<void> {\n    this.signal?.throwIfAborted();\n\n    if (typeof iterator !== 'function') {\n      throw new MongoInvalidArgumentError('Argument \"iterator\" must be a function');\n    }\n    for await (const document of this) {\n      const result = iterator(document);\n      if (result === false) {\n        break;\n      }\n    }\n  }\n\n  /**\n   * Frees any client-side resources used by the cursor.\n   */\n  async close(options?: { timeoutMS?: number }): Promise<void> {\n    await this.cleanup(options?.timeoutMS);\n  }\n\n  /**\n   * Returns an array of documents. The caller is responsible for making sure that there\n   * is enough memory to store the results. Note that the array only contains partial\n   * results when this cursor had been previously accessed. In that case,\n   * cursor.rewind() can be used to reset the cursor.\n   */\n  async toArray(): Promise<TSchema[]> {\n    this.signal?.throwIfAborted();\n\n    const array: TSchema[] = [];\n    // at the end of the loop (since readBufferedDocuments is called) the buffer will be empty\n    // then, the 'await of' syntax will run a getMore call\n    for await (const document of this) {\n      array.push(document);\n      const docs = this.readBufferedDocuments();\n      if (this.transform != null) {\n        for (const doc of docs) {\n          array.push(await this.transformDocument(doc));\n        }\n      } else {\n        array.push(...docs);\n      }\n    }\n    return array;\n  }\n  /**\n   * Add a cursor flag to the cursor\n   *\n   * @param flag - The flag to set, must be one of following ['tailable', 'oplogReplay', 'noCursorTimeout', 'awaitData', 'partial' -.\n   * @param value - The flag boolean value.\n   */\n  addCursorFlag(flag: CursorFlag, value: boolean): this {\n    this.throwIfInitialized();\n    if (!CURSOR_FLAGS.includes(flag)) {\n      throw new MongoInvalidArgumentError(`Flag ${flag} is not one of ${CURSOR_FLAGS}`);\n    }\n\n    if (typeof value !== 'boolean') {\n      throw new MongoInvalidArgumentError(`Flag ${flag} must be a boolean value`);\n    }\n\n    this.cursorOptions[flag] = value;\n    return this;\n  }\n\n  /**\n   * Map all documents using the provided function\n   * If there is a transform set on the cursor, that will be called first and the result passed to\n   * this function's transform.\n   *\n   * @remarks\n   *\n   * **Note** Cursors use `null` internally to indicate that there are no more documents in the cursor. Providing a mapping\n   * function that maps values to `null` will result in the cursor closing itself before it has finished iterating\n   * all documents.  This will **not** result in a memory leak, just surprising behavior.  For example:\n   *\n   * ```typescript\n   * const cursor = collection.find({});\n   * cursor.map(() => null);\n   *\n   * const documents = await cursor.toArray();\n   * // documents is always [], regardless of how many documents are in the collection.\n   * ```\n   *\n   * Other falsey values are allowed:\n   *\n   * ```typescript\n   * const cursor = collection.find({});\n   * cursor.map(() => '');\n   *\n   * const documents = await cursor.toArray();\n   * // documents is now an array of empty strings\n   * ```\n   *\n   * **Note for Typescript Users:** adding a transform changes the return type of the iteration of this cursor,\n   * it **does not** return a new instance of a cursor. This means when calling map,\n   * you should always assign the result to a new variable in order to get a correctly typed cursor variable.\n   * Take note of the following example:\n   *\n   * @example\n   * ```typescript\n   * const cursor: FindCursor<Document> = coll.find();\n   * const mappedCursor: FindCursor<number> = cursor.map(doc => Object.keys(doc).length);\n   * const keyCounts: number[] = await mappedCursor.toArray(); // cursor.toArray() still returns Document[]\n   * ```\n   * @param transform - The mapping transformation method.\n   */\n  map<T = any>(transform: (doc: TSchema) => T): AbstractCursor<T> {\n    this.throwIfInitialized();\n    const oldTransform = this.transform;\n    if (oldTransform) {\n      this.transform = doc => {\n        return transform(oldTransform(doc));\n      };\n    } else {\n      this.transform = transform;\n    }\n\n    return this as unknown as AbstractCursor<T>;\n  }\n\n  /**\n   * Set the ReadPreference for the cursor.\n   *\n   * @param readPreference - The new read preference for the cursor.\n   */\n  withReadPreference(readPreference: ReadPreferenceLike): this {\n    this.throwIfInitialized();\n    if (readPreference instanceof ReadPreference) {\n      this.cursorOptions.readPreference = readPreference;\n    } else if (typeof readPreference === 'string') {\n      this.cursorOptions.readPreference = ReadPreference.fromString(readPreference);\n    } else {\n      throw new MongoInvalidArgumentError(`Invalid read preference: ${readPreference}`);\n    }\n\n    return this;\n  }\n\n  /**\n   * Set the ReadPreference for the cursor.\n   *\n   * @param readPreference - The new read preference for the cursor.\n   */\n  withReadConcern(readConcern: ReadConcernLike): this {\n    this.throwIfInitialized();\n    const resolvedReadConcern = ReadConcern.fromOptions({ readConcern });\n    if (resolvedReadConcern) {\n      this.cursorOptions.readConcern = resolvedReadConcern;\n    }\n\n    return this;\n  }\n\n  /**\n   * Set a maxTimeMS on the cursor query, allowing for hard timeout limits on queries (Only supported on MongoDB 2.6 or higher)\n   *\n   * @param value - Number of milliseconds to wait before aborting the query.\n   */\n  maxTimeMS(value: number): this {\n    this.throwIfInitialized();\n    if (typeof value !== 'number') {\n      throw new MongoInvalidArgumentError('Argument for maxTimeMS must be a number');\n    }\n\n    this.cursorOptions.maxTimeMS = value;\n    return this;\n  }\n\n  /**\n   * Set the batch size for the cursor.\n   *\n   * @param value - The number of documents to return per batch. See {@link https://www.mongodb.com/docs/manual/reference/command/find/|find command documentation}.\n   */\n  batchSize(value: number): this {\n    this.throwIfInitialized();\n    if (this.cursorOptions.tailable) {\n      throw new MongoTailableCursorError('Tailable cursor does not support batchSize');\n    }\n\n    if (typeof value !== 'number') {\n      throw new MongoInvalidArgumentError('Operation \"batchSize\" requires an integer');\n    }\n\n    this.cursorOptions.batchSize = value;\n    return this;\n  }\n\n  /**\n   * Rewind this cursor to its uninitialized state. Any options that are present on the cursor will\n   * remain in effect. Iterating this cursor will cause new queries to be sent to the server, even\n   * if the resultant data has already been retrieved by this cursor.\n   */\n  rewind(): void {\n    if (this.timeoutContext && this.timeoutContext.owner !== this) {\n      throw new MongoAPIError(`Cannot rewind cursor that does not own its timeout context.`);\n    }\n    if (!this.initialized) {\n      return;\n    }\n\n    this.cursorId = null;\n    this.documents?.clear();\n    this.timeoutContext?.clear();\n    this.timeoutContext = undefined;\n    this.isClosed = false;\n    this.isKilled = false;\n    this.initialized = false;\n    this.hasEmittedClose = false;\n    this.trackCursor();\n\n    // We only want to end this session if we created it, and it hasn't ended yet\n    if (this.cursorSession.explicit === false) {\n      if (!this.cursorSession.hasEnded) {\n        this.cursorSession.endSession().then(undefined, squashError);\n      }\n      this.cursorSession = this.cursorClient.startSession({ owner: this, explicit: false });\n    }\n  }\n\n  /**\n   * Returns a new uninitialized copy of this cursor, with options matching those that have been set on the current instance\n   */\n  abstract clone(): AbstractCursor<TSchema>;\n\n  /** @internal */\n  protected abstract _initialize(\n    session: ClientSession | undefined\n  ): Promise<InitialCursorResponse>;\n\n  /** @internal */\n  async getMore(batchSize: number): Promise<CursorResponse> {\n    if (this.cursorId == null) {\n      throw new MongoRuntimeError(\n        'Unexpected null cursor id. A cursor creating command should have set this'\n      );\n    }\n    if (this.selectedServer == null) {\n      throw new MongoRuntimeError(\n        'Unexpected null selectedServer. A cursor creating command should have set this'\n      );\n    }\n    const getMoreOptions = {\n      ...this.cursorOptions,\n      session: this.cursorSession,\n      batchSize\n    };\n\n    const getMoreOperation = new GetMoreOperation(\n      this.cursorNamespace,\n      this.cursorId,\n      this.selectedServer,\n      getMoreOptions\n    );\n\n    return await executeOperation(this.cursorClient, getMoreOperation, this.timeoutContext);\n  }\n\n  /**\n   * @internal\n   *\n   * This function is exposed for the unified test runner's createChangeStream\n   * operation.  We cannot refactor to use the abstract _initialize method without\n   * a significant refactor.\n   */\n  private async cursorInit(): Promise<void> {\n    if (this.cursorOptions.timeoutMS != null) {\n      this.timeoutContext ??= new CursorTimeoutContext(\n        TimeoutContext.create({\n          serverSelectionTimeoutMS: this.client.s.options.serverSelectionTimeoutMS,\n          timeoutMS: this.cursorOptions.timeoutMS\n        }),\n        this\n      );\n    }\n    try {\n      const state = await this._initialize(this.cursorSession);\n      // Set omitMaxTimeMS to the value needed for subsequent getMore calls\n      this.cursorOptions.omitMaxTimeMS = this.cursorOptions.timeoutMS != null;\n      const response = state.response;\n      this.selectedServer = state.server;\n      this.cursorId = response.id;\n      this.cursorNamespace = response.ns ?? this.namespace;\n      this.documents = response;\n      this.initialized = true; // the cursor is now initialized, even if it is dead\n    } catch (error) {\n      // the cursor is now initialized, even if an error occurred\n      this.initialized = true;\n      await this.cleanup(undefined, error);\n      throw error;\n    }\n\n    if (this.isDead) {\n      await this.cleanup();\n    }\n\n    return;\n  }\n\n  /** @internal Attempt to obtain more documents */\n  private async fetchBatch(): Promise<void> {\n    if (this.isClosed) {\n      return;\n    }\n\n    if (this.isDead) {\n      // if the cursor is dead, we clean it up\n      // cleanupCursor should never throw, but if it does it indicates a bug in the driver\n      // and we should surface the error\n      await this.cleanup();\n      return;\n    }\n\n    if (this.cursorId == null) {\n      await this.cursorInit();\n      // If the cursor died or returned documents, return\n      if ((this.documents?.length ?? 0) !== 0 || this.isDead) return;\n      // Otherwise, run a getMore\n    }\n\n    // otherwise need to call getMore\n    const batchSize = this.cursorOptions.batchSize || 1000;\n\n    try {\n      const response = await this.getMore(batchSize);\n      this.cursorId = response.id;\n      this.documents = response;\n    } catch (error) {\n      try {\n        await this.cleanup(undefined, error);\n      } catch (cleanupError) {\n        // `cleanupCursor` should never throw, squash and throw the original error\n        squashError(cleanupError);\n      }\n      throw error;\n    }\n\n    if (this.isDead) {\n      // If we successfully received a response from a cursor BUT the cursor indicates that it is exhausted,\n      // we intentionally clean up the cursor to release its session back into the pool before the cursor\n      // is iterated.  This prevents a cursor that is exhausted on the server from holding\n      // onto a session indefinitely until the AbstractCursor is iterated.\n      //\n      // cleanupCursorAsync should never throw, but if it does it indicates a bug in the driver\n      // and we should surface the error\n      await this.cleanup();\n    }\n  }\n\n  /** @internal */\n  private async cleanup(timeoutMS?: number, error?: Error) {\n    this.abortListener?.[kDispose]();\n    this.isClosed = true;\n    const timeoutContextForKillCursors = (): CursorTimeoutContext | undefined => {\n      if (timeoutMS != null) {\n        this.timeoutContext?.clear();\n        return new CursorTimeoutContext(\n          TimeoutContext.create({\n            serverSelectionTimeoutMS: this.client.s.options.serverSelectionTimeoutMS,\n            timeoutMS\n          }),\n          this\n        );\n      } else {\n        return this.timeoutContext?.refreshed();\n      }\n    };\n    try {\n      if (\n        !this.isKilled &&\n        this.cursorId &&\n        !this.cursorId.isZero() &&\n        this.cursorNamespace &&\n        this.selectedServer &&\n        !this.cursorSession.hasEnded\n      ) {\n        this.isKilled = true;\n        const cursorId = this.cursorId;\n        this.cursorId = Long.ZERO;\n\n        await executeOperation(\n          this.cursorClient,\n          new KillCursorsOperation(cursorId, this.cursorNamespace, this.selectedServer, {\n            session: this.cursorSession\n          }),\n          timeoutContextForKillCursors()\n        );\n      }\n    } catch (error) {\n      squashError(error);\n    } finally {\n      try {\n        if (this.cursorSession?.owner === this) {\n          await this.cursorSession.endSession({ error });\n        }\n        if (!this.cursorSession?.inTransaction()) {\n          maybeClearPinnedConnection(this.cursorSession, { error });\n        }\n      } finally {\n        this.emitClose();\n      }\n    }\n  }\n\n  /** @internal */\n  private hasEmittedClose = false;\n  /** @internal */\n  private emitClose() {\n    try {\n      if (!this.hasEmittedClose && ((this.documents?.length ?? 0) === 0 || this.isClosed)) {\n        // @ts-expect-error: CursorEvents is generic so Parameters<CursorEvents[\"close\"]> may not be assignable to `[]`. Not sure how to require extenders do not add parameters.\n        this.emit('close');\n      }\n    } finally {\n      this.hasEmittedClose = true;\n    }\n  }\n\n  /** @internal */\n  private async transformDocument(document: NonNullable<TSchema>): Promise<NonNullable<TSchema>> {\n    if (this.transform == null) return document;\n\n    try {\n      const transformedDocument = this.transform(document);\n      // eslint-disable-next-line no-restricted-syntax\n      if (transformedDocument === null) {\n        const TRANSFORM_TO_NULL_ERROR =\n          'Cursor returned a `null` document, but the cursor is not exhausted.  Mapping documents to `null` is not supported in the cursor transform.';\n        throw new MongoAPIError(TRANSFORM_TO_NULL_ERROR);\n      }\n      return transformedDocument;\n    } catch (transformError) {\n      try {\n        await this.close();\n      } catch (closeError) {\n        squashError(closeError);\n      }\n      throw transformError;\n    }\n  }\n\n  /** @internal */\n  protected throwIfInitialized() {\n    if (this.initialized) throw new MongoCursorInUseError();\n  }\n}\n\nclass ReadableCursorStream extends Readable {\n  private _cursor: AbstractCursor;\n  private _readInProgress = false;\n\n  constructor(cursor: AbstractCursor) {\n    super({\n      objectMode: true,\n      autoDestroy: false,\n      highWaterMark: 1\n    });\n    this._cursor = cursor;\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  override _read(size: number): void {\n    if (!this._readInProgress) {\n      this._readInProgress = true;\n      this._readNext();\n    }\n  }\n\n  override _destroy(error: Error | null, callback: (error?: Error | null) => void): void {\n    this._cursor.close().then(\n      () => callback(error),\n      closeError => callback(closeError)\n    );\n  }\n\n  private _readNext() {\n    if (this._cursor.id === Long.ZERO) {\n      this.push(null);\n      return;\n    }\n\n    this._cursor\n      .next()\n      .then(\n        // result from next()\n        result => {\n          if (result == null) {\n            this.push(null);\n          } else if (this.destroyed) {\n            this._cursor.close().then(undefined, squashError);\n          } else {\n            if (this.push(result)) {\n              return this._readNext();\n            }\n\n            this._readInProgress = false;\n          }\n        },\n        // error from next()\n        err => {\n          // NOTE: This is questionable, but we have a test backing the behavior. It seems the\n          //       desired behavior is that a stream ends cleanly when a user explicitly closes\n          //       a client during iteration. Alternatively, we could do the \"right\" thing and\n          //       propagate the error message by removing this special case.\n          if (err.message.match(/server is closed/)) {\n            this._cursor.close().then(undefined, squashError);\n            return this.push(null);\n          }\n\n          // NOTE: This is also perhaps questionable. The rationale here is that these errors tend\n          //       to be \"operation was interrupted\", where a cursor has been closed but there is an\n          //       active getMore in-flight. This used to check if the cursor was killed but once\n          //       that changed to happen in cleanup legitimate errors would not destroy the\n          //       stream. There are change streams test specifically test these cases.\n          if (err.message.match(/operation was interrupted/)) {\n            return this.push(null);\n          }\n\n          // NOTE: The two above checks on the message of the error will cause a null to be pushed\n          //       to the stream, thus closing the stream before the destroy call happens. This means\n          //       that either of those error messages on a change stream will not get a proper\n          //       'error' event to be emitted (the error passed to destroy). Change stream resumability\n          //       relies on that error event to be emitted to create its new cursor and thus was not\n          //       working on 4.4 servers because the error emitted on failover was \"interrupted at\n          //       shutdown\" while on 5.0+ it is \"The server is in quiesce mode and will shut down\".\n          //       See NODE-4475.\n          return this.destroy(err);\n        }\n      )\n      // if either of the above handlers throw\n      .catch(error => {\n        this._readInProgress = false;\n        this.destroy(error);\n      });\n  }\n}\n\nconfigureResourceManagement(AbstractCursor.prototype);\n\n/**\n * @internal\n * The cursor timeout context is a wrapper around a timeout context\n * that keeps track of the \"owner\" of the cursor.  For timeout contexts\n * instantiated inside a cursor, the owner will be the cursor.\n *\n * All timeout behavior is exactly the same as the wrapped timeout context's.\n */\nexport class CursorTimeoutContext extends TimeoutContext {\n  constructor(\n    public timeoutContext: TimeoutContext,\n    public owner: symbol | AbstractCursor\n  ) {\n    super();\n  }\n  override get serverSelectionTimeout(): Timeout | null {\n    return this.timeoutContext.serverSelectionTimeout;\n  }\n  override get connectionCheckoutTimeout(): Timeout | null {\n    return this.timeoutContext.connectionCheckoutTimeout;\n  }\n  override get clearServerSelectionTimeout(): boolean {\n    return this.timeoutContext.clearServerSelectionTimeout;\n  }\n  override get timeoutForSocketWrite(): Timeout | null {\n    return this.timeoutContext.timeoutForSocketWrite;\n  }\n  override get timeoutForSocketRead(): Timeout | null {\n    return this.timeoutContext.timeoutForSocketRead;\n  }\n  override csotEnabled(): this is CSOTTimeoutContext {\n    return this.timeoutContext.csotEnabled();\n  }\n  override refresh(): void {\n    if (typeof this.owner !== 'symbol') return this.timeoutContext.refresh();\n  }\n  override clear(): void {\n    if (typeof this.owner !== 'symbol') return this.timeoutContext.clear();\n  }\n  override get maxTimeMS(): number | null {\n    return this.timeoutContext.maxTimeMS;\n  }\n  get timeoutMS(): number | null {\n    return this.timeoutContext.csotEnabled() ? this.timeoutContext.timeoutMS : null;\n  }\n  override refreshed(): CursorTimeoutContext {\n    return new CursorTimeoutContext(this.timeoutContext.refreshed(), this.owner);\n  }\n  override addMaxTimeMSToCommand(command: Document, options: { omitMaxTimeMS?: boolean }): void {\n    this.timeoutContext.addMaxTimeMSToCommand(command, options);\n  }\n  override getSocketTimeoutMS(): number | undefined {\n    return this.timeoutContext.getSocketTimeoutMS();\n  }\n}\n"],"names":[],"mappings":";;;;;AAAA,MAAA;AAEA,MAAA;AAGA,MAAA;AASA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAEA,MAAA;AACA,MAAA;AACA,MAAA;AA2BA,YAAA,GACa,QAAA,YAAY,GAAG;IAC1B;IACA;IACA;IACA;IACA;IACA;CACQ;AAWV,SAAS;IACP,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,aAAa,CAAC,MAAM,CAAC,IAAI;AACzC;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA6Ba,QAAA,iBAAiB,GAAG,OAAO,MAAM,CAAC;IAC7C,WAAW;IACX,UAAU;;AAiHZ,YAAA,GACA,MAAsB,uBAIZ,cAAA,iBAA+B;IAwCvC,cAAA,GACA,YACE,MAAmB,EACnB,SAA2B,EAC3B,UAA6C,CAAA,CAAE,CAAA;QAE/C,KAAK;QAnCP,cAAA,GACQ,IAAA,CAAA,SAAS,GAA0B;QAo0B3C,cAAA,GACQ,IAAA,CAAA,eAAe,GAAG;QAlyBxB,IAAI,CAAC,EAAE,CAAC,SAAS,QAAA,IAAI;QAErB,IAAI,CAAC,OAAO,CAAC,CAAC,aAAa,EAAE;YAC3B,MAAM,IAAI,QAAA,iBAAiB,CAAC;QAC9B;QACA,IAAI,CAAC,YAAY,GAAG;QACpB,IAAI,CAAC,eAAe,GAAG;QACvB,IAAI,CAAC,QAAQ,GAAG;QAChB,IAAI,CAAC,WAAW,GAAG;QACnB,IAAI,CAAC,QAAQ,GAAG;QAChB,IAAI,CAAC,QAAQ,GAAG;QAChB,IAAI,CAAC,aAAa,GAAG;YACnB,gBACE,QAAQ,cAAc,IAAI,QAAQ,cAAc,YAAY,kBAAA,cAAc,GACtE,QAAQ,cAAc,GACtB,kBAAA,cAAc,CAAC,OAAO;YAC5B,GAAG,CAAA,GAAA,OAAA,yBAAyB,EAAC,QAAQ;YACrC,WAAW,SAAS,gBAAgB,gBAChC,QAAQ,cAAc,CAAC,SAAS,GAChC,QAAQ,SAAS;YACrB,UAAU,QAAQ,QAAQ;YAC1B,WAAW,QAAQ,SAAS;;QAG9B,IAAI,IAAI,CAAC,aAAa,CAAC,SAAS,IAAI,MAAM;YACxC,IAAI,QAAQ,WAAW,IAAI,MAAM;gBAC/B,IAAI,QAAQ,QAAQ,EAAE;oBACpB,IAAI,QAAQ,SAAS,EAAE;wBACrB,IACE,QAAQ,cAAc,IAAI,QAC1B,QAAQ,cAAc,IAAI,IAAI,CAAC,aAAa,CAAC,SAAS,EAEtD,MAAM,IAAI,QAAA,yBAAyB,CACjC;oBAEN;oBAEA,IAAI,CAAC,aAAa,CAAC,WAAW,GAAG,QAAA,iBAAiB,CAAC,SAAS;gBAC9D,OAAO;oBACL,IAAI,CAAC,aAAa,CAAC,WAAW,GAAG,QAAA,iBAAiB,CAAC,QAAQ;gBAC7D;YACF,OAAO;gBACL,IAAI,QAAQ,QAAQ,IAAI,QAAQ,WAAW,KAAK,QAAA,iBAAiB,CAAC,QAAQ,EAAE;oBAC1E,MAAM,IAAI,QAAA,yBAAyB,CACjC;gBAEJ;gBACA,IAAI,CAAC,aAAa,CAAC,WAAW,GAAG,QAAQ,WAAW;YACtD;QACF,OAAO;YACL,IAAI,QAAQ,WAAW,IAAI,MACzB,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACxC;QAEA,0BAA0B;QAC1B,IAAI,CAAC,aAAa,CAAC,aAAa,GAC9B,IAAI,CAAC,aAAa,CAAC,SAAS,IAAI,QAChC,CAAC,AAAC,IAAI,CAAC,aAAa,CAAC,WAAW,KAAK,QAAA,iBAAiB,CAAC,SAAS,IAC9D,CAAC,IAAI,CAAC,aAAa,CAAC,QAAQ,IAC3B,IAAI,CAAC,aAAa,CAAC,QAAQ,IAAI,CAAC,IAAI,CAAC,aAAa,CAAC,SAAS,AAAC;QAElE,MAAM,cAAc,eAAA,WAAW,CAAC,WAAW,CAAC;QAC5C,IAAI,aAAa;YACf,IAAI,CAAC,aAAa,CAAC,WAAW,GAAG;QACnC;QAEA,IAAI,OAAO,QAAQ,SAAS,KAAK,UAAU;YACzC,IAAI,CAAC,aAAa,CAAC,SAAS,GAAG,QAAQ,SAAS;QAClD;QAEA,iEAAiE;QACjE,gDAAgD;QAChD,IAAI,QAAQ,OAAO,KAAK,WAAW;YACjC,IAAI,CAAC,aAAa,CAAC,OAAO,GAAG,QAAQ,OAAO;QAC9C;QAEA,IAAI,OAAO,QAAQ,SAAS,KAAK,UAAU;YACzC,IAAI,CAAC,aAAa,CAAC,SAAS,GAAG,QAAQ,SAAS;QAClD;QAEA,IAAI,OAAO,QAAQ,cAAc,KAAK,UAAU;YAC9C,IAAI,CAAC,aAAa,CAAC,cAAc,GAAG,QAAQ,cAAc;QAC5D;QAEA,IAAI,QAAQ,OAAO,YAAY,WAAA,aAAa,EAAE;YAC5C,IAAI,CAAC,aAAa,GAAG,QAAQ,OAAO;QACtC,OAAO;YACL,IAAI,CAAC,aAAa,GAAG,IAAI,CAAC,YAAY,CAAC,YAAY,CAAC;gBAAE,OAAO,IAAI;gBAAE,UAAU;YAAK;QACpF;QAEA,IAAI,CAAC,sBAAsB,GAAG;YAC5B,GAAG,IAAI,CAAC,aAAa;YACrB,YAAY;gBACV,MAAM,SAAS,yBAAyB,QAAQ,QAAQ;;;QAI5D,IAAI,CAAC,cAAc,GAAG,QAAQ,cAAc;QAC5C,IAAI,CAAC,MAAM,GAAG,QAAQ,MAAM;QAC5B,IAAI,CAAC,aAAa,GAAG,CAAA,GAAA,QAAA,gBAAgB,EACnC,IAAI,CAAC,MAAM,EACX,IAAM,KAAK,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,WAAW,QAAA,WAAW;QAErD,IAAI,CAAC,WAAW;IAClB;IAEA;;;;;;QAOA,IAAI,KAAE;QACJ,OAAO,IAAI,CAAC,QAAQ,IAAI;IAC1B;IAEA,cAAA,GACA,IAAI,SAAM;QACR,OAAO,CAAC,IAAI,CAAC,QAAQ,EAAE,YAAY,KAAK,KAAK,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,QAAQ;IAC7E;IAEA,cAAA,GACA,IAAI,SAAM;QACR,OAAO,IAAI,CAAC,YAAY;IAC1B;IAEA,cAAA,GACA,IAAI,SAAM;QACR,OAAO,IAAI,CAAC,cAAc;IAC5B;IAEA,IAAI,YAAS;QACX,OAAO,IAAI,CAAC,eAAe;IAC7B;IAEA,IAAI,iBAAc;QAChB,OAAO,IAAI,CAAC,aAAa,CAAC,cAAc;IAC1C;IAEA,IAAI,cAAW;QACb,OAAO,IAAI,CAAC,aAAa,CAAC,WAAW;IACvC;IAEA,cAAA,GACA,IAAI,UAAO;QACT,OAAO,IAAI,CAAC,aAAa;IAC3B;IAEA,IAAI,QAAQ,aAA4B,EAAA;QACtC,IAAI,CAAC,aAAa,GAAG;IACvB;IAEA;;QAGA,IAAI,SAAM;QACR,OAAO,IAAI,CAAC,QAAQ,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE,UAAU,CAAC,MAAM;IAC5D;IAEA;;;QAIA,IAAI,SAAM;QACR,OAAO,IAAI,CAAC,QAAQ;IACtB;IAEA,IAAI,eAAY;QACd,OAAO,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC,QAAQ,EAAE;IACvC;IAQA,cAAA,GACA,MAAM,eAAY;QAChB,MAAM,IAAI,CAAC,KAAK;IAClB;IAEA,iFAAA,GACQ,cAAW;QACjB,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,aAAa,CAAC,GAAG,CAAC,IAAI;QAC1C,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,SAAS,QAAQ,CAAC,qBAAqB;YACzD,IAAI,CAAC,IAAI,CAAC,SAAS;QACrB;IACF;IAEA,8CAAA,GACA,gBAAa;QACX,OAAO,IAAI,CAAC,SAAS,EAAE,UAAU;IACnC;IAEA,uCAAA,GACA,sBAAsB,MAAe,EAAA;QACnC,MAAM,eAAuC,EAAE;QAC/C,MAAM,kBAAkB,KAAK,GAAG,CAC9B,UAAU,IAAI,CAAC,SAAS,EAAE,UAAU,GACpC,IAAI,CAAC,SAAS,EAAE,UAAU;QAG5B,IAAK,IAAI,QAAQ,GAAG,QAAQ,iBAAiB,QAAS;YACpD,MAAM,WAAW,IAAI,CAAC,SAAS,EAAE,MAAM,IAAI,CAAC,sBAAsB;YAClE,IAAI,YAAY,MAAM;gBACpB,aAAa,IAAI,CAAC;YACpB;QACF;QAEA,OAAO;IACT;IAEA,OAAO,CAAC,OAAO,aAAa,CAAC,GAAA;QAC3B,IAAI,CAAC,MAAM,EAAE;QAEb,IAAI,IAAI,CAAC,MAAM,EAAE;YACf;QACF;QAEA,IAAI;YACF,MAAO,KAAM;gBACX,IAAI,IAAI,CAAC,QAAQ,EAAE;oBACjB;gBACF;gBAEA,IAAI,IAAI,CAAC,MAAM,EAAE;oBACf;gBACF;gBAEA,IAAI,IAAI,CAAC,QAAQ,IAAI,QAAQ,IAAI,CAAC,MAAM,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE,UAAU,CAAC,MAAM,GAAG;oBAC/E;gBACF;gBAEA,MAAM,WAAW,MAAM,IAAI,CAAC,IAAI;gBAEhC,gDAAgD;gBAChD,IAAI,aAAa,MAAM;oBACrB;gBACF;gBAEA,MAAM;gBAEN,IAAI,CAAC,MAAM,EAAE;YACf;QACF,SAAU;YACR,uFAAuF;YACvF,qEAAqE;YACrE,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE;gBAClB,IAAI;oBACF,MAAM,IAAI,CAAC,KAAK;gBAClB,EAAE,OAAO,OAAO;oBACd,CAAA,GAAA,QAAA,WAAW,EAAC;gBACd;YACF;QACF;IACF;IAEA,OAAO,OAA6B,EAAA;QAClC,MAAM,WAAW,IAAI,qBAAqB,IAAI;QAC9C,MAAM,gBAAgB,CAAA,GAAA,QAAA,gBAAgB,EAAC,IAAI,CAAC,MAAM,EAAE;YAClD,SAAS,OAAO,CAAC,IAAI,CAAC,MAAM;QAC9B;QACA,SAAS,IAAI,CAAC,OAAO;YACnB,eAAe,CAAC,QAAA,QAAQ,CAAC;QAC3B;QAEA,IAAI,SAAS,WAAW;YACtB,MAAM,YAAY,QAAQ,SAAS;YAEnC,MAAM,oBAAoB,SAAS,IAAI,CACrC,IAAI,SAAA,SAAS,CAAC;gBACZ,YAAY;gBACZ,eAAe;gBACf,WAAU,KAAK,EAAE,CAAC,EAAE,QAAQ;oBAC1B,IAAI;wBACF,MAAM,cAAc,UAAU;wBAC9B,SAAS,WAAW;oBACtB,EAAE,OAAO,KAAK;wBACZ,SAAS;oBACX;gBACF;;YAIJ,gEAAgE;YAChE,wBAAwB;YACxB,SAAS,EAAE,CAAC,SAAS,CAAA,MAAO,kBAAkB,IAAI,CAAC,SAAS;YAE5D,OAAO;QACT;QAEA,OAAO;IACT;IAEA,MAAM,UAAO;QACX,IAAI,CAAC,MAAM,EAAE;QAEb,IAAI,IAAI,CAAC,QAAQ,KAAK,OAAA,IAAI,CAAC,IAAI,EAAE;YAC/B,OAAO;QACT;QAEA,IAAI,IAAI,CAAC,aAAa,CAAC,WAAW,KAAK,QAAA,iBAAiB,CAAC,SAAS,IAAI,IAAI,CAAC,QAAQ,IAAI,MAAM;YAC3F,IAAI,CAAC,cAAc,EAAE;QACvB;QACA,IAAI;YACF,GAAG;gBACD,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE,UAAU,CAAC,MAAM,GAAG;oBACvC,OAAO;gBACT;gBACA,MAAM,IAAI,CAAC,UAAU;YACvB,QAAS,CAAC,IAAI,CAAC,MAAM,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE,UAAU,CAAC,MAAM,EAAG;QAChE,SAAU;YACR,IAAI,IAAI,CAAC,aAAa,CAAC,WAAW,KAAK,QAAA,iBAAiB,CAAC,SAAS,EAAE;gBAClE,IAAI,CAAC,cAAc,EAAE;YACvB;QACF;QAEA,OAAO;IACT;IAEA,sGAAA,GACA,MAAM,OAAI;QACR,IAAI,CAAC,MAAM,EAAE;QAEb,IAAI,IAAI,CAAC,QAAQ,KAAK,OAAA,IAAI,CAAC,IAAI,EAAE;YAC/B,MAAM,IAAI,QAAA,yBAAyB;QACrC;QAEA,IAAI,IAAI,CAAC,aAAa,CAAC,WAAW,KAAK,QAAA,iBAAiB,CAAC,SAAS,IAAI,IAAI,CAAC,QAAQ,IAAI,MAAM;YAC3F,IAAI,CAAC,cAAc,EAAE;QACvB;QAEA,IAAI;YACF,GAAG;gBACD,MAAM,MAAM,IAAI,CAAC,SAAS,EAAE,MAAM,IAAI,CAAC,sBAAsB;gBAC7D,IAAI,OAAO,MAAM;oBACf,IAAI,IAAI,CAAC,SAAS,IAAI,MAAM,OAAO,MAAM,IAAI,CAAC,iBAAiB,CAAC;oBAChE,OAAO;gBACT;gBACA,MAAM,IAAI,CAAC,UAAU;YACvB,QAAS,CAAC,IAAI,CAAC,MAAM,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE,UAAU,CAAC,MAAM,EAAG;QAChE,SAAU;YACR,IAAI,IAAI,CAAC,aAAa,CAAC,WAAW,KAAK,QAAA,iBAAiB,CAAC,SAAS,EAAE;gBAClE,IAAI,CAAC,cAAc,EAAE;YACvB;QACF;QAEA,OAAO;IACT;IAEA;;QAGA,MAAM,UAAO;QACX,IAAI,CAAC,MAAM,EAAE;QAEb,IAAI,IAAI,CAAC,QAAQ,KAAK,OAAA,IAAI,CAAC,IAAI,EAAE;YAC/B,MAAM,IAAI,QAAA,yBAAyB;QACrC;QAEA,IAAI,IAAI,CAAC,aAAa,CAAC,WAAW,KAAK,QAAA,iBAAiB,CAAC,SAAS,IAAI,IAAI,CAAC,QAAQ,IAAI,MAAM;YAC3F,IAAI,CAAC,cAAc,EAAE;QACvB;QACA,IAAI;YACF,IAAI,MAAM,IAAI,CAAC,SAAS,EAAE,MAAM,IAAI,CAAC,sBAAsB;YAC3D,IAAI,OAAO,MAAM;gBACf,IAAI,IAAI,CAAC,SAAS,IAAI,MAAM,OAAO,MAAM,IAAI,CAAC,iBAAiB,CAAC;gBAChE,OAAO;YACT;YAEA,MAAM,IAAI,CAAC,UAAU;YAErB,MAAM,IAAI,CAAC,SAAS,EAAE,MAAM,IAAI,CAAC,sBAAsB;YACvD,IAAI,OAAO,MAAM;gBACf,IAAI,IAAI,CAAC,SAAS,IAAI,MAAM,OAAO,MAAM,IAAI,CAAC,iBAAiB,CAAC;gBAChE,OAAO;YACT;QACF,SAAU;YACR,IAAI,IAAI,CAAC,aAAa,CAAC,WAAW,KAAK,QAAA,iBAAiB,CAAC,SAAS,EAAE;gBAClE,IAAI,CAAC,cAAc,EAAE;YACvB;QACF;QAEA,OAAO;IACT;IAEA;;;;;;;QAQA,MAAM,QAAQ,QAA0C,EAAA;QACtD,IAAI,CAAC,MAAM,EAAE;QAEb,IAAI,OAAO,aAAa,YAAY;YAClC,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QACA,WAAW,MAAM,YAAY,IAAI,CAAE;YACjC,MAAM,SAAS,SAAS;YACxB,IAAI,WAAW,OAAO;gBACpB;YACF;QACF;IACF;IAEA;;QAGA,MAAM,MAAM,OAAgC,EAAA;QAC1C,MAAM,IAAI,CAAC,OAAO,CAAC,SAAS;IAC9B;IAEA;;;;;QAMA,MAAM,UAAO;QACX,IAAI,CAAC,MAAM,EAAE;QAEb,MAAM,QAAmB,EAAE;QAC3B,0FAA0F;QAC1F,sDAAsD;QACtD,WAAW,MAAM,YAAY,IAAI,CAAE;YACjC,MAAM,IAAI,CAAC;YACX,MAAM,OAAO,IAAI,CAAC,qBAAqB;YACvC,IAAI,IAAI,CAAC,SAAS,IAAI,MAAM;gBAC1B,KAAK,MAAM,OAAO,KAAM;oBACtB,MAAM,IAAI,CAAC,MAAM,IAAI,CAAC,iBAAiB,CAAC;gBAC1C;YACF,OAAO;gBACL,MAAM,IAAI,IAAI;YAChB;QACF;QACA,OAAO;IACT;IACA;;;;;QAMA,cAAc,IAAgB,EAAE,KAAc,EAAA;QAC5C,IAAI,CAAC,kBAAkB;QACvB,IAAI,CAAC,QAAA,YAAY,CAAC,QAAQ,CAAC,OAAO;YAChC,MAAM,IAAI,QAAA,yBAAyB,CAAC,CAAA,KAAA,EAAQ,KAAI,eAAA,EAAkB,QAAA,YAAY,CAAA,CAAE;QAClF;QAEA,IAAI,OAAO,UAAU,WAAW;YAC9B,MAAM,IAAI,QAAA,yBAAyB,CAAC,CAAA,KAAA,EAAQ,KAAI,wBAAA,CAA0B;QAC5E;QAEA,IAAI,CAAC,aAAa,CAAC,KAAK,GAAG;QAC3B,OAAO,IAAI;IACb;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;QA0CA,IAAa,SAA8B,EAAA;QACzC,IAAI,CAAC,kBAAkB;QACvB,MAAM,eAAe,IAAI,CAAC,SAAS;QACnC,IAAI,cAAc;YAChB,IAAI,CAAC,SAAS,GAAG,CAAA;gBACf,OAAO,UAAU,aAAa;YAChC;QACF,OAAO;YACL,IAAI,CAAC,SAAS,GAAG;QACnB;QAEA,OAAO,IAAoC;IAC7C;IAEA;;;;QAKA,mBAAmB,cAAkC,EAAA;QACnD,IAAI,CAAC,kBAAkB;QACvB,IAAI,0BAA0B,kBAAA,cAAc,EAAE;YAC5C,IAAI,CAAC,aAAa,CAAC,cAAc,GAAG;QACtC,OAAO,IAAI,OAAO,mBAAmB,UAAU;YAC7C,IAAI,CAAC,aAAa,CAAC,cAAc,GAAG,kBAAA,cAAc,CAAC,UAAU,CAAC;QAChE,OAAO;YACL,MAAM,IAAI,QAAA,yBAAyB,CAAC,CAAA,yBAAA,EAA4B,eAAc,CAAE;QAClF;QAEA,OAAO,IAAI;IACb;IAEA;;;;QAKA,gBAAgB,WAA4B,EAAA;QAC1C,IAAI,CAAC,kBAAkB;QACvB,MAAM,sBAAsB,eAAA,WAAW,CAAC,WAAW,CAAC;YAAE;QAAW;QACjE,IAAI,qBAAqB;YACvB,IAAI,CAAC,aAAa,CAAC,WAAW,GAAG;QACnC;QAEA,OAAO,IAAI;IACb;IAEA;;;;QAKA,UAAU,KAAa,EAAA;QACrB,IAAI,CAAC,kBAAkB;QACvB,IAAI,OAAO,UAAU,UAAU;YAC7B,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,IAAI,CAAC,aAAa,CAAC,SAAS,GAAG;QAC/B,OAAO,IAAI;IACb;IAEA;;;;QAKA,UAAU,KAAa,EAAA;QACrB,IAAI,CAAC,kBAAkB;QACvB,IAAI,IAAI,CAAC,aAAa,CAAC,QAAQ,EAAE;YAC/B,MAAM,IAAI,QAAA,wBAAwB,CAAC;QACrC;QAEA,IAAI,OAAO,UAAU,UAAU;YAC7B,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,IAAI,CAAC,aAAa,CAAC,SAAS,GAAG;QAC/B,OAAO,IAAI;IACb;IAEA;;;;QAKA,SAAM;QACJ,IAAI,IAAI,CAAC,cAAc,IAAI,IAAI,CAAC,cAAc,CAAC,KAAK,KAAK,IAAI,EAAE;YAC7D,MAAM,IAAI,QAAA,aAAa,CAAC,CAAA,2DAAA,CAA6D;QACvF;QACA,IAAI,CAAC,IAAI,CAAC,WAAW,EAAE;YACrB;QACF;QAEA,IAAI,CAAC,QAAQ,GAAG;QAChB,IAAI,CAAC,SAAS,EAAE;QAChB,IAAI,CAAC,cAAc,EAAE;QACrB,IAAI,CAAC,cAAc,GAAG;QACtB,IAAI,CAAC,QAAQ,GAAG;QAChB,IAAI,CAAC,QAAQ,GAAG;QAChB,IAAI,CAAC,WAAW,GAAG;QACnB,IAAI,CAAC,eAAe,GAAG;QACvB,IAAI,CAAC,WAAW;QAEhB,6EAA6E;QAC7E,IAAI,IAAI,CAAC,aAAa,CAAC,QAAQ,KAAK,OAAO;YACzC,IAAI,CAAC,IAAI,CAAC,aAAa,CAAC,QAAQ,EAAE;gBAChC,IAAI,CAAC,aAAa,CAAC,UAAU,GAAG,IAAI,CAAC,WAAW,QAAA,WAAW;YAC7D;YACA,IAAI,CAAC,aAAa,GAAG,IAAI,CAAC,YAAY,CAAC,YAAY,CAAC;gBAAE,OAAO,IAAI;gBAAE,UAAU;YAAK;QACpF;IACF;IAYA,cAAA,GACA,MAAM,QAAQ,SAAiB,EAAA;QAC7B,IAAI,IAAI,CAAC,QAAQ,IAAI,MAAM;YACzB,MAAM,IAAI,QAAA,iBAAiB,CACzB;QAEJ;QACA,IAAI,IAAI,CAAC,cAAc,IAAI,MAAM;YAC/B,MAAM,IAAI,QAAA,iBAAiB,CACzB;QAEJ;QACA,MAAM,iBAAiB;YACrB,GAAG,IAAI,CAAC,aAAa;YACrB,SAAS,IAAI,CAAC,aAAa;YAC3B;;QAGF,MAAM,mBAAmB,IAAI,WAAA,gBAAgB,CAC3C,IAAI,CAAC,eAAe,EACpB,IAAI,CAAC,QAAQ,EACb,IAAI,CAAC,cAAc,EACnB;QAGF,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAAC,IAAI,CAAC,YAAY,EAAE,kBAAkB,IAAI,CAAC,cAAc;IACxF;IAEA;;;;;;QAOQ,MAAM,aAAU;QACtB,IAAI,IAAI,CAAC,aAAa,CAAC,SAAS,IAAI,MAAM;YACxC,IAAI,CAAC,cAAc,KAAK,IAAI,qBAC1B,UAAA,cAAc,CAAC,MAAM,CAAC;gBACpB,0BAA0B,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,OAAO,CAAC,wBAAwB;gBACxE,WAAW,IAAI,CAAC,aAAa,CAAC,SAAS;gBAEzC,IAAI;QAER;QACA,IAAI;YACF,MAAM,QAAQ,MAAM,IAAI,CAAC,WAAW,CAAC,IAAI,CAAC,aAAa;YACvD,qEAAqE;YACrE,IAAI,CAAC,aAAa,CAAC,aAAa,GAAG,IAAI,CAAC,aAAa,CAAC,SAAS,IAAI;YACnE,MAAM,WAAW,MAAM,QAAQ;YAC/B,IAAI,CAAC,cAAc,GAAG,MAAM,MAAM;YAClC,IAAI,CAAC,QAAQ,GAAG,SAAS,EAAE;YAC3B,IAAI,CAAC,eAAe,GAAG,SAAS,EAAE,IAAI,IAAI,CAAC,SAAS;YACpD,IAAI,CAAC,SAAS,GAAG;YACjB,IAAI,CAAC,WAAW,GAAG,MAAM,oDAAoD;QAC/E,EAAE,OAAO,OAAO;YACd,2DAA2D;YAC3D,IAAI,CAAC,WAAW,GAAG;YACnB,MAAM,IAAI,CAAC,OAAO,CAAC,WAAW;YAC9B,MAAM;QACR;QAEA,IAAI,IAAI,CAAC,MAAM,EAAE;YACf,MAAM,IAAI,CAAC,OAAO;QACpB;QAEA;IACF;IAEA,+CAAA,GACQ,MAAM,aAAU;QACtB,IAAI,IAAI,CAAC,QAAQ,EAAE;YACjB;QACF;QAEA,IAAI,IAAI,CAAC,MAAM,EAAE;YACf,wCAAwC;YACxC,oFAAoF;YACpF,kCAAkC;YAClC,MAAM,IAAI,CAAC,OAAO;YAClB;QACF;QAEA,IAAI,IAAI,CAAC,QAAQ,IAAI,MAAM;YACzB,MAAM,IAAI,CAAC,UAAU;YACrB,mDAAmD;YACnD,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE,UAAU,CAAC,MAAM,KAAK,IAAI,CAAC,MAAM,EAAE;QACxD,2BAA2B;QAC7B;QAEA,iCAAiC;QACjC,MAAM,YAAY,IAAI,CAAC,aAAa,CAAC,SAAS,IAAI;QAElD,IAAI;YACF,MAAM,WAAW,MAAM,IAAI,CAAC,OAAO,CAAC;YACpC,IAAI,CAAC,QAAQ,GAAG,SAAS,EAAE;YAC3B,IAAI,CAAC,SAAS,GAAG;QACnB,EAAE,OAAO,OAAO;YACd,IAAI;gBACF,MAAM,IAAI,CAAC,OAAO,CAAC,WAAW;YAChC,EAAE,OAAO,cAAc;gBACrB,0EAA0E;gBAC1E,CAAA,GAAA,QAAA,WAAW,EAAC;YACd;YACA,MAAM;QACR;QAEA,IAAI,IAAI,CAAC,MAAM,EAAE;YACf,sGAAsG;YACtG,mGAAmG;YACnG,oFAAoF;YACpF,oEAAoE;YACpE,EAAE;YACF,yFAAyF;YACzF,kCAAkC;YAClC,MAAM,IAAI,CAAC,OAAO;QACpB;IACF;IAEA,cAAA,GACQ,MAAM,QAAQ,SAAkB,EAAE,KAAa,EAAA;QACrD,IAAI,CAAC,aAAa,EAAE,CAAC,QAAA,QAAQ,CAAC;QAC9B,IAAI,CAAC,QAAQ,GAAG;QAChB,MAAM,+BAA+B;YACnC,IAAI,aAAa,MAAM;gBACrB,IAAI,CAAC,cAAc,EAAE;gBACrB,OAAO,IAAI,qBACT,UAAA,cAAc,CAAC,MAAM,CAAC;oBACpB,0BAA0B,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,OAAO,CAAC,wBAAwB;oBACxE;oBAEF,IAAI;YAER,OAAO;gBACL,OAAO,IAAI,CAAC,cAAc,EAAE;YAC9B;QACF;QACA,IAAI;YACF,IACE,CAAC,IAAI,CAAC,QAAQ,IACd,IAAI,CAAC,QAAQ,IACb,CAAC,IAAI,CAAC,QAAQ,CAAC,MAAM,MACrB,IAAI,CAAC,eAAe,IACpB,IAAI,CAAC,cAAc,IACnB,CAAC,IAAI,CAAC,aAAa,CAAC,QAAQ,EAC5B;gBACA,IAAI,CAAC,QAAQ,GAAG;gBAChB,MAAM,WAAW,IAAI,CAAC,QAAQ;gBAC9B,IAAI,CAAC,QAAQ,GAAG,OAAA,IAAI,CAAC,IAAI;gBAEzB,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EACpB,IAAI,CAAC,YAAY,EACjB,IAAI,eAAA,oBAAoB,CAAC,UAAU,IAAI,CAAC,eAAe,EAAE,IAAI,CAAC,cAAc,EAAE;oBAC5E,SAAS,IAAI,CAAC,aAAa;oBAE7B;YAEJ;QACF,EAAE,OAAO,OAAO;YACd,CAAA,GAAA,QAAA,WAAW,EAAC;QACd,SAAU;YACR,IAAI;gBACF,IAAI,IAAI,CAAC,aAAa,EAAE,UAAU,IAAI,EAAE;oBACtC,MAAM,IAAI,CAAC,aAAa,CAAC,UAAU,CAAC;wBAAE;oBAAK;gBAC7C;gBACA,IAAI,CAAC,IAAI,CAAC,aAAa,EAAE,iBAAiB;oBACxC,CAAA,GAAA,WAAA,0BAA0B,EAAC,IAAI,CAAC,aAAa,EAAE;wBAAE;oBAAK;gBACxD;YACF,SAAU;gBACR,IAAI,CAAC,SAAS;YAChB;QACF;IACF;IAIA,cAAA,GACQ,YAAS;QACf,IAAI;YACF,IAAI,CAAC,IAAI,CAAC,eAAe,IAAI,CAAC,CAAC,IAAI,CAAC,SAAS,EAAE,UAAU,CAAC,MAAM,KAAK,IAAI,CAAC,QAAQ,GAAG;gBACnF,yKAAyK;gBACzK,IAAI,CAAC,IAAI,CAAC;YACZ;QACF,SAAU;YACR,IAAI,CAAC,eAAe,GAAG;QACzB;IACF;IAEA,cAAA,GACQ,MAAM,kBAAkB,QAA8B,EAAA;QAC5D,IAAI,IAAI,CAAC,SAAS,IAAI,MAAM,OAAO;QAEnC,IAAI;YACF,MAAM,sBAAsB,IAAI,CAAC,SAAS,CAAC;YAC3C,gDAAgD;YAChD,IAAI,wBAAwB,MAAM;gBAChC,MAAM,0BACJ;gBACF,MAAM,IAAI,QAAA,aAAa,CAAC;YAC1B;YACA,OAAO;QACT,EAAE,OAAO,gBAAgB;YACvB,IAAI;gBACF,MAAM,IAAI,CAAC,KAAK;YAClB,EAAE,OAAO,YAAY;gBACnB,CAAA,GAAA,QAAA,WAAW,EAAC;YACd;YACA,MAAM;QACR;IACF;IAEA,cAAA,GACU,qBAAkB;QAC1B,IAAI,IAAI,CAAC,WAAW,EAAE,MAAM,IAAI,QAAA,qBAAqB;IACvD;;AA53BF,QAAA,cAAA,GAAA;AAoCE,WAAA,GACgB,eAAA,KAAK,GAAG;AA01B1B,MAAM,6BAA6B,SAAA,QAAQ;IAIzC,YAAY,MAAsB,CAAA;QAChC,KAAK,CAAC;YACJ,YAAY;YACZ,aAAa;YACb,eAAe;;QANX,IAAA,CAAA,eAAe,GAAG;QAQxB,IAAI,CAAC,OAAO,GAAG;IACjB;IAEA,6DAA6D;IACpD,MAAM,IAAY,EAAA;QACzB,IAAI,CAAC,IAAI,CAAC,eAAe,EAAE;YACzB,IAAI,CAAC,eAAe,GAAG;YACvB,IAAI,CAAC,SAAS;QAChB;IACF;IAES,SAAS,KAAmB,EAAE,QAAwC,EAAA;QAC7E,IAAI,CAAC,OAAO,CAAC,KAAK,GAAG,IAAI,CACvB,IAAM,SAAS,QACf,CAAA,aAAc,SAAS;IAE3B;IAEQ,YAAS;QACf,IAAI,IAAI,CAAC,OAAO,CAAC,EAAE,KAAK,OAAA,IAAI,CAAC,IAAI,EAAE;YACjC,IAAI,CAAC,IAAI,CAAC;YACV;QACF;QAEA,IAAI,CAAC,OAAO,CACT,IAAI,GACJ,IAAI,CACH,qBAAqB;QACrB,CAAA;YACE,IAAI,UAAU,MAAM;gBAClB,IAAI,CAAC,IAAI,CAAC;YACZ,OAAO,IAAI,IAAI,CAAC,SAAS,EAAE;gBACzB,IAAI,CAAC,OAAO,CAAC,KAAK,GAAG,IAAI,CAAC,WAAW,QAAA,WAAW;YAClD,OAAO;gBACL,IAAI,IAAI,CAAC,IAAI,CAAC,SAAS;oBACrB,OAAO,IAAI,CAAC,SAAS;gBACvB;gBAEA,IAAI,CAAC,eAAe,GAAG;YACzB;QACF,GACA,oBAAoB;QACpB,CAAA;YACE,oFAAoF;YACpF,qFAAqF;YACrF,oFAAoF;YACpF,mEAAmE;YACnE,IAAI,IAAI,OAAO,CAAC,KAAK,CAAC,qBAAqB;gBACzC,IAAI,CAAC,OAAO,CAAC,KAAK,GAAG,IAAI,CAAC,WAAW,QAAA,WAAW;gBAChD,OAAO,IAAI,CAAC,IAAI,CAAC;YACnB;YAEA,wFAAwF;YACxF,0FAA0F;YAC1F,uFAAuF;YACvF,kFAAkF;YAClF,6EAA6E;YAC7E,IAAI,IAAI,OAAO,CAAC,KAAK,CAAC,8BAA8B;gBAClD,OAAO,IAAI,CAAC,IAAI,CAAC;YACnB;YAEA,wFAAwF;YACxF,2FAA2F;YAC3F,qFAAqF;YACrF,8FAA8F;YAC9F,2FAA2F;YAC3F,yFAAyF;YACzF,0FAA0F;YAC1F,uBAAuB;YACvB,OAAO,IAAI,CAAC,OAAO,CAAC;QACtB,EAEF,wCAAwC;SACvC,KAAK,CAAC,CAAA;YACL,IAAI,CAAC,eAAe,GAAG;YACvB,IAAI,CAAC,OAAO,CAAC;QACf;IACJ;;AAGF,CAAA,GAAA,sBAAA,2BAA2B,EAAC,eAAe,SAAS;AAEpD;;;;;;;IAQA,MAAa,6BAA6B,UAAA,cAAc;IACtD,YACS,cAA8B,EAC9B,KAA8B,CAAA;QAErC,KAAK;QAHE,IAAA,CAAA,cAAc,GAAd;QACA,IAAA,CAAA,KAAK,GAAL;IAGT;IACA,IAAa,yBAAsB;QACjC,OAAO,IAAI,CAAC,cAAc,CAAC,sBAAsB;IACnD;IACA,IAAa,4BAAyB;QACpC,OAAO,IAAI,CAAC,cAAc,CAAC,yBAAyB;IACtD;IACA,IAAa,8BAA2B;QACtC,OAAO,IAAI,CAAC,cAAc,CAAC,2BAA2B;IACxD;IACA,IAAa,wBAAqB;QAChC,OAAO,IAAI,CAAC,cAAc,CAAC,qBAAqB;IAClD;IACA,IAAa,uBAAoB;QAC/B,OAAO,IAAI,CAAC,cAAc,CAAC,oBAAoB;IACjD;IACS,cAAW;QAClB,OAAO,IAAI,CAAC,cAAc,CAAC,WAAW;IACxC;IACS,UAAO;QACd,IAAI,OAAO,IAAI,CAAC,KAAK,KAAK,UAAU,OAAO,IAAI,CAAC,cAAc,CAAC,OAAO;IACxE;IACS,QAAK;QACZ,IAAI,OAAO,IAAI,CAAC,KAAK,KAAK,UAAU,OAAO,IAAI,CAAC,cAAc,CAAC,KAAK;IACtE;IACA,IAAa,YAAS;QACpB,OAAO,IAAI,CAAC,cAAc,CAAC,SAAS;IACtC;IACA,IAAI,YAAS;QACX,OAAO,IAAI,CAAC,cAAc,CAAC,WAAW,KAAK,IAAI,CAAC,cAAc,CAAC,SAAS,GAAG;IAC7E;IACS,YAAS;QAChB,OAAO,IAAI,qBAAqB,IAAI,CAAC,cAAc,CAAC,SAAS,IAAI,IAAI,CAAC,KAAK;IAC7E;IACS,sBAAsB,OAAiB,EAAE,OAAoC,EAAA;QACpF,IAAI,CAAC,cAAc,CAAC,qBAAqB,CAAC,SAAS;IACrD;IACS,qBAAkB;QACzB,OAAO,IAAI,CAAC,cAAc,CAAC,kBAAkB;IAC/C;;AA7CF,QAAA,oBAAA,GAAA"}},
    {"offset": {"line": 6950, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6954, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/collection.ts"],"sourcesContent":["import { type BSONSerializeOptions, type Document, resolveBSONOptions } from './bson';\nimport type { AnyBulkWriteOperation, BulkWriteOptions, BulkWriteResult } from './bulk/common';\nimport { OrderedBulkOperation } from './bulk/ordered';\nimport { UnorderedBulkOperation } from './bulk/unordered';\nimport { ChangeStream, type ChangeStreamDocument, type ChangeStreamOptions } from './change_stream';\nimport { AggregationCursor } from './cursor/aggregation_cursor';\nimport { FindCursor } from './cursor/find_cursor';\nimport { ListIndexesCursor } from './cursor/list_indexes_cursor';\nimport {\n  ListSearchIndexesCursor,\n  type ListSearchIndexesOptions\n} from './cursor/list_search_indexes_cursor';\nimport type { Db } from './db';\nimport { MongoInvalidArgumentError, MongoOperationTimeoutError } from './error';\nimport type { MongoClient, PkFactory } from './mongo_client';\nimport type {\n  Abortable,\n  Filter,\n  Flatten,\n  OptionalUnlessRequiredId,\n  TODO_NODE_3286,\n  UpdateFilter,\n  WithId,\n  WithoutId\n} from './mongo_types';\nimport type { AggregateOptions } from './operations/aggregate';\nimport { BulkWriteOperation } from './operations/bulk_write';\nimport { CountOperation, type CountOptions } from './operations/count';\nimport {\n  DeleteManyOperation,\n  DeleteOneOperation,\n  type DeleteOptions,\n  type DeleteResult\n} from './operations/delete';\nimport { DistinctOperation, type DistinctOptions } from './operations/distinct';\nimport { DropCollectionOperation, type DropCollectionOptions } from './operations/drop';\nimport {\n  EstimatedDocumentCountOperation,\n  type EstimatedDocumentCountOptions\n} from './operations/estimated_document_count';\nimport { executeOperation } from './operations/execute_operation';\nimport type { FindOptions } from './operations/find';\nimport {\n  FindOneAndDeleteOperation,\n  type FindOneAndDeleteOptions,\n  FindOneAndReplaceOperation,\n  type FindOneAndReplaceOptions,\n  FindOneAndUpdateOperation,\n  type FindOneAndUpdateOptions\n} from './operations/find_and_modify';\nimport {\n  CreateIndexesOperation,\n  type CreateIndexesOptions,\n  type DropIndexesOptions,\n  DropIndexOperation,\n  type IndexDescription,\n  type IndexDescriptionCompact,\n  type IndexDescriptionInfo,\n  type IndexInformationOptions,\n  type IndexSpecification,\n  type ListIndexesOptions\n} from './operations/indexes';\nimport {\n  InsertManyOperation,\n  type InsertManyResult,\n  InsertOneOperation,\n  type InsertOneOptions,\n  type InsertOneResult\n} from './operations/insert';\nimport { IsCappedOperation } from './operations/is_capped';\nimport type { Hint, OperationOptions } from './operations/operation';\nimport { OptionsOperation } from './operations/options_operation';\nimport { RenameOperation, type RenameOptions } from './operations/rename';\nimport {\n  CreateSearchIndexesOperation,\n  type SearchIndexDescription\n} from './operations/search_indexes/create';\nimport { DropSearchIndexOperation } from './operations/search_indexes/drop';\nimport { UpdateSearchIndexOperation } from './operations/search_indexes/update';\nimport {\n  ReplaceOneOperation,\n  type ReplaceOptions,\n  UpdateManyOperation,\n  UpdateOneOperation,\n  type UpdateOptions,\n  type UpdateResult\n} from './operations/update';\nimport { ReadConcern, type ReadConcernLike } from './read_concern';\nimport { ReadPreference, type ReadPreferenceLike } from './read_preference';\nimport { type Sort } from './sort';\nimport {\n  DEFAULT_PK_FACTORY,\n  MongoDBCollectionNamespace,\n  normalizeHintField,\n  resolveOptions\n} from './utils';\nimport { WriteConcern, type WriteConcernOptions } from './write_concern';\n\n/** @public */\nexport interface ModifyResult<TSchema = Document> {\n  value: WithId<TSchema> | null;\n  lastErrorObject?: Document;\n  ok: 0 | 1;\n}\n\n/** @public */\nexport interface CountDocumentsOptions extends AggregateOptions {\n  /** The number of documents to skip. */\n  skip?: number;\n  /** The maximum amount of documents to consider. */\n  limit?: number;\n}\n\n/** @public */\nexport interface CollectionOptions extends BSONSerializeOptions, WriteConcernOptions {\n  /** Specify a read concern for the collection. (only MongoDB 3.2 or higher supported) */\n  readConcern?: ReadConcernLike;\n  /** The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST). */\n  readPreference?: ReadPreferenceLike;\n  /**\n   * @experimental\n   * Specifies the time an operation will run until it throws a timeout error\n   */\n  timeoutMS?: number;\n}\n\n/** @internal */\nexport interface CollectionPrivate {\n  pkFactory: PkFactory;\n  db: Db;\n  options: any;\n  namespace: MongoDBCollectionNamespace;\n  readPreference?: ReadPreference;\n  bsonOptions: BSONSerializeOptions;\n  collectionHint?: Hint;\n  readConcern?: ReadConcern;\n  writeConcern?: WriteConcern;\n}\n\n/**\n * The **Collection** class is an internal class that embodies a MongoDB collection\n * allowing for insert/find/update/delete and other command operation on that MongoDB collection.\n *\n * **COLLECTION Cannot directly be instantiated**\n * @public\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * interface Pet {\n *   name: string;\n *   kind: 'dog' | 'cat' | 'fish';\n * }\n *\n * const client = new MongoClient('mongodb://localhost:27017');\n * const pets = client.db().collection<Pet>('pets');\n *\n * const petCursor = pets.find();\n *\n * for await (const pet of petCursor) {\n *   console.log(`${pet.name} is a ${pet.kind}!`);\n * }\n * ```\n */\nexport class Collection<TSchema extends Document = Document> {\n  /** @internal */\n  s: CollectionPrivate;\n\n  /** @internal */\n  client: MongoClient;\n\n  /**\n   * Create a new Collection instance\n   * @internal\n   */\n  constructor(db: Db, name: string, options?: CollectionOptions) {\n    // Internal state\n    this.s = {\n      db,\n      options,\n      namespace: new MongoDBCollectionNamespace(db.databaseName, name),\n      pkFactory: db.options?.pkFactory ?? DEFAULT_PK_FACTORY,\n      readPreference: ReadPreference.fromOptions(options),\n      bsonOptions: resolveBSONOptions(options, db),\n      readConcern: ReadConcern.fromOptions(options),\n      writeConcern: WriteConcern.fromOptions(options)\n    };\n\n    this.client = db.client;\n  }\n\n  /**\n   * The name of the database this collection belongs to\n   */\n  get dbName(): string {\n    return this.s.namespace.db;\n  }\n\n  /**\n   * The name of this collection\n   */\n  get collectionName(): string {\n    return this.s.namespace.collection;\n  }\n\n  /**\n   * The namespace of this collection, in the format `${this.dbName}.${this.collectionName}`\n   */\n  get namespace(): string {\n    return this.fullNamespace.toString();\n  }\n\n  /**\n   *  @internal\n   *\n   * The `MongoDBNamespace` for the collection.\n   */\n  get fullNamespace(): MongoDBCollectionNamespace {\n    return this.s.namespace;\n  }\n\n  /**\n   * The current readConcern of the collection. If not explicitly defined for\n   * this collection, will be inherited from the parent DB\n   */\n  get readConcern(): ReadConcern | undefined {\n    if (this.s.readConcern == null) {\n      return this.s.db.readConcern;\n    }\n    return this.s.readConcern;\n  }\n\n  /**\n   * The current readPreference of the collection. If not explicitly defined for\n   * this collection, will be inherited from the parent DB\n   */\n  get readPreference(): ReadPreference | undefined {\n    if (this.s.readPreference == null) {\n      return this.s.db.readPreference;\n    }\n\n    return this.s.readPreference;\n  }\n\n  get bsonOptions(): BSONSerializeOptions {\n    return this.s.bsonOptions;\n  }\n\n  /**\n   * The current writeConcern of the collection. If not explicitly defined for\n   * this collection, will be inherited from the parent DB\n   */\n  get writeConcern(): WriteConcern | undefined {\n    if (this.s.writeConcern == null) {\n      return this.s.db.writeConcern;\n    }\n    return this.s.writeConcern;\n  }\n\n  /** The current index hint for the collection */\n  get hint(): Hint | undefined {\n    return this.s.collectionHint;\n  }\n\n  set hint(v: Hint | undefined) {\n    this.s.collectionHint = normalizeHintField(v);\n  }\n\n  public get timeoutMS(): number | undefined {\n    return this.s.options.timeoutMS;\n  }\n\n  /**\n   * Inserts a single document into MongoDB. If documents passed in do not contain the **_id** field,\n   * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n   * can be overridden by setting the **forceServerObjectId** flag.\n   *\n   * @param doc - The document to insert\n   * @param options - Optional settings for the command\n   */\n  async insertOne(\n    doc: OptionalUnlessRequiredId<TSchema>,\n    options?: InsertOneOptions\n  ): Promise<InsertOneResult<TSchema>> {\n    return await executeOperation(\n      this.client,\n      new InsertOneOperation(\n        this as TODO_NODE_3286,\n        doc,\n        resolveOptions(this, options)\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Inserts an array of documents into MongoDB. If documents passed in do not contain the **_id** field,\n   * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n   * can be overridden by setting the **forceServerObjectId** flag.\n   *\n   * @param docs - The documents to insert\n   * @param options - Optional settings for the command\n   */\n  async insertMany(\n    docs: ReadonlyArray<OptionalUnlessRequiredId<TSchema>>,\n    options?: BulkWriteOptions\n  ): Promise<InsertManyResult<TSchema>> {\n    return await executeOperation(\n      this.client,\n      new InsertManyOperation(\n        this as TODO_NODE_3286,\n        docs,\n        resolveOptions(this, options ?? { ordered: true })\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Perform a bulkWrite operation without a fluent API\n   *\n   * Legal operation types are\n   * - `insertOne`\n   * - `replaceOne`\n   * - `updateOne`\n   * - `updateMany`\n   * - `deleteOne`\n   * - `deleteMany`\n   *\n   * If documents passed in do not contain the **_id** field,\n   * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n   * can be overridden by setting the **forceServerObjectId** flag.\n   *\n   * @param operations - Bulk operations to perform\n   * @param options - Optional settings for the command\n   * @throws MongoDriverError if operations is not an array\n   */\n  async bulkWrite(\n    operations: ReadonlyArray<AnyBulkWriteOperation<TSchema>>,\n    options?: BulkWriteOptions\n  ): Promise<BulkWriteResult> {\n    if (!Array.isArray(operations)) {\n      throw new MongoInvalidArgumentError('Argument \"operations\" must be an array of documents');\n    }\n\n    return await executeOperation(\n      this.client,\n      new BulkWriteOperation(\n        this as TODO_NODE_3286,\n        operations,\n        resolveOptions(this, options ?? { ordered: true })\n      )\n    );\n  }\n\n  /**\n   * Update a single document in a collection\n   *\n   * The value of `update` can be either:\n   * - UpdateFilter<TSchema> - A document that contains update operator expressions,\n   * - Document[] - an aggregation pipeline.\n   *\n   * @param filter - The filter used to select the document to update\n   * @param update - The modifications to apply\n   * @param options - Optional settings for the command\n   */\n  async updateOne(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options?: UpdateOptions & { sort?: Sort }\n  ): Promise<UpdateResult<TSchema>> {\n    return await executeOperation(\n      this.client,\n      new UpdateOneOperation(\n        this as TODO_NODE_3286,\n        filter,\n        update,\n        resolveOptions(this, options)\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Replace a document in a collection with another document\n   *\n   * @param filter - The filter used to select the document to replace\n   * @param replacement - The Document that replaces the matching document\n   * @param options - Optional settings for the command\n   */\n  async replaceOne(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>,\n    options?: ReplaceOptions\n  ): Promise<UpdateResult<TSchema>> {\n    return await executeOperation(\n      this.client,\n      new ReplaceOneOperation(\n        this as TODO_NODE_3286,\n        filter,\n        replacement,\n        resolveOptions(this, options)\n      )\n    );\n  }\n\n  /**\n   * Update multiple documents in a collection\n   *\n   * The value of `update` can be either:\n   * - UpdateFilter<TSchema> - A document that contains update operator expressions,\n   * - Document[] - an aggregation pipeline.\n   *\n   * @param filter - The filter used to select the document to update\n   * @param update - The modifications to apply\n   * @param options - Optional settings for the command\n   */\n  async updateMany(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options?: UpdateOptions\n  ): Promise<UpdateResult<TSchema>> {\n    return await executeOperation(\n      this.client,\n      new UpdateManyOperation(\n        this as TODO_NODE_3286,\n        filter,\n        update,\n        resolveOptions(this, options)\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Delete a document from a collection\n   *\n   * @param filter - The filter used to select the document to remove\n   * @param options - Optional settings for the command\n   */\n  async deleteOne(\n    filter: Filter<TSchema> = {},\n    options: DeleteOptions = {}\n  ): Promise<DeleteResult> {\n    return await executeOperation(\n      this.client,\n      new DeleteOneOperation(this as TODO_NODE_3286, filter, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Delete multiple documents from a collection\n   *\n   * @param filter - The filter used to select the documents to remove\n   * @param options - Optional settings for the command\n   */\n  async deleteMany(\n    filter: Filter<TSchema> = {},\n    options: DeleteOptions = {}\n  ): Promise<DeleteResult> {\n    return await executeOperation(\n      this.client,\n      new DeleteManyOperation(this as TODO_NODE_3286, filter, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Rename the collection.\n   *\n   * @remarks\n   * This operation does not inherit options from the Db or MongoClient.\n   *\n   * @param newName - New name of of the collection.\n   * @param options - Optional settings for the command\n   */\n  async rename(newName: string, options?: RenameOptions): Promise<Collection> {\n    // Intentionally, we do not inherit options from parent for this operation.\n    return await executeOperation(\n      this.client,\n      new RenameOperation(\n        this as TODO_NODE_3286,\n        newName,\n        resolveOptions(undefined, {\n          ...options,\n          readPreference: ReadPreference.PRIMARY\n        })\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Drop the collection from the database, removing it permanently. New accesses will create a new collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  async drop(options?: DropCollectionOptions): Promise<boolean> {\n    return await executeOperation(\n      this.client,\n      new DropCollectionOperation(this.s.db, this.collectionName, options)\n    );\n  }\n\n  /**\n   * Fetches the first document that matches the filter\n   *\n   * @param filter - Query for find Operation\n   * @param options - Optional settings for the command\n   */\n  async findOne(): Promise<WithId<TSchema> | null>;\n  async findOne(filter: Filter<TSchema>): Promise<WithId<TSchema> | null>;\n  async findOne(\n    filter: Filter<TSchema>,\n    options: Omit<FindOptions, 'timeoutMode'> & Abortable\n  ): Promise<WithId<TSchema> | null>;\n\n  // allow an override of the schema.\n  async findOne<T = TSchema>(): Promise<T | null>;\n  async findOne<T = TSchema>(filter: Filter<TSchema>): Promise<T | null>;\n  async findOne<T = TSchema>(\n    filter: Filter<TSchema>,\n    options?: Omit<FindOptions, 'timeoutMode'> & Abortable\n  ): Promise<T | null>;\n\n  async findOne(\n    filter: Filter<TSchema> = {},\n    options: FindOptions & Abortable = {}\n  ): Promise<WithId<TSchema> | null> {\n    const cursor = this.find(filter, options).limit(-1).batchSize(1);\n    const res = await cursor.next();\n    await cursor.close();\n    return res;\n  }\n\n  /**\n   * Creates a cursor for a filter that can be used to iterate over results from MongoDB\n   *\n   * @param filter - The filter predicate. If unspecified, then all documents in the collection will match the predicate\n   */\n  find(): FindCursor<WithId<TSchema>>;\n  find(filter: Filter<TSchema>, options?: FindOptions & Abortable): FindCursor<WithId<TSchema>>;\n  find<T extends Document>(\n    filter: Filter<TSchema>,\n    options?: FindOptions & Abortable\n  ): FindCursor<T>;\n  find(\n    filter: Filter<TSchema> = {},\n    options: FindOptions & Abortable = {}\n  ): FindCursor<WithId<TSchema>> {\n    return new FindCursor<WithId<TSchema>>(\n      this.client,\n      this.s.namespace,\n      filter,\n      resolveOptions(this as TODO_NODE_3286, options)\n    );\n  }\n\n  /**\n   * Returns the options of the collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  async options(options?: OperationOptions): Promise<Document> {\n    return await executeOperation(\n      this.client,\n      new OptionsOperation(this as TODO_NODE_3286, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Returns if the collection is a capped collection\n   *\n   * @param options - Optional settings for the command\n   */\n  async isCapped(options?: OperationOptions): Promise<boolean> {\n    return await executeOperation(\n      this.client,\n      new IsCappedOperation(this as TODO_NODE_3286, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Creates an index on the db and collection collection.\n   *\n   * @param indexSpec - The field name or index specification to create an index for\n   * @param options - Optional settings for the command\n   *\n   * @example\n   * ```ts\n   * const collection = client.db('foo').collection('bar');\n   *\n   * await collection.createIndex({ a: 1, b: -1 });\n   *\n   * // Alternate syntax for { c: 1, d: -1 } that ensures order of indexes\n   * await collection.createIndex([ [c, 1], [d, -1] ]);\n   *\n   * // Equivalent to { e: 1 }\n   * await collection.createIndex('e');\n   *\n   * // Equivalent to { f: 1, g: 1 }\n   * await collection.createIndex(['f', 'g'])\n   *\n   * // Equivalent to { h: 1, i: -1 }\n   * await collection.createIndex([ { h: 1 }, { i: -1 } ]);\n   *\n   * // Equivalent to { j: 1, k: -1, l: 2d }\n   * await collection.createIndex(['j', ['k', -1], { l: '2d' }])\n   * ```\n   */\n  async createIndex(\n    indexSpec: IndexSpecification,\n    options?: CreateIndexesOptions\n  ): Promise<string> {\n    const indexes = await executeOperation(\n      this.client,\n      CreateIndexesOperation.fromIndexSpecification(\n        this,\n        this.collectionName,\n        indexSpec,\n        resolveOptions(this, options)\n      )\n    );\n\n    return indexes[0];\n  }\n\n  /**\n   * Creates multiple indexes in the collection, this method is only supported for\n   * MongoDB 2.6 or higher. Earlier version of MongoDB will throw a command not supported\n   * error.\n   *\n   * **Note**: Unlike {@link Collection#createIndex| createIndex}, this function takes in raw index specifications.\n   * Index specifications are defined {@link https://www.mongodb.com/docs/manual/reference/command/createIndexes/| here}.\n   *\n   * @param indexSpecs - An array of index specifications to be created\n   * @param options - Optional settings for the command\n   *\n   * @example\n   * ```ts\n   * const collection = client.db('foo').collection('bar');\n   * await collection.createIndexes([\n   *   // Simple index on field fizz\n   *   {\n   *     key: { fizz: 1 },\n   *   }\n   *   // wildcard index\n   *   {\n   *     key: { '$**': 1 }\n   *   },\n   *   // named index on darmok and jalad\n   *   {\n   *     key: { darmok: 1, jalad: -1 }\n   *     name: 'tanagra'\n   *   }\n   * ]);\n   * ```\n   */\n  async createIndexes(\n    indexSpecs: IndexDescription[],\n    options?: CreateIndexesOptions\n  ): Promise<string[]> {\n    return await executeOperation(\n      this.client,\n      CreateIndexesOperation.fromIndexDescriptionArray(\n        this,\n        this.collectionName,\n        indexSpecs,\n        resolveOptions(this, { ...options, maxTimeMS: undefined })\n      )\n    );\n  }\n\n  /**\n   * Drops an index from this collection.\n   *\n   * @param indexName - Name of the index to drop.\n   * @param options - Optional settings for the command\n   */\n  async dropIndex(indexName: string, options?: DropIndexesOptions): Promise<Document> {\n    return await executeOperation(\n      this.client,\n      new DropIndexOperation(this as TODO_NODE_3286, indexName, {\n        ...resolveOptions(this, options),\n        readPreference: ReadPreference.primary\n      })\n    );\n  }\n\n  /**\n   * Drops all indexes from this collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  async dropIndexes(options?: DropIndexesOptions): Promise<boolean> {\n    try {\n      await executeOperation(\n        this.client,\n        new DropIndexOperation(this as TODO_NODE_3286, '*', resolveOptions(this, options))\n      );\n      return true;\n    } catch (error) {\n      // TODO(NODE-6517): Driver should only filter for namespace not found error. Other errors should be thrown.\n      if (error instanceof MongoOperationTimeoutError) throw error;\n      return false;\n    }\n  }\n\n  /**\n   * Get the list of all indexes information for the collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  listIndexes(options?: ListIndexesOptions): ListIndexesCursor {\n    return new ListIndexesCursor(this as TODO_NODE_3286, resolveOptions(this, options));\n  }\n\n  /**\n   * Checks if one or more indexes exist on the collection, fails on first non-existing index\n   *\n   * @param indexes - One or more index names to check.\n   * @param options - Optional settings for the command\n   */\n  async indexExists(indexes: string | string[], options?: ListIndexesOptions): Promise<boolean> {\n    const indexNames: string[] = Array.isArray(indexes) ? indexes : [indexes];\n    const allIndexes: Set<string> = new Set(\n      await this.listIndexes(options)\n        .map(({ name }) => name)\n        .toArray()\n    );\n    return indexNames.every(name => allIndexes.has(name));\n  }\n\n  /**\n   * Retrieves this collections index info.\n   *\n   * @param options - Optional settings for the command\n   */\n  indexInformation(\n    options: IndexInformationOptions & { full: true }\n  ): Promise<IndexDescriptionInfo[]>;\n  indexInformation(\n    options: IndexInformationOptions & { full?: false }\n  ): Promise<IndexDescriptionCompact>;\n  indexInformation(\n    options: IndexInformationOptions\n  ): Promise<IndexDescriptionCompact | IndexDescriptionInfo[]>;\n  indexInformation(): Promise<IndexDescriptionCompact>;\n  async indexInformation(\n    options?: IndexInformationOptions\n  ): Promise<IndexDescriptionCompact | IndexDescriptionInfo[]> {\n    return await this.indexes({\n      ...options,\n      full: options?.full ?? false\n    });\n  }\n\n  /**\n   * Gets an estimate of the count of documents in a collection using collection metadata.\n   * This will always run a count command on all server versions.\n   *\n   * due to an oversight in versions 5.0.0-5.0.8 of MongoDB, the count command,\n   * which estimatedDocumentCount uses in its implementation, was not included in v1 of\n   * the Stable API, and so users of the Stable API with estimatedDocumentCount are\n   * recommended to upgrade their server version to 5.0.9+ or set apiStrict: false to avoid\n   * encountering errors.\n   *\n   * @see {@link https://www.mongodb.com/docs/manual/reference/command/count/#behavior|Count: Behavior}\n   * @param options - Optional settings for the command\n   */\n  async estimatedDocumentCount(options?: EstimatedDocumentCountOptions): Promise<number> {\n    return await executeOperation(\n      this.client,\n      new EstimatedDocumentCountOperation(this as TODO_NODE_3286, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Gets the number of documents matching the filter.\n   * For a fast count of the total documents in a collection see {@link Collection#estimatedDocumentCount| estimatedDocumentCount}.\n   *\n   * Due to countDocuments using the $match aggregation pipeline stage, certain query operators cannot be used in countDocuments. This includes the $where and $near query operators, among others. Details can be found in the documentation for the $match aggregation pipeline stage.\n   *\n   * **Note**: When migrating from {@link Collection#count| count} to {@link Collection#countDocuments| countDocuments}\n   * the following query operators must be replaced:\n   *\n   * | Operator | Replacement |\n   * | -------- | ----------- |\n   * | `$where`   | [`$expr`][1] |\n   * | `$near`    | [`$geoWithin`][2] with [`$center`][3] |\n   * | `$nearSphere` | [`$geoWithin`][2] with [`$centerSphere`][4] |\n   *\n   * [1]: https://www.mongodb.com/docs/manual/reference/operator/query/expr/\n   * [2]: https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/\n   * [3]: https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center\n   * [4]: https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere\n   *\n   * @param filter - The filter for the count\n   * @param options - Optional settings for the command\n   *\n   * @see https://www.mongodb.com/docs/manual/reference/operator/query/expr/\n   * @see https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/\n   * @see https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center\n   * @see https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere\n   */\n  async countDocuments(\n    filter: Filter<TSchema> = {},\n    options: CountDocumentsOptions & Abortable = {}\n  ): Promise<number> {\n    const pipeline = [];\n    pipeline.push({ $match: filter });\n\n    if (typeof options.skip === 'number') {\n      pipeline.push({ $skip: options.skip });\n    }\n\n    if (typeof options.limit === 'number') {\n      pipeline.push({ $limit: options.limit });\n    }\n\n    pipeline.push({ $group: { _id: 1, n: { $sum: 1 } } });\n\n    const cursor = this.aggregate<{ n: number }>(pipeline, options);\n    const doc = await cursor.next();\n    await cursor.close();\n    return doc?.n ?? 0;\n  }\n\n  /**\n   * The distinct command returns a list of distinct values for the given key across a collection.\n   *\n   * @param key - Field of the document to find distinct values for\n   * @param filter - The filter for filtering the set of documents to which we apply the distinct filter.\n   * @param options - Optional settings for the command\n   */\n  distinct<Key extends keyof WithId<TSchema>>(\n    key: Key\n  ): Promise<Array<Flatten<WithId<TSchema>[Key]>>>;\n  distinct<Key extends keyof WithId<TSchema>>(\n    key: Key,\n    filter: Filter<TSchema>\n  ): Promise<Array<Flatten<WithId<TSchema>[Key]>>>;\n  distinct<Key extends keyof WithId<TSchema>>(\n    key: Key,\n    filter: Filter<TSchema>,\n    options: DistinctOptions\n  ): Promise<Array<Flatten<WithId<TSchema>[Key]>>>;\n\n  // Embedded documents overload\n  distinct(key: string): Promise<any[]>;\n  distinct(key: string, filter: Filter<TSchema>): Promise<any[]>;\n  distinct(key: string, filter: Filter<TSchema>, options: DistinctOptions): Promise<any[]>;\n\n  async distinct<Key extends keyof WithId<TSchema>>(\n    key: Key,\n    filter: Filter<TSchema> = {},\n    options: DistinctOptions = {}\n  ): Promise<any[]> {\n    return await executeOperation(\n      this.client,\n      new DistinctOperation(\n        this as TODO_NODE_3286,\n        key as TODO_NODE_3286,\n        filter,\n        resolveOptions(this, options)\n      )\n    );\n  }\n\n  /**\n   * Retrieve all the indexes on the collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  indexes(options: IndexInformationOptions & { full?: true }): Promise<IndexDescriptionInfo[]>;\n  indexes(options: IndexInformationOptions & { full: false }): Promise<IndexDescriptionCompact>;\n  indexes(\n    options: IndexInformationOptions\n  ): Promise<IndexDescriptionCompact | IndexDescriptionInfo[]>;\n  indexes(options?: ListIndexesOptions): Promise<IndexDescriptionInfo[]>;\n  async indexes(\n    options?: IndexInformationOptions\n  ): Promise<IndexDescriptionCompact | IndexDescriptionInfo[]> {\n    const indexes: IndexDescriptionInfo[] = await this.listIndexes(options).toArray();\n    const full = options?.full ?? true;\n    if (full) {\n      return indexes;\n    }\n\n    const object: IndexDescriptionCompact = Object.fromEntries(\n      indexes.map(({ name, key }) => [name, Object.entries(key)])\n    );\n\n    return object;\n  }\n\n  /**\n   * Find a document and delete it in one atomic operation. Requires a write lock for the duration of the operation.\n   *\n   * @param filter - The filter used to select the document to remove\n   * @param options - Optional settings for the command\n   */\n  async findOneAndDelete(\n    filter: Filter<TSchema>,\n    options: FindOneAndDeleteOptions & { includeResultMetadata: true }\n  ): Promise<ModifyResult<TSchema>>;\n  async findOneAndDelete(\n    filter: Filter<TSchema>,\n    options: FindOneAndDeleteOptions & { includeResultMetadata: false }\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndDelete(\n    filter: Filter<TSchema>,\n    options: FindOneAndDeleteOptions\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndDelete(filter: Filter<TSchema>): Promise<WithId<TSchema> | null>;\n  async findOneAndDelete(\n    filter: Filter<TSchema>,\n    options?: FindOneAndDeleteOptions\n  ): Promise<WithId<TSchema> | ModifyResult<TSchema> | null> {\n    return await executeOperation(\n      this.client,\n      new FindOneAndDeleteOperation(\n        this as TODO_NODE_3286,\n        filter,\n        resolveOptions(this, options)\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Find a document and replace it in one atomic operation. Requires a write lock for the duration of the operation.\n   *\n   * @param filter - The filter used to select the document to replace\n   * @param replacement - The Document that replaces the matching document\n   * @param options - Optional settings for the command\n   */\n  async findOneAndReplace(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>,\n    options: FindOneAndReplaceOptions & { includeResultMetadata: true }\n  ): Promise<ModifyResult<TSchema>>;\n  async findOneAndReplace(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>,\n    options: FindOneAndReplaceOptions & { includeResultMetadata: false }\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndReplace(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>,\n    options: FindOneAndReplaceOptions\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndReplace(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndReplace(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>,\n    options?: FindOneAndReplaceOptions\n  ): Promise<WithId<TSchema> | ModifyResult<TSchema> | null> {\n    return await executeOperation(\n      this.client,\n      new FindOneAndReplaceOperation(\n        this as TODO_NODE_3286,\n        filter,\n        replacement,\n        resolveOptions(this, options)\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Find a document and update it in one atomic operation. Requires a write lock for the duration of the operation.\n   *\n   * The value of `update` can be either:\n   * - UpdateFilter<TSchema> - A document that contains update operator expressions,\n   * - Document[] - an aggregation pipeline consisting of the following stages:\n   *   - $addFields and its alias $set\n   *   - $project and its alias $unset\n   *   - $replaceRoot and its alias $replaceWith.\n   * See the [findAndModify command documentation](https://www.mongodb.com/docs/manual/reference/command/findAndModify) for details.\n   *\n   * @param filter - The filter used to select the document to update\n   * @param update - The modifications to apply\n   * @param options - Optional settings for the command\n   */\n  async findOneAndUpdate(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options: FindOneAndUpdateOptions & { includeResultMetadata: true }\n  ): Promise<ModifyResult<TSchema>>;\n  async findOneAndUpdate(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options: FindOneAndUpdateOptions & { includeResultMetadata: false }\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndUpdate(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options: FindOneAndUpdateOptions\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndUpdate(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[]\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndUpdate(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options?: FindOneAndUpdateOptions\n  ): Promise<WithId<TSchema> | ModifyResult<TSchema> | null> {\n    return await executeOperation(\n      this.client,\n      new FindOneAndUpdateOperation(\n        this as TODO_NODE_3286,\n        filter,\n        update,\n        resolveOptions(this, options)\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Execute an aggregation framework pipeline against the collection, needs MongoDB \\>= 2.2\n   *\n   * @param pipeline - An array of aggregation pipelines to execute\n   * @param options - Optional settings for the command\n   */\n  aggregate<T extends Document = Document>(\n    pipeline: Document[] = [],\n    options?: AggregateOptions & Abortable\n  ): AggregationCursor<T> {\n    if (!Array.isArray(pipeline)) {\n      throw new MongoInvalidArgumentError(\n        'Argument \"pipeline\" must be an array of aggregation stages'\n      );\n    }\n\n    return new AggregationCursor(\n      this.client,\n      this.s.namespace,\n      pipeline,\n      resolveOptions(this, options)\n    );\n  }\n\n  /**\n   * Create a new Change Stream, watching for new changes (insertions, updates, replacements, deletions, and invalidations) in this collection.\n   *\n   * @remarks\n   * watch() accepts two generic arguments for distinct use cases:\n   * - The first is to override the schema that may be defined for this specific collection\n   * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n   * @example\n   * By just providing the first argument I can type the change to be `ChangeStreamDocument<{ _id: number }>`\n   * ```ts\n   * collection.watch<{ _id: number }>()\n   *   .on('change', change => console.log(change._id.toFixed(4)));\n   * ```\n   *\n   * @example\n   * Passing a second argument provides a way to reflect the type changes caused by an advanced pipeline.\n   * Here, we are using a pipeline to have MongoDB filter for insert changes only and add a comment.\n   * No need start from scratch on the ChangeStreamInsertDocument type!\n   * By using an intersection we can save time and ensure defaults remain the same type!\n   * ```ts\n   * collection\n   *   .watch<Schema, ChangeStreamInsertDocument<Schema> & { comment: string }>([\n   *     { $addFields: { comment: 'big changes' } },\n   *     { $match: { operationType: 'insert' } }\n   *   ])\n   *   .on('change', change => {\n   *     change.comment.startsWith('big');\n   *     change.operationType === 'insert';\n   *     // No need to narrow in code because the generics did that for us!\n   *     expectType<Schema>(change.fullDocument);\n   *   });\n   * ```\n   *\n   * @remarks\n   * When `timeoutMS` is configured for a change stream, it will have different behaviour depending\n   * on whether the change stream is in iterator mode or emitter mode. In both cases, a change\n   * stream will time out if it does not receive a change event within `timeoutMS` of the last change\n   * event.\n   *\n   * Note that if a change stream is consistently timing out when watching a collection, database or\n   * client that is being changed, then this may be due to the server timing out before it can finish\n   * processing the existing oplog. To address this, restart the change stream with a higher\n   * `timeoutMS`.\n   *\n   * If the change stream times out the initial aggregate operation to establish the change stream on\n   * the server, then the client will close the change stream. If the getMore calls to the server\n   * time out, then the change stream will be left open, but will throw a MongoOperationTimeoutError\n   * when in iterator mode and emit an error event that returns a MongoOperationTimeoutError in\n   * emitter mode.\n   *\n   * To determine whether or not the change stream is still open following a timeout, check the\n   * {@link ChangeStream.closed} getter.\n   *\n   * @example\n   * In iterator mode, if a next() call throws a timeout error, it will attempt to resume the change stream.\n   * The next call can just be retried after this succeeds.\n   * ```ts\n   * const changeStream = collection.watch([], { timeoutMS: 100 });\n   * try {\n   *     await changeStream.next();\n   * } catch (e) {\n   *     if (e instanceof MongoOperationTimeoutError && !changeStream.closed) {\n   *       await changeStream.next();\n   *     }\n   *     throw e;\n   * }\n   * ```\n   *\n   * @example\n   * In emitter mode, if the change stream goes `timeoutMS` without emitting a change event, it will\n   * emit an error event that returns a MongoOperationTimeoutError, but will not close the change\n   * stream unless the resume attempt fails. There is no need to re-establish change listeners as\n   * this will automatically continue emitting change events once the resume attempt completes.\n   *\n   * ```ts\n   * const changeStream = collection.watch([], { timeoutMS: 100 });\n   * changeStream.on('change', console.log);\n   * changeStream.on('error', e => {\n   *     if (e instanceof MongoOperationTimeoutError && !changeStream.closed) {\n   *         // do nothing\n   *     } else {\n   *         changeStream.close();\n   *     }\n   * });\n   * ```\n   *\n   * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n   * @param options - Optional settings for the command\n   * @typeParam TLocal - Type of the data being detected by the change stream\n   * @typeParam TChange - Type of the whole change stream document emitted\n   */\n  watch<TLocal extends Document = TSchema, TChange extends Document = ChangeStreamDocument<TLocal>>(\n    pipeline: Document[] = [],\n    options: ChangeStreamOptions = {}\n  ): ChangeStream<TLocal, TChange> {\n    // Allow optionally not specifying a pipeline\n    if (!Array.isArray(pipeline)) {\n      options = pipeline;\n      pipeline = [];\n    }\n\n    return new ChangeStream<TLocal, TChange>(this, pipeline, resolveOptions(this, options));\n  }\n\n  /**\n   * Initiate an Out of order batch write operation. All operations will be buffered into insert/update/remove commands executed out of order.\n   *\n   * @throws MongoNotConnectedError\n   * @remarks\n   * **NOTE:** MongoClient must be connected prior to calling this method due to a known limitation in this legacy implementation.\n   * However, `collection.bulkWrite()` provides an equivalent API that does not require prior connecting.\n   */\n  initializeUnorderedBulkOp(options?: BulkWriteOptions): UnorderedBulkOperation {\n    return new UnorderedBulkOperation(this as TODO_NODE_3286, resolveOptions(this, options));\n  }\n\n  /**\n   * Initiate an In order bulk write operation. Operations will be serially executed in the order they are added, creating a new operation for each switch in types.\n   *\n   * @throws MongoNotConnectedError\n   * @remarks\n   * **NOTE:** MongoClient must be connected prior to calling this method due to a known limitation in this legacy implementation.\n   * However, `collection.bulkWrite()` provides an equivalent API that does not require prior connecting.\n   */\n  initializeOrderedBulkOp(options?: BulkWriteOptions): OrderedBulkOperation {\n    return new OrderedBulkOperation(this as TODO_NODE_3286, resolveOptions(this, options));\n  }\n\n  /**\n   * An estimated count of matching documents in the db to a filter.\n   *\n   * **NOTE:** This method has been deprecated, since it does not provide an accurate count of the documents\n   * in a collection. To obtain an accurate count of documents in the collection, use {@link Collection#countDocuments| countDocuments}.\n   * To obtain an estimated count of all documents in the collection, use {@link Collection#estimatedDocumentCount| estimatedDocumentCount}.\n   *\n   * @deprecated use {@link Collection#countDocuments| countDocuments} or {@link Collection#estimatedDocumentCount| estimatedDocumentCount} instead\n   *\n   * @param filter - The filter for the count.\n   * @param options - Optional settings for the command\n   */\n  async count(filter: Filter<TSchema> = {}, options: CountOptions = {}): Promise<number> {\n    return await executeOperation(\n      this.client,\n      new CountOperation(this.fullNamespace, filter, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Returns all search indexes for the current collection.\n   *\n   * @param options - The options for the list indexes operation.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  listSearchIndexes(options?: ListSearchIndexesOptions): ListSearchIndexesCursor;\n  /**\n   * Returns all search indexes for the current collection.\n   *\n   * @param name - The name of the index to search for.  Only indexes with matching index names will be returned.\n   * @param options - The options for the list indexes operation.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  listSearchIndexes(name: string, options?: ListSearchIndexesOptions): ListSearchIndexesCursor;\n  listSearchIndexes(\n    indexNameOrOptions?: string | ListSearchIndexesOptions,\n    options?: ListSearchIndexesOptions\n  ): ListSearchIndexesCursor {\n    options =\n      typeof indexNameOrOptions === 'object' ? indexNameOrOptions : options == null ? {} : options;\n\n    const indexName =\n      indexNameOrOptions == null\n        ? null\n        : typeof indexNameOrOptions === 'object'\n          ? null\n          : indexNameOrOptions;\n\n    return new ListSearchIndexesCursor(this as TODO_NODE_3286, indexName, options);\n  }\n\n  /**\n   * Creates a single search index for the collection.\n   *\n   * @param description - The index description for the new search index.\n   * @returns A promise that resolves to the name of the new search index.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  async createSearchIndex(description: SearchIndexDescription): Promise<string> {\n    const [index] = await this.createSearchIndexes([description]);\n    return index;\n  }\n\n  /**\n   * Creates multiple search indexes for the current collection.\n   *\n   * @param descriptions - An array of `SearchIndexDescription`s for the new search indexes.\n   * @returns A promise that resolves to an array of the newly created search index names.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   * @returns\n   */\n  async createSearchIndexes(descriptions: SearchIndexDescription[]): Promise<string[]> {\n    return await executeOperation(\n      this.client,\n      new CreateSearchIndexesOperation(this as TODO_NODE_3286, descriptions)\n    );\n  }\n\n  /**\n   * Deletes a search index by index name.\n   *\n   * @param name - The name of the search index to be deleted.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  async dropSearchIndex(name: string): Promise<void> {\n    return await executeOperation(\n      this.client,\n      new DropSearchIndexOperation(this as TODO_NODE_3286, name)\n    );\n  }\n\n  /**\n   * Updates a search index by replacing the existing index definition with the provided definition.\n   *\n   * @param name - The name of the search index to update.\n   * @param definition - The new search index definition.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  async updateSearchIndex(name: string, definition: Document): Promise<void> {\n    return await executeOperation(\n      this.client,\n      new UpdateSearchIndexOperation(this as TODO_NODE_3286, name, definition)\n    );\n  }\n}\n"],"names":[],"mappings":";;;;;AAAA,MAAA;AAEA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAKA,MAAA;AAaA,MAAA;AACA,MAAA;AACA,MAAA;AAMA,MAAA;AACA,MAAA;AACA,MAAA;AAIA,MAAA;AAEA,MAAA;AAQA,MAAA;AAYA,MAAA;AAOA,MAAA;AAEA,MAAA;AACA,MAAA;AACA,MAAA;AAIA,MAAA;AACA,MAAA;AACA,MAAA;AAQA,MAAA;AACA,MAAA;AAEA,MAAA;AAMA,MAAA;AA2CA;;;;;;;;;;;;;;;;;;;;;;;;;IA0BA,MAAa;IAOX;;;QAIA,YAAY,EAAM,EAAE,IAAY,EAAE,OAA2B,CAAA;QAC3D,iBAAiB;QACjB,IAAI,CAAC,CAAC,GAAG;YACP;YACA;YACA,WAAW,IAAI,QAAA,0BAA0B,CAAC,GAAG,YAAY,EAAE;YAC3D,WAAW,GAAG,OAAO,EAAE,aAAa,QAAA,kBAAkB;YACtD,gBAAgB,kBAAA,cAAc,CAAC,WAAW,CAAC;YAC3C,aAAa,CAAA,GAAA,OAAA,kBAAkB,EAAC,SAAS;YACzC,aAAa,eAAA,WAAW,CAAC,WAAW,CAAC;YACrC,cAAc,gBAAA,YAAY,CAAC,WAAW,CAAC;;QAGzC,IAAI,CAAC,MAAM,GAAG,GAAG,MAAM;IACzB;IAEA;;QAGA,IAAI,SAAM;QACR,OAAO,IAAI,CAAC,CAAC,CAAC,SAAS,CAAC,EAAE;IAC5B;IAEA;;QAGA,IAAI,iBAAc;QAChB,OAAO,IAAI,CAAC,CAAC,CAAC,SAAS,CAAC,UAAU;IACpC;IAEA;;QAGA,IAAI,YAAS;QACX,OAAO,IAAI,CAAC,aAAa,CAAC,QAAQ;IACpC;IAEA;;;;QAKA,IAAI,gBAAa;QACf,OAAO,IAAI,CAAC,CAAC,CAAC,SAAS;IACzB;IAEA;;;QAIA,IAAI,cAAW;QACb,IAAI,IAAI,CAAC,CAAC,CAAC,WAAW,IAAI,MAAM;YAC9B,OAAO,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,WAAW;QAC9B;QACA,OAAO,IAAI,CAAC,CAAC,CAAC,WAAW;IAC3B;IAEA;;;QAIA,IAAI,iBAAc;QAChB,IAAI,IAAI,CAAC,CAAC,CAAC,cAAc,IAAI,MAAM;YACjC,OAAO,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,cAAc;QACjC;QAEA,OAAO,IAAI,CAAC,CAAC,CAAC,cAAc;IAC9B;IAEA,IAAI,cAAW;QACb,OAAO,IAAI,CAAC,CAAC,CAAC,WAAW;IAC3B;IAEA;;;QAIA,IAAI,eAAY;QACd,IAAI,IAAI,CAAC,CAAC,CAAC,YAAY,IAAI,MAAM;YAC/B,OAAO,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,YAAY;QAC/B;QACA,OAAO,IAAI,CAAC,CAAC,CAAC,YAAY;IAC5B;IAEA,8CAAA,GACA,IAAI,OAAI;QACN,OAAO,IAAI,CAAC,CAAC,CAAC,cAAc;IAC9B;IAEA,IAAI,KAAK,CAAmB,EAAA;QAC1B,IAAI,CAAC,CAAC,CAAC,cAAc,GAAG,CAAA,GAAA,QAAA,kBAAkB,EAAC;IAC7C;IAEA,IAAW,YAAS;QAClB,OAAO,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,SAAS;IACjC;IAEA;;;;;;;QAQA,MAAM,UACJ,GAAsC,EACtC,OAA0B,EAAA;QAE1B,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,SAAA,kBAAkB,CACpB,IAAsB,EACtB,KACA,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAG3B;IAEA;;;;;;;QAQA,MAAM,WACJ,IAAsD,EACtD,OAA0B,EAAA;QAE1B,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,SAAA,mBAAmB,CACrB,IAAsB,EACtB,MACA,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE,WAAW;YAAE,SAAS;QAAI;IAGrD;IAEA;;;;;;;;;;;;;;;;;;QAmBA,MAAM,UACJ,UAAyD,EACzD,OAA0B,EAAA;QAE1B,IAAI,CAAC,MAAM,OAAO,CAAC,aAAa;YAC9B,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,aAAA,kBAAkB,CACpB,IAAsB,EACtB,YACA,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE,WAAW;YAAE,SAAS;QAAI;IAGrD;IAEA;;;;;;;;;;QAWA,MAAM,UACJ,MAAuB,EACvB,MAA0C,EAC1C,OAAyC,EAAA;QAEzC,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,SAAA,kBAAkB,CACpB,IAAsB,EACtB,QACA,QACA,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAG3B;IAEA;;;;;;QAOA,MAAM,WACJ,MAAuB,EACvB,WAA+B,EAC/B,OAAwB,EAAA;QAExB,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,SAAA,mBAAmB,CACrB,IAAsB,EACtB,QACA,aACA,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAG3B;IAEA;;;;;;;;;;QAWA,MAAM,WACJ,MAAuB,EACvB,MAA0C,EAC1C,OAAuB,EAAA;QAEvB,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,SAAA,mBAAmB,CACrB,IAAsB,EACtB,QACA,QACA,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAG3B;IAEA;;;;;QAMA,MAAM,UACJ,SAA0B,CAAA,CAAE,EAC5B,UAAyB,CAAA,CAAE,EAAA;QAE3B,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,SAAA,kBAAkB,CAAC,IAAsB,EAAE,QAAQ,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAEhF;IAEA;;;;;QAMA,MAAM,WACJ,SAA0B,CAAA,CAAE,EAC5B,UAAyB,CAAA,CAAE,EAAA;QAE3B,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,SAAA,mBAAmB,CAAC,IAAsB,EAAE,QAAQ,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAEjF;IAEA;;;;;;;;QASA,MAAM,OAAO,OAAe,EAAE,OAAuB,EAAA;QACnD,2EAA2E;QAC3E,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,SAAA,eAAe,CACjB,IAAsB,EACtB,SACA,CAAA,GAAA,QAAA,cAAc,EAAC,WAAW;YACxB,GAAG,OAAO;YACV,gBAAgB,kBAAA,cAAc,CAAC,OAAO;;IAI9C;IAEA;;;;QAKA,MAAM,KAAK,OAA+B,EAAA;QACxC,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,OAAA,uBAAuB,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,IAAI,CAAC,cAAc,EAAE;IAEhE;IAuBA,MAAM,QACJ,SAA0B,CAAA,CAAE,EAC5B,UAAmC,CAAA,CAAE,EAAA;QAErC,MAAM,SAAS,IAAI,CAAC,IAAI,CAAC,QAAQ,SAAS,KAAK,CAAC,CAAC,GAAG,SAAS,CAAC;QAC9D,MAAM,MAAM,MAAM,OAAO,IAAI;QAC7B,MAAM,OAAO,KAAK;QAClB,OAAO;IACT;IAaA,KACE,SAA0B,CAAA,CAAE,EAC5B,UAAmC,CAAA,CAAE,EAAA;QAErC,OAAO,IAAI,cAAA,UAAU,CACnB,IAAI,CAAC,MAAM,EACX,IAAI,CAAC,CAAC,CAAC,SAAS,EAChB,QACA,CAAA,GAAA,QAAA,cAAc,EAAC,IAAsB,EAAE;IAE3C;IAEA;;;;QAKA,MAAM,QAAQ,OAA0B,EAAA;QACtC,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,oBAAA,gBAAgB,CAAC,IAAsB,EAAE,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAEtE;IAEA;;;;QAKA,MAAM,SAAS,OAA0B,EAAA;QACvC,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,YAAA,iBAAiB,CAAC,IAAsB,EAAE,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAEvE;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;QA4BA,MAAM,YACJ,SAA6B,EAC7B,OAA8B,EAAA;QAE9B,MAAM,UAAU,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EACpC,IAAI,CAAC,MAAM,EACX,UAAA,sBAAsB,CAAC,sBAAsB,CAC3C,IAAI,EACJ,IAAI,CAAC,cAAc,EACnB,WACA,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;QAIzB,OAAO,OAAO,CAAC,EAAE;IACnB;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;QA+BA,MAAM,cACJ,UAA8B,EAC9B,OAA8B,EAAA;QAE9B,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,UAAA,sBAAsB,CAAC,yBAAyB,CAC9C,IAAI,EACJ,IAAI,CAAC,cAAc,EACnB,YACA,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;YAAE,GAAG,OAAO;YAAE,WAAW;QAAS;IAG7D;IAEA;;;;;QAMA,MAAM,UAAU,SAAiB,EAAE,OAA4B,EAAA;QAC7D,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,UAAA,kBAAkB,CAAC,IAAsB,EAAE,WAAW;YACxD,GAAG,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE,QAAQ;YAChC,gBAAgB,kBAAA,cAAc,CAAC,OAAO;;IAG5C;IAEA;;;;QAKA,MAAM,YAAY,OAA4B,EAAA;QAC5C,IAAI;YACF,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EACpB,IAAI,CAAC,MAAM,EACX,IAAI,UAAA,kBAAkB,CAAC,IAAsB,EAAE,KAAK,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;YAE3E,OAAO;QACT,EAAE,OAAO,OAAO;YACd,2GAA2G;YAC3G,IAAI,iBAAiB,QAAA,0BAA0B,EAAE,MAAM;YACvD,OAAO;QACT;IACF;IAEA;;;;QAKA,YAAY,OAA4B,EAAA;QACtC,OAAO,IAAI,sBAAA,iBAAiB,CAAC,IAAsB,EAAE,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAC5E;IAEA;;;;;QAMA,MAAM,YAAY,OAA0B,EAAE,OAA4B,EAAA;QACxE,MAAM,aAAuB,MAAM,OAAO,CAAC,WAAW,UAAU;YAAC;SAAQ;QACzE,MAAM,aAA0B,IAAI,IAClC,MAAM,IAAI,CAAC,WAAW,CAAC,SACpB,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,GAAK,MAClB,OAAO;QAEZ,OAAO,WAAW,KAAK,CAAC,CAAA,OAAQ,WAAW,GAAG,CAAC;IACjD;IAiBA,MAAM,iBACJ,OAAiC,EAAA;QAEjC,OAAO,MAAM,IAAI,CAAC,OAAO,CAAC;YACxB,GAAG,OAAO;YACV,MAAM,SAAS,QAAQ;;IAE3B;IAEA;;;;;;;;;;;;QAaA,MAAM,uBAAuB,OAAuC,EAAA;QAClE,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,2BAAA,+BAA+B,CAAC,IAAsB,EAAE,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAErF;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;QA4BA,MAAM,eACJ,SAA0B,CAAA,CAAE,EAC5B,UAA6C,CAAA,CAAE,EAAA;QAE/C,MAAM,WAAW,EAAE;QACnB,SAAS,IAAI,CAAC;YAAE,QAAQ;QAAM;QAE9B,IAAI,OAAO,QAAQ,IAAI,KAAK,UAAU;YACpC,SAAS,IAAI,CAAC;gBAAE,OAAO,QAAQ,IAAI;YAAA;QACrC;QAEA,IAAI,OAAO,QAAQ,KAAK,KAAK,UAAU;YACrC,SAAS,IAAI,CAAC;gBAAE,QAAQ,QAAQ,KAAK;YAAA;QACvC;QAEA,SAAS,IAAI,CAAC;YAAE,QAAQ;gBAAE,KAAK;gBAAG,GAAG;oBAAE,MAAM;gBAAC;YAAE;QAAE;QAElD,MAAM,SAAS,IAAI,CAAC,SAAS,CAAgB,UAAU;QACvD,MAAM,MAAM,MAAM,OAAO,IAAI;QAC7B,MAAM,OAAO,KAAK;QAClB,OAAO,KAAK,KAAK;IACnB;IA2BA,MAAM,SACJ,GAAQ,EACR,SAA0B,CAAA,CAAE,EAC5B,UAA2B,CAAA,CAAE,EAAA;QAE7B,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,WAAA,iBAAiB,CACnB,IAAsB,EACtB,KACA,QACA,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAG3B;IAaA,MAAM,QACJ,OAAiC,EAAA;QAEjC,MAAM,UAAkC,MAAM,IAAI,CAAC,WAAW,CAAC,SAAS,OAAO;QAC/E,MAAM,OAAO,SAAS,QAAQ;QAC9B,IAAI,MAAM;YACR,OAAO;QACT;QAEA,MAAM,SAAkC,OAAO,WAAW,CACxD,QAAQ,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,GAAG,EAAE,GAAK;gBAAC;gBAAM,OAAO,OAAO,CAAC;aAAK;QAG5D,OAAO;IACT;IAqBA,MAAM,iBACJ,MAAuB,EACvB,OAAiC,EAAA;QAEjC,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,kBAAA,yBAAyB,CAC3B,IAAsB,EACtB,QACA,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAG3B;IA4BA,MAAM,kBACJ,MAAuB,EACvB,WAA+B,EAC/B,OAAkC,EAAA;QAElC,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,kBAAA,0BAA0B,CAC5B,IAAsB,EACtB,QACA,aACA,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAG3B;IAoCA,MAAM,iBACJ,MAAuB,EACvB,MAA0C,EAC1C,OAAiC,EAAA;QAEjC,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,kBAAA,yBAAyB,CAC3B,IAAsB,EACtB,QACA,QACA,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAG3B;IAEA;;;;;QAMA,UACE,WAAuB,EAAE,EACzB,OAAsC,EAAA;QAEtC,IAAI,CAAC,MAAM,OAAO,CAAC,WAAW;YAC5B,MAAM,IAAI,QAAA,yBAAyB,CACjC;QAEJ;QAEA,OAAO,IAAI,qBAAA,iBAAiB,CAC1B,IAAI,CAAC,MAAM,EACX,IAAI,CAAC,CAAC,CAAC,SAAS,EAChB,UACA,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAEzB;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;QA2FA,MACE,WAAuB,EAAE,EACzB,UAA+B,CAAA,CAAE,EAAA;QAEjC,6CAA6C;QAC7C,IAAI,CAAC,MAAM,OAAO,CAAC,WAAW;YAC5B,UAAU;YACV,WAAW,EAAE;QACf;QAEA,OAAO,IAAI,gBAAA,YAAY,CAAkB,IAAI,EAAE,UAAU,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAChF;IAEA;;;;;;;QAQA,0BAA0B,OAA0B,EAAA;QAClD,OAAO,IAAI,YAAA,sBAAsB,CAAC,IAAsB,EAAE,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IACjF;IAEA;;;;;;;QAQA,wBAAwB,OAA0B,EAAA;QAChD,OAAO,IAAI,UAAA,oBAAoB,CAAC,IAAsB,EAAE,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAC/E;IAEA;;;;;;;;;;;QAYA,MAAM,MAAM,SAA0B,CAAA,CAAE,EAAE,UAAwB,CAAA,CAAE,EAAA;QAClE,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,QAAA,cAAc,CAAC,IAAI,CAAC,aAAa,EAAE,QAAQ,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAExE;IAmBA,kBACE,kBAAsD,EACtD,OAAkC,EAAA;QAElC,UACE,OAAO,uBAAuB,WAAW,qBAAqB,WAAW,OAAO,CAAA,IAAK;QAEvF,MAAM,YACJ,sBAAsB,OAClB,OACA,OAAO,uBAAuB,WAC5B,OACA;QAER,OAAO,IAAI,6BAAA,uBAAuB,CAAC,IAAsB,EAAE,WAAW;IACxE;IAEA;;;;;;;QAQA,MAAM,kBAAkB,WAAmC,EAAA;QACzD,MAAM,CAAC,MAAM,GAAG,MAAM,IAAI,CAAC,mBAAmB,CAAC;YAAC;SAAY;QAC5D,OAAO;IACT;IAEA;;;;;;;;QASA,MAAM,oBAAoB,YAAsC,EAAA;QAC9D,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,SAAA,4BAA4B,CAAC,IAAsB,EAAE;IAE7D;IAEA;;;;;;QAOA,MAAM,gBAAgB,IAAY,EAAA;QAChC,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,OAAA,wBAAwB,CAAC,IAAsB,EAAE;IAEzD;IAEA;;;;;;;QAQA,MAAM,kBAAkB,IAAY,EAAE,UAAoB,EAAA;QACxD,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,SAAA,0BAA0B,CAAC,IAAsB,EAAE,MAAM;IAEjE;;AAxlCF,QAAA,UAAA,GAAA"}},
    {"offset": {"line": 7641, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 7645, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/db.ts"],"sourcesContent":["import { Admin } from './admin';\nimport { type BSONSerializeOptions, type Document, resolveBSONOptions } from './bson';\nimport { ChangeStream, type ChangeStreamDocument, type ChangeStreamOptions } from './change_stream';\nimport { Collection, type CollectionOptions } from './collection';\nimport * as CONSTANTS from './constants';\nimport { AggregationCursor } from './cursor/aggregation_cursor';\nimport { ListCollectionsCursor } from './cursor/list_collections_cursor';\nimport { RunCommandCursor, type RunCursorCommandOptions } from './cursor/run_command_cursor';\nimport { MongoInvalidArgumentError } from './error';\nimport type { MongoClient, PkFactory } from './mongo_client';\nimport type { Abortable, TODO_NODE_3286 } from './mongo_types';\nimport type { AggregateOptions } from './operations/aggregate';\nimport { CollectionsOperation } from './operations/collections';\nimport {\n  CreateCollectionOperation,\n  type CreateCollectionOptions\n} from './operations/create_collection';\nimport {\n  DropCollectionOperation,\n  type DropCollectionOptions,\n  DropDatabaseOperation,\n  type DropDatabaseOptions\n} from './operations/drop';\nimport { executeOperation } from './operations/execute_operation';\nimport {\n  CreateIndexesOperation,\n  type CreateIndexesOptions,\n  type IndexDescriptionCompact,\n  type IndexDescriptionInfo,\n  type IndexInformationOptions,\n  type IndexSpecification\n} from './operations/indexes';\nimport type { CollectionInfo, ListCollectionsOptions } from './operations/list_collections';\nimport { ProfilingLevelOperation, type ProfilingLevelOptions } from './operations/profiling_level';\nimport { RemoveUserOperation, type RemoveUserOptions } from './operations/remove_user';\nimport { RenameOperation, type RenameOptions } from './operations/rename';\nimport { RunCommandOperation, type RunCommandOptions } from './operations/run_command';\nimport {\n  type ProfilingLevel,\n  SetProfilingLevelOperation,\n  type SetProfilingLevelOptions\n} from './operations/set_profiling_level';\nimport { DbStatsOperation, type DbStatsOptions } from './operations/stats';\nimport { ReadConcern } from './read_concern';\nimport { ReadPreference, type ReadPreferenceLike } from './read_preference';\nimport { DEFAULT_PK_FACTORY, filterOptions, MongoDBNamespace, resolveOptions } from './utils';\nimport { WriteConcern, type WriteConcernOptions } from './write_concern';\n\n// Allowed parameters\nconst DB_OPTIONS_ALLOW_LIST = [\n  'writeConcern',\n  'readPreference',\n  'readPreferenceTags',\n  'native_parser',\n  'forceServerObjectId',\n  'pkFactory',\n  'serializeFunctions',\n  'raw',\n  'authSource',\n  'ignoreUndefined',\n  'readConcern',\n  'retryMiliSeconds',\n  'numberOfRetries',\n  'useBigInt64',\n  'promoteBuffers',\n  'promoteLongs',\n  'bsonRegExp',\n  'enableUtf8Validation',\n  'promoteValues',\n  'compression',\n  'retryWrites',\n  'timeoutMS'\n];\n\n/** @internal */\nexport interface DbPrivate {\n  options?: DbOptions;\n  readPreference?: ReadPreference;\n  pkFactory: PkFactory;\n  readConcern?: ReadConcern;\n  bsonOptions: BSONSerializeOptions;\n  writeConcern?: WriteConcern;\n  namespace: MongoDBNamespace;\n}\n\n/** @public */\nexport interface DbOptions extends BSONSerializeOptions, WriteConcernOptions {\n  /** If the database authentication is dependent on another databaseName. */\n  authSource?: string;\n  /** Force server to assign _id values instead of driver. */\n  forceServerObjectId?: boolean;\n  /** The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST). */\n  readPreference?: ReadPreferenceLike;\n  /** A primary key factory object for generation of custom _id keys. */\n  pkFactory?: PkFactory;\n  /** Specify a read concern for the collection. (only MongoDB 3.2 or higher supported) */\n  readConcern?: ReadConcern;\n  /** Should retry failed writes */\n  retryWrites?: boolean;\n  /**\n   * @experimental\n   * Specifies the time an operation will run until it throws a timeout error\n   */\n  timeoutMS?: number;\n}\n\n/**\n * The **Db** class is a class that represents a MongoDB Database.\n * @public\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * interface Pet {\n *   name: string;\n *   kind: 'dog' | 'cat' | 'fish';\n * }\n *\n * const client = new MongoClient('mongodb://localhost:27017');\n * const db = client.db();\n *\n * // Create a collection that validates our union\n * await db.createCollection<Pet>('pets', {\n *   validator: { $expr: { $in: ['$kind', ['dog', 'cat', 'fish']] } }\n * })\n * ```\n */\nexport class Db {\n  /** @internal */\n  s: DbPrivate;\n\n  /** @internal */\n  readonly client: MongoClient;\n\n  public static SYSTEM_NAMESPACE_COLLECTION = CONSTANTS.SYSTEM_NAMESPACE_COLLECTION;\n  public static SYSTEM_INDEX_COLLECTION = CONSTANTS.SYSTEM_INDEX_COLLECTION;\n  public static SYSTEM_PROFILE_COLLECTION = CONSTANTS.SYSTEM_PROFILE_COLLECTION;\n  public static SYSTEM_USER_COLLECTION = CONSTANTS.SYSTEM_USER_COLLECTION;\n  public static SYSTEM_COMMAND_COLLECTION = CONSTANTS.SYSTEM_COMMAND_COLLECTION;\n  public static SYSTEM_JS_COLLECTION = CONSTANTS.SYSTEM_JS_COLLECTION;\n\n  /**\n   * Creates a new Db instance.\n   *\n   * Db name cannot contain a dot, the server may apply more restrictions when an operation is run.\n   *\n   * @param client - The MongoClient for the database.\n   * @param databaseName - The name of the database this instance represents.\n   * @param options - Optional settings for Db construction.\n   */\n  constructor(client: MongoClient, databaseName: string, options?: DbOptions) {\n    options = options ?? {};\n\n    // Filter the options\n    options = filterOptions(options, DB_OPTIONS_ALLOW_LIST);\n\n    // Ensure there are no dots in database name\n    if (typeof databaseName === 'string' && databaseName.includes('.')) {\n      throw new MongoInvalidArgumentError(`Database names cannot contain the character '.'`);\n    }\n\n    // Internal state of the db object\n    this.s = {\n      // Options\n      options,\n      // Unpack read preference\n      readPreference: ReadPreference.fromOptions(options),\n      // Merge bson options\n      bsonOptions: resolveBSONOptions(options, client),\n      // Set up the primary key factory or fallback to ObjectId\n      pkFactory: options?.pkFactory ?? DEFAULT_PK_FACTORY,\n      // ReadConcern\n      readConcern: ReadConcern.fromOptions(options),\n      writeConcern: WriteConcern.fromOptions(options),\n      // Namespace\n      namespace: new MongoDBNamespace(databaseName)\n    };\n\n    this.client = client;\n  }\n\n  get databaseName(): string {\n    return this.s.namespace.db;\n  }\n\n  // Options\n  get options(): DbOptions | undefined {\n    return this.s.options;\n  }\n\n  /**\n   * Check if a secondary can be used (because the read preference is *not* set to primary)\n   */\n  get secondaryOk(): boolean {\n    return this.s.readPreference?.preference !== 'primary' || false;\n  }\n\n  get readConcern(): ReadConcern | undefined {\n    return this.s.readConcern;\n  }\n\n  /**\n   * The current readPreference of the Db. If not explicitly defined for\n   * this Db, will be inherited from the parent MongoClient\n   */\n  get readPreference(): ReadPreference {\n    if (this.s.readPreference == null) {\n      return this.client.readPreference;\n    }\n\n    return this.s.readPreference;\n  }\n\n  get bsonOptions(): BSONSerializeOptions {\n    return this.s.bsonOptions;\n  }\n\n  // get the write Concern\n  get writeConcern(): WriteConcern | undefined {\n    return this.s.writeConcern;\n  }\n\n  get namespace(): string {\n    return this.s.namespace.toString();\n  }\n\n  public get timeoutMS(): number | undefined {\n    return this.s.options?.timeoutMS;\n  }\n\n  /**\n   * Create a new collection on a server with the specified options. Use this to create capped collections.\n   * More information about command options available at https://www.mongodb.com/docs/manual/reference/command/create/\n   *\n   * Collection namespace validation is performed server-side.\n   *\n   * @param name - The name of the collection to create\n   * @param options - Optional settings for the command\n   */\n  async createCollection<TSchema extends Document = Document>(\n    name: string,\n    options?: CreateCollectionOptions\n  ): Promise<Collection<TSchema>> {\n    return await executeOperation(\n      this.client,\n      new CreateCollectionOperation(this, name, resolveOptions(this, options)) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Execute a command\n   *\n   * @remarks\n   * This command does not inherit options from the MongoClient.\n   *\n   * The driver will ensure the following fields are attached to the command sent to the server:\n   * - `lsid` - sourced from an implicit session or options.session\n   * - `$readPreference` - defaults to primary or can be configured by options.readPreference\n   * - `$db` - sourced from the name of this database\n   *\n   * If the client has a serverApi setting:\n   * - `apiVersion`\n   * - `apiStrict`\n   * - `apiDeprecationErrors`\n   *\n   * When in a transaction:\n   * - `readConcern` - sourced from readConcern set on the TransactionOptions\n   * - `writeConcern` - sourced from writeConcern set on the TransactionOptions\n   *\n   * Attaching any of the above fields to the command will have no effect as the driver will overwrite the value.\n   *\n   * @param command - The command to run\n   * @param options - Optional settings for the command\n   */\n  async command(command: Document, options?: RunCommandOptions & Abortable): Promise<Document> {\n    // Intentionally, we do not inherit options from parent for this operation.\n    return await executeOperation(\n      this.client,\n      new RunCommandOperation(\n        this,\n        command,\n        resolveOptions(undefined, {\n          ...resolveBSONOptions(options),\n          timeoutMS: options?.timeoutMS ?? this.timeoutMS,\n          session: options?.session,\n          readPreference: options?.readPreference,\n          signal: options?.signal\n        })\n      )\n    );\n  }\n\n  /**\n   * Execute an aggregation framework pipeline against the database.\n   *\n   * @param pipeline - An array of aggregation stages to be executed\n   * @param options - Optional settings for the command\n   */\n  aggregate<T extends Document = Document>(\n    pipeline: Document[] = [],\n    options?: AggregateOptions\n  ): AggregationCursor<T> {\n    return new AggregationCursor(\n      this.client,\n      this.s.namespace,\n      pipeline,\n      resolveOptions(this, options)\n    );\n  }\n\n  /** Return the Admin db instance */\n  admin(): Admin {\n    return new Admin(this);\n  }\n\n  /**\n   * Returns a reference to a MongoDB Collection. If it does not exist it will be created implicitly.\n   *\n   * Collection namespace validation is performed server-side.\n   *\n   * @param name - the collection name we wish to access.\n   * @returns return the new Collection instance\n   */\n  collection<TSchema extends Document = Document>(\n    name: string,\n    options: CollectionOptions = {}\n  ): Collection<TSchema> {\n    if (typeof options === 'function') {\n      throw new MongoInvalidArgumentError('The callback form of this helper has been removed.');\n    }\n    return new Collection<TSchema>(this, name, resolveOptions(this, options));\n  }\n\n  /**\n   * Get all the db statistics.\n   *\n   * @param options - Optional settings for the command\n   */\n  async stats(options?: DbStatsOptions): Promise<Document> {\n    return await executeOperation(\n      this.client,\n      new DbStatsOperation(this, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * List all collections of this database with optional filter\n   *\n   * @param filter - Query to filter collections by\n   * @param options - Optional settings for the command\n   */\n  listCollections(\n    filter: Document,\n    options: Exclude<ListCollectionsOptions, 'nameOnly'> & { nameOnly: true } & Abortable\n  ): ListCollectionsCursor<Pick<CollectionInfo, 'name' | 'type'>>;\n  listCollections(\n    filter: Document,\n    options: Exclude<ListCollectionsOptions, 'nameOnly'> & { nameOnly: false } & Abortable\n  ): ListCollectionsCursor<CollectionInfo>;\n  listCollections<\n    T extends Pick<CollectionInfo, 'name' | 'type'> | CollectionInfo =\n      | Pick<CollectionInfo, 'name' | 'type'>\n      | CollectionInfo\n  >(filter?: Document, options?: ListCollectionsOptions & Abortable): ListCollectionsCursor<T>;\n  listCollections<\n    T extends Pick<CollectionInfo, 'name' | 'type'> | CollectionInfo =\n      | Pick<CollectionInfo, 'name' | 'type'>\n      | CollectionInfo\n  >(\n    filter: Document = {},\n    options: ListCollectionsOptions & Abortable = {}\n  ): ListCollectionsCursor<T> {\n    return new ListCollectionsCursor<T>(this, filter, resolveOptions(this, options));\n  }\n\n  /**\n   * Rename a collection.\n   *\n   * @remarks\n   * This operation does not inherit options from the MongoClient.\n   *\n   * @param fromCollection - Name of current collection to rename\n   * @param toCollection - New name of of the collection\n   * @param options - Optional settings for the command\n   */\n  async renameCollection<TSchema extends Document = Document>(\n    fromCollection: string,\n    toCollection: string,\n    options?: RenameOptions\n  ): Promise<Collection<TSchema>> {\n    // Intentionally, we do not inherit options from parent for this operation.\n    return await executeOperation(\n      this.client,\n      new RenameOperation(\n        this.collection<TSchema>(fromCollection) as TODO_NODE_3286,\n        toCollection,\n        resolveOptions(undefined, {\n          ...options,\n          new_collection: true,\n          readPreference: ReadPreference.primary\n        })\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Drop a collection from the database, removing it permanently. New accesses will create a new collection.\n   *\n   * @param name - Name of collection to drop\n   * @param options - Optional settings for the command\n   */\n  async dropCollection(name: string, options?: DropCollectionOptions): Promise<boolean> {\n    return await executeOperation(\n      this.client,\n      new DropCollectionOperation(this, name, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Drop a database, removing it permanently from the server.\n   *\n   * @param options - Optional settings for the command\n   */\n  async dropDatabase(options?: DropDatabaseOptions): Promise<boolean> {\n    return await executeOperation(\n      this.client,\n      new DropDatabaseOperation(this, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Fetch all collections for the current db.\n   *\n   * @param options - Optional settings for the command\n   */\n  async collections(options?: ListCollectionsOptions): Promise<Collection[]> {\n    return await executeOperation(\n      this.client,\n      new CollectionsOperation(this, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Creates an index on the db and collection.\n   *\n   * @param name - Name of the collection to create the index on.\n   * @param indexSpec - Specify the field to index, or an index specification\n   * @param options - Optional settings for the command\n   */\n  async createIndex(\n    name: string,\n    indexSpec: IndexSpecification,\n    options?: CreateIndexesOptions\n  ): Promise<string> {\n    const indexes = await executeOperation(\n      this.client,\n      CreateIndexesOperation.fromIndexSpecification(this, name, indexSpec, options)\n    );\n    return indexes[0];\n  }\n\n  /**\n   * Remove a user from a database\n   *\n   * @param username - The username to remove\n   * @param options - Optional settings for the command\n   */\n  async removeUser(username: string, options?: RemoveUserOptions): Promise<boolean> {\n    return await executeOperation(\n      this.client,\n      new RemoveUserOperation(this, username, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Set the current profiling level of MongoDB\n   *\n   * @param level - The new profiling level (off, slow_only, all).\n   * @param options - Optional settings for the command\n   */\n  async setProfilingLevel(\n    level: ProfilingLevel,\n    options?: SetProfilingLevelOptions\n  ): Promise<ProfilingLevel> {\n    return await executeOperation(\n      this.client,\n      new SetProfilingLevelOperation(this, level, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Retrieve the current profiling Level for MongoDB\n   *\n   * @param options - Optional settings for the command\n   */\n  async profilingLevel(options?: ProfilingLevelOptions): Promise<string> {\n    return await executeOperation(\n      this.client,\n      new ProfilingLevelOperation(this, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Retrieves this collections index info.\n   *\n   * @param name - The name of the collection.\n   * @param options - Optional settings for the command\n   */\n  indexInformation(\n    name: string,\n    options: IndexInformationOptions & { full: true }\n  ): Promise<IndexDescriptionInfo[]>;\n  indexInformation(\n    name: string,\n    options: IndexInformationOptions & { full?: false }\n  ): Promise<IndexDescriptionCompact>;\n  indexInformation(\n    name: string,\n    options: IndexInformationOptions\n  ): Promise<IndexDescriptionCompact | IndexDescriptionInfo[]>;\n  indexInformation(name: string): Promise<IndexDescriptionCompact>;\n  async indexInformation(\n    name: string,\n    options?: IndexInformationOptions\n  ): Promise<IndexDescriptionCompact | IndexDescriptionInfo[]> {\n    return await this.collection(name).indexInformation(resolveOptions(this, options));\n  }\n\n  /**\n   * Create a new Change Stream, watching for new changes (insertions, updates,\n   * replacements, deletions, and invalidations) in this database. Will ignore all\n   * changes to system collections.\n   *\n   * @remarks\n   * watch() accepts two generic arguments for distinct use cases:\n   * - The first is to provide the schema that may be defined for all the collections within this database\n   * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n   *\n   * @remarks\n   * When `timeoutMS` is configured for a change stream, it will have different behaviour depending\n   * on whether the change stream is in iterator mode or emitter mode. In both cases, a change\n   * stream will time out if it does not receive a change event within `timeoutMS` of the last change\n   * event.\n   *\n   * Note that if a change stream is consistently timing out when watching a collection, database or\n   * client that is being changed, then this may be due to the server timing out before it can finish\n   * processing the existing oplog. To address this, restart the change stream with a higher\n   * `timeoutMS`.\n   *\n   * If the change stream times out the initial aggregate operation to establish the change stream on\n   * the server, then the client will close the change stream. If the getMore calls to the server\n   * time out, then the change stream will be left open, but will throw a MongoOperationTimeoutError\n   * when in iterator mode and emit an error event that returns a MongoOperationTimeoutError in\n   * emitter mode.\n   *\n   * To determine whether or not the change stream is still open following a timeout, check the\n   * {@link ChangeStream.closed} getter.\n   *\n   * @example\n   * In iterator mode, if a next() call throws a timeout error, it will attempt to resume the change stream.\n   * The next call can just be retried after this succeeds.\n   * ```ts\n   * const changeStream = collection.watch([], { timeoutMS: 100 });\n   * try {\n   *     await changeStream.next();\n   * } catch (e) {\n   *     if (e instanceof MongoOperationTimeoutError && !changeStream.closed) {\n   *       await changeStream.next();\n   *     }\n   *     throw e;\n   * }\n   * ```\n   *\n   * @example\n   * In emitter mode, if the change stream goes `timeoutMS` without emitting a change event, it will\n   * emit an error event that returns a MongoOperationTimeoutError, but will not close the change\n   * stream unless the resume attempt fails. There is no need to re-establish change listeners as\n   * this will automatically continue emitting change events once the resume attempt completes.\n   *\n   * ```ts\n   * const changeStream = collection.watch([], { timeoutMS: 100 });\n   * changeStream.on('change', console.log);\n   * changeStream.on('error', e => {\n   *     if (e instanceof MongoOperationTimeoutError && !changeStream.closed) {\n   *         // do nothing\n   *     } else {\n   *         changeStream.close();\n   *     }\n   * });\n   * ```\n   * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n   * @param options - Optional settings for the command\n   * @typeParam TSchema - Type of the data being detected by the change stream\n   * @typeParam TChange - Type of the whole change stream document emitted\n   */\n  watch<\n    TSchema extends Document = Document,\n    TChange extends Document = ChangeStreamDocument<TSchema>\n  >(pipeline: Document[] = [], options: ChangeStreamOptions = {}): ChangeStream<TSchema, TChange> {\n    // Allow optionally not specifying a pipeline\n    if (!Array.isArray(pipeline)) {\n      options = pipeline;\n      pipeline = [];\n    }\n\n    return new ChangeStream<TSchema, TChange>(this, pipeline, resolveOptions(this, options));\n  }\n\n  /**\n   * A low level cursor API providing basic driver functionality:\n   * - ClientSession management\n   * - ReadPreference for server selection\n   * - Running getMores automatically when a local batch is exhausted\n   *\n   * @param command - The command that will start a cursor on the server.\n   * @param options - Configurations for running the command, bson options will apply to getMores\n   */\n  runCursorCommand(command: Document, options?: RunCursorCommandOptions): RunCommandCursor {\n    return new RunCommandCursor(this, command, options);\n  }\n}\n"],"names":[],"mappings":";;;;;AAAA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAIA,MAAA;AACA,MAAA;AAIA,MAAA;AAMA,MAAA;AACA,MAAA;AASA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAKA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAEA,qBAAqB;AACrB,MAAM,wBAAwB;IAC5B;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;CACD;AAkCD;;;;;;;;;;;;;;;;;;;;;IAsBA,MAAa;IAcX;;;;;;;;QASA,YAAY,MAAmB,EAAE,YAAoB,EAAE,OAAmB,CAAA;QACxE,UAAU,WAAW,CAAA;QAErB,qBAAqB;QACrB,UAAU,CAAA,GAAA,QAAA,aAAa,EAAC,SAAS;QAEjC,4CAA4C;QAC5C,IAAI,OAAO,iBAAiB,YAAY,aAAa,QAAQ,CAAC,MAAM;YAClE,MAAM,IAAI,QAAA,yBAAyB,CAAC,CAAA,+CAAA,CAAiD;QACvF;QAEA,kCAAkC;QAClC,IAAI,CAAC,CAAC,GAAG;YACP,UAAU;YACV;YACA,yBAAyB;YACzB,gBAAgB,kBAAA,cAAc,CAAC,WAAW,CAAC;YAC3C,qBAAqB;YACrB,aAAa,CAAA,GAAA,OAAA,kBAAkB,EAAC,SAAS;YACzC,yDAAyD;YACzD,WAAW,SAAS,aAAa,QAAA,kBAAkB;YACnD,cAAc;YACd,aAAa,eAAA,WAAW,CAAC,WAAW,CAAC;YACrC,cAAc,gBAAA,YAAY,CAAC,WAAW,CAAC;YACvC,YAAY;YACZ,WAAW,IAAI,QAAA,gBAAgB,CAAC;;QAGlC,IAAI,CAAC,MAAM,GAAG;IAChB;IAEA,IAAI,eAAY;QACd,OAAO,IAAI,CAAC,CAAC,CAAC,SAAS,CAAC,EAAE;IAC5B;IAEA,UAAU;IACV,IAAI,UAAO;QACT,OAAO,IAAI,CAAC,CAAC,CAAC,OAAO;IACvB;IAEA;;QAGA,IAAI,cAAW;QACb,OAAO,IAAI,CAAC,CAAC,CAAC,cAAc,EAAE,eAAe,aAAa;IAC5D;IAEA,IAAI,cAAW;QACb,OAAO,IAAI,CAAC,CAAC,CAAC,WAAW;IAC3B;IAEA;;;QAIA,IAAI,iBAAc;QAChB,IAAI,IAAI,CAAC,CAAC,CAAC,cAAc,IAAI,MAAM;YACjC,OAAO,IAAI,CAAC,MAAM,CAAC,cAAc;QACnC;QAEA,OAAO,IAAI,CAAC,CAAC,CAAC,cAAc;IAC9B;IAEA,IAAI,cAAW;QACb,OAAO,IAAI,CAAC,CAAC,CAAC,WAAW;IAC3B;IAEA,wBAAwB;IACxB,IAAI,eAAY;QACd,OAAO,IAAI,CAAC,CAAC,CAAC,YAAY;IAC5B;IAEA,IAAI,YAAS;QACX,OAAO,IAAI,CAAC,CAAC,CAAC,SAAS,CAAC,QAAQ;IAClC;IAEA,IAAW,YAAS;QAClB,OAAO,IAAI,CAAC,CAAC,CAAC,OAAO,EAAE;IACzB;IAEA;;;;;;;;QASA,MAAM,iBACJ,IAAY,EACZ,OAAiC,EAAA;QAEjC,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,oBAAA,yBAAyB,CAAC,IAAI,EAAE,MAAM,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAEnE;IAEA;;;;;;;;;;;;;;;;;;;;;;;;QAyBA,MAAM,QAAQ,OAAiB,EAAE,OAAuC,EAAA;QACtE,2EAA2E;QAC3E,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,cAAA,mBAAmB,CACrB,IAAI,EACJ,SACA,CAAA,GAAA,QAAA,cAAc,EAAC,WAAW;YACxB,GAAG,CAAA,GAAA,OAAA,kBAAkB,EAAC,QAAQ;YAC9B,WAAW,SAAS,aAAa,IAAI,CAAC,SAAS;YAC/C,SAAS,SAAS;YAClB,gBAAgB,SAAS;YACzB,QAAQ,SAAS;;IAIzB;IAEA;;;;;QAMA,UACE,WAAuB,EAAE,EACzB,OAA0B,EAAA;QAE1B,OAAO,IAAI,qBAAA,iBAAiB,CAC1B,IAAI,CAAC,MAAM,EACX,IAAI,CAAC,CAAC,CAAC,SAAS,EAChB,UACA,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAEzB;IAEA,iCAAA,GACA,QAAK;QACH,OAAO,IAAI,QAAA,KAAK,CAAC,IAAI;IACvB;IAEA;;;;;;;QAQA,WACE,IAAY,EACZ,UAA6B,CAAA,CAAE,EAAA;QAE/B,IAAI,OAAO,YAAY,YAAY;YACjC,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QACA,OAAO,IAAI,aAAA,UAAU,CAAU,IAAI,EAAE,MAAM,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAClE;IAEA;;;;QAKA,MAAM,MAAM,OAAwB,EAAA;QAClC,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,QAAA,gBAAgB,CAAC,IAAI,EAAE,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAEpD;IAqBA,gBAKE,SAAmB,CAAA,CAAE,EACrB,UAA8C,CAAA,CAAE,EAAA;QAEhD,OAAO,IAAI,0BAAA,qBAAqB,CAAI,IAAI,EAAE,QAAQ,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IACzE;IAEA;;;;;;;;;QAUA,MAAM,iBACJ,cAAsB,EACtB,YAAoB,EACpB,OAAuB,EAAA;QAEvB,2EAA2E;QAC3E,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,SAAA,eAAe,CACjB,IAAI,CAAC,UAAU,CAAU,iBACzB,cACA,CAAA,GAAA,QAAA,cAAc,EAAC,WAAW;YACxB,GAAG,OAAO;YACV,gBAAgB;YAChB,gBAAgB,kBAAA,cAAc,CAAC,OAAO;;IAI9C;IAEA;;;;;QAMA,MAAM,eAAe,IAAY,EAAE,OAA+B,EAAA;QAChE,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,OAAA,uBAAuB,CAAC,IAAI,EAAE,MAAM,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAEjE;IAEA;;;;QAKA,MAAM,aAAa,OAA6B,EAAA;QAC9C,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,OAAA,qBAAqB,CAAC,IAAI,EAAE,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAEzD;IAEA;;;;QAKA,MAAM,YAAY,OAAgC,EAAA;QAChD,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,cAAA,oBAAoB,CAAC,IAAI,EAAE,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAExD;IAEA;;;;;;QAOA,MAAM,YACJ,IAAY,EACZ,SAA6B,EAC7B,OAA8B,EAAA;QAE9B,MAAM,UAAU,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EACpC,IAAI,CAAC,MAAM,EACX,UAAA,sBAAsB,CAAC,sBAAsB,CAAC,IAAI,EAAE,MAAM,WAAW;QAEvE,OAAO,OAAO,CAAC,EAAE;IACnB;IAEA;;;;;QAMA,MAAM,WAAW,QAAgB,EAAE,OAA2B,EAAA;QAC5D,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,cAAA,mBAAmB,CAAC,IAAI,EAAE,UAAU,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAEjE;IAEA;;;;;QAMA,MAAM,kBACJ,KAAqB,EACrB,OAAkC,EAAA;QAElC,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,sBAAA,0BAA0B,CAAC,IAAI,EAAE,OAAO,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAErE;IAEA;;;;QAKA,MAAM,eAAe,OAA+B,EAAA;QAClD,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,MAAM,EACX,IAAI,kBAAA,uBAAuB,CAAC,IAAI,EAAE,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAE3D;IAqBA,MAAM,iBACJ,IAAY,EACZ,OAAiC,EAAA;QAEjC,OAAO,MAAM,IAAI,CAAC,UAAU,CAAC,MAAM,gBAAgB,CAAC,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IAC3E;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;QAmEA,MAGE,WAAuB,EAAE,EAAE,UAA+B,CAAA,CAAE,EAAA;QAC5D,6CAA6C;QAC7C,IAAI,CAAC,MAAM,OAAO,CAAC,WAAW;YAC5B,UAAU;YACV,WAAW,EAAE;QACf;QAEA,OAAO,IAAI,gBAAA,YAAY,CAAmB,IAAI,EAAE,UAAU,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IACjF;IAEA;;;;;;;;QASA,iBAAiB,OAAiB,EAAE,OAAiC,EAAA;QACnE,OAAO,IAAI,qBAAA,gBAAgB,CAAC,IAAI,EAAE,SAAS;IAC7C;;AA5eF,QAAA,EAAA,GAAA;AAOgB,GAAA,2BAA2B,GAAG,UAAU,2BAA2B;AACnE,GAAA,uBAAuB,GAAG,UAAU,uBAAuB;AAC3D,GAAA,yBAAyB,GAAG,UAAU,yBAAyB;AAC/D,GAAA,sBAAsB,GAAG,UAAU,sBAAsB;AACzD,GAAA,yBAAyB,GAAG,UAAU,yBAAyB;AAC/D,GAAA,oBAAoB,GAAG,UAAU,oBAAoB"}},
    {"offset": {"line": 8039, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 8043, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/change_stream.ts"],"sourcesContent":["import type { Readable } from 'stream';\n\nimport type { Binary, Document, Timestamp } from './bson';\nimport { Collection } from './collection';\nimport { CHANGE, CLOSE, END, ERROR, INIT, MORE, RESPONSE, RESUME_TOKEN_CHANGED } from './constants';\nimport { type CursorStreamOptions, CursorTimeoutContext } from './cursor/abstract_cursor';\nimport { ChangeStreamCursor, type ChangeStreamCursorOptions } from './cursor/change_stream_cursor';\nimport { Db } from './db';\nimport {\n  type AnyError,\n  isResumableError,\n  MongoAPIError,\n  MongoChangeStreamError,\n  MongoOperationTimeoutError,\n  MongoRuntimeError\n} from './error';\nimport { MongoClient } from './mongo_client';\nimport { type InferIdType, TypedEventEmitter } from './mongo_types';\nimport type { AggregateOptions } from './operations/aggregate';\nimport type { CollationOptions, OperationParent } from './operations/command';\nimport type { ReadPreference } from './read_preference';\nimport { type AsyncDisposable, configureResourceManagement } from './resource_management';\nimport type { ServerSessionId } from './sessions';\nimport { CSOTTimeoutContext, type TimeoutContext } from './timeout';\nimport { filterOptions, getTopology, type MongoDBNamespace, squashError } from './utils';\n\nconst CHANGE_STREAM_OPTIONS = [\n  'resumeAfter',\n  'startAfter',\n  'startAtOperationTime',\n  'fullDocument',\n  'fullDocumentBeforeChange',\n  'showExpandedEvents'\n] as const;\n\nconst CHANGE_DOMAIN_TYPES = {\n  COLLECTION: Symbol('Collection'),\n  DATABASE: Symbol('Database'),\n  CLUSTER: Symbol('Cluster')\n};\n\nconst CHANGE_STREAM_EVENTS = [RESUME_TOKEN_CHANGED, END, CLOSE] as const;\n\nconst NO_RESUME_TOKEN_ERROR =\n  'A change stream document has been received that lacks a resume token (_id).';\nconst CHANGESTREAM_CLOSED_ERROR = 'ChangeStream is closed';\n\n/**\n * @public\n * @deprecated Please use the ChangeStreamCursorOptions type instead.\n */\nexport interface ResumeOptions {\n  startAtOperationTime?: Timestamp;\n  batchSize?: number;\n  maxAwaitTimeMS?: number;\n  collation?: CollationOptions;\n  readPreference?: ReadPreference;\n  resumeAfter?: ResumeToken;\n  startAfter?: ResumeToken;\n  fullDocument?: string;\n}\n\n/**\n * Represents the logical starting point for a new ChangeStream or resuming a ChangeStream on the server.\n * @see https://www.mongodb.com/docs/manual/changeStreams/#std-label-change-stream-resume\n * @public\n */\nexport type ResumeToken = unknown;\n\n/**\n * Represents a specific point in time on a server. Can be retrieved by using `db.command()`\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/method/db.runCommand/#response\n */\nexport type OperationTime = Timestamp;\n\n/**\n * Options that can be passed to a ChangeStream. Note that startAfter, resumeAfter, and startAtOperationTime are all mutually exclusive, and the server will error if more than one is specified.\n * @public\n */\nexport interface ChangeStreamOptions extends Omit<AggregateOptions, 'writeConcern'> {\n  /**\n   * Allowed values: 'updateLookup', 'whenAvailable', 'required'.\n   *\n   * When set to 'updateLookup', the change notification for partial updates\n   * will include both a delta describing the changes to the document as well\n   * as a copy of the entire document that was changed from some time after\n   * the change occurred.\n   *\n   * When set to 'whenAvailable', configures the change stream to return the\n   * post-image of the modified document for replace and update change events\n   * if the post-image for this event is available.\n   *\n   * When set to 'required', the same behavior as 'whenAvailable' except that\n   * an error is raised if the post-image is not available.\n   */\n  fullDocument?: string;\n\n  /**\n   * Allowed values: 'whenAvailable', 'required', 'off'.\n   *\n   * The default is to not send a value, which is equivalent to 'off'.\n   *\n   * When set to 'whenAvailable', configures the change stream to return the\n   * pre-image of the modified document for replace, update, and delete change\n   * events if it is available.\n   *\n   * When set to 'required', the same behavior as 'whenAvailable' except that\n   * an error is raised if the pre-image is not available.\n   */\n  fullDocumentBeforeChange?: string;\n  /** The maximum amount of time for the server to wait on new documents to satisfy a change stream query. */\n  maxAwaitTimeMS?: number;\n  /**\n   * Allows you to start a changeStream after a specified event.\n   * @see https://www.mongodb.com/docs/manual/changeStreams/#resumeafter-for-change-streams\n   */\n  resumeAfter?: ResumeToken;\n  /**\n   * Similar to resumeAfter, but will allow you to start after an invalidated event.\n   * @see https://www.mongodb.com/docs/manual/changeStreams/#startafter-for-change-streams\n   */\n  startAfter?: ResumeToken;\n  /** Will start the changeStream after the specified operationTime. */\n  startAtOperationTime?: OperationTime;\n  /**\n   * The number of documents to return per batch.\n   * @see https://www.mongodb.com/docs/manual/reference/command/aggregate\n   */\n  batchSize?: number;\n\n  /**\n   * When enabled, configures the change stream to include extra change events.\n   *\n   * - createIndexes\n   * - dropIndexes\n   * - modify\n   * - create\n   * - shardCollection\n   * - reshardCollection\n   * - refineCollectionShardKey\n   */\n  showExpandedEvents?: boolean;\n}\n\n/** @public */\nexport interface ChangeStreamNameSpace {\n  db: string;\n  coll: string;\n}\n\n/** @public */\nexport interface ChangeStreamDocumentKey<TSchema extends Document = Document> {\n  /**\n   * For unsharded collections this contains a single field `_id`.\n   * For sharded collections, this will contain all the components of the shard key\n   */\n  documentKey: { _id: InferIdType<TSchema>; [shardKey: string]: any };\n}\n\n/** @public */\nexport interface ChangeStreamSplitEvent {\n  /** Which fragment of the change this is. */\n  fragment: number;\n  /** The total number of fragments. */\n  of: number;\n}\n\n/** @public */\nexport interface ChangeStreamDocumentCommon {\n  /**\n   * The id functions as an opaque token for use when resuming an interrupted\n   * change stream.\n   */\n  _id: ResumeToken;\n  /**\n   * The timestamp from the oplog entry associated with the event.\n   * For events that happened as part of a multi-document transaction, the associated change stream\n   * notifications will have the same clusterTime value, namely the time when the transaction was committed.\n   * On a sharded cluster, events that occur on different shards can have the same clusterTime but be\n   * associated with different transactions or even not be associated with any transaction.\n   * To identify events for a single transaction, you can use the combination of lsid and txnNumber in the change stream event document.\n   */\n  clusterTime?: Timestamp;\n\n  /**\n   * The transaction number.\n   * Only present if the operation is part of a multi-document transaction.\n   *\n   * **NOTE:** txnNumber can be a Long if promoteLongs is set to false\n   */\n  txnNumber?: number;\n\n  /**\n   * The identifier for the session associated with the transaction.\n   * Only present if the operation is part of a multi-document transaction.\n   */\n  lsid?: ServerSessionId;\n\n  /**\n   * When the change stream's backing aggregation pipeline contains the $changeStreamSplitLargeEvent\n   * stage, events larger than 16MB will be split into multiple events and contain the\n   * following information about which fragment the current event is.\n   */\n  splitEvent?: ChangeStreamSplitEvent;\n}\n\n/** @public */\nexport interface ChangeStreamDocumentCollectionUUID {\n  /**\n   * The UUID (Binary subtype 4) of the collection that the operation was performed on.\n   *\n   * Only present when the `showExpandedEvents` flag is enabled.\n   *\n   * **NOTE:** collectionUUID will be converted to a NodeJS Buffer if the promoteBuffers\n   *    flag is enabled.\n   *\n   * @sinceServerVersion 6.1.0\n   */\n  collectionUUID: Binary;\n}\n\n/** @public */\nexport interface ChangeStreamDocumentOperationDescription {\n  /**\n   * An description of the operation.\n   *\n   * Only present when the `showExpandedEvents` flag is enabled.\n   *\n   * @sinceServerVersion 6.1.0\n   */\n  operationDescription?: Document;\n}\n\n/**\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/change-events/#insert-event\n */\nexport interface ChangeStreamInsertDocument<TSchema extends Document = Document>\n  extends ChangeStreamDocumentCommon,\n    ChangeStreamDocumentKey<TSchema>,\n    ChangeStreamDocumentCollectionUUID {\n  /** Describes the type of operation represented in this change notification */\n  operationType: 'insert';\n  /** This key will contain the document being inserted */\n  fullDocument: TSchema;\n  /** Namespace the insert event occurred on */\n  ns: ChangeStreamNameSpace;\n}\n\n/**\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/change-events/#update-event\n */\nexport interface ChangeStreamUpdateDocument<TSchema extends Document = Document>\n  extends ChangeStreamDocumentCommon,\n    ChangeStreamDocumentKey<TSchema>,\n    ChangeStreamDocumentCollectionUUID {\n  /** Describes the type of operation represented in this change notification */\n  operationType: 'update';\n  /**\n   * This is only set if `fullDocument` is set to `'updateLookup'`\n   * Contains the point-in-time post-image of the modified document if the\n   * post-image is available and either 'required' or 'whenAvailable' was\n   * specified for the 'fullDocument' option when creating the change stream.\n   */\n  fullDocument?: TSchema;\n  /** Contains a description of updated and removed fields in this operation */\n  updateDescription: UpdateDescription<TSchema>;\n  /** Namespace the update event occurred on */\n  ns: ChangeStreamNameSpace;\n  /**\n   * Contains the pre-image of the modified or deleted document if the\n   * pre-image is available for the change event and either 'required' or\n   * 'whenAvailable' was specified for the 'fullDocumentBeforeChange' option\n   * when creating the change stream. If 'whenAvailable' was specified but the\n   * pre-image is unavailable, this will be explicitly set to null.\n   */\n  fullDocumentBeforeChange?: TSchema;\n}\n\n/**\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/change-events/#replace-event\n */\nexport interface ChangeStreamReplaceDocument<TSchema extends Document = Document>\n  extends ChangeStreamDocumentCommon,\n    ChangeStreamDocumentKey<TSchema> {\n  /** Describes the type of operation represented in this change notification */\n  operationType: 'replace';\n  /** The fullDocument of a replace event represents the document after the insert of the replacement document */\n  fullDocument: TSchema;\n  /** Namespace the replace event occurred on */\n  ns: ChangeStreamNameSpace;\n  /**\n   * Contains the pre-image of the modified or deleted document if the\n   * pre-image is available for the change event and either 'required' or\n   * 'whenAvailable' was specified for the 'fullDocumentBeforeChange' option\n   * when creating the change stream. If 'whenAvailable' was specified but the\n   * pre-image is unavailable, this will be explicitly set to null.\n   */\n  fullDocumentBeforeChange?: TSchema;\n}\n\n/**\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/change-events/#delete-event\n */\nexport interface ChangeStreamDeleteDocument<TSchema extends Document = Document>\n  extends ChangeStreamDocumentCommon,\n    ChangeStreamDocumentKey<TSchema>,\n    ChangeStreamDocumentCollectionUUID {\n  /** Describes the type of operation represented in this change notification */\n  operationType: 'delete';\n  /** Namespace the delete event occurred on */\n  ns: ChangeStreamNameSpace;\n  /**\n   * Contains the pre-image of the modified or deleted document if the\n   * pre-image is available for the change event and either 'required' or\n   * 'whenAvailable' was specified for the 'fullDocumentBeforeChange' option\n   * when creating the change stream. If 'whenAvailable' was specified but the\n   * pre-image is unavailable, this will be explicitly set to null.\n   */\n  fullDocumentBeforeChange?: TSchema;\n}\n\n/**\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/change-events/#drop-event\n */\nexport interface ChangeStreamDropDocument\n  extends ChangeStreamDocumentCommon,\n    ChangeStreamDocumentCollectionUUID {\n  /** Describes the type of operation represented in this change notification */\n  operationType: 'drop';\n  /** Namespace the drop event occurred on */\n  ns: ChangeStreamNameSpace;\n}\n\n/**\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/change-events/#rename-event\n */\nexport interface ChangeStreamRenameDocument\n  extends ChangeStreamDocumentCommon,\n    ChangeStreamDocumentCollectionUUID {\n  /** Describes the type of operation represented in this change notification */\n  operationType: 'rename';\n  /** The new name for the `ns.coll` collection */\n  to: { db: string; coll: string };\n  /** The \"from\" namespace that the rename occurred on */\n  ns: ChangeStreamNameSpace;\n}\n\n/**\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/change-events/#dropdatabase-event\n */\nexport interface ChangeStreamDropDatabaseDocument extends ChangeStreamDocumentCommon {\n  /** Describes the type of operation represented in this change notification */\n  operationType: 'dropDatabase';\n  /** The database dropped */\n  ns: { db: string };\n}\n\n/**\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/change-events/#invalidate-event\n */\nexport interface ChangeStreamInvalidateDocument extends ChangeStreamDocumentCommon {\n  /** Describes the type of operation represented in this change notification */\n  operationType: 'invalidate';\n}\n\n/**\n * Only present when the `showExpandedEvents` flag is enabled.\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/change-events/createIndexes/#mongodb-data-createIndexes\n */\nexport interface ChangeStreamCreateIndexDocument\n  extends ChangeStreamDocumentCommon,\n    ChangeStreamDocumentCollectionUUID,\n    ChangeStreamDocumentOperationDescription {\n  /** Describes the type of operation represented in this change notification */\n  operationType: 'createIndexes';\n}\n\n/**\n * Only present when the `showExpandedEvents` flag is enabled.\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/change-events/dropIndexes/#mongodb-data-dropIndexes\n */\nexport interface ChangeStreamDropIndexDocument\n  extends ChangeStreamDocumentCommon,\n    ChangeStreamDocumentCollectionUUID,\n    ChangeStreamDocumentOperationDescription {\n  /** Describes the type of operation represented in this change notification */\n  operationType: 'dropIndexes';\n}\n\n/**\n * Only present when the `showExpandedEvents` flag is enabled.\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/change-events/modify/#mongodb-data-modify\n */\nexport interface ChangeStreamCollModDocument\n  extends ChangeStreamDocumentCommon,\n    ChangeStreamDocumentCollectionUUID {\n  /** Describes the type of operation represented in this change notification */\n  operationType: 'modify';\n}\n\n/**\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/change-events/create/#mongodb-data-create\n */\nexport interface ChangeStreamCreateDocument\n  extends ChangeStreamDocumentCommon,\n    ChangeStreamDocumentCollectionUUID {\n  /** Describes the type of operation represented in this change notification */\n  operationType: 'create';\n\n  /**\n   * The type of the newly created object.\n   *\n   * @sinceServerVersion 8.1.0\n   */\n  nsType?: 'collection' | 'timeseries' | 'view';\n}\n\n/**\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/change-events/shardCollection/#mongodb-data-shardCollection\n */\nexport interface ChangeStreamShardCollectionDocument\n  extends ChangeStreamDocumentCommon,\n    ChangeStreamDocumentCollectionUUID,\n    ChangeStreamDocumentOperationDescription {\n  /** Describes the type of operation represented in this change notification */\n  operationType: 'shardCollection';\n}\n\n/**\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/change-events/reshardCollection/#mongodb-data-reshardCollection\n */\nexport interface ChangeStreamReshardCollectionDocument\n  extends ChangeStreamDocumentCommon,\n    ChangeStreamDocumentCollectionUUID,\n    ChangeStreamDocumentOperationDescription {\n  /** Describes the type of operation represented in this change notification */\n  operationType: 'reshardCollection';\n}\n\n/**\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/change-events/refineCollectionShardKey/#mongodb-data-refineCollectionShardKey\n */\nexport interface ChangeStreamRefineCollectionShardKeyDocument\n  extends ChangeStreamDocumentCommon,\n    ChangeStreamDocumentCollectionUUID,\n    ChangeStreamDocumentOperationDescription {\n  /** Describes the type of operation represented in this change notification */\n  operationType: 'refineCollectionShardKey';\n}\n\n/** @public */\nexport type ChangeStreamDocument<TSchema extends Document = Document> =\n  | ChangeStreamInsertDocument<TSchema>\n  | ChangeStreamUpdateDocument<TSchema>\n  | ChangeStreamReplaceDocument<TSchema>\n  | ChangeStreamDeleteDocument<TSchema>\n  | ChangeStreamDropDocument\n  | ChangeStreamRenameDocument\n  | ChangeStreamDropDatabaseDocument\n  | ChangeStreamInvalidateDocument\n  | ChangeStreamCreateIndexDocument\n  | ChangeStreamCreateDocument\n  | ChangeStreamCollModDocument\n  | ChangeStreamDropIndexDocument\n  | ChangeStreamShardCollectionDocument\n  | ChangeStreamReshardCollectionDocument\n  | ChangeStreamRefineCollectionShardKeyDocument;\n\n/** @public */\nexport interface UpdateDescription<TSchema extends Document = Document> {\n  /**\n   * A document containing key:value pairs of names of the fields that were\n   * changed, and the new value for those fields.\n   */\n  updatedFields?: Partial<TSchema>;\n\n  /**\n   * An array of field names that were removed from the document.\n   */\n  removedFields?: string[];\n\n  /**\n   * An array of documents which record array truncations performed with pipeline-based updates using one or more of the following stages:\n   * - $addFields\n   * - $set\n   * - $replaceRoot\n   * - $replaceWith\n   */\n  truncatedArrays?: Array<{\n    /** The name of the truncated field. */\n    field: string;\n    /** The number of elements in the truncated array. */\n    newSize: number;\n  }>;\n\n  /**\n   * A document containing additional information about any ambiguous update paths from the update event.  The document\n   * maps the full ambiguous update path to an array containing the actual resolved components of the path.  For example,\n   * given a document shaped like `{ a: { '0': 0 } }`, and an update of `{ $inc: 'a.0' }`, disambiguated paths would look like\n   * the following:\n   *\n   * ```\n   *   {\n   *     'a.0': ['a', '0']\n   *   }\n   * ```\n   *\n   * This field is only present when there are ambiguous paths that are updated as a part of the update event.\n   *\n   * On \\<8.2.0 servers, this field is only present when `showExpandedEvents` is set to true.\n   * is enabled for the change stream.\n   *\n   * On 8.2.0+ servers, this field is present for update events regardless of whether `showExpandedEvents` is enabled.\n   * @sinceServerVersion 6.1.0\n   */\n  disambiguatedPaths?: Document;\n}\n\n/** @public */\nexport type ChangeStreamEvents<\n  TSchema extends Document = Document,\n  TChange extends Document = ChangeStreamDocument<TSchema>\n> = {\n  resumeTokenChanged(token: ResumeToken): void;\n  init(response: any): void;\n  more(response?: any): void;\n  response(): void;\n  end(): void;\n  error(error: Error): void;\n  change(change: TChange): void;\n  /**\n   * @remarks Note that the `close` event is currently emitted whenever the internal `ChangeStreamCursor`\n   * instance is closed, which can occur multiple times for a given `ChangeStream` instance.\n   *\n   * TODO(NODE-6434): address this issue in NODE-6434\n   */\n  close(): void;\n};\n\n/**\n * Creates a new Change Stream instance. Normally created using {@link Collection#watch|Collection.watch()}.\n * @public\n */\nexport class ChangeStream<\n    TSchema extends Document = Document,\n    TChange extends Document = ChangeStreamDocument<TSchema>\n  >\n  extends TypedEventEmitter<ChangeStreamEvents<TSchema, TChange>>\n  implements AsyncDisposable\n{\n  /**\n   * @beta\n   * @experimental\n   * An alias for {@link ChangeStream.close|ChangeStream.close()}.\n   */\n  declare [Symbol.asyncDispose]: () => Promise<void>;\n  /** @internal */\n  async asyncDispose() {\n    await this.close();\n  }\n\n  pipeline: Document[];\n  /**\n   * @remarks WriteConcern can still be present on the options because\n   * we inherit options from the client/db/collection.  The\n   * key must be present on the options in order to delete it.\n   * This allows typescript to delete the key but will\n   * not allow a writeConcern to be assigned as a property on options.\n   */\n  options: ChangeStreamOptions & { writeConcern?: never };\n  parent: MongoClient | Db | Collection;\n  namespace: MongoDBNamespace;\n  type: symbol;\n  /** @internal */\n  private cursor: ChangeStreamCursor<TSchema, TChange>;\n  streamOptions?: CursorStreamOptions;\n  /** @internal */\n  private cursorStream?: Readable & AsyncIterable<TChange>;\n  /** @internal */\n  private isClosed: boolean;\n  /** @internal */\n  private mode: false | 'iterator' | 'emitter';\n\n  /** @event */\n  static readonly RESPONSE = RESPONSE;\n  /** @event */\n  static readonly MORE = MORE;\n  /** @event */\n  static readonly INIT = INIT;\n  /** @event */\n  static readonly CLOSE = CLOSE;\n  /**\n   * Fired for each new matching change in the specified namespace. Attaching a `change`\n   * event listener to a Change Stream will switch the stream into flowing mode. Data will\n   * then be passed as soon as it is available.\n   * @event\n   */\n  static readonly CHANGE = CHANGE;\n  /** @event */\n  static readonly END = END;\n  /** @event */\n  static readonly ERROR = ERROR;\n  /**\n   * Emitted each time the change stream stores a new resume token.\n   * @event\n   */\n  static readonly RESUME_TOKEN_CHANGED = RESUME_TOKEN_CHANGED;\n\n  private timeoutContext?: TimeoutContext;\n  /**\n   * Note that this property is here to uniquely identify a ChangeStream instance as the owner of\n   * the {@link CursorTimeoutContext} instance (see {@link ChangeStream._createChangeStreamCursor}) to ensure\n   * that {@link AbstractCursor.close} does not mutate the timeoutContext.\n   */\n  private contextOwner: symbol;\n  /**\n   * @internal\n   *\n   * @param parent - The parent object that created this change stream\n   * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents\n   */\n  constructor(\n    parent: OperationParent,\n    pipeline: Document[] = [],\n    options: ChangeStreamOptions = {}\n  ) {\n    super();\n\n    this.pipeline = pipeline;\n    this.options = { ...options };\n    let serverSelectionTimeoutMS: number;\n    delete this.options.writeConcern;\n\n    if (parent instanceof Collection) {\n      this.type = CHANGE_DOMAIN_TYPES.COLLECTION;\n      serverSelectionTimeoutMS = parent.s.db.client.options.serverSelectionTimeoutMS;\n    } else if (parent instanceof Db) {\n      this.type = CHANGE_DOMAIN_TYPES.DATABASE;\n      serverSelectionTimeoutMS = parent.client.options.serverSelectionTimeoutMS;\n    } else if (parent instanceof MongoClient) {\n      this.type = CHANGE_DOMAIN_TYPES.CLUSTER;\n      serverSelectionTimeoutMS = parent.options.serverSelectionTimeoutMS;\n    } else {\n      throw new MongoChangeStreamError(\n        'Parent provided to ChangeStream constructor must be an instance of Collection, Db, or MongoClient'\n      );\n    }\n\n    this.contextOwner = Symbol();\n    this.parent = parent;\n    this.namespace = parent.s.namespace;\n    if (!this.options.readPreference && parent.readPreference) {\n      this.options.readPreference = parent.readPreference;\n    }\n\n    // Create contained Change Stream cursor\n    this.cursor = this._createChangeStreamCursor(options);\n\n    this.isClosed = false;\n    this.mode = false;\n\n    // Listen for any `change` listeners being added to ChangeStream\n    this.on('newListener', eventName => {\n      if (eventName === 'change' && this.cursor && this.listenerCount('change') === 0) {\n        this._streamEvents(this.cursor);\n      }\n    });\n\n    this.on('removeListener', eventName => {\n      if (eventName === 'change' && this.listenerCount('change') === 0 && this.cursor) {\n        this.cursorStream?.removeAllListeners('data');\n      }\n    });\n\n    if (this.options.timeoutMS != null) {\n      this.timeoutContext = new CSOTTimeoutContext({\n        timeoutMS: this.options.timeoutMS,\n        serverSelectionTimeoutMS\n      });\n    }\n  }\n\n  /** The cached resume token that is used to resume after the most recently returned change. */\n  get resumeToken(): ResumeToken {\n    return this.cursor?.resumeToken;\n  }\n\n  /** Check if there is any document still available in the Change Stream */\n  async hasNext(): Promise<boolean> {\n    this._setIsIterator();\n    // Change streams must resume indefinitely while each resume event succeeds.\n    // This loop continues until either a change event is received or until a resume attempt\n    // fails.\n\n    this.timeoutContext?.refresh();\n    try {\n      while (true) {\n        try {\n          const hasNext = await this.cursor.hasNext();\n          return hasNext;\n        } catch (error) {\n          try {\n            await this._processErrorIteratorMode(error, this.cursor.id != null);\n          } catch (error) {\n            if (error instanceof MongoOperationTimeoutError && this.cursor.id == null) {\n              throw error;\n            }\n            try {\n              await this.close();\n            } catch (error) {\n              squashError(error);\n            }\n            throw error;\n          }\n        }\n      }\n    } finally {\n      this.timeoutContext?.clear();\n    }\n  }\n\n  /** Get the next available document from the Change Stream. */\n  async next(): Promise<TChange> {\n    this._setIsIterator();\n    // Change streams must resume indefinitely while each resume event succeeds.\n    // This loop continues until either a change event is received or until a resume attempt\n    // fails.\n    this.timeoutContext?.refresh();\n\n    try {\n      while (true) {\n        try {\n          const change = await this.cursor.next();\n          const processedChange = this._processChange(change ?? null);\n          return processedChange;\n        } catch (error) {\n          try {\n            await this._processErrorIteratorMode(error, this.cursor.id != null);\n          } catch (error) {\n            if (error instanceof MongoOperationTimeoutError && this.cursor.id == null) {\n              throw error;\n            }\n            try {\n              await this.close();\n            } catch (error) {\n              squashError(error);\n            }\n            throw error;\n          }\n        }\n      }\n    } finally {\n      this.timeoutContext?.clear();\n    }\n  }\n\n  /**\n   * Try to get the next available document from the Change Stream's cursor or `null` if an empty batch is returned\n   */\n  async tryNext(): Promise<TChange | null> {\n    this._setIsIterator();\n    // Change streams must resume indefinitely while each resume event succeeds.\n    // This loop continues until either a change event is received or until a resume attempt\n    // fails.\n    this.timeoutContext?.refresh();\n\n    try {\n      while (true) {\n        try {\n          const change = await this.cursor.tryNext();\n          return change ?? null;\n        } catch (error) {\n          try {\n            await this._processErrorIteratorMode(error, this.cursor.id != null);\n          } catch (error) {\n            if (error instanceof MongoOperationTimeoutError && this.cursor.id == null) throw error;\n            try {\n              await this.close();\n            } catch (error) {\n              squashError(error);\n            }\n            throw error;\n          }\n        }\n      }\n    } finally {\n      this.timeoutContext?.clear();\n    }\n  }\n\n  async *[Symbol.asyncIterator](): AsyncGenerator<TChange, void, void> {\n    if (this.closed) {\n      return;\n    }\n\n    try {\n      // Change streams run indefinitely as long as errors are resumable\n      // So the only loop breaking condition is if `next()` throws\n      while (true) {\n        yield await this.next();\n      }\n    } finally {\n      try {\n        await this.close();\n      } catch (error) {\n        squashError(error);\n      }\n    }\n  }\n\n  /** Is the cursor closed */\n  public get closed(): boolean {\n    return this.isClosed || this.cursor.closed;\n  }\n\n  /**\n   * Frees the internal resources used by the change stream.\n   */\n  async close(): Promise<void> {\n    this.timeoutContext?.clear();\n    this.timeoutContext = undefined;\n    this.isClosed = true;\n\n    const cursor = this.cursor;\n    try {\n      await cursor.close();\n    } finally {\n      this._endStream();\n    }\n  }\n\n  /**\n   * Return a modified Readable stream including a possible transform method.\n   *\n   * NOTE: When using a Stream to process change stream events, the stream will\n   * NOT automatically resume in the case a resumable error is encountered.\n   *\n   * @throws MongoChangeStreamError if the underlying cursor or the change stream is closed\n   */\n  stream(options?: CursorStreamOptions): Readable & AsyncIterable<TChange> {\n    if (this.closed) {\n      throw new MongoChangeStreamError(CHANGESTREAM_CLOSED_ERROR);\n    }\n\n    this.streamOptions = options;\n    return this.cursor.stream(options);\n  }\n\n  /** @internal */\n  private _setIsEmitter(): void {\n    if (this.mode === 'iterator') {\n      // TODO(NODE-3485): Replace with MongoChangeStreamModeError\n      throw new MongoAPIError(\n        'ChangeStream cannot be used as an EventEmitter after being used as an iterator'\n      );\n    }\n    this.mode = 'emitter';\n  }\n\n  /** @internal */\n  private _setIsIterator(): void {\n    if (this.mode === 'emitter') {\n      // TODO(NODE-3485): Replace with MongoChangeStreamModeError\n      throw new MongoAPIError(\n        'ChangeStream cannot be used as an iterator after being used as an EventEmitter'\n      );\n    }\n    this.mode = 'iterator';\n  }\n\n  /**\n   * Create a new change stream cursor based on self's configuration\n   * @internal\n   */\n  private _createChangeStreamCursor(\n    options: ChangeStreamOptions | ChangeStreamCursorOptions\n  ): ChangeStreamCursor<TSchema, TChange> {\n    const changeStreamStageOptions = filterOptions(options, CHANGE_STREAM_OPTIONS);\n    if (this.type === CHANGE_DOMAIN_TYPES.CLUSTER) {\n      changeStreamStageOptions.allChangesForCluster = true;\n    }\n    const pipeline = [{ $changeStream: changeStreamStageOptions }, ...this.pipeline];\n\n    const client: MongoClient | null =\n      this.type === CHANGE_DOMAIN_TYPES.CLUSTER\n        ? (this.parent as MongoClient)\n        : this.type === CHANGE_DOMAIN_TYPES.DATABASE\n          ? (this.parent as Db).client\n          : this.type === CHANGE_DOMAIN_TYPES.COLLECTION\n            ? (this.parent as Collection).client\n            : null;\n\n    if (client == null) {\n      // This should never happen because of the assertion in the constructor\n      throw new MongoRuntimeError(\n        `Changestream type should only be one of cluster, database, collection. Found ${this.type.toString()}`\n      );\n    }\n\n    const changeStreamCursor = new ChangeStreamCursor<TSchema, TChange>(\n      client,\n      this.namespace,\n      pipeline,\n      {\n        ...options,\n        timeoutContext: this.timeoutContext\n          ? new CursorTimeoutContext(this.timeoutContext, this.contextOwner)\n          : undefined\n      }\n    );\n\n    for (const event of CHANGE_STREAM_EVENTS) {\n      changeStreamCursor.on(event, e => this.emit(event, e));\n    }\n\n    if (this.listenerCount(ChangeStream.CHANGE) > 0) {\n      this._streamEvents(changeStreamCursor);\n    }\n\n    return changeStreamCursor;\n  }\n\n  /** @internal */\n  private _closeEmitterModeWithError(error: AnyError): void {\n    this.emit(ChangeStream.ERROR, error);\n\n    this.close().then(undefined, squashError);\n  }\n\n  /** @internal */\n  private _streamEvents(cursor: ChangeStreamCursor<TSchema, TChange>): void {\n    this._setIsEmitter();\n    const stream = this.cursorStream ?? cursor.stream();\n    this.cursorStream = stream;\n    stream.on('data', change => {\n      try {\n        const processedChange = this._processChange(change);\n        this.emit(ChangeStream.CHANGE, processedChange);\n      } catch (error) {\n        this.emit(ChangeStream.ERROR, error);\n      }\n      this.timeoutContext?.refresh();\n    });\n    stream.on('error', error => this._processErrorStreamMode(error, this.cursor.id != null));\n  }\n\n  /** @internal */\n  private _endStream(): void {\n    this.cursorStream?.removeAllListeners('data');\n    this.cursorStream?.removeAllListeners('close');\n    this.cursorStream?.removeAllListeners('end');\n    this.cursorStream?.destroy();\n    this.cursorStream = undefined;\n  }\n\n  /** @internal */\n  private _processChange(change: TChange | null): TChange {\n    if (this.isClosed) {\n      // TODO(NODE-3485): Replace with MongoChangeStreamClosedError\n      throw new MongoAPIError(CHANGESTREAM_CLOSED_ERROR);\n    }\n\n    // a null change means the cursor has been notified, implicitly closing the change stream\n    if (change == null) {\n      // TODO(NODE-3485): Replace with MongoChangeStreamClosedError\n      throw new MongoRuntimeError(CHANGESTREAM_CLOSED_ERROR);\n    }\n\n    if (change && !change._id) {\n      throw new MongoChangeStreamError(NO_RESUME_TOKEN_ERROR);\n    }\n\n    // cache the resume token\n    this.cursor.cacheResumeToken(change._id);\n\n    // wipe the startAtOperationTime if there was one so that there won't be a conflict\n    // between resumeToken and startAtOperationTime if we need to reconnect the cursor\n    this.options.startAtOperationTime = undefined;\n\n    return change;\n  }\n\n  /** @internal */\n  private _processErrorStreamMode(changeStreamError: AnyError, cursorInitialized: boolean) {\n    // If the change stream has been closed explicitly, do not process error.\n    if (this.isClosed) return;\n\n    if (\n      cursorInitialized &&\n      (isResumableError(changeStreamError, this.cursor.maxWireVersion) ||\n        changeStreamError instanceof MongoOperationTimeoutError)\n    ) {\n      this._endStream();\n\n      this.cursor\n        .close()\n        .then(\n          () => this._resume(changeStreamError),\n          e => {\n            squashError(e);\n            return this._resume(changeStreamError);\n          }\n        )\n        .then(\n          () => {\n            if (changeStreamError instanceof MongoOperationTimeoutError)\n              this.emit(ChangeStream.ERROR, changeStreamError);\n          },\n          () => this._closeEmitterModeWithError(changeStreamError)\n        );\n    } else {\n      this._closeEmitterModeWithError(changeStreamError);\n    }\n  }\n\n  /** @internal */\n  private async _processErrorIteratorMode(changeStreamError: AnyError, cursorInitialized: boolean) {\n    if (this.isClosed) {\n      // TODO(NODE-3485): Replace with MongoChangeStreamClosedError\n      throw new MongoAPIError(CHANGESTREAM_CLOSED_ERROR);\n    }\n\n    if (\n      cursorInitialized &&\n      (isResumableError(changeStreamError, this.cursor.maxWireVersion) ||\n        changeStreamError instanceof MongoOperationTimeoutError)\n    ) {\n      try {\n        await this.cursor.close();\n      } catch (error) {\n        squashError(error);\n      }\n\n      await this._resume(changeStreamError);\n\n      if (changeStreamError instanceof MongoOperationTimeoutError) throw changeStreamError;\n    } else {\n      try {\n        await this.close();\n      } catch (error) {\n        squashError(error);\n      }\n\n      throw changeStreamError;\n    }\n  }\n\n  private async _resume(changeStreamError: AnyError) {\n    this.timeoutContext?.refresh();\n    const topology = getTopology(this.parent);\n    try {\n      await topology.selectServer(this.cursor.readPreference, {\n        operationName: 'reconnect topology in change stream',\n        timeoutContext: this.timeoutContext\n      });\n      this.cursor = this._createChangeStreamCursor(this.cursor.resumeOptions);\n    } catch {\n      // if the topology can't reconnect, close the stream\n      await this.close();\n      throw changeStreamError;\n    }\n  }\n}\n\nconfigureResourceManagement(ChangeStream.prototype);\n"],"names":[],"mappings":";;;;;AAGA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAQA,MAAA;AACA,MAAA;AAIA,MAAA;AAEA,MAAA;AACA,MAAA;AAEA,MAAM,wBAAwB;IAC5B;IACA;IACA;IACA;IACA;IACA;CACQ;AAEV,MAAM,sBAAsB;IAC1B,YAAY,OAAO;IACnB,UAAU,OAAO;IACjB,SAAS,OAAO;;AAGlB,MAAM,uBAAuB;IAAC,YAAA,oBAAoB;IAAE,YAAA,GAAG;IAAE,YAAA,KAAK;CAAU;AAExE,MAAM,wBACJ;AACF,MAAM,4BAA4B;AA8flC;;;IAIA,MAAa,qBAIH,cAAA,iBAAuD;IAS/D,cAAA,GACA,MAAM,eAAY;QAChB,MAAM,IAAI,CAAC,KAAK;IAClB;IAwDA;;;;;QAMA,YACE,MAAuB,EACvB,WAAuB,EAAE,EACzB,UAA+B,CAAA,CAAE,CAAA;QAEjC,KAAK;QAEL,IAAI,CAAC,QAAQ,GAAG;QAChB,IAAI,CAAC,OAAO,GAAG;YAAE,GAAG,OAAO;QAAA;QAC3B,IAAI;QACJ,OAAO,IAAI,CAAC,OAAO,CAAC,YAAY;QAEhC,IAAI,kBAAkB,aAAA,UAAU,EAAE;YAChC,IAAI,CAAC,IAAI,GAAG,oBAAoB,UAAU;YAC1C,2BAA2B,OAAO,CAAC,CAAC,EAAE,CAAC,MAAM,CAAC,OAAO,CAAC,wBAAwB;QAChF,OAAO,IAAI,kBAAkB,KAAA,EAAE,EAAE;YAC/B,IAAI,CAAC,IAAI,GAAG,oBAAoB,QAAQ;YACxC,2BAA2B,OAAO,MAAM,CAAC,OAAO,CAAC,wBAAwB;QAC3E,OAAO,IAAI,kBAAkB,eAAA,WAAW,EAAE;YACxC,IAAI,CAAC,IAAI,GAAG,oBAAoB,OAAO;YACvC,2BAA2B,OAAO,OAAO,CAAC,wBAAwB;QACpE,OAAO;YACL,MAAM,IAAI,QAAA,sBAAsB,CAC9B;QAEJ;QAEA,IAAI,CAAC,YAAY,GAAG;QACpB,IAAI,CAAC,MAAM,GAAG;QACd,IAAI,CAAC,SAAS,GAAG,OAAO,CAAC,CAAC,SAAS;QACnC,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,cAAc,IAAI,OAAO,cAAc,EAAE;YACzD,IAAI,CAAC,OAAO,CAAC,cAAc,GAAG,OAAO,cAAc;QACrD;QAEA,wCAAwC;QACxC,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,yBAAyB,CAAC;QAE7C,IAAI,CAAC,QAAQ,GAAG;QAChB,IAAI,CAAC,IAAI,GAAG;QAEZ,gEAAgE;QAChE,IAAI,CAAC,EAAE,CAAC,eAAe,CAAA;YACrB,IAAI,cAAc,YAAY,IAAI,CAAC,MAAM,IAAI,IAAI,CAAC,aAAa,CAAC,cAAc,GAAG;gBAC/E,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,MAAM;YAChC;QACF;QAEA,IAAI,CAAC,EAAE,CAAC,kBAAkB,CAAA;YACxB,IAAI,cAAc,YAAY,IAAI,CAAC,aAAa,CAAC,cAAc,KAAK,IAAI,CAAC,MAAM,EAAE;gBAC/E,IAAI,CAAC,YAAY,EAAE,mBAAmB;YACxC;QACF;QAEA,IAAI,IAAI,CAAC,OAAO,CAAC,SAAS,IAAI,MAAM;YAClC,IAAI,CAAC,cAAc,GAAG,IAAI,UAAA,kBAAkB,CAAC;gBAC3C,WAAW,IAAI,CAAC,OAAO,CAAC,SAAS;gBACjC;;QAEJ;IACF;IAEA,4FAAA,GACA,IAAI,cAAW;QACb,OAAO,IAAI,CAAC,MAAM,EAAE;IACtB;IAEA,wEAAA,GACA,MAAM,UAAO;QACX,IAAI,CAAC,cAAc;QACnB,4EAA4E;QAC5E,wFAAwF;QACxF,SAAS;QAET,IAAI,CAAC,cAAc,EAAE;QACrB,IAAI;YACF,MAAO,KAAM;gBACX,IAAI;oBACF,MAAM,UAAU,MAAM,IAAI,CAAC,MAAM,CAAC,OAAO;oBACzC,OAAO;gBACT,EAAE,OAAO,OAAO;oBACd,IAAI;wBACF,MAAM,IAAI,CAAC,yBAAyB,CAAC,OAAO,IAAI,CAAC,MAAM,CAAC,EAAE,IAAI;oBAChE,EAAE,OAAO,OAAO;wBACd,IAAI,iBAAiB,QAAA,0BAA0B,IAAI,IAAI,CAAC,MAAM,CAAC,EAAE,IAAI,MAAM;4BACzE,MAAM;wBACR;wBACA,IAAI;4BACF,MAAM,IAAI,CAAC,KAAK;wBAClB,EAAE,OAAO,OAAO;4BACd,CAAA,GAAA,QAAA,WAAW,EAAC;wBACd;wBACA,MAAM;oBACR;gBACF;YACF;QACF,SAAU;YACR,IAAI,CAAC,cAAc,EAAE;QACvB;IACF;IAEA,4DAAA,GACA,MAAM,OAAI;QACR,IAAI,CAAC,cAAc;QACnB,4EAA4E;QAC5E,wFAAwF;QACxF,SAAS;QACT,IAAI,CAAC,cAAc,EAAE;QAErB,IAAI;YACF,MAAO,KAAM;gBACX,IAAI;oBACF,MAAM,SAAS,MAAM,IAAI,CAAC,MAAM,CAAC,IAAI;oBACrC,MAAM,kBAAkB,IAAI,CAAC,cAAc,CAAC,UAAU;oBACtD,OAAO;gBACT,EAAE,OAAO,OAAO;oBACd,IAAI;wBACF,MAAM,IAAI,CAAC,yBAAyB,CAAC,OAAO,IAAI,CAAC,MAAM,CAAC,EAAE,IAAI;oBAChE,EAAE,OAAO,OAAO;wBACd,IAAI,iBAAiB,QAAA,0BAA0B,IAAI,IAAI,CAAC,MAAM,CAAC,EAAE,IAAI,MAAM;4BACzE,MAAM;wBACR;wBACA,IAAI;4BACF,MAAM,IAAI,CAAC,KAAK;wBAClB,EAAE,OAAO,OAAO;4BACd,CAAA,GAAA,QAAA,WAAW,EAAC;wBACd;wBACA,MAAM;oBACR;gBACF;YACF;QACF,SAAU;YACR,IAAI,CAAC,cAAc,EAAE;QACvB;IACF;IAEA;;QAGA,MAAM,UAAO;QACX,IAAI,CAAC,cAAc;QACnB,4EAA4E;QAC5E,wFAAwF;QACxF,SAAS;QACT,IAAI,CAAC,cAAc,EAAE;QAErB,IAAI;YACF,MAAO,KAAM;gBACX,IAAI;oBACF,MAAM,SAAS,MAAM,IAAI,CAAC,MAAM,CAAC,OAAO;oBACxC,OAAO,UAAU;gBACnB,EAAE,OAAO,OAAO;oBACd,IAAI;wBACF,MAAM,IAAI,CAAC,yBAAyB,CAAC,OAAO,IAAI,CAAC,MAAM,CAAC,EAAE,IAAI;oBAChE,EAAE,OAAO,OAAO;wBACd,IAAI,iBAAiB,QAAA,0BAA0B,IAAI,IAAI,CAAC,MAAM,CAAC,EAAE,IAAI,MAAM,MAAM;wBACjF,IAAI;4BACF,MAAM,IAAI,CAAC,KAAK;wBAClB,EAAE,OAAO,OAAO;4BACd,CAAA,GAAA,QAAA,WAAW,EAAC;wBACd;wBACA,MAAM;oBACR;gBACF;YACF;QACF,SAAU;YACR,IAAI,CAAC,cAAc,EAAE;QACvB;IACF;IAEA,OAAO,CAAC,OAAO,aAAa,CAAC,GAAA;QAC3B,IAAI,IAAI,CAAC,MAAM,EAAE;YACf;QACF;QAEA,IAAI;YACF,kEAAkE;YAClE,4DAA4D;YAC5D,MAAO,KAAM;gBACX,MAAM,MAAM,IAAI,CAAC,IAAI;YACvB;QACF,SAAU;YACR,IAAI;gBACF,MAAM,IAAI,CAAC,KAAK;YAClB,EAAE,OAAO,OAAO;gBACd,CAAA,GAAA,QAAA,WAAW,EAAC;YACd;QACF;IACF;IAEA,yBAAA,GACA,IAAW,SAAM;QACf,OAAO,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,MAAM,CAAC,MAAM;IAC5C;IAEA;;QAGA,MAAM,QAAK;QACT,IAAI,CAAC,cAAc,EAAE;QACrB,IAAI,CAAC,cAAc,GAAG;QACtB,IAAI,CAAC,QAAQ,GAAG;QAEhB,MAAM,SAAS,IAAI,CAAC,MAAM;QAC1B,IAAI;YACF,MAAM,OAAO,KAAK;QACpB,SAAU;YACR,IAAI,CAAC,UAAU;QACjB;IACF;IAEA;;;;;;;QAQA,OAAO,OAA6B,EAAA;QAClC,IAAI,IAAI,CAAC,MAAM,EAAE;YACf,MAAM,IAAI,QAAA,sBAAsB,CAAC;QACnC;QAEA,IAAI,CAAC,aAAa,GAAG;QACrB,OAAO,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC;IAC5B;IAEA,cAAA,GACQ,gBAAa;QACnB,IAAI,IAAI,CAAC,IAAI,KAAK,YAAY;YAC5B,2DAA2D;YAC3D,MAAM,IAAI,QAAA,aAAa,CACrB;QAEJ;QACA,IAAI,CAAC,IAAI,GAAG;IACd;IAEA,cAAA,GACQ,iBAAc;QACpB,IAAI,IAAI,CAAC,IAAI,KAAK,WAAW;YAC3B,2DAA2D;YAC3D,MAAM,IAAI,QAAA,aAAa,CACrB;QAEJ;QACA,IAAI,CAAC,IAAI,GAAG;IACd;IAEA;;;QAIQ,0BACN,OAAwD,EAAA;QAExD,MAAM,2BAA2B,CAAA,GAAA,QAAA,aAAa,EAAC,SAAS;QACxD,IAAI,IAAI,CAAC,IAAI,KAAK,oBAAoB,OAAO,EAAE;YAC7C,yBAAyB,oBAAoB,GAAG;QAClD;QACA,MAAM,WAAW;YAAC;gBAAE,eAAe;YAAwB;eAAO,IAAI,CAAC,QAAQ;SAAC;QAEhF,MAAM,SACJ,IAAI,CAAC,IAAI,KAAK,oBAAoB,OAAO,GACpC,IAAI,CAAC,MAAsB,GAC5B,IAAI,CAAC,IAAI,KAAK,oBAAoB,QAAQ,GACvC,IAAI,CAAC,MAAa,CAAC,MAAM,GAC1B,IAAI,CAAC,IAAI,KAAK,oBAAoB,UAAU,GACzC,IAAI,CAAC,MAAqB,CAAC,MAAM,GAClC;QAEV,IAAI,UAAU,MAAM;YAClB,uEAAuE;YACvE,MAAM,IAAI,QAAA,iBAAiB,CACzB,CAAA,6EAAA,EAAgF,IAAI,CAAC,IAAI,CAAC,QAAQ,GAAE,CAAE;QAE1G;QAEA,MAAM,qBAAqB,IAAI,uBAAA,kBAAkB,CAC/C,QACA,IAAI,CAAC,SAAS,EACd,UACA;YACE,GAAG,OAAO;YACV,gBAAgB,IAAI,CAAC,cAAc,GAC/B,IAAI,kBAAA,oBAAoB,CAAC,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,YAAY,IAC/D;;QAIR,KAAK,MAAM,SAAS,qBAAsB;YACxC,mBAAmB,EAAE,CAAC,OAAO,CAAA,IAAK,IAAI,CAAC,IAAI,CAAC,OAAO;QACrD;QAEA,IAAI,IAAI,CAAC,aAAa,CAAC,aAAa,MAAM,IAAI,GAAG;YAC/C,IAAI,CAAC,aAAa,CAAC;QACrB;QAEA,OAAO;IACT;IAEA,cAAA,GACQ,2BAA2B,KAAe,EAAA;QAChD,IAAI,CAAC,IAAI,CAAC,aAAa,KAAK,EAAE;QAE9B,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,WAAW,QAAA,WAAW;IAC1C;IAEA,cAAA,GACQ,cAAc,MAA4C,EAAA;QAChE,IAAI,CAAC,aAAa;QAClB,MAAM,SAAS,IAAI,CAAC,YAAY,IAAI,OAAO,MAAM;QACjD,IAAI,CAAC,YAAY,GAAG;QACpB,OAAO,EAAE,CAAC,QAAQ,CAAA;YAChB,IAAI;gBACF,MAAM,kBAAkB,IAAI,CAAC,cAAc,CAAC;gBAC5C,IAAI,CAAC,IAAI,CAAC,aAAa,MAAM,EAAE;YACjC,EAAE,OAAO,OAAO;gBACd,IAAI,CAAC,IAAI,CAAC,aAAa,KAAK,EAAE;YAChC;YACA,IAAI,CAAC,cAAc,EAAE;QACvB;QACA,OAAO,EAAE,CAAC,SAAS,CAAA,QAAS,IAAI,CAAC,uBAAuB,CAAC,OAAO,IAAI,CAAC,MAAM,CAAC,EAAE,IAAI;IACpF;IAEA,cAAA,GACQ,aAAU;QAChB,IAAI,CAAC,YAAY,EAAE,mBAAmB;QACtC,IAAI,CAAC,YAAY,EAAE,mBAAmB;QACtC,IAAI,CAAC,YAAY,EAAE,mBAAmB;QACtC,IAAI,CAAC,YAAY,EAAE;QACnB,IAAI,CAAC,YAAY,GAAG;IACtB;IAEA,cAAA,GACQ,eAAe,MAAsB,EAAA;QAC3C,IAAI,IAAI,CAAC,QAAQ,EAAE;YACjB,6DAA6D;YAC7D,MAAM,IAAI,QAAA,aAAa,CAAC;QAC1B;QAEA,yFAAyF;QACzF,IAAI,UAAU,MAAM;YAClB,6DAA6D;YAC7D,MAAM,IAAI,QAAA,iBAAiB,CAAC;QAC9B;QAEA,IAAI,UAAU,CAAC,OAAO,GAAG,EAAE;YACzB,MAAM,IAAI,QAAA,sBAAsB,CAAC;QACnC;QAEA,yBAAyB;QACzB,IAAI,CAAC,MAAM,CAAC,gBAAgB,CAAC,OAAO,GAAG;QAEvC,mFAAmF;QACnF,kFAAkF;QAClF,IAAI,CAAC,OAAO,CAAC,oBAAoB,GAAG;QAEpC,OAAO;IACT;IAEA,cAAA,GACQ,wBAAwB,iBAA2B,EAAE,iBAA0B,EAAA;QACrF,yEAAyE;QACzE,IAAI,IAAI,CAAC,QAAQ,EAAE;QAEnB,IACE,qBACA,CAAC,CAAA,GAAA,QAAA,gBAAgB,EAAC,mBAAmB,IAAI,CAAC,MAAM,CAAC,cAAc,KAC7D,6BAA6B,QAAA,0BAA0B,GACzD;YACA,IAAI,CAAC,UAAU;YAEf,IAAI,CAAC,MAAM,CACR,KAAK,GACL,IAAI,CACH,IAAM,IAAI,CAAC,OAAO,CAAC,oBACnB,CAAA;gBACE,CAAA,GAAA,QAAA,WAAW,EAAC;gBACZ,OAAO,IAAI,CAAC,OAAO,CAAC;YACtB,GAED,IAAI,CACH;gBACE,IAAI,6BAA6B,QAAA,0BAA0B,EACzD,IAAI,CAAC,IAAI,CAAC,aAAa,KAAK,EAAE;YAClC,GACA,IAAM,IAAI,CAAC,0BAA0B,CAAC;QAE5C,OAAO;YACL,IAAI,CAAC,0BAA0B,CAAC;QAClC;IACF;IAEA,cAAA,GACQ,MAAM,0BAA0B,iBAA2B,EAAE,iBAA0B,EAAA;QAC7F,IAAI,IAAI,CAAC,QAAQ,EAAE;YACjB,6DAA6D;YAC7D,MAAM,IAAI,QAAA,aAAa,CAAC;QAC1B;QAEA,IACE,qBACA,CAAC,CAAA,GAAA,QAAA,gBAAgB,EAAC,mBAAmB,IAAI,CAAC,MAAM,CAAC,cAAc,KAC7D,6BAA6B,QAAA,0BAA0B,GACzD;YACA,IAAI;gBACF,MAAM,IAAI,CAAC,MAAM,CAAC,KAAK;YACzB,EAAE,OAAO,OAAO;gBACd,CAAA,GAAA,QAAA,WAAW,EAAC;YACd;YAEA,MAAM,IAAI,CAAC,OAAO,CAAC;YAEnB,IAAI,6BAA6B,QAAA,0BAA0B,EAAE,MAAM;QACrE,OAAO;YACL,IAAI;gBACF,MAAM,IAAI,CAAC,KAAK;YAClB,EAAE,OAAO,OAAO;gBACd,CAAA,GAAA,QAAA,WAAW,EAAC;YACd;YAEA,MAAM;QACR;IACF;IAEQ,MAAM,QAAQ,iBAA2B,EAAA;QAC/C,IAAI,CAAC,cAAc,EAAE;QACrB,MAAM,WAAW,CAAA,GAAA,QAAA,WAAW,EAAC,IAAI,CAAC,MAAM;QACxC,IAAI;YACF,MAAM,SAAS,YAAY,CAAC,IAAI,CAAC,MAAM,CAAC,cAAc,EAAE;gBACtD,eAAe;gBACf,gBAAgB,IAAI,CAAC,cAAc;;YAErC,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,yBAAyB,CAAC,IAAI,CAAC,MAAM,CAAC,aAAa;QACxE,EAAE,OAAM;YACN,oDAAoD;YACpD,MAAM,IAAI,CAAC,KAAK;YAChB,MAAM;QACR;IACF;;AAtgBF,QAAA,YAAA,GAAA;AAwCE,WAAA,GACgB,aAAA,QAAQ,GAAG,YAAA,QAAQ;AACnC,WAAA,GACgB,aAAA,IAAI,GAAG,YAAA,IAAI;AAC3B,WAAA,GACgB,aAAA,IAAI,GAAG,YAAA,IAAI;AAC3B,WAAA,GACgB,aAAA,KAAK,GAAG,YAAA,KAAK;AAC7B;;;;;IAMgB,aAAA,MAAM,GAAG,YAAA,MAAM;AAC/B,WAAA,GACgB,aAAA,GAAG,GAAG,YAAA,GAAG;AACzB,WAAA,GACgB,aAAA,KAAK,GAAG,YAAA,KAAK;AAC7B;;;IAIgB,aAAA,oBAAoB,GAAG,YAAA,oBAAoB;AA0c7D,CAAA,GAAA,sBAAA,2BAA2B,EAAC,aAAa,SAAS"}},
    {"offset": {"line": 8446, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 8450, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/deps.ts"],"sourcesContent":["import { type Stream } from './cmap/connect';\nimport { MongoMissingDependencyError } from './error';\nimport type { Callback } from './utils';\n\nfunction makeErrorModule(error: any) {\n  const props = error ? { kModuleError: error } : {};\n  return new Proxy(props, {\n    get: (_: any, key: any) => {\n      if (key === 'kModuleError') {\n        return error;\n      }\n      throw error;\n    },\n    set: () => {\n      throw error;\n    }\n  });\n}\n\nexport type Kerberos = typeof import('kerberos') | { kModuleError: MongoMissingDependencyError };\n\nexport function getKerberos(): Kerberos {\n  let kerberos: Kerberos;\n  try {\n    // Ensure you always wrap an optional require in the try block NODE-3199\n    // eslint-disable-next-line @typescript-eslint/no-require-imports\n    kerberos = require('kerberos');\n  } catch (error) {\n    kerberos = makeErrorModule(\n      new MongoMissingDependencyError(\n        'Optional module `kerberos` not found. Please install it to enable kerberos authentication',\n        { cause: error, dependencyName: 'kerberos' }\n      )\n    );\n  }\n  return kerberos;\n}\n\nexport interface KerberosClient {\n  step(challenge: string): Promise<string>;\n  step(challenge: string, callback: Callback<string>): void;\n  wrap(challenge: string, options: { user: string }): Promise<string>;\n  wrap(challenge: string, options: { user: string }, callback: Callback<string>): void;\n  unwrap(challenge: string): Promise<string>;\n  unwrap(challenge: string, callback: Callback<string>): void;\n}\n\ntype ZStandardLib = {\n  /**\n   * Compress using zstd.\n   * @param buf - Buffer to be compressed.\n   */\n  compress(buf: Buffer, level?: number): Promise<Buffer>;\n\n  /**\n   * Decompress using zstd.\n   */\n  decompress(buf: Buffer): Promise<Buffer>;\n};\n\nexport type ZStandard = ZStandardLib | { kModuleError: MongoMissingDependencyError };\n\nexport function getZstdLibrary(): ZStandardLib | { kModuleError: MongoMissingDependencyError } {\n  let ZStandard: ZStandardLib | { kModuleError: MongoMissingDependencyError };\n  try {\n    // eslint-disable-next-line @typescript-eslint/no-require-imports\n    ZStandard = require('@mongodb-js/zstd');\n  } catch (error) {\n    ZStandard = makeErrorModule(\n      new MongoMissingDependencyError(\n        'Optional module `@mongodb-js/zstd` not found. Please install it to enable zstd compression',\n        { cause: error, dependencyName: 'zstd' }\n      )\n    );\n  }\n\n  return ZStandard;\n}\n\n/**\n * @public\n * Copy of the AwsCredentialIdentityProvider interface from [`smithy/types`](https://socket.dev/npm/package/\\@smithy/types/files/1.1.1/dist-types/identity/awsCredentialIdentity.d.ts),\n * the return type of the aws-sdk's `fromNodeProviderChain().provider()`.\n */\nexport interface AWSCredentials {\n  accessKeyId: string;\n  secretAccessKey: string;\n  sessionToken?: string;\n  expiration?: Date;\n}\n\ntype CredentialProvider = {\n  fromNodeProviderChain(\n    this: void,\n    options: { clientConfig: { region: string } }\n  ): () => Promise<AWSCredentials>;\n  fromNodeProviderChain(this: void): () => Promise<AWSCredentials>;\n};\n\nexport function getAwsCredentialProvider():\n  | CredentialProvider\n  | { kModuleError: MongoMissingDependencyError } {\n  try {\n    // Ensure you always wrap an optional require in the try block NODE-3199\n    // eslint-disable-next-line @typescript-eslint/no-require-imports\n    const credentialProvider = require('@aws-sdk/credential-providers');\n    return credentialProvider;\n  } catch (error) {\n    return makeErrorModule(\n      new MongoMissingDependencyError(\n        'Optional module `@aws-sdk/credential-providers` not found.' +\n          ' Please install it to enable getting aws credentials via the official sdk.',\n        { cause: error, dependencyName: '@aws-sdk/credential-providers' }\n      )\n    );\n  }\n}\n\n/** @internal */\nexport type GcpMetadata =\n  | typeof import('gcp-metadata')\n  | { kModuleError: MongoMissingDependencyError };\n\nexport function getGcpMetadata(): GcpMetadata {\n  try {\n    // Ensure you always wrap an optional require in the try block NODE-3199\n    // eslint-disable-next-line @typescript-eslint/no-require-imports\n    const credentialProvider = require('gcp-metadata');\n    return credentialProvider;\n  } catch (error) {\n    return makeErrorModule(\n      new MongoMissingDependencyError(\n        'Optional module `gcp-metadata` not found.' +\n          ' Please install it to enable getting gcp credentials via the official sdk.',\n        { cause: error, dependencyName: 'gcp-metadata' }\n      )\n    );\n  }\n}\n\n/** @internal */\nexport type SnappyLib = {\n  /**\n   * In order to support both we must check the return value of the function\n   * @param buf - Buffer to be compressed\n   */\n  compress(buf: Buffer): Promise<Buffer>;\n\n  /**\n   * In order to support both we must check the return value of the function\n   * @param buf - Buffer to be compressed\n   */\n  uncompress(buf: Buffer, opt: { asBuffer: true }): Promise<Buffer>;\n};\n\nexport function getSnappy(): SnappyLib | { kModuleError: MongoMissingDependencyError } {\n  try {\n    // Ensure you always wrap an optional require in the try block NODE-3199\n    // eslint-disable-next-line @typescript-eslint/no-require-imports\n    const value = require('snappy');\n    return value;\n  } catch (error) {\n    const kModuleError = new MongoMissingDependencyError(\n      'Optional module `snappy` not found. Please install it to enable snappy compression',\n      { cause: error, dependencyName: 'snappy' }\n    );\n    return { kModuleError };\n  }\n}\n\nexport type SocksLib = {\n  SocksClient: {\n    createConnection(options: {\n      command: 'connect';\n      destination: { host: string; port: number };\n      proxy: {\n        /** host and port are ignored because we pass existing_socket */\n        host: 'iLoveJavaScript';\n        port: 0;\n        type: 5;\n        userId?: string;\n        password?: string;\n      };\n      timeout?: number;\n      /** We always create our own socket, and pass it to this API for proxy negotiation */\n      existing_socket: Stream;\n    }): Promise<{ socket: Stream }>;\n  };\n};\n\nexport function getSocks(): SocksLib | { kModuleError: MongoMissingDependencyError } {\n  try {\n    // Ensure you always wrap an optional require in the try block NODE-3199\n    // eslint-disable-next-line @typescript-eslint/no-require-imports\n    const value = require('socks');\n    return value;\n  } catch (error) {\n    const kModuleError = new MongoMissingDependencyError(\n      'Optional module `socks` not found. Please install it to connections over a SOCKS5 proxy',\n      { cause: error, dependencyName: 'socks' }\n    );\n    return { kModuleError };\n  }\n}\n\ninterface AWS4 {\n  /**\n   * Created these inline types to better assert future usage of this API\n   * @param options - options for request\n   * @param credentials - AWS credential details, sessionToken should be omitted entirely if its false-y\n   */\n  sign(\n    this: void,\n    options: {\n      path: '/';\n      body: string;\n      host: string;\n      method: 'POST';\n      headers: {\n        'Content-Type': 'application/x-www-form-urlencoded';\n        'Content-Length': number;\n        'X-MongoDB-Server-Nonce': string;\n        'X-MongoDB-GS2-CB-Flag': 'n';\n      };\n      service: string;\n      region: string;\n    },\n    credentials:\n      | {\n          accessKeyId: string;\n          secretAccessKey: string;\n          sessionToken: string;\n        }\n      | {\n          accessKeyId: string;\n          secretAccessKey: string;\n        }\n      | undefined\n  ): {\n    headers: {\n      Authorization: string;\n      'X-Amz-Date': string;\n    };\n  };\n}\n\nexport const aws4: AWS4 | { kModuleError: MongoMissingDependencyError } = loadAws4();\n\nfunction loadAws4() {\n  let aws4: AWS4 | { kModuleError: MongoMissingDependencyError };\n  try {\n    // eslint-disable-next-line @typescript-eslint/no-require-imports\n    aws4 = require('aws4');\n  } catch (error) {\n    aws4 = makeErrorModule(\n      new MongoMissingDependencyError(\n        'Optional module `aws4` not found. Please install it to enable AWS authentication',\n        { cause: error, dependencyName: 'aws4' }\n      )\n    );\n  }\n\n  return aws4;\n}\n\n/** A utility function to get the instance of mongodb-client-encryption, if it exists. */\nexport function getMongoDBClientEncryption():\n  | typeof import('mongodb-client-encryption')\n  | { kModuleError: MongoMissingDependencyError } {\n  let mongodbClientEncryption = null;\n\n  try {\n    // NOTE(NODE-3199): Ensure you always wrap an optional require literally in the try block\n    // Cannot be moved to helper utility function, bundlers search and replace the actual require call\n    // in a way that makes this line throw at bundle time, not runtime, catching here will make bundling succeed\n    // eslint-disable-next-line @typescript-eslint/no-require-imports\n    mongodbClientEncryption = require('mongodb-client-encryption');\n  } catch (error) {\n    const kModuleError = new MongoMissingDependencyError(\n      'Optional module `mongodb-client-encryption` not found. Please install it to use auto encryption or ClientEncryption.',\n      { cause: error, dependencyName: 'mongodb-client-encryption' }\n    );\n    return { kModuleError };\n  }\n\n  return mongodbClientEncryption;\n}\n"],"names":[],"mappings":";;;;;AAqBA,QAAA,WAAA,GAAA;AAyCA,QAAA,cAAA,GAAA;AAqCA,QAAA,wBAAA,GAAA;AAwBA,QAAA,cAAA,GAAA;AAgCA,QAAA,SAAA,GAAA;AAmCA,QAAA,QAAA,GAAA;AA4EA,QAAA,0BAAA,GAAA;AAzQA,MAAA;AAGA,SAAS,gBAAgB,KAAU;IACjC,MAAM,QAAQ,QAAQ;QAAE,cAAc;IAAK,IAAK,CAAA;IAChD,OAAO,IAAI,MAAM,OAAO;QACtB,KAAK,CAAC,GAAQ;YACZ,IAAI,QAAQ,gBAAgB;gBAC1B,OAAO;YACT;YACA,MAAM;QACR;QACA,KAAK;YACH,MAAM;QACR;;AAEJ;AAIA,SAAgB;IACd,IAAI;IACJ,IAAI;QACF,wEAAwE;QACxE,iEAAiE;QACjE;;;;;IACF,EAAE,OAAO,OAAO;QACd,WAAW,gBACT,IAAI,QAAA,2BAA2B,CAC7B,6FACA;YAAE,OAAO;YAAO,gBAAgB;QAAU;IAGhD;IACA,OAAO;AACT;AA0BA,SAAgB;IACd,IAAI;IACJ,IAAI;QACF,iEAAiE;QACjE;;;;;IACF,EAAE,OAAO,OAAO;QACd,YAAY,gBACV,IAAI,QAAA,2BAA2B,CAC7B,8FACA;YAAE,OAAO;YAAO,gBAAgB;QAAM;IAG5C;IAEA,OAAO;AACT;AAsBA,SAAgB;IAGd,IAAI;QACF,wEAAwE;QACxE,iEAAiE;QACjE,MAAM;;;;;QACN,OAAO;IACT,EAAE,OAAO,OAAO;QACd,OAAO,gBACL,IAAI,QAAA,2BAA2B,CAC7B,+DACE,8EACF;YAAE,OAAO;YAAO,gBAAgB;QAA+B;IAGrE;AACF;AAOA,SAAgB;IACd,IAAI;QACF,wEAAwE;QACxE,iEAAiE;QACjE,MAAM;;;;;QACN,OAAO;IACT,EAAE,OAAO,OAAO;QACd,OAAO,gBACL,IAAI,QAAA,2BAA2B,CAC7B,8CACE,8EACF;YAAE,OAAO;YAAO,gBAAgB;QAAc;IAGpD;AACF;AAiBA,SAAgB;IACd,IAAI;QACF,wEAAwE;QACxE,iEAAiE;QACjE,MAAM;;;;;QACN,OAAO;IACT,EAAE,OAAO,OAAO;QACd,MAAM,eAAe,IAAI,QAAA,2BAA2B,CAClD,sFACA;YAAE,OAAO;YAAO,gBAAgB;QAAQ;QAE1C,OAAO;YAAE;QAAY;IACvB;AACF;AAsBA,SAAgB;IACd,IAAI;QACF,wEAAwE;QACxE,iEAAiE;QACjE,MAAM;;;;;QACN,OAAO;IACT,EAAE,OAAO,OAAO;QACd,MAAM,eAAe,IAAI,QAAA,2BAA2B,CAClD,2FACA;YAAE,OAAO;YAAO,gBAAgB;QAAO;QAEzC,OAAO;YAAE;QAAY;IACvB;AACF;AA2Ca,QAAA,IAAI,GAAyD;AAE1E,SAAS;IACP,IAAI;IACJ,IAAI;QACF,iEAAiE;QACjE;;;;;IACF,EAAE,OAAO,OAAO;QACd,OAAO,gBACL,IAAI,QAAA,2BAA2B,CAC7B,oFACA;YAAE,OAAO;YAAO,gBAAgB;QAAM;IAG5C;IAEA,OAAO;AACT;AAEA,uFAAA,GACA,SAAgB;IAGd,IAAI,0BAA0B;IAE9B,IAAI;QACF,yFAAyF;QACzF,kGAAkG;QAClG,4GAA4G;QAC5G,iEAAiE;QACjE;;;;;IACF,EAAE,OAAO,OAAO;QACd,MAAM,eAAe,IAAI,QAAA,2BAA2B,CAClD,wHACA;YAAE,OAAO;YAAO,gBAAgB;QAA2B;QAE7D,OAAO;YAAE;QAAY;IACvB;IAEA,OAAO;AACT"}},
    {"offset": {"line": 8629, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 8633, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/client-side-encryption/crypto_callbacks.ts"],"sourcesContent":["import * as crypto from 'crypto';\n\ntype AES256Callback = (key: Buffer, iv: Buffer, input: Buffer, output: Buffer) => number | Error;\n\nexport function makeAES256Hook(\n  method: 'createCipheriv' | 'createDecipheriv',\n  mode: 'aes-256-cbc' | 'aes-256-ctr'\n): AES256Callback {\n  return function (key: Buffer, iv: Buffer, input: Buffer, output: Buffer): number | Error {\n    let result;\n\n    try {\n      const cipher = crypto[method](mode, key, iv);\n      cipher.setAutoPadding(false);\n      result = cipher.update(input);\n      const final = cipher.final();\n      if (final.length > 0) {\n        result = Buffer.concat([result, final]);\n      }\n    } catch (e) {\n      return e;\n    }\n\n    result.copy(output);\n    return result.length;\n  };\n}\n\nexport function randomHook(buffer: Buffer, count: number): number | Error {\n  try {\n    crypto.randomFillSync(buffer, 0, count);\n  } catch (e) {\n    return e;\n  }\n  return count;\n}\n\nexport function sha256Hook(input: Buffer, output: Buffer): number | Error {\n  let result;\n  try {\n    result = crypto.createHash('sha256').update(input).digest();\n  } catch (e) {\n    return e;\n  }\n\n  result.copy(output);\n  return result.length;\n}\n\ntype HMACHook = (key: Buffer, input: Buffer, output: Buffer) => number | Error;\nexport function makeHmacHook(algorithm: 'sha512' | 'sha256'): HMACHook {\n  return (key: Buffer, input: Buffer, output: Buffer): number | Error => {\n    let result;\n    try {\n      result = crypto.createHmac(algorithm, key).update(input).digest();\n    } catch (e) {\n      return e;\n    }\n\n    result.copy(output);\n    return result.length;\n  };\n}\n\nexport function signRsaSha256Hook(key: Buffer, input: Buffer, output: Buffer): number | Error {\n  let result;\n  try {\n    const signer = crypto.createSign('sha256WithRSAEncryption');\n    const privateKey = Buffer.from(\n      `-----BEGIN PRIVATE KEY-----\\n${key.toString('base64')}\\n-----END PRIVATE KEY-----\\n`\n    );\n\n    result = signer.update(input).end().sign(privateKey);\n  } catch (e) {\n    return e;\n  }\n\n  result.copy(output);\n  return result.length;\n}\n\nexport const aes256CbcEncryptHook = makeAES256Hook('createCipheriv', 'aes-256-cbc');\nexport const aes256CbcDecryptHook = makeAES256Hook('createDecipheriv', 'aes-256-cbc');\nexport const aes256CtrEncryptHook = makeAES256Hook('createCipheriv', 'aes-256-ctr');\nexport const aes256CtrDecryptHook = makeAES256Hook('createDecipheriv', 'aes-256-ctr');\nexport const hmacSha512Hook = makeHmacHook('sha512');\nexport const hmacSha256Hook = makeHmacHook('sha256');\n"],"names":[],"mappings":";;;;;AAIA,QAAA,cAAA,GAAA;AAwBA,QAAA,UAAA,GAAA;AASA,QAAA,UAAA,GAAA;AAaA,QAAA,YAAA,GAAA;AAcA,QAAA,iBAAA,GAAA;AAhEA,MAAA;AAIA,SAAgB,eACd,MAA6C,EAC7C,IAAmC;IAEnC,OAAO,SAAU,GAAW,EAAE,EAAU,EAAE,KAAa,EAAE,MAAc;QACrE,IAAI;QAEJ,IAAI;YACF,MAAM,SAAS,MAAM,CAAC,OAAO,CAAC,MAAM,KAAK;YACzC,OAAO,cAAc,CAAC;YACtB,SAAS,OAAO,MAAM,CAAC;YACvB,MAAM,QAAQ,OAAO,KAAK;YAC1B,IAAI,MAAM,MAAM,GAAG,GAAG;gBACpB,SAAS,OAAO,MAAM,CAAC;oBAAC;oBAAQ;iBAAM;YACxC;QACF,EAAE,OAAO,GAAG;YACV,OAAO;QACT;QAEA,OAAO,IAAI,CAAC;QACZ,OAAO,OAAO,MAAM;IACtB;AACF;AAEA,SAAgB,WAAW,MAAc,EAAE,KAAa;IACtD,IAAI;QACF,OAAO,cAAc,CAAC,QAAQ,GAAG;IACnC,EAAE,OAAO,GAAG;QACV,OAAO;IACT;IACA,OAAO;AACT;AAEA,SAAgB,WAAW,KAAa,EAAE,MAAc;IACtD,IAAI;IACJ,IAAI;QACF,SAAS,OAAO,UAAU,CAAC,UAAU,MAAM,CAAC,OAAO,MAAM;IAC3D,EAAE,OAAO,GAAG;QACV,OAAO;IACT;IAEA,OAAO,IAAI,CAAC;IACZ,OAAO,OAAO,MAAM;AACtB;AAGA,SAAgB,aAAa,SAA8B;IACzD,OAAO,CAAC,KAAa,OAAe;QAClC,IAAI;QACJ,IAAI;YACF,SAAS,OAAO,UAAU,CAAC,WAAW,KAAK,MAAM,CAAC,OAAO,MAAM;QACjE,EAAE,OAAO,GAAG;YACV,OAAO;QACT;QAEA,OAAO,IAAI,CAAC;QACZ,OAAO,OAAO,MAAM;IACtB;AACF;AAEA,SAAgB,kBAAkB,GAAW,EAAE,KAAa,EAAE,MAAc;IAC1E,IAAI;IACJ,IAAI;QACF,MAAM,SAAS,OAAO,UAAU,CAAC;QACjC,MAAM,aAAa,OAAO,IAAI,CAC5B,CAAA,6BAAA,EAAgC,IAAI,QAAQ,CAAC,UAAS,6BAAA,CAA+B;QAGvF,SAAS,OAAO,MAAM,CAAC,OAAO,GAAG,GAAG,IAAI,CAAC;IAC3C,EAAE,OAAO,GAAG;QACV,OAAO;IACT;IAEA,OAAO,IAAI,CAAC;IACZ,OAAO,OAAO,MAAM;AACtB;AAEa,QAAA,oBAAoB,GAAG,eAAe,kBAAkB;AACxD,QAAA,oBAAoB,GAAG,eAAe,oBAAoB;AAC1D,QAAA,oBAAoB,GAAG,eAAe,kBAAkB;AACxD,QAAA,oBAAoB,GAAG,eAAe,oBAAoB;AAC1D,QAAA,cAAc,GAAG,aAAa;AAC9B,QAAA,cAAc,GAAG,aAAa"}},
    {"offset": {"line": 8713, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 8717, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/client-side-encryption/errors.ts"],"sourcesContent":["import { type Document } from '../bson';\nimport { MongoError } from '../error';\n\n/**\n * @public\n * An error indicating that something went wrong specifically with MongoDB Client Encryption\n */\nexport class MongoCryptError extends MongoError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string, options: { cause?: Error } = {}) {\n    super(message, options);\n  }\n\n  override get name() {\n    return 'MongoCryptError';\n  }\n}\n\n/**\n * @public\n *\n * An error indicating an invalid argument was provided to an encryption API.\n */\nexport class MongoCryptInvalidArgumentError extends MongoCryptError {\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string) {\n    super(message);\n  }\n\n  override get name() {\n    return 'MongoCryptInvalidArgumentError';\n  }\n}\n/**\n * @public\n * An error indicating that `ClientEncryption.createEncryptedCollection()` failed to create data keys\n */\nexport class MongoCryptCreateDataKeyError extends MongoCryptError {\n  encryptedFields: Document;\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(encryptedFields: Document, { cause }: { cause: Error }) {\n    super(`Unable to complete creating data keys: ${cause.message}`, { cause });\n    this.encryptedFields = encryptedFields;\n  }\n\n  override get name() {\n    return 'MongoCryptCreateDataKeyError';\n  }\n}\n\n/**\n * @public\n * An error indicating that `ClientEncryption.createEncryptedCollection()` failed to create a collection\n */\nexport class MongoCryptCreateEncryptedCollectionError extends MongoCryptError {\n  encryptedFields: Document;\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(encryptedFields: Document, { cause }: { cause: Error }) {\n    super(`Unable to create collection: ${cause.message}`, { cause });\n    this.encryptedFields = encryptedFields;\n  }\n\n  override get name() {\n    return 'MongoCryptCreateEncryptedCollectionError';\n  }\n}\n\n/**\n * @public\n * An error indicating that mongodb-client-encryption failed to auto-refresh Azure KMS credentials.\n */\nexport class MongoCryptAzureKMSRequestError extends MongoCryptError {\n  /** The body of the http response that failed, if present. */\n  body?: Document;\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(message: string, body?: Document) {\n    super(message);\n    this.body = body;\n  }\n\n  override get name(): string {\n    return 'MongoCryptAzureKMSRequestError';\n  }\n}\n\n/** @public */\nexport class MongoCryptKMSRequestNetworkTimeoutError extends MongoCryptError {\n  override get name(): string {\n    return 'MongoCryptKMSRequestNetworkTimeoutError';\n  }\n}\n"],"names":[],"mappings":";;;;;AACA,MAAA;AAEA;;;IAIA,MAAa,wBAAwB,QAAA,UAAU;IAC7C;;;;;;;;;;SAWA,YAAY,OAAe,EAAE,UAA6B,CAAA,CAAE,CAAA;QAC1D,KAAK,CAAC,SAAS;IACjB;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,eAAA,GAAA;AAqBA;;;;IAKA,MAAa,uCAAuC;IAClD;;;;;;;;;;SAWA,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC;IACR;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AAlBF,QAAA,8BAAA,GAAA;AAoBA;;;IAIA,MAAa,qCAAqC;IAEhD;;;;;;;;;;SAWA,YAAY,eAAyB,EAAE,EAAE,KAAK,EAAoB,CAAA;QAChE,KAAK,CAAC,CAAA,uCAAA,EAA0C,MAAM,OAAO,CAAA,CAAE,EAAE;YAAE;QAAK;QACxE,IAAI,CAAC,eAAe,GAAG;IACzB;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AApBF,QAAA,4BAAA,GAAA;AAuBA;;;IAIA,MAAa,iDAAiD;IAE5D;;;;;;;;;;SAWA,YAAY,eAAyB,EAAE,EAAE,KAAK,EAAoB,CAAA;QAChE,KAAK,CAAC,CAAA,6BAAA,EAAgC,MAAM,OAAO,CAAA,CAAE,EAAE;YAAE;QAAK;QAC9D,IAAI,CAAC,eAAe,GAAG;IACzB;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AApBF,QAAA,wCAAA,GAAA;AAuBA;;;IAIA,MAAa,uCAAuC;IAGlD;;;;;;;;;;SAWA,YAAY,OAAe,EAAE,IAAe,CAAA;QAC1C,KAAK,CAAC;QACN,IAAI,CAAC,IAAI,GAAG;IACd;IAEA,IAAa,OAAI;QACf,OAAO;IACT;;AArBF,QAAA,8BAAA,GAAA;AAwBA,YAAA,GACA,MAAa,gDAAgD;IAC3D,IAAa,OAAI;QACf,OAAO;IACT;;AAHF,QAAA,uCAAA,GAAA"}},
    {"offset": {"line": 8847, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 8851, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/client-side-encryption/providers/aws.ts"],"sourcesContent":["import {\n  type AWSCredentialProvider,\n  AWSSDKCredentialProvider\n} from '../../cmap/auth/aws_temporary_credentials';\nimport { type KMSProviders } from '.';\n\n/**\n * @internal\n */\nexport async function loadAWSCredentials(\n  kmsProviders: KMSProviders,\n  provider?: AWSCredentialProvider\n): Promise<KMSProviders> {\n  const credentialProvider = new AWSSDKCredentialProvider(provider);\n\n  // We shouldn't ever receive a response from the AWS SDK that doesn't have a `SecretAccessKey`\n  // or `AccessKeyId`.  However, TS says these fields are optional.  We provide empty strings\n  // and let libmongocrypt error if we're unable to fetch the required keys.\n  const {\n    SecretAccessKey = '',\n    AccessKeyId = '',\n    Token\n  } = await credentialProvider.getCredentials();\n  const aws: NonNullable<KMSProviders['aws']> = {\n    secretAccessKey: SecretAccessKey,\n    accessKeyId: AccessKeyId\n  };\n  // the AWS session token is only required for temporary credentials so only attach it to the\n  // result if it's present in the response from the aws sdk\n  Token != null && (aws.sessionToken = Token);\n\n  return { ...kmsProviders, aws };\n}\n"],"names":[],"mappings":";;;;AASA,QAAA,kBAAA,GAAA;AATA,MAAA;AAMA;;IAGO,eAAe,mBACpB,YAA0B,EAC1B,QAAgC;IAEhC,MAAM,qBAAqB,IAAI,4BAAA,wBAAwB,CAAC;IAExD,8FAA8F;IAC9F,2FAA2F;IAC3F,0EAA0E;IAC1E,MAAM,EACJ,kBAAkB,EAAE,EACpB,cAAc,EAAE,EAChB,KAAK,EACN,GAAG,MAAM,mBAAmB,cAAc;IAC3C,MAAM,MAAwC;QAC5C,iBAAiB;QACjB,aAAa;;IAEf,4FAA4F;IAC5F,0DAA0D;IAC1D,SAAS,QAAQ,CAAC,IAAI,YAAY,GAAG,KAAK;IAE1C,OAAO;QAAE,GAAG,YAAY;QAAE;IAAG;AAC/B"}},
    {"offset": {"line": 8877, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 8881, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/client-side-encryption/providers/azure.ts"],"sourcesContent":["import { type Document } from '../../bson';\nimport { MongoNetworkTimeoutError } from '../../error';\nimport { get } from '../../utils';\nimport { MongoCryptAzureKMSRequestError } from '../errors';\nimport { type KMSProviders } from './index';\n\nconst MINIMUM_TOKEN_REFRESH_IN_MILLISECONDS = 6000;\n/** Base URL for getting Azure tokens. */\nexport const AZURE_BASE_URL = 'http://169.254.169.254/metadata/identity/oauth2/token?';\n\n/**\n * The access token that libmongocrypt expects for Azure kms.\n */\ninterface AccessToken {\n  accessToken: string;\n}\n\n/**\n * The response from the azure idms endpoint, including the `expiresOnTimestamp`.\n * `expiresOnTimestamp` is needed for caching.\n */\ninterface AzureTokenCacheEntry extends AccessToken {\n  accessToken: string;\n  expiresOnTimestamp: number;\n}\n\n/**\n * @internal\n */\nexport class AzureCredentialCache {\n  cachedToken: AzureTokenCacheEntry | null = null;\n\n  async getToken(): Promise<AccessToken> {\n    if (this.cachedToken == null || this.needsRefresh(this.cachedToken)) {\n      this.cachedToken = await this._getToken();\n    }\n\n    return { accessToken: this.cachedToken.accessToken };\n  }\n\n  needsRefresh(token: AzureTokenCacheEntry): boolean {\n    const timeUntilExpirationMS = token.expiresOnTimestamp - Date.now();\n    return timeUntilExpirationMS <= MINIMUM_TOKEN_REFRESH_IN_MILLISECONDS;\n  }\n\n  /**\n   * exposed for testing\n   */\n  resetCache() {\n    this.cachedToken = null;\n  }\n\n  /**\n   * exposed for testing\n   */\n  _getToken(): Promise<AzureTokenCacheEntry> {\n    return fetchAzureKMSToken();\n  }\n}\n\n/** @internal */\nexport const tokenCache = new AzureCredentialCache();\n\n/** @internal */\nasync function parseResponse(response: {\n  body: string;\n  status?: number;\n}): Promise<AzureTokenCacheEntry> {\n  const { status, body: rawBody } = response;\n\n  const body: { expires_in?: number; access_token?: string } = (() => {\n    try {\n      return JSON.parse(rawBody);\n    } catch {\n      throw new MongoCryptAzureKMSRequestError('Malformed JSON body in GET request.');\n    }\n  })();\n\n  if (status !== 200) {\n    throw new MongoCryptAzureKMSRequestError('Unable to complete request.', body);\n  }\n\n  if (!body.access_token) {\n    throw new MongoCryptAzureKMSRequestError(\n      'Malformed response body - missing field `access_token`.'\n    );\n  }\n\n  if (!body.expires_in) {\n    throw new MongoCryptAzureKMSRequestError(\n      'Malformed response body - missing field `expires_in`.'\n    );\n  }\n\n  const expiresInMS = Number(body.expires_in) * 1000;\n  if (Number.isNaN(expiresInMS)) {\n    throw new MongoCryptAzureKMSRequestError(\n      'Malformed response body - unable to parse int from `expires_in` field.'\n    );\n  }\n\n  return {\n    accessToken: body.access_token,\n    expiresOnTimestamp: Date.now() + expiresInMS\n  };\n}\n\n/**\n * @internal\n *\n * exposed for CSFLE\n * [prose test 18](https://github.com/mongodb/specifications/tree/master/source/client-side-encryption/tests#azure-imds-credentials)\n */\nexport interface AzureKMSRequestOptions {\n  headers?: Document;\n  url?: URL | string;\n}\n\n/**\n * @internal\n * Get the Azure endpoint URL.\n */\nexport function addAzureParams(url: URL, resource: string, username?: string): URL {\n  url.searchParams.append('api-version', '2018-02-01');\n  url.searchParams.append('resource', resource);\n  if (username) {\n    url.searchParams.append('client_id', username);\n  }\n  return url;\n}\n\n/**\n * @internal\n *\n * parses any options provided by prose tests to `fetchAzureKMSToken` and merges them with\n * the default values for headers and the request url.\n */\nexport function prepareRequest(options: AzureKMSRequestOptions): {\n  headers: Document;\n  url: URL;\n} {\n  const url = new URL(options.url?.toString() ?? AZURE_BASE_URL);\n  addAzureParams(url, 'https://vault.azure.net');\n  const headers = { ...options.headers, 'Content-Type': 'application/json', Metadata: true };\n  return { headers, url };\n}\n\n/**\n * @internal\n *\n * `AzureKMSRequestOptions` allows prose tests to modify the http request sent to the idms\n * servers.  This is required to simulate different server conditions.  No options are expected to\n * be set outside of tests.\n *\n * exposed for CSFLE\n * [prose test 18](https://github.com/mongodb/specifications/tree/master/source/client-side-encryption/tests#azure-imds-credentials)\n */\nexport async function fetchAzureKMSToken(\n  options: AzureKMSRequestOptions = {}\n): Promise<AzureTokenCacheEntry> {\n  const { headers, url } = prepareRequest(options);\n  try {\n    const response = await get(url, { headers });\n    return await parseResponse(response);\n  } catch (error) {\n    if (error instanceof MongoNetworkTimeoutError) {\n      throw new MongoCryptAzureKMSRequestError(`[Azure KMS] ${error.message}`);\n    }\n    throw error;\n  }\n}\n\n/**\n * @internal\n *\n * @throws Will reject with a `MongoCryptError` if the http request fails or the http response is malformed.\n */\nexport async function loadAzureCredentials(kmsProviders: KMSProviders): Promise<KMSProviders> {\n  const azure = await tokenCache.getToken();\n  return { ...kmsProviders, azure };\n}\n"],"names":[],"mappings":";;;;;AA0HA,QAAA,cAAA,GAAA;AAeA,QAAA,cAAA,GAAA;AAoBA,QAAA,kBAAA,GAAA;AAoBA,QAAA,oBAAA,GAAA;AAhLA,MAAA;AACA,MAAA;AACA,MAAA;AAGA,MAAM,wCAAwC;AAC9C,uCAAA,GACa,QAAA,cAAc,GAAG;AAkB9B;;IAGA,MAAa;IAAb,aAAA;QACE,IAAA,CAAA,WAAW,GAAgC;IA4B7C;IA1BE,MAAM,WAAQ;QACZ,IAAI,IAAI,CAAC,WAAW,IAAI,QAAQ,IAAI,CAAC,YAAY,CAAC,IAAI,CAAC,WAAW,GAAG;YACnE,IAAI,CAAC,WAAW,GAAG,MAAM,IAAI,CAAC,SAAS;QACzC;QAEA,OAAO;YAAE,aAAa,IAAI,CAAC,WAAW,CAAC,WAAW;QAAA;IACpD;IAEA,aAAa,KAA2B,EAAA;QACtC,MAAM,wBAAwB,MAAM,kBAAkB,GAAG,KAAK,GAAG;QACjE,OAAO,yBAAyB;IAClC;IAEA;;QAGA,aAAU;QACR,IAAI,CAAC,WAAW,GAAG;IACrB;IAEA;;QAGA,YAAS;QACP,OAAO;IACT;;AA5BF,QAAA,oBAAA,GAAA;AA+BA,cAAA,GACa,QAAA,UAAU,GAAG,IAAI;AAE9B,cAAA,GACA,eAAe,cAAc,QAG5B;IACC,MAAM,EAAE,MAAM,EAAE,MAAM,OAAO,EAAE,GAAG;IAElC,MAAM,OAAuD,CAAC;QAC5D,IAAI;YACF,OAAO,KAAK,KAAK,CAAC;QACpB,EAAE,OAAM;YACN,MAAM,IAAI,SAAA,8BAA8B,CAAC;QAC3C;IACF,CAAC;IAED,IAAI,WAAW,KAAK;QAClB,MAAM,IAAI,SAAA,8BAA8B,CAAC,+BAA+B;IAC1E;IAEA,IAAI,CAAC,KAAK,YAAY,EAAE;QACtB,MAAM,IAAI,SAAA,8BAA8B,CACtC;IAEJ;IAEA,IAAI,CAAC,KAAK,UAAU,EAAE;QACpB,MAAM,IAAI,SAAA,8BAA8B,CACtC;IAEJ;IAEA,MAAM,cAAc,OAAO,KAAK,UAAU,IAAI;IAC9C,IAAI,OAAO,KAAK,CAAC,cAAc;QAC7B,MAAM,IAAI,SAAA,8BAA8B,CACtC;IAEJ;IAEA,OAAO;QACL,aAAa,KAAK,YAAY;QAC9B,oBAAoB,KAAK,GAAG,KAAK;;AAErC;AAaA;;;IAIA,SAAgB,eAAe,GAAQ,EAAE,QAAgB,EAAE,QAAiB;IAC1E,IAAI,YAAY,CAAC,MAAM,CAAC,eAAe;IACvC,IAAI,YAAY,CAAC,MAAM,CAAC,YAAY;IACpC,IAAI,UAAU;QACZ,IAAI,YAAY,CAAC,MAAM,CAAC,aAAa;IACvC;IACA,OAAO;AACT;AAEA;;;;;IAMA,SAAgB,eAAe,OAA+B;IAI5D,MAAM,MAAM,IAAI,IAAI,QAAQ,GAAG,EAAE,cAAc,QAAA,cAAc;IAC7D,eAAe,KAAK;IACpB,MAAM,UAAU;QAAE,GAAG,QAAQ,OAAO;QAAE,gBAAgB;QAAoB,UAAU;IAAI;IACxF,OAAO;QAAE;QAAS;IAAG;AACvB;AAEA;;;;;;;;;IAUO,eAAe,mBACpB,UAAkC,CAAA,CAAE;IAEpC,MAAM,EAAE,OAAO,EAAE,GAAG,EAAE,GAAG,eAAe;IACxC,IAAI;QACF,MAAM,WAAW,MAAM,CAAA,GAAA,QAAA,GAAG,EAAC,KAAK;YAAE;QAAO;QACzC,OAAO,MAAM,cAAc;IAC7B,EAAE,OAAO,OAAO;QACd,IAAI,iBAAiB,QAAA,wBAAwB,EAAE;YAC7C,MAAM,IAAI,SAAA,8BAA8B,CAAC,CAAA,YAAA,EAAe,MAAM,OAAO,CAAA,CAAE;QACzE;QACA,MAAM;IACR;AACF;AAEA;;;;IAKO,eAAe,qBAAqB,YAA0B;IACnE,MAAM,QAAQ,MAAM,QAAA,UAAU,CAAC,QAAQ;IACvC,OAAO;QAAE,GAAG,YAAY;QAAE;IAAK;AACjC"}},
    {"offset": {"line": 9016, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 9020, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/client-side-encryption/providers/gcp.ts"],"sourcesContent":["import { getGcpMetadata } from '../../deps';\nimport { type KMSProviders } from '.';\n\n/** @internal */\nexport async function loadGCPCredentials(kmsProviders: KMSProviders): Promise<KMSProviders> {\n  const gcpMetadata = getGcpMetadata();\n\n  if ('kModuleError' in gcpMetadata) {\n    return kmsProviders;\n  }\n\n  const { access_token: accessToken } = await gcpMetadata.instance<{ access_token: string }>({\n    property: 'service-accounts/default/token'\n  });\n  return { ...kmsProviders, gcp: { accessToken } };\n}\n"],"names":[],"mappings":";;;;AAIA,QAAA,kBAAA,GAAA;AAJA,MAAA;AAGA,cAAA,GACO,eAAe,mBAAmB,YAA0B;IACjE,MAAM,cAAc,CAAA,GAAA,OAAA,cAAc;IAElC,IAAI,kBAAkB,aAAa;QACjC,OAAO;IACT;IAEA,MAAM,EAAE,cAAc,WAAW,EAAE,GAAG,MAAM,YAAY,QAAQ,CAA2B;QACzF,UAAU;;IAEZ,OAAO;QAAE,GAAG,YAAY;QAAE,KAAK;YAAE;QAAW;IAAE;AAChD"}},
    {"offset": {"line": 9041, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 9045, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/client-side-encryption/providers/index.ts"],"sourcesContent":["import type { Binary } from '../../bson';\nimport { type AWSCredentialProvider } from '../../cmap/auth/aws_temporary_credentials';\nimport { loadAWSCredentials } from './aws';\nimport { loadAzureCredentials } from './azure';\nimport { loadGCPCredentials } from './gcp';\n\n/**\n * @public\n *\n * A data key provider.  Allowed values:\n *\n * - aws, gcp, local, kmip or azure\n * - (`mongodb-client-encryption>=6.0.1` only) a named key, in the form of:\n *    `aws:<name>`, `gcp:<name>`, `local:<name>`, `kmip:<name>`, `azure:<name>`\n *  where `name` is an alphanumeric string, underscores allowed.\n */\nexport type ClientEncryptionDataKeyProvider = keyof KMSProviders;\n\n/** @public */\nexport interface AWSKMSProviderConfiguration {\n  /**\n   * The access key used for the AWS KMS provider\n   */\n  accessKeyId: string;\n\n  /**\n   * The secret access key used for the AWS KMS provider\n   */\n  secretAccessKey: string;\n\n  /**\n   * An optional AWS session token that will be used as the\n   * X-Amz-Security-Token header for AWS requests.\n   */\n  sessionToken?: string;\n}\n\n/** @public */\nexport interface LocalKMSProviderConfiguration {\n  /**\n   * The master key used to encrypt/decrypt data keys.\n   * A 96-byte long Buffer or base64 encoded string.\n   */\n  key: Binary | Uint8Array | string;\n}\n\n/** @public */\nexport interface KMIPKMSProviderConfiguration {\n  /**\n   * The output endpoint string.\n   * The endpoint consists of a hostname and port separated by a colon.\n   * E.g. \"example.com:123\". A port is always present.\n   */\n  endpoint?: string;\n}\n\n/** @public */\nexport type AzureKMSProviderConfiguration =\n  | {\n      /**\n       * The tenant ID identifies the organization for the account\n       */\n      tenantId: string;\n\n      /**\n       * The client ID to authenticate a registered application\n       */\n      clientId: string;\n\n      /**\n       * The client secret to authenticate a registered application\n       */\n      clientSecret: string;\n\n      /**\n       * If present, a host with optional port. E.g. \"example.com\" or \"example.com:443\".\n       * This is optional, and only needed if customer is using a non-commercial Azure instance\n       * (e.g. a government or China account, which use different URLs).\n       * Defaults to \"login.microsoftonline.com\"\n       */\n      identityPlatformEndpoint?: string | undefined;\n    }\n  | {\n      /**\n       * If present, an access token to authenticate with Azure.\n       */\n      accessToken: string;\n    };\n\n/** @public */\nexport type GCPKMSProviderConfiguration =\n  | {\n      /**\n       * The service account email to authenticate\n       */\n      email: string;\n\n      /**\n       * A PKCS#8 encrypted key. This can either be a base64 string or a binary representation\n       */\n      privateKey: string | Buffer;\n\n      /**\n       * If present, a host with optional port. E.g. \"example.com\" or \"example.com:443\".\n       * Defaults to \"oauth2.googleapis.com\"\n       */\n      endpoint?: string | undefined;\n    }\n  | {\n      /**\n       * If present, an access token to authenticate with GCP.\n       */\n      accessToken: string;\n    };\n\n/**\n * @public\n * Configuration options for custom credential providers for KMS requests.\n */\nexport interface CredentialProviders {\n  /* A custom AWS credential provider */\n  aws?: AWSCredentialProvider;\n}\n\n/**\n * @public\n * Configuration options that are used by specific KMS providers during key generation, encryption, and decryption.\n *\n * Named KMS providers _are not supported_ for automatic KMS credential fetching.\n */\nexport interface KMSProviders {\n  /**\n   * Configuration options for using 'aws' as your KMS provider\n   */\n  aws?: AWSKMSProviderConfiguration | Record<string, never>;\n  [key: `aws:${string}`]: AWSKMSProviderConfiguration;\n\n  /**\n   * Configuration options for using 'local' as your KMS provider\n   */\n  local?: LocalKMSProviderConfiguration;\n  [key: `local:${string}`]: LocalKMSProviderConfiguration;\n\n  /**\n   * Configuration options for using 'kmip' as your KMS provider\n   */\n  kmip?: KMIPKMSProviderConfiguration;\n  [key: `kmip:${string}`]: KMIPKMSProviderConfiguration;\n\n  /**\n   * Configuration options for using 'azure' as your KMS provider\n   */\n  azure?: AzureKMSProviderConfiguration | Record<string, never>;\n  [key: `azure:${string}`]: AzureKMSProviderConfiguration;\n\n  /**\n   * Configuration options for using 'gcp' as your KMS provider\n   */\n  gcp?: GCPKMSProviderConfiguration | Record<string, never>;\n  [key: `gcp:${string}`]: GCPKMSProviderConfiguration;\n}\n\n/**\n * Auto credential fetching should only occur when the provider is defined on the kmsProviders map\n * and the settings are an empty object.\n *\n * This is distinct from a nullish provider key.\n *\n * @internal - exposed for testing purposes only\n */\nexport function isEmptyCredentials(\n  providerName: ClientEncryptionDataKeyProvider,\n  kmsProviders: KMSProviders\n): boolean {\n  const provider = kmsProviders[providerName];\n  if (provider == null) {\n    return false;\n  }\n  return typeof provider === 'object' && Object.keys(provider).length === 0;\n}\n\n/**\n * Load cloud provider credentials for the user provided KMS providers.\n * Credentials will only attempt to get loaded if they do not exist\n * and no existing credentials will get overwritten.\n *\n * @internal\n */\nexport async function refreshKMSCredentials(\n  kmsProviders: KMSProviders,\n  credentialProviders?: CredentialProviders\n): Promise<KMSProviders> {\n  let finalKMSProviders = kmsProviders;\n\n  if (isEmptyCredentials('aws', kmsProviders)) {\n    finalKMSProviders = await loadAWSCredentials(finalKMSProviders, credentialProviders?.aws);\n  }\n\n  if (isEmptyCredentials('gcp', kmsProviders)) {\n    finalKMSProviders = await loadGCPCredentials(finalKMSProviders);\n  }\n\n  if (isEmptyCredentials('azure', kmsProviders)) {\n    finalKMSProviders = await loadAzureCredentials(finalKMSProviders);\n  }\n  return finalKMSProviders;\n}\n"],"names":[],"mappings":";;;;AA0KA,QAAA,kBAAA,GAAA;AAkBA,QAAA,qBAAA,GAAA;AA1LA,MAAA;AACA,MAAA;AACA,MAAA;AA8JA;;;;;;;IAQA,SAAgB,mBACd,YAA6C,EAC7C,YAA0B;IAE1B,MAAM,WAAW,YAAY,CAAC,aAAa;IAC3C,IAAI,YAAY,MAAM;QACpB,OAAO;IACT;IACA,OAAO,OAAO,aAAa,YAAY,OAAO,IAAI,CAAC,UAAU,MAAM,KAAK;AAC1E;AAEA;;;;;;IAOO,eAAe,sBACpB,YAA0B,EAC1B,mBAAyC;IAEzC,IAAI,oBAAoB;IAExB,IAAI,mBAAmB,OAAO,eAAe;QAC3C,oBAAoB,MAAM,CAAA,GAAA,MAAA,kBAAkB,EAAC,mBAAmB,qBAAqB;IACvF;IAEA,IAAI,mBAAmB,OAAO,eAAe;QAC3C,oBAAoB,MAAM,CAAA,GAAA,MAAA,kBAAkB,EAAC;IAC/C;IAEA,IAAI,mBAAmB,SAAS,eAAe;QAC7C,oBAAoB,MAAM,CAAA,GAAA,QAAA,oBAAoB,EAAC;IACjD;IACA,OAAO;AACT"}},
    {"offset": {"line": 9087, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 9091, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/client-side-encryption/state_machine.ts"],"sourcesContent":["import * as fs from 'fs/promises';\nimport { type MongoCryptContext, type MongoCryptKMSRequest } from 'mongodb-client-encryption';\nimport * as net from 'net';\nimport * as tls from 'tls';\n\nimport {\n  type BSONSerializeOptions,\n  deserialize,\n  type Document,\n  pluckBSONSerializeOptions,\n  serialize\n} from '../bson';\nimport { type ProxyOptions } from '../cmap/connection';\nimport { CursorTimeoutContext } from '../cursor/abstract_cursor';\nimport { getSocks, type SocksLib } from '../deps';\nimport { MongoOperationTimeoutError } from '../error';\nimport { type MongoClient, type MongoClientOptions } from '../mongo_client';\nimport { type Abortable } from '../mongo_types';\nimport { type CollectionInfo } from '../operations/list_collections';\nimport { Timeout, type TimeoutContext, TimeoutError } from '../timeout';\nimport {\n  addAbortListener,\n  BufferPool,\n  kDispose,\n  MongoDBCollectionNamespace,\n  promiseWithResolvers\n} from '../utils';\nimport { autoSelectSocketOptions, type DataKey } from './client_encryption';\nimport { MongoCryptError } from './errors';\nimport { type MongocryptdManager } from './mongocryptd_manager';\nimport { type KMSProviders } from './providers';\n\nlet socks: SocksLib | null = null;\nfunction loadSocks(): SocksLib {\n  if (socks == null) {\n    const socksImport = getSocks();\n    if ('kModuleError' in socksImport) {\n      throw socksImport.kModuleError;\n    }\n    socks = socksImport;\n  }\n  return socks;\n}\n\n// libmongocrypt states\nconst MONGOCRYPT_CTX_ERROR = 0;\nconst MONGOCRYPT_CTX_NEED_MONGO_COLLINFO = 1;\nconst MONGOCRYPT_CTX_NEED_MONGO_MARKINGS = 2;\nconst MONGOCRYPT_CTX_NEED_MONGO_KEYS = 3;\nconst MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS = 7;\nconst MONGOCRYPT_CTX_NEED_KMS = 4;\nconst MONGOCRYPT_CTX_READY = 5;\nconst MONGOCRYPT_CTX_DONE = 6;\n\nconst HTTPS_PORT = 443;\n\nconst stateToString = new Map([\n  [MONGOCRYPT_CTX_ERROR, 'MONGOCRYPT_CTX_ERROR'],\n  [MONGOCRYPT_CTX_NEED_MONGO_COLLINFO, 'MONGOCRYPT_CTX_NEED_MONGO_COLLINFO'],\n  [MONGOCRYPT_CTX_NEED_MONGO_MARKINGS, 'MONGOCRYPT_CTX_NEED_MONGO_MARKINGS'],\n  [MONGOCRYPT_CTX_NEED_MONGO_KEYS, 'MONGOCRYPT_CTX_NEED_MONGO_KEYS'],\n  [MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS, 'MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS'],\n  [MONGOCRYPT_CTX_NEED_KMS, 'MONGOCRYPT_CTX_NEED_KMS'],\n  [MONGOCRYPT_CTX_READY, 'MONGOCRYPT_CTX_READY'],\n  [MONGOCRYPT_CTX_DONE, 'MONGOCRYPT_CTX_DONE']\n]);\n\nconst INSECURE_TLS_OPTIONS = [\n  'tlsInsecure',\n  'tlsAllowInvalidCertificates',\n  'tlsAllowInvalidHostnames',\n\n  // These options are disallowed by the spec, so we explicitly filter them out if provided, even\n  // though the StateMachine does not declare support for these options.\n  'tlsDisableOCSPEndpointCheck',\n  'tlsDisableCertificateRevocationCheck'\n];\n\n/**\n * Helper function for logging. Enabled by setting the environment flag MONGODB_CRYPT_DEBUG.\n * @param msg - Anything you want to be logged.\n */\nfunction debug(msg: unknown) {\n  if (process.env.MONGODB_CRYPT_DEBUG) {\n    // eslint-disable-next-line no-console\n    console.error(msg);\n  }\n}\n\ndeclare module 'mongodb-client-encryption' {\n  // the properties added to `MongoCryptContext` here are only used for the `StateMachine`'s\n  // execute method and are not part of the C++ bindings.\n  interface MongoCryptContext {\n    id: number;\n    document: Document;\n    ns: string;\n  }\n}\n\n/**\n * @public\n *\n * TLS options to use when connecting. The spec specifically calls out which insecure\n * tls options are not allowed:\n *\n *  - tlsAllowInvalidCertificates\n *  - tlsAllowInvalidHostnames\n *  - tlsInsecure\n *\n * These options are not included in the type, and are ignored if provided.\n */\nexport type ClientEncryptionTlsOptions = Pick<\n  MongoClientOptions,\n  'tlsCAFile' | 'tlsCertificateKeyFile' | 'tlsCertificateKeyFilePassword'\n>;\n\n/** @public */\nexport type CSFLEKMSTlsOptions = {\n  aws?: ClientEncryptionTlsOptions;\n  gcp?: ClientEncryptionTlsOptions;\n  kmip?: ClientEncryptionTlsOptions;\n  local?: ClientEncryptionTlsOptions;\n  azure?: ClientEncryptionTlsOptions;\n\n  [key: string]: ClientEncryptionTlsOptions | undefined;\n};\n\n/**\n * @public\n *\n * Socket options to use for KMS requests.\n */\nexport type ClientEncryptionSocketOptions = Pick<\n  MongoClientOptions,\n  'autoSelectFamily' | 'autoSelectFamilyAttemptTimeout'\n>;\n\n/**\n * This is kind of a hack.  For `rewrapManyDataKey`, we have tests that\n * guarantee that when there are no matching keys, `rewrapManyDataKey` returns\n * nothing.  We also have tests for auto encryption that guarantee for `encrypt`\n * we return an error when there are no matching keys.  This error is generated in\n * subsequent iterations of the state machine.\n * Some apis (`encrypt`) throw if there are no filter matches and others (`rewrapManyDataKey`)\n * do not.  We set the result manually here, and let the state machine continue.  `libmongocrypt`\n * will inform us if we need to error by setting the state to `MONGOCRYPT_CTX_ERROR` but\n * otherwise we'll return `{ v: [] }`.\n */\nlet EMPTY_V;\n\n/**\n * @internal\n *\n * An interface representing an object that can be passed to the `StateMachine.execute` method.\n *\n * Not all properties are required for all operations.\n */\nexport interface StateMachineExecutable {\n  _keyVaultNamespace: string;\n  _keyVaultClient: MongoClient;\n  askForKMSCredentials: () => Promise<KMSProviders>;\n\n  /** only used for auto encryption */\n  _metaDataClient?: MongoClient;\n  /** only used for auto encryption */\n  _mongocryptdClient?: MongoClient;\n  /** only used for auto encryption */\n  _mongocryptdManager?: MongocryptdManager;\n}\n\nexport type StateMachineOptions = {\n  /** socks5 proxy options, if set. */\n  proxyOptions: ProxyOptions;\n\n  /** TLS options for KMS requests, if set. */\n  tlsOptions: CSFLEKMSTlsOptions;\n\n  /** Socket specific options we support. */\n  socketOptions: ClientEncryptionSocketOptions;\n} & Pick<BSONSerializeOptions, 'promoteLongs' | 'promoteValues'>;\n\n/**\n * @internal\n * An internal class that executes across a MongoCryptContext until either\n * a finishing state or an error is reached. Do not instantiate directly.\n */\n// TODO(DRIVERS-2671): clarify CSOT behavior for FLE APIs\nexport class StateMachine {\n  constructor(\n    private options: StateMachineOptions,\n    private bsonOptions = pluckBSONSerializeOptions(options)\n  ) {}\n\n  /**\n   * Executes the state machine according to the specification\n   */\n  async execute(\n    executor: StateMachineExecutable,\n    context: MongoCryptContext,\n    options: { timeoutContext?: TimeoutContext } & Abortable\n  ): Promise<Uint8Array> {\n    const keyVaultNamespace = executor._keyVaultNamespace;\n    const keyVaultClient = executor._keyVaultClient;\n    const metaDataClient = executor._metaDataClient;\n    const mongocryptdClient = executor._mongocryptdClient;\n    const mongocryptdManager = executor._mongocryptdManager;\n    let result: Uint8Array | null = null;\n\n    // Typescript treats getters just like properties: Once you've tested it for equality\n    // it cannot change. Which is exactly the opposite of what we use state and status for.\n    // Every call to at least `addMongoOperationResponse` and `finalize` can change the state.\n    // These wrappers let us write code more naturally and not add compiler exceptions\n    // to conditions checks inside the state machine.\n    const getStatus = () => context.status;\n    const getState = () => context.state;\n\n    while (getState() !== MONGOCRYPT_CTX_DONE && getState() !== MONGOCRYPT_CTX_ERROR) {\n      options.signal?.throwIfAborted();\n      debug(`[context#${context.id}] ${stateToString.get(getState()) || getState()}`);\n\n      switch (getState()) {\n        case MONGOCRYPT_CTX_NEED_MONGO_COLLINFO: {\n          const filter = deserialize(context.nextMongoOperation());\n          if (!metaDataClient) {\n            throw new MongoCryptError(\n              'unreachable state machine state: entered MONGOCRYPT_CTX_NEED_MONGO_COLLINFO but metadata client is undefined'\n            );\n          }\n\n          const collInfoCursor = this.fetchCollectionInfo(\n            metaDataClient,\n            context.ns,\n            filter,\n            options\n          );\n\n          for await (const collInfo of collInfoCursor) {\n            context.addMongoOperationResponse(serialize(collInfo));\n            if (getState() === MONGOCRYPT_CTX_ERROR) break;\n          }\n\n          if (getState() === MONGOCRYPT_CTX_ERROR) break;\n\n          context.finishMongoOperation();\n          break;\n        }\n\n        case MONGOCRYPT_CTX_NEED_MONGO_MARKINGS: {\n          const command = context.nextMongoOperation();\n          if (getState() === MONGOCRYPT_CTX_ERROR) break;\n\n          if (!mongocryptdClient) {\n            throw new MongoCryptError(\n              'unreachable state machine state: entered MONGOCRYPT_CTX_NEED_MONGO_MARKINGS but mongocryptdClient is undefined'\n            );\n          }\n\n          // When we are using the shared library, we don't have a mongocryptd manager.\n          const markedCommand: Uint8Array = mongocryptdManager\n            ? await mongocryptdManager.withRespawn(\n                this.markCommand.bind(this, mongocryptdClient, context.ns, command, options)\n              )\n            : await this.markCommand(mongocryptdClient, context.ns, command, options);\n\n          context.addMongoOperationResponse(markedCommand);\n          context.finishMongoOperation();\n          break;\n        }\n\n        case MONGOCRYPT_CTX_NEED_MONGO_KEYS: {\n          const filter = context.nextMongoOperation();\n          const keys = await this.fetchKeys(keyVaultClient, keyVaultNamespace, filter, options);\n\n          if (keys.length === 0) {\n            // See docs on EMPTY_V\n            result = EMPTY_V ??= serialize({ v: [] });\n          }\n          for (const key of keys) {\n            context.addMongoOperationResponse(serialize(key));\n          }\n\n          context.finishMongoOperation();\n\n          break;\n        }\n\n        case MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS: {\n          const kmsProviders = await executor.askForKMSCredentials();\n          context.provideKMSProviders(serialize(kmsProviders));\n          break;\n        }\n\n        case MONGOCRYPT_CTX_NEED_KMS: {\n          await Promise.all(this.requests(context, options));\n          context.finishKMSRequests();\n          break;\n        }\n\n        case MONGOCRYPT_CTX_READY: {\n          const finalizedContext = context.finalize();\n          if (getState() === MONGOCRYPT_CTX_ERROR) {\n            const message = getStatus().message || 'Finalization error';\n            throw new MongoCryptError(message);\n          }\n          result = finalizedContext;\n          break;\n        }\n\n        default:\n          throw new MongoCryptError(`Unknown state: ${getState()}`);\n      }\n    }\n\n    if (getState() === MONGOCRYPT_CTX_ERROR || result == null) {\n      const message = getStatus().message;\n      if (!message) {\n        debug(\n          `unidentifiable error in MongoCrypt - received an error status from \\`libmongocrypt\\` but received no error message.`\n        );\n      }\n      throw new MongoCryptError(\n        message ??\n          'unidentifiable error in MongoCrypt - received an error status from `libmongocrypt` but received no error message.'\n      );\n    }\n\n    return result;\n  }\n\n  /**\n   * Handles the request to the KMS service. Exposed for testing purposes. Do not directly invoke.\n   * @param kmsContext - A C++ KMS context returned from the bindings\n   * @returns A promise that resolves when the KMS reply has be fully parsed\n   */\n  async kmsRequest(\n    request: MongoCryptKMSRequest,\n    options?: { timeoutContext?: TimeoutContext } & Abortable\n  ): Promise<void> {\n    const parsedUrl = request.endpoint.split(':');\n    const port = parsedUrl[1] != null ? Number.parseInt(parsedUrl[1], 10) : HTTPS_PORT;\n    const socketOptions: tls.ConnectionOptions & {\n      host: string;\n      port: number;\n      autoSelectFamily?: boolean;\n      autoSelectFamilyAttemptTimeout?: number;\n    } = {\n      host: parsedUrl[0],\n      servername: parsedUrl[0],\n      port,\n      ...autoSelectSocketOptions(this.options.socketOptions || {})\n    };\n    const message = request.message;\n    const buffer = new BufferPool();\n\n    let netSocket: net.Socket;\n    let socket: tls.TLSSocket;\n\n    function destroySockets() {\n      for (const sock of [socket, netSocket]) {\n        if (sock) {\n          sock.destroy();\n        }\n      }\n    }\n\n    function onerror(cause: Error) {\n      return new MongoCryptError('KMS request failed', { cause });\n    }\n\n    function onclose() {\n      return new MongoCryptError('KMS request closed');\n    }\n\n    const tlsOptions = this.options.tlsOptions;\n    if (tlsOptions) {\n      const kmsProvider = request.kmsProvider;\n      const providerTlsOptions = tlsOptions[kmsProvider];\n      if (providerTlsOptions) {\n        const error = this.validateTlsOptions(kmsProvider, providerTlsOptions);\n        if (error) {\n          throw error;\n        }\n        try {\n          await this.setTlsOptions(providerTlsOptions, socketOptions);\n        } catch (err) {\n          throw onerror(err);\n        }\n      }\n    }\n\n    let abortListener;\n\n    try {\n      if (this.options.proxyOptions && this.options.proxyOptions.proxyHost) {\n        netSocket = new net.Socket();\n\n        const {\n          promise: willConnect,\n          reject: rejectOnNetSocketError,\n          resolve: resolveOnNetSocketConnect\n        } = promiseWithResolvers<void>();\n\n        netSocket\n          .once('error', err => rejectOnNetSocketError(onerror(err)))\n          .once('close', () => rejectOnNetSocketError(onclose()))\n          .once('connect', () => resolveOnNetSocketConnect());\n\n        const netSocketOptions = {\n          ...socketOptions,\n          host: this.options.proxyOptions.proxyHost,\n          port: this.options.proxyOptions.proxyPort || 1080\n        };\n\n        netSocket.connect(netSocketOptions);\n\n        await willConnect;\n\n        try {\n          socks ??= loadSocks();\n          socketOptions.socket = (\n            await socks.SocksClient.createConnection({\n              existing_socket: netSocket,\n              command: 'connect',\n              destination: { host: socketOptions.host, port: socketOptions.port },\n              proxy: {\n                // host and port are ignored because we pass existing_socket\n                host: 'iLoveJavaScript',\n                port: 0,\n                type: 5,\n                userId: this.options.proxyOptions.proxyUsername,\n                password: this.options.proxyOptions.proxyPassword\n              }\n            })\n          ).socket;\n        } catch (err) {\n          throw onerror(err);\n        }\n      }\n\n      socket = tls.connect(socketOptions, () => {\n        socket.write(message);\n      });\n\n      const {\n        promise: willResolveKmsRequest,\n        reject: rejectOnTlsSocketError,\n        resolve\n      } = promiseWithResolvers<void>();\n\n      abortListener = addAbortListener(options?.signal, function () {\n        destroySockets();\n        rejectOnTlsSocketError(this.reason);\n      });\n\n      socket\n        .once('error', err => rejectOnTlsSocketError(onerror(err)))\n        .once('close', () => rejectOnTlsSocketError(onclose()))\n        .on('data', data => {\n          buffer.append(data);\n          while (request.bytesNeeded > 0 && buffer.length) {\n            const bytesNeeded = Math.min(request.bytesNeeded, buffer.length);\n            request.addResponse(buffer.read(bytesNeeded));\n          }\n\n          if (request.bytesNeeded <= 0) {\n            resolve();\n          }\n        });\n      await (options?.timeoutContext?.csotEnabled()\n        ? Promise.all([\n            willResolveKmsRequest,\n            Timeout.expires(options.timeoutContext?.remainingTimeMS)\n          ])\n        : willResolveKmsRequest);\n    } catch (error) {\n      if (error instanceof TimeoutError)\n        throw new MongoOperationTimeoutError('KMS request timed out');\n      throw error;\n    } finally {\n      // There's no need for any more activity on this socket at this point.\n      destroySockets();\n      abortListener?.[kDispose]();\n    }\n  }\n\n  *requests(context: MongoCryptContext, options?: { timeoutContext?: TimeoutContext } & Abortable) {\n    for (\n      let request = context.nextKMSRequest();\n      request != null;\n      request = context.nextKMSRequest()\n    ) {\n      yield this.kmsRequest(request, options);\n    }\n  }\n\n  /**\n   * Validates the provided TLS options are secure.\n   *\n   * @param kmsProvider - The KMS provider name.\n   * @param tlsOptions - The client TLS options for the provider.\n   *\n   * @returns An error if any option is invalid.\n   */\n  validateTlsOptions(\n    kmsProvider: string,\n    tlsOptions: ClientEncryptionTlsOptions\n  ): MongoCryptError | void {\n    const tlsOptionNames = Object.keys(tlsOptions);\n    for (const option of INSECURE_TLS_OPTIONS) {\n      if (tlsOptionNames.includes(option)) {\n        return new MongoCryptError(`Insecure TLS options prohibited for ${kmsProvider}: ${option}`);\n      }\n    }\n  }\n\n  /**\n   * Sets only the valid secure TLS options.\n   *\n   * @param tlsOptions - The client TLS options for the provider.\n   * @param options - The existing connection options.\n   */\n  async setTlsOptions(\n    tlsOptions: ClientEncryptionTlsOptions,\n    options: tls.ConnectionOptions\n  ): Promise<void> {\n    if (tlsOptions.tlsCertificateKeyFile) {\n      const cert = await fs.readFile(tlsOptions.tlsCertificateKeyFile);\n      options.cert = options.key = cert;\n    }\n    if (tlsOptions.tlsCAFile) {\n      options.ca = await fs.readFile(tlsOptions.tlsCAFile);\n    }\n    if (tlsOptions.tlsCertificateKeyFilePassword) {\n      options.passphrase = tlsOptions.tlsCertificateKeyFilePassword;\n    }\n  }\n\n  /**\n   * Fetches collection info for a provided namespace, when libmongocrypt\n   * enters the `MONGOCRYPT_CTX_NEED_MONGO_COLLINFO` state. The result is\n   * used to inform libmongocrypt of the schema associated with this\n   * namespace. Exposed for testing purposes. Do not directly invoke.\n   *\n   * @param client - A MongoClient connected to the topology\n   * @param ns - The namespace to list collections from\n   * @param filter - A filter for the listCollections command\n   * @param callback - Invoked with the info of the requested collection, or with an error\n   */\n  fetchCollectionInfo(\n    client: MongoClient,\n    ns: string,\n    filter: Document,\n    options?: { timeoutContext?: TimeoutContext } & Abortable\n  ): AsyncIterable<CollectionInfo> {\n    const { db } = MongoDBCollectionNamespace.fromString(ns);\n\n    const cursor = client.db(db).listCollections(filter, {\n      promoteLongs: false,\n      promoteValues: false,\n      timeoutContext:\n        options?.timeoutContext && new CursorTimeoutContext(options?.timeoutContext, Symbol()),\n      signal: options?.signal,\n      nameOnly: false\n    });\n\n    return cursor;\n  }\n\n  /**\n   * Calls to the mongocryptd to provide markings for a command.\n   * Exposed for testing purposes. Do not directly invoke.\n   * @param client - A MongoClient connected to a mongocryptd\n   * @param ns - The namespace (database.collection) the command is being executed on\n   * @param command - The command to execute.\n   * @param callback - Invoked with the serialized and marked bson command, or with an error\n   */\n  async markCommand(\n    client: MongoClient,\n    ns: string,\n    command: Uint8Array,\n    options?: { timeoutContext?: TimeoutContext } & Abortable\n  ): Promise<Uint8Array> {\n    const { db } = MongoDBCollectionNamespace.fromString(ns);\n    const bsonOptions = { promoteLongs: false, promoteValues: false };\n    const rawCommand = deserialize(command, bsonOptions);\n\n    const commandOptions: {\n      timeoutMS?: number;\n      signal?: AbortSignal;\n    } = {\n      timeoutMS: undefined,\n      signal: undefined\n    };\n\n    if (options?.timeoutContext?.csotEnabled()) {\n      commandOptions.timeoutMS = options.timeoutContext.remainingTimeMS;\n    }\n    if (options?.signal) {\n      commandOptions.signal = options.signal;\n    }\n\n    const response = await client.db(db).command(rawCommand, {\n      ...bsonOptions,\n      ...commandOptions\n    });\n\n    return serialize(response, this.bsonOptions);\n  }\n\n  /**\n   * Requests keys from the keyVault collection on the topology.\n   * Exposed for testing purposes. Do not directly invoke.\n   * @param client - A MongoClient connected to the topology\n   * @param keyVaultNamespace - The namespace (database.collection) of the keyVault Collection\n   * @param filter - The filter for the find query against the keyVault Collection\n   * @param callback - Invoked with the found keys, or with an error\n   */\n  fetchKeys(\n    client: MongoClient,\n    keyVaultNamespace: string,\n    filter: Uint8Array,\n    options?: { timeoutContext?: TimeoutContext } & Abortable\n  ): Promise<Array<DataKey>> {\n    const { db: dbName, collection: collectionName } =\n      MongoDBCollectionNamespace.fromString(keyVaultNamespace);\n\n    const commandOptions: {\n      timeoutContext?: CursorTimeoutContext;\n      signal?: AbortSignal;\n    } = {\n      timeoutContext: undefined,\n      signal: undefined\n    };\n\n    if (options?.timeoutContext != null) {\n      commandOptions.timeoutContext = new CursorTimeoutContext(options.timeoutContext, Symbol());\n    }\n    if (options?.signal != null) {\n      commandOptions.signal = options.signal;\n    }\n\n    return client\n      .db(dbName)\n      .collection<DataKey>(collectionName, { readConcern: { level: 'majority' } })\n      .find(deserialize(filter), commandOptions)\n      .toArray();\n  }\n}\n"],"names":[],"mappings":";;;;;AAAA,MAAA;AAEA,MAAA;AACA,MAAA;AAEA,MAAA;AAQA,MAAA;AACA,MAAA;AACA,MAAA;AAIA,MAAA;AACA,MAAA;AAOA,MAAA;AACA,MAAA;AAIA,IAAI,QAAyB;AAC7B,SAAS;IACP,IAAI,SAAS,MAAM;QACjB,MAAM,cAAc,CAAA,GAAA,OAAA,QAAQ;QAC5B,IAAI,kBAAkB,aAAa;YACjC,MAAM,YAAY,YAAY;QAChC;QACA,QAAQ;IACV;IACA,OAAO;AACT;AAEA,uBAAuB;AACvB,MAAM,uBAAuB;AAC7B,MAAM,qCAAqC;AAC3C,MAAM,qCAAqC;AAC3C,MAAM,iCAAiC;AACvC,MAAM,sCAAsC;AAC5C,MAAM,0BAA0B;AAChC,MAAM,uBAAuB;AAC7B,MAAM,sBAAsB;AAE5B,MAAM,aAAa;AAEnB,MAAM,gBAAgB,IAAI,IAAI;IAC5B;QAAC;QAAsB;KAAuB;IAC9C;QAAC;QAAoC;KAAqC;IAC1E;QAAC;QAAoC;KAAqC;IAC1E;QAAC;QAAgC;KAAiC;IAClE;QAAC;QAAqC;KAAsC;IAC5E;QAAC;QAAyB;KAA0B;IACpD;QAAC;QAAsB;KAAuB;IAC9C;QAAC;QAAqB;KAAsB;CAC7C;AAED,MAAM,uBAAuB;IAC3B;IACA;IACA;IAEA,+FAA+F;IAC/F,sEAAsE;IACtE;IACA;CACD;AAED;;;IAIA,SAAS,MAAM,GAAY;IACzB,IAAI,QAAQ,GAAG,CAAC,mBAAmB,EAAE;QACnC,sCAAsC;QACtC,QAAQ,KAAK,CAAC;IAChB;AACF;AAkDA;;;;;;;;;;IAWA,IAAI;AAiCJ;;;;IAKA,yDAAyD;AACzD,MAAa;IACX,YACU,OAA4B,EAC5B,cAAc,CAAA,GAAA,OAAA,yBAAyB,EAAC,QAAQ,CAAA;QADhD,IAAA,CAAA,OAAO,GAAP;QACA,IAAA,CAAA,WAAW,GAAX;IACP;IAEH;;QAGA,MAAM,QACJ,QAAgC,EAChC,OAA0B,EAC1B,OAAwD,EAAA;QAExD,MAAM,oBAAoB,SAAS,kBAAkB;QACrD,MAAM,iBAAiB,SAAS,eAAe;QAC/C,MAAM,iBAAiB,SAAS,eAAe;QAC/C,MAAM,oBAAoB,SAAS,kBAAkB;QACrD,MAAM,qBAAqB,SAAS,mBAAmB;QACvD,IAAI,SAA4B;QAEhC,qFAAqF;QACrF,uFAAuF;QACvF,0FAA0F;QAC1F,kFAAkF;QAClF,iDAAiD;QACjD,MAAM,YAAY,IAAM,QAAQ,MAAM;QACtC,MAAM,WAAW,IAAM,QAAQ,KAAK;QAEpC,MAAO,eAAe,uBAAuB,eAAe,qBAAsB;YAChF,QAAQ,MAAM,EAAE;YAChB,MAAM,CAAA,SAAA,EAAY,QAAQ,EAAE,CAAA,EAAA,EAAK,cAAc,GAAG,CAAC,eAAe,WAAU,CAAE;YAE9E,OAAQ;gBACN,KAAK;oBAAoC;wBACvC,MAAM,SAAS,CAAA,GAAA,OAAA,WAAW,EAAC,QAAQ,kBAAkB;wBACrD,IAAI,CAAC,gBAAgB;4BACnB,MAAM,IAAI,SAAA,eAAe,CACvB;wBAEJ;wBAEA,MAAM,iBAAiB,IAAI,CAAC,mBAAmB,CAC7C,gBACA,QAAQ,EAAE,EACV,QACA;wBAGF,WAAW,MAAM,YAAY,eAAgB;4BAC3C,QAAQ,yBAAyB,CAAC,CAAA,GAAA,OAAA,SAAS,EAAC;4BAC5C,IAAI,eAAe,sBAAsB;wBAC3C;wBAEA,IAAI,eAAe,sBAAsB;wBAEzC,QAAQ,oBAAoB;wBAC5B;oBACF;gBAEA,KAAK;oBAAoC;wBACvC,MAAM,UAAU,QAAQ,kBAAkB;wBAC1C,IAAI,eAAe,sBAAsB;wBAEzC,IAAI,CAAC,mBAAmB;4BACtB,MAAM,IAAI,SAAA,eAAe,CACvB;wBAEJ;wBAEA,6EAA6E;wBAC7E,MAAM,gBAA4B,qBAC9B,MAAM,mBAAmB,WAAW,CAClC,IAAI,CAAC,WAAW,CAAC,IAAI,CAAC,IAAI,EAAE,mBAAmB,QAAQ,EAAE,EAAE,SAAS,YAEtE,MAAM,IAAI,CAAC,WAAW,CAAC,mBAAmB,QAAQ,EAAE,EAAE,SAAS;wBAEnE,QAAQ,yBAAyB,CAAC;wBAClC,QAAQ,oBAAoB;wBAC5B;oBACF;gBAEA,KAAK;oBAAgC;wBACnC,MAAM,SAAS,QAAQ,kBAAkB;wBACzC,MAAM,OAAO,MAAM,IAAI,CAAC,SAAS,CAAC,gBAAgB,mBAAmB,QAAQ;wBAE7E,IAAI,KAAK,MAAM,KAAK,GAAG;4BACrB,sBAAsB;4BACtB,SAAS,YAAY,CAAA,GAAA,OAAA,SAAS,EAAC;gCAAE,GAAG,EAAE;4BAAA;wBACxC;wBACA,KAAK,MAAM,OAAO,KAAM;4BACtB,QAAQ,yBAAyB,CAAC,CAAA,GAAA,OAAA,SAAS,EAAC;wBAC9C;wBAEA,QAAQ,oBAAoB;wBAE5B;oBACF;gBAEA,KAAK;oBAAqC;wBACxC,MAAM,eAAe,MAAM,SAAS,oBAAoB;wBACxD,QAAQ,mBAAmB,CAAC,CAAA,GAAA,OAAA,SAAS,EAAC;wBACtC;oBACF;gBAEA,KAAK;oBAAyB;wBAC5B,MAAM,QAAQ,GAAG,CAAC,IAAI,CAAC,QAAQ,CAAC,SAAS;wBACzC,QAAQ,iBAAiB;wBACzB;oBACF;gBAEA,KAAK;oBAAsB;wBACzB,MAAM,mBAAmB,QAAQ,QAAQ;wBACzC,IAAI,eAAe,sBAAsB;4BACvC,MAAM,UAAU,YAAY,OAAO,IAAI;4BACvC,MAAM,IAAI,SAAA,eAAe,CAAC;wBAC5B;wBACA,SAAS;wBACT;oBACF;gBAEA;oBACE,MAAM,IAAI,SAAA,eAAe,CAAC,CAAA,eAAA,EAAkB,WAAU,CAAE;YAC5D;QACF;QAEA,IAAI,eAAe,wBAAwB,UAAU,MAAM;YACzD,MAAM,UAAU,YAAY,OAAO;YACnC,IAAI,CAAC,SAAS;gBACZ,MACE,CAAA,mHAAA,CAAqH;YAEzH;YACA,MAAM,IAAI,SAAA,eAAe,CACvB,WACE;QAEN;QAEA,OAAO;IACT;IAEA;;;;QAKA,MAAM,WACJ,OAA6B,EAC7B,OAAyD,EAAA;QAEzD,MAAM,YAAY,QAAQ,QAAQ,CAAC,KAAK,CAAC;QACzC,MAAM,OAAO,SAAS,CAAC,EAAE,IAAI,OAAO,OAAO,QAAQ,CAAC,SAAS,CAAC,EAAE,EAAE,MAAM;QACxE,MAAM,gBAKF;YACF,MAAM,SAAS,CAAC,EAAE;YAClB,YAAY,SAAS,CAAC,EAAE;YACxB;YACA,GAAG,CAAA,GAAA,oBAAA,uBAAuB,EAAC,IAAI,CAAC,OAAO,CAAC,aAAa,IAAI,CAAA,EAAG;;QAE9D,MAAM,UAAU,QAAQ,OAAO;QAC/B,MAAM,SAAS,IAAI,QAAA,UAAU;QAE7B,IAAI;QACJ,IAAI;QAEJ,SAAS;YACP,KAAK,MAAM,QAAQ;gBAAC;gBAAQ;aAAU,CAAE;gBACtC,IAAI,MAAM;oBACR,KAAK,OAAO;gBACd;YACF;QACF;QAEA,SAAS,QAAQ,KAAY;YAC3B,OAAO,IAAI,SAAA,eAAe,CAAC,sBAAsB;gBAAE;YAAK;QAC1D;QAEA,SAAS;YACP,OAAO,IAAI,SAAA,eAAe,CAAC;QAC7B;QAEA,MAAM,aAAa,IAAI,CAAC,OAAO,CAAC,UAAU;QAC1C,IAAI,YAAY;YACd,MAAM,cAAc,QAAQ,WAAW;YACvC,MAAM,qBAAqB,UAAU,CAAC,YAAY;YAClD,IAAI,oBAAoB;gBACtB,MAAM,QAAQ,IAAI,CAAC,kBAAkB,CAAC,aAAa;gBACnD,IAAI,OAAO;oBACT,MAAM;gBACR;gBACA,IAAI;oBACF,MAAM,IAAI,CAAC,aAAa,CAAC,oBAAoB;gBAC/C,EAAE,OAAO,KAAK;oBACZ,MAAM,QAAQ;gBAChB;YACF;QACF;QAEA,IAAI;QAEJ,IAAI;YACF,IAAI,IAAI,CAAC,OAAO,CAAC,YAAY,IAAI,IAAI,CAAC,OAAO,CAAC,YAAY,CAAC,SAAS,EAAE;gBACpE,YAAY,IAAI,IAAI,MAAM;gBAE1B,MAAM,EACJ,SAAS,WAAW,EACpB,QAAQ,sBAAsB,EAC9B,SAAS,yBAAyB,EACnC,GAAG,CAAA,GAAA,QAAA,oBAAoB;gBAExB,UACG,IAAI,CAAC,SAAS,CAAA,MAAO,uBAAuB,QAAQ,OACpD,IAAI,CAAC,SAAS,IAAM,uBAAuB,YAC3C,IAAI,CAAC,WAAW,IAAM;gBAEzB,MAAM,mBAAmB;oBACvB,GAAG,aAAa;oBAChB,MAAM,IAAI,CAAC,OAAO,CAAC,YAAY,CAAC,SAAS;oBACzC,MAAM,IAAI,CAAC,OAAO,CAAC,YAAY,CAAC,SAAS,IAAI;;gBAG/C,UAAU,OAAO,CAAC;gBAElB,MAAM;gBAEN,IAAI;oBACF,UAAU;oBACV,cAAc,MAAM,GAAG,CACrB,MAAM,MAAM,WAAW,CAAC,gBAAgB,CAAC;wBACvC,iBAAiB;wBACjB,SAAS;wBACT,aAAa;4BAAE,MAAM,cAAc,IAAI;4BAAE,MAAM,cAAc,IAAI;wBAAA;wBACjE,OAAO;4BACL,4DAA4D;4BAC5D,MAAM;4BACN,MAAM;4BACN,MAAM;4BACN,QAAQ,IAAI,CAAC,OAAO,CAAC,YAAY,CAAC,aAAa;4BAC/C,UAAU,IAAI,CAAC,OAAO,CAAC,YAAY,CAAC,aAAa;;sBAEnD,EACF,MAAM;gBACV,EAAE,OAAO,KAAK;oBACZ,MAAM,QAAQ;gBAChB;YACF;YAEA,SAAS,IAAI,OAAO,CAAC,eAAe;gBAClC,OAAO,KAAK,CAAC;YACf;YAEA,MAAM,EACJ,SAAS,qBAAqB,EAC9B,QAAQ,sBAAsB,EAC9B,OAAO,EACR,GAAG,CAAA,GAAA,QAAA,oBAAoB;YAExB,gBAAgB,CAAA,GAAA,QAAA,gBAAgB,EAAC,SAAS,QAAQ;gBAChD;gBACA,uBAAuB,IAAI,CAAC,MAAM;YACpC;YAEA,OACG,IAAI,CAAC,SAAS,CAAA,MAAO,uBAAuB,QAAQ,OACpD,IAAI,CAAC,SAAS,IAAM,uBAAuB,YAC3C,EAAE,CAAC,QAAQ,CAAA;gBACV,OAAO,MAAM,CAAC;gBACd,MAAO,QAAQ,WAAW,GAAG,KAAK,OAAO,MAAM,CAAE;oBAC/C,MAAM,cAAc,KAAK,GAAG,CAAC,QAAQ,WAAW,EAAE,OAAO,MAAM;oBAC/D,QAAQ,WAAW,CAAC,OAAO,IAAI,CAAC;gBAClC;gBAEA,IAAI,QAAQ,WAAW,IAAI,GAAG;oBAC5B;gBACF;YACF;YACF,MAAM,CAAC,SAAS,gBAAgB,gBAC5B,QAAQ,GAAG,CAAC;gBACV;gBACA,UAAA,OAAO,CAAC,OAAO,CAAC,QAAQ,cAAc,EAAE;aACzC,IACD,qBAAqB;QAC3B,EAAE,OAAO,OAAO;YACd,IAAI,iBAAiB,UAAA,YAAY,EAC/B,MAAM,IAAI,QAAA,0BAA0B,CAAC;YACvC,MAAM;QACR,SAAU;YACR,sEAAsE;YACtE;YACA,eAAe,CAAC,QAAA,QAAQ,CAAC;QAC3B;IACF;IAEA,CAAC,SAAS,OAA0B,EAAE,OAAyD,EAAA;QAC7F,IACE,IAAI,UAAU,QAAQ,cAAc,IACpC,WAAW,MACX,UAAU,QAAQ,cAAc,GAChC;YACA,MAAM,IAAI,CAAC,UAAU,CAAC,SAAS;QACjC;IACF;IAEA;;;;;;;QAQA,mBACE,WAAmB,EACnB,UAAsC,EAAA;QAEtC,MAAM,iBAAiB,OAAO,IAAI,CAAC;QACnC,KAAK,MAAM,UAAU,qBAAsB;YACzC,IAAI,eAAe,QAAQ,CAAC,SAAS;gBACnC,OAAO,IAAI,SAAA,eAAe,CAAC,CAAA,oCAAA,EAAuC,YAAW,EAAA,EAAK,OAAM,CAAE;YAC5F;QACF;IACF;IAEA;;;;;QAMA,MAAM,cACJ,UAAsC,EACtC,OAA8B,EAAA;QAE9B,IAAI,WAAW,qBAAqB,EAAE;YACpC,MAAM,OAAO,MAAM,GAAG,QAAQ,CAAC,WAAW,qBAAqB;YAC/D,QAAQ,IAAI,GAAG,QAAQ,GAAG,GAAG;QAC/B;QACA,IAAI,WAAW,SAAS,EAAE;YACxB,QAAQ,EAAE,GAAG,MAAM,GAAG,QAAQ,CAAC,WAAW,SAAS;QACrD;QACA,IAAI,WAAW,6BAA6B,EAAE;YAC5C,QAAQ,UAAU,GAAG,WAAW,6BAA6B;QAC/D;IACF;IAEA;;;;;;;;;;QAWA,oBACE,MAAmB,EACnB,EAAU,EACV,MAAgB,EAChB,OAAyD,EAAA;QAEzD,MAAM,EAAE,EAAE,EAAE,GAAG,QAAA,0BAA0B,CAAC,UAAU,CAAC;QAErD,MAAM,SAAS,OAAO,EAAE,CAAC,IAAI,eAAe,CAAC,QAAQ;YACnD,cAAc;YACd,eAAe;YACf,gBACE,SAAS,kBAAkB,IAAI,kBAAA,oBAAoB,CAAC,SAAS,gBAAgB;YAC/E,QAAQ,SAAS;YACjB,UAAU;;QAGZ,OAAO;IACT;IAEA;;;;;;;QAQA,MAAM,YACJ,MAAmB,EACnB,EAAU,EACV,OAAmB,EACnB,OAAyD,EAAA;QAEzD,MAAM,EAAE,EAAE,EAAE,GAAG,QAAA,0BAA0B,CAAC,UAAU,CAAC;QACrD,MAAM,cAAc;YAAE,cAAc;YAAO,eAAe;QAAK;QAC/D,MAAM,aAAa,CAAA,GAAA,OAAA,WAAW,EAAC,SAAS;QAExC,MAAM,iBAGF;YACF,WAAW;YACX,QAAQ;;QAGV,IAAI,SAAS,gBAAgB,eAAe;YAC1C,eAAe,SAAS,GAAG,QAAQ,cAAc,CAAC,eAAe;QACnE;QACA,IAAI,SAAS,QAAQ;YACnB,eAAe,MAAM,GAAG,QAAQ,MAAM;QACxC;QAEA,MAAM,WAAW,MAAM,OAAO,EAAE,CAAC,IAAI,OAAO,CAAC,YAAY;YACvD,GAAG,WAAW;YACd,GAAG,cAAc;;QAGnB,OAAO,CAAA,GAAA,OAAA,SAAS,EAAC,UAAU,IAAI,CAAC,WAAW;IAC7C;IAEA;;;;;;;QAQA,UACE,MAAmB,EACnB,iBAAyB,EACzB,MAAkB,EAClB,OAAyD,EAAA;QAEzD,MAAM,EAAE,IAAI,MAAM,EAAE,YAAY,cAAc,EAAE,GAC9C,QAAA,0BAA0B,CAAC,UAAU,CAAC;QAExC,MAAM,iBAGF;YACF,gBAAgB;YAChB,QAAQ;;QAGV,IAAI,SAAS,kBAAkB,MAAM;YACnC,eAAe,cAAc,GAAG,IAAI,kBAAA,oBAAoB,CAAC,QAAQ,cAAc,EAAE;QACnF;QACA,IAAI,SAAS,UAAU,MAAM;YAC3B,eAAe,MAAM,GAAG,QAAQ,MAAM;QACxC;QAEA,OAAO,OACJ,EAAE,CAAC,QACH,UAAU,CAAU,gBAAgB;YAAE,aAAa;gBAAE,OAAO;YAAU;QAAE,GACxE,IAAI,CAAC,CAAA,GAAA,OAAA,WAAW,EAAC,SAAS,gBAC1B,OAAO;IACZ;;AA3cF,QAAA,YAAA,GAAA"}},
    {"offset": {"line": 9532, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 9536, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/client-side-encryption/client_encryption.ts"],"sourcesContent":["import type {\n  ExplicitEncryptionContextOptions,\n  MongoCrypt,\n  MongoCryptConstructor,\n  MongoCryptOptions\n} from 'mongodb-client-encryption';\n\nimport {\n  type Binary,\n  deserialize,\n  type Document,\n  type Int32,\n  type Long,\n  serialize,\n  type UUID\n} from '../bson';\nimport { type AnyBulkWriteOperation, type BulkWriteResult } from '../bulk/common';\nimport { type ProxyOptions } from '../cmap/connection';\nimport { type Collection } from '../collection';\nimport { type FindCursor } from '../cursor/find_cursor';\nimport { type Db } from '../db';\nimport { getMongoDBClientEncryption } from '../deps';\nimport { type MongoClient, type MongoClientOptions } from '../mongo_client';\nimport { type Filter, type WithId } from '../mongo_types';\nimport { type CreateCollectionOptions } from '../operations/create_collection';\nimport { type DeleteResult } from '../operations/delete';\nimport { type CSOTTimeoutContext, TimeoutContext } from '../timeout';\nimport { MongoDBCollectionNamespace, resolveTimeoutOptions } from '../utils';\nimport * as cryptoCallbacks from './crypto_callbacks';\nimport {\n  MongoCryptCreateDataKeyError,\n  MongoCryptCreateEncryptedCollectionError,\n  MongoCryptInvalidArgumentError\n} from './errors';\nimport {\n  type ClientEncryptionDataKeyProvider,\n  type CredentialProviders,\n  isEmptyCredentials,\n  type KMSProviders,\n  refreshKMSCredentials\n} from './providers/index';\nimport {\n  type ClientEncryptionSocketOptions,\n  type CSFLEKMSTlsOptions,\n  StateMachine\n} from './state_machine';\n\n/**\n * @public\n * The schema for a DataKey in the key vault collection.\n */\nexport interface DataKey {\n  _id: UUID;\n  version?: number;\n  keyAltNames?: string[];\n  keyMaterial: Binary;\n  creationDate: Date;\n  updateDate: Date;\n  status: number;\n  masterKey: Document;\n}\n\n/**\n * @public\n * The public interface for explicit in-use encryption\n */\nexport class ClientEncryption {\n  /** @internal */\n  _client: MongoClient;\n  /** @internal */\n  _keyVaultNamespace: string;\n  /** @internal */\n  _keyVaultClient: MongoClient;\n  /** @internal */\n  _proxyOptions: ProxyOptions;\n  /** @internal */\n  _tlsOptions: CSFLEKMSTlsOptions;\n  /** @internal */\n  _kmsProviders: KMSProviders;\n  /** @internal */\n  _timeoutMS?: number;\n\n  /** @internal */\n  _mongoCrypt: MongoCrypt;\n\n  /** @internal */\n  _credentialProviders?: CredentialProviders;\n\n  /** @internal */\n  static getMongoCrypt(): MongoCryptConstructor {\n    const encryption = getMongoDBClientEncryption();\n    if ('kModuleError' in encryption) {\n      throw encryption.kModuleError;\n    }\n    return encryption.MongoCrypt;\n  }\n\n  /**\n   * Create a new encryption instance\n   *\n   * @example\n   * ```ts\n   * new ClientEncryption(mongoClient, {\n   *   keyVaultNamespace: 'client.encryption',\n   *   kmsProviders: {\n   *     local: {\n   *       key: masterKey // The master key used for encryption/decryption. A 96-byte long Buffer\n   *     }\n   *   }\n   * });\n   * ```\n   *\n   * @example\n   * ```ts\n   * new ClientEncryption(mongoClient, {\n   *   keyVaultNamespace: 'client.encryption',\n   *   kmsProviders: {\n   *     aws: {\n   *       accessKeyId: AWS_ACCESS_KEY,\n   *       secretAccessKey: AWS_SECRET_KEY\n   *     }\n   *   }\n   * });\n   * ```\n   */\n  constructor(client: MongoClient, options: ClientEncryptionOptions) {\n    this._client = client;\n    this._proxyOptions = options.proxyOptions ?? {};\n    this._tlsOptions = options.tlsOptions ?? {};\n    this._kmsProviders = options.kmsProviders || {};\n    const { timeoutMS } = resolveTimeoutOptions(client, options);\n    this._timeoutMS = timeoutMS;\n    this._credentialProviders = options.credentialProviders;\n\n    if (options.credentialProviders?.aws && !isEmptyCredentials('aws', this._kmsProviders)) {\n      throw new MongoCryptInvalidArgumentError(\n        'Can only provide a custom AWS credential provider when the state machine is configured for automatic AWS credential fetching'\n      );\n    }\n\n    if (options.keyVaultNamespace == null) {\n      throw new MongoCryptInvalidArgumentError('Missing required option `keyVaultNamespace`');\n    }\n\n    const mongoCryptOptions: MongoCryptOptions = {\n      ...options,\n      cryptoCallbacks,\n      kmsProviders: !Buffer.isBuffer(this._kmsProviders)\n        ? (serialize(this._kmsProviders) as Buffer)\n        : this._kmsProviders\n    };\n\n    this._keyVaultNamespace = options.keyVaultNamespace;\n    this._keyVaultClient = options.keyVaultClient || client;\n    const MongoCrypt = ClientEncryption.getMongoCrypt();\n    this._mongoCrypt = new MongoCrypt(mongoCryptOptions);\n  }\n\n  /**\n   * Creates a data key used for explicit encryption and inserts it into the key vault namespace\n   *\n   * @example\n   * ```ts\n   * // Using async/await to create a local key\n   * const dataKeyId = await clientEncryption.createDataKey('local');\n   * ```\n   *\n   * @example\n   * ```ts\n   * // Using async/await to create an aws key\n   * const dataKeyId = await clientEncryption.createDataKey('aws', {\n   *   masterKey: {\n   *     region: 'us-east-1',\n   *     key: 'xxxxxxxxxxxxxx' // CMK ARN here\n   *   }\n   * });\n   * ```\n   *\n   * @example\n   * ```ts\n   * // Using async/await to create an aws key with a keyAltName\n   * const dataKeyId = await clientEncryption.createDataKey('aws', {\n   *   masterKey: {\n   *     region: 'us-east-1',\n   *     key: 'xxxxxxxxxxxxxx' // CMK ARN here\n   *   },\n   *   keyAltNames: [ 'mySpecialKey' ]\n   * });\n   * ```\n   */\n  async createDataKey(\n    provider: ClientEncryptionDataKeyProvider,\n    options: ClientEncryptionCreateDataKeyProviderOptions = {}\n  ): Promise<UUID> {\n    if (options.keyAltNames && !Array.isArray(options.keyAltNames)) {\n      throw new MongoCryptInvalidArgumentError(\n        `Option \"keyAltNames\" must be an array of strings, but was of type ${typeof options.keyAltNames}.`\n      );\n    }\n\n    let keyAltNames = undefined;\n    if (options.keyAltNames && options.keyAltNames.length > 0) {\n      keyAltNames = options.keyAltNames.map((keyAltName, i) => {\n        if (typeof keyAltName !== 'string') {\n          throw new MongoCryptInvalidArgumentError(\n            `Option \"keyAltNames\" must be an array of strings, but item at index ${i} was of type ${typeof keyAltName}`\n          );\n        }\n\n        return serialize({ keyAltName });\n      });\n    }\n\n    let keyMaterial = undefined;\n    if (options.keyMaterial) {\n      keyMaterial = serialize({ keyMaterial: options.keyMaterial });\n    }\n\n    const dataKeyBson = serialize({\n      provider,\n      ...options.masterKey\n    });\n\n    const context = this._mongoCrypt.makeDataKeyContext(dataKeyBson, {\n      keyAltNames,\n      keyMaterial\n    });\n\n    const stateMachine = new StateMachine({\n      proxyOptions: this._proxyOptions,\n      tlsOptions: this._tlsOptions,\n      socketOptions: autoSelectSocketOptions(this._client.s.options)\n    });\n\n    const timeoutContext =\n      options?.timeoutContext ??\n      TimeoutContext.create(resolveTimeoutOptions(this._client, { timeoutMS: this._timeoutMS }));\n\n    const dataKey = deserialize(\n      await stateMachine.execute(this, context, { timeoutContext })\n    ) as DataKey;\n\n    const { db: dbName, collection: collectionName } = MongoDBCollectionNamespace.fromString(\n      this._keyVaultNamespace\n    );\n\n    const { insertedId } = await this._keyVaultClient\n      .db(dbName)\n      .collection<DataKey>(collectionName)\n      .insertOne(dataKey, {\n        writeConcern: { w: 'majority' },\n        timeoutMS: timeoutContext?.csotEnabled()\n          ? timeoutContext?.getRemainingTimeMSOrThrow()\n          : undefined\n      });\n\n    return insertedId;\n  }\n\n  /**\n   * Searches the keyvault for any data keys matching the provided filter.  If there are matches, rewrapManyDataKey then attempts to re-wrap the data keys using the provided options.\n   *\n   * If no matches are found, then no bulk write is performed.\n   *\n   * @example\n   * ```ts\n   * // rewrapping all data data keys (using a filter that matches all documents)\n   * const filter = {};\n   *\n   * const result = await clientEncryption.rewrapManyDataKey(filter);\n   * if (result.bulkWriteResult != null) {\n   *  // keys were re-wrapped, results will be available in the bulkWrite object.\n   * }\n   * ```\n   *\n   * @example\n   * ```ts\n   * // attempting to rewrap all data keys with no matches\n   * const filter = { _id: new Binary() } // assume _id matches no documents in the database\n   * const result = await clientEncryption.rewrapManyDataKey(filter);\n   *\n   * if (result.bulkWriteResult == null) {\n   *  // no keys matched, `bulkWriteResult` does not exist on the result object\n   * }\n   * ```\n   */\n  async rewrapManyDataKey(\n    filter: Filter<DataKey>,\n    options: ClientEncryptionRewrapManyDataKeyProviderOptions\n  ): Promise<{ bulkWriteResult?: BulkWriteResult }> {\n    let keyEncryptionKeyBson = undefined;\n    if (options) {\n      const keyEncryptionKey = Object.assign({ provider: options.provider }, options.masterKey);\n      keyEncryptionKeyBson = serialize(keyEncryptionKey);\n    }\n    const filterBson = serialize(filter);\n    const context = this._mongoCrypt.makeRewrapManyDataKeyContext(filterBson, keyEncryptionKeyBson);\n    const stateMachine = new StateMachine({\n      proxyOptions: this._proxyOptions,\n      tlsOptions: this._tlsOptions,\n      socketOptions: autoSelectSocketOptions(this._client.s.options)\n    });\n\n    const timeoutContext = TimeoutContext.create(\n      resolveTimeoutOptions(this._client, { timeoutMS: this._timeoutMS })\n    );\n\n    const { v: dataKeys } = deserialize(\n      await stateMachine.execute(this, context, { timeoutContext })\n    );\n    if (dataKeys.length === 0) {\n      return {};\n    }\n\n    const { db: dbName, collection: collectionName } = MongoDBCollectionNamespace.fromString(\n      this._keyVaultNamespace\n    );\n\n    const replacements = dataKeys.map(\n      (key: DataKey): AnyBulkWriteOperation<DataKey> => ({\n        updateOne: {\n          filter: { _id: key._id },\n          update: {\n            $set: {\n              masterKey: key.masterKey,\n              keyMaterial: key.keyMaterial\n            },\n            $currentDate: {\n              updateDate: true\n            }\n          }\n        }\n      })\n    );\n\n    const result = await this._keyVaultClient\n      .db(dbName)\n      .collection<DataKey>(collectionName)\n      .bulkWrite(replacements, {\n        writeConcern: { w: 'majority' },\n        timeoutMS: timeoutContext.csotEnabled() ? timeoutContext?.remainingTimeMS : undefined\n      });\n\n    return { bulkWriteResult: result };\n  }\n\n  /**\n   * Deletes the key with the provided id from the keyvault, if it exists.\n   *\n   * @example\n   * ```ts\n   * // delete a key by _id\n   * const id = new Binary(); // id is a bson binary subtype 4 object\n   * const { deletedCount } = await clientEncryption.deleteKey(id);\n   *\n   * if (deletedCount != null && deletedCount > 0) {\n   *   // successful deletion\n   * }\n   * ```\n   *\n   */\n  async deleteKey(_id: Binary): Promise<DeleteResult> {\n    const { db: dbName, collection: collectionName } = MongoDBCollectionNamespace.fromString(\n      this._keyVaultNamespace\n    );\n\n    return await this._keyVaultClient\n      .db(dbName)\n      .collection<DataKey>(collectionName)\n      .deleteOne({ _id }, { writeConcern: { w: 'majority' }, timeoutMS: this._timeoutMS });\n  }\n\n  /**\n   * Finds all the keys currently stored in the keyvault.\n   *\n   * This method will not throw.\n   *\n   * @returns a FindCursor over all keys in the keyvault.\n   * @example\n   * ```ts\n   * // fetching all keys\n   * const keys = await clientEncryption.getKeys().toArray();\n   * ```\n   */\n  getKeys(): FindCursor<DataKey> {\n    const { db: dbName, collection: collectionName } = MongoDBCollectionNamespace.fromString(\n      this._keyVaultNamespace\n    );\n\n    return this._keyVaultClient\n      .db(dbName)\n      .collection<DataKey>(collectionName)\n      .find({}, { readConcern: { level: 'majority' }, timeoutMS: this._timeoutMS });\n  }\n\n  /**\n   * Finds a key in the keyvault with the specified _id.\n   *\n   * Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents\n   * match the id.  The promise rejects with an error if an error is thrown.\n   * @example\n   * ```ts\n   * // getting a key by id\n   * const id = new Binary(); // id is a bson binary subtype 4 object\n   * const key = await clientEncryption.getKey(id);\n   * if (!key) {\n   *  // key is null if there was no matching key\n   * }\n   * ```\n   */\n  async getKey(_id: Binary): Promise<DataKey | null> {\n    const { db: dbName, collection: collectionName } = MongoDBCollectionNamespace.fromString(\n      this._keyVaultNamespace\n    );\n\n    return await this._keyVaultClient\n      .db(dbName)\n      .collection<DataKey>(collectionName)\n      .findOne({ _id }, { readConcern: { level: 'majority' }, timeoutMS: this._timeoutMS });\n  }\n\n  /**\n   * Finds a key in the keyvault which has the specified keyAltName.\n   *\n   * @param keyAltName - a keyAltName to search for a key\n   * @returns Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents\n   * match the keyAltName.  The promise rejects with an error if an error is thrown.\n   * @example\n   * ```ts\n   * // get a key by alt name\n   * const keyAltName = 'keyAltName';\n   * const key = await clientEncryption.getKeyByAltName(keyAltName);\n   * if (!key) {\n   *  // key is null if there is no matching key\n   * }\n   * ```\n   */\n  async getKeyByAltName(keyAltName: string): Promise<WithId<DataKey> | null> {\n    const { db: dbName, collection: collectionName } = MongoDBCollectionNamespace.fromString(\n      this._keyVaultNamespace\n    );\n\n    return await this._keyVaultClient\n      .db(dbName)\n      .collection<DataKey>(collectionName)\n      .findOne(\n        { keyAltNames: keyAltName },\n        { readConcern: { level: 'majority' }, timeoutMS: this._timeoutMS }\n      );\n  }\n\n  /**\n   * Adds a keyAltName to a key identified by the provided _id.\n   *\n   * This method resolves to/returns the *old* key value (prior to adding the new altKeyName).\n   *\n   * @param _id - The id of the document to update.\n   * @param keyAltName - a keyAltName to search for a key\n   * @returns Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents\n   * match the id.  The promise rejects with an error if an error is thrown.\n   * @example\n   * ```ts\n   * // adding an keyAltName to a data key\n   * const id = new Binary();  // id is a bson binary subtype 4 object\n   * const keyAltName = 'keyAltName';\n   * const oldKey = await clientEncryption.addKeyAltName(id, keyAltName);\n   * if (!oldKey) {\n   *  // null is returned if there is no matching document with an id matching the supplied id\n   * }\n   * ```\n   */\n  async addKeyAltName(_id: Binary, keyAltName: string): Promise<WithId<DataKey> | null> {\n    const { db: dbName, collection: collectionName } = MongoDBCollectionNamespace.fromString(\n      this._keyVaultNamespace\n    );\n\n    const value = await this._keyVaultClient\n      .db(dbName)\n      .collection<DataKey>(collectionName)\n      .findOneAndUpdate(\n        { _id },\n        { $addToSet: { keyAltNames: keyAltName } },\n        { writeConcern: { w: 'majority' }, returnDocument: 'before', timeoutMS: this._timeoutMS }\n      );\n\n    return value;\n  }\n\n  /**\n   * Adds a keyAltName to a key identified by the provided _id.\n   *\n   * This method resolves to/returns the *old* key value (prior to removing the new altKeyName).\n   *\n   * If the removed keyAltName is the last keyAltName for that key, the `altKeyNames` property is unset from the document.\n   *\n   * @param _id - The id of the document to update.\n   * @param keyAltName - a keyAltName to search for a key\n   * @returns Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents\n   * match the id.  The promise rejects with an error if an error is thrown.\n   * @example\n   * ```ts\n   * // removing a key alt name from a data key\n   * const id = new Binary();  // id is a bson binary subtype 4 object\n   * const keyAltName = 'keyAltName';\n   * const oldKey = await clientEncryption.removeKeyAltName(id, keyAltName);\n   *\n   * if (!oldKey) {\n   *  // null is returned if there is no matching document with an id matching the supplied id\n   * }\n   * ```\n   */\n  async removeKeyAltName(_id: Binary, keyAltName: string): Promise<WithId<DataKey> | null> {\n    const { db: dbName, collection: collectionName } = MongoDBCollectionNamespace.fromString(\n      this._keyVaultNamespace\n    );\n\n    const pipeline = [\n      {\n        $set: {\n          keyAltNames: {\n            $cond: [\n              {\n                $eq: ['$keyAltNames', [keyAltName]]\n              },\n              '$$REMOVE',\n              {\n                $filter: {\n                  input: '$keyAltNames',\n                  cond: {\n                    $ne: ['$$this', keyAltName]\n                  }\n                }\n              }\n            ]\n          }\n        }\n      }\n    ];\n\n    const value = await this._keyVaultClient\n      .db(dbName)\n      .collection<DataKey>(collectionName)\n      .findOneAndUpdate({ _id }, pipeline, {\n        writeConcern: { w: 'majority' },\n        returnDocument: 'before',\n        timeoutMS: this._timeoutMS\n      });\n\n    return value;\n  }\n\n  /**\n   * A convenience method for creating an encrypted collection.\n   * This method will create data keys for any encryptedFields that do not have a `keyId` defined\n   * and then create a new collection with the full set of encryptedFields.\n   *\n   * @param db - A Node.js driver Db object with which to create the collection\n   * @param name - The name of the collection to be created\n   * @param options - Options for createDataKey and for createCollection\n   * @returns created collection and generated encryptedFields\n   * @throws MongoCryptCreateDataKeyError - If part way through the process a createDataKey invocation fails, an error will be rejected that has the partial `encryptedFields` that were created.\n   * @throws MongoCryptCreateEncryptedCollectionError - If creating the collection fails, an error will be rejected that has the entire `encryptedFields` that were created.\n   */\n  async createEncryptedCollection<TSchema extends Document = Document>(\n    db: Db,\n    name: string,\n    options: {\n      provider: ClientEncryptionDataKeyProvider;\n      createCollectionOptions: Omit<CreateCollectionOptions, 'encryptedFields'> & {\n        encryptedFields: Document;\n      };\n      masterKey?: AWSEncryptionKeyOptions | AzureEncryptionKeyOptions | GCPEncryptionKeyOptions;\n    }\n  ): Promise<{ collection: Collection<TSchema>; encryptedFields: Document }> {\n    const {\n      provider,\n      masterKey,\n      createCollectionOptions: {\n        encryptedFields: { ...encryptedFields },\n        ...createCollectionOptions\n      }\n    } = options;\n\n    const timeoutContext =\n      this._timeoutMS != null\n        ? TimeoutContext.create(resolveTimeoutOptions(this._client, { timeoutMS: this._timeoutMS }))\n        : undefined;\n\n    if (Array.isArray(encryptedFields.fields)) {\n      const createDataKeyPromises = encryptedFields.fields.map(async field =>\n        field == null || typeof field !== 'object' || field.keyId != null\n          ? field\n          : {\n              ...field,\n              keyId: await this.createDataKey(provider, {\n                masterKey,\n                // clone the timeoutContext\n                // in order to avoid sharing the same timeout for server selection and connection checkout across different concurrent operations\n                timeoutContext: timeoutContext?.csotEnabled() ? timeoutContext?.clone() : undefined\n              })\n            }\n      );\n      const createDataKeyResolutions = await Promise.allSettled(createDataKeyPromises);\n\n      encryptedFields.fields = createDataKeyResolutions.map((resolution, index) =>\n        resolution.status === 'fulfilled' ? resolution.value : encryptedFields.fields[index]\n      );\n\n      const rejection = createDataKeyResolutions.find(\n        (result): result is PromiseRejectedResult => result.status === 'rejected'\n      );\n      if (rejection != null) {\n        throw new MongoCryptCreateDataKeyError(encryptedFields, { cause: rejection.reason });\n      }\n    }\n\n    try {\n      const collection = await db.createCollection<TSchema>(name, {\n        ...createCollectionOptions,\n        encryptedFields,\n        timeoutMS: timeoutContext?.csotEnabled()\n          ? timeoutContext?.getRemainingTimeMSOrThrow()\n          : undefined\n      });\n      return { collection, encryptedFields };\n    } catch (cause) {\n      throw new MongoCryptCreateEncryptedCollectionError(encryptedFields, { cause });\n    }\n  }\n\n  /**\n   * Explicitly encrypt a provided value. Note that either `options.keyId` or `options.keyAltName` must\n   * be specified. Specifying both `options.keyId` and `options.keyAltName` is considered an error.\n   *\n   * @param value - The value that you wish to serialize. Must be of a type that can be serialized into BSON\n   * @param options -\n   * @returns a Promise that either resolves with the encrypted value, or rejects with an error.\n   *\n   * @example\n   * ```ts\n   * // Encryption with async/await api\n   * async function encryptMyData(value) {\n   *   const keyId = await clientEncryption.createDataKey('local');\n   *   return clientEncryption.encrypt(value, { keyId, algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic' });\n   * }\n   * ```\n   *\n   * @example\n   * ```ts\n   * // Encryption using a keyAltName\n   * async function encryptMyData(value) {\n   *   await clientEncryption.createDataKey('local', { keyAltNames: 'mySpecialKey' });\n   *   return clientEncryption.encrypt(value, { keyAltName: 'mySpecialKey', algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic' });\n   * }\n   * ```\n   */\n  async encrypt(value: unknown, options: ClientEncryptionEncryptOptions): Promise<Binary> {\n    return await this._encrypt(value, false, options);\n  }\n\n  /**\n   * Encrypts a Match Expression or Aggregate Expression to query a range index.\n   *\n   * Only supported when queryType is \"range\" and algorithm is \"Range\".\n   *\n   * @param expression - a BSON document of one of the following forms:\n   *  1. A Match Expression of this form:\n   *      `{$and: [{<field>: {$gt: <value1>}}, {<field>: {$lt: <value2> }}]}`\n   *  2. An Aggregate Expression of this form:\n   *      `{$and: [{$gt: [<fieldpath>, <value1>]}, {$lt: [<fieldpath>, <value2>]}]}`\n   *\n   *    `$gt` may also be `$gte`. `$lt` may also be `$lte`.\n   *\n   * @param options -\n   * @returns Returns a Promise that either resolves with the encrypted value or rejects with an error.\n   */\n  async encryptExpression(\n    expression: Document,\n    options: ClientEncryptionEncryptOptions\n  ): Promise<Binary> {\n    return await this._encrypt(expression, true, options);\n  }\n\n  /**\n   * Explicitly decrypt a provided encrypted value\n   *\n   * @param value - An encrypted value\n   * @returns a Promise that either resolves with the decrypted value, or rejects with an error\n   *\n   * @example\n   * ```ts\n   * // Decrypting value with async/await API\n   * async function decryptMyValue(value) {\n   *   return clientEncryption.decrypt(value);\n   * }\n   * ```\n   */\n  async decrypt<T = any>(value: Binary): Promise<T> {\n    const valueBuffer = serialize({ v: value });\n    const context = this._mongoCrypt.makeExplicitDecryptionContext(valueBuffer);\n\n    const stateMachine = new StateMachine({\n      proxyOptions: this._proxyOptions,\n      tlsOptions: this._tlsOptions,\n      socketOptions: autoSelectSocketOptions(this._client.s.options)\n    });\n\n    const timeoutContext =\n      this._timeoutMS != null\n        ? TimeoutContext.create(resolveTimeoutOptions(this._client, { timeoutMS: this._timeoutMS }))\n        : undefined;\n\n    const { v } = deserialize(await stateMachine.execute(this, context, { timeoutContext }));\n\n    return v;\n  }\n\n  /**\n   * @internal\n   * Ask the user for KMS credentials.\n   *\n   * This returns anything that looks like the kmsProviders original input\n   * option. It can be empty, and any provider specified here will override\n   * the original ones.\n   */\n  async askForKMSCredentials(): Promise<KMSProviders> {\n    return await refreshKMSCredentials(this._kmsProviders, this._credentialProviders);\n  }\n\n  static get libmongocryptVersion() {\n    return ClientEncryption.getMongoCrypt().libmongocryptVersion;\n  }\n\n  /**\n   * @internal\n   * A helper that perform explicit encryption of values and expressions.\n   * Explicitly encrypt a provided value. Note that either `options.keyId` or `options.keyAltName` must\n   * be specified. Specifying both `options.keyId` and `options.keyAltName` is considered an error.\n   *\n   * @param value - The value that you wish to encrypt. Must be of a type that can be serialized into BSON\n   * @param expressionMode - a boolean that indicates whether or not to encrypt the value as an expression\n   * @param options - options to pass to encrypt\n   * @returns the raw result of the call to stateMachine.execute().  When expressionMode is set to true, the return\n   *          value will be a bson document.  When false, the value will be a BSON Binary.\n   *\n   */\n  private async _encrypt(\n    value: unknown,\n    expressionMode: boolean,\n    options: ClientEncryptionEncryptOptions\n  ): Promise<Binary> {\n    const { algorithm, keyId, keyAltName, contentionFactor, queryType, rangeOptions } = options;\n    const contextOptions: ExplicitEncryptionContextOptions = {\n      expressionMode,\n      algorithm\n    };\n    if (keyId) {\n      contextOptions.keyId = keyId.buffer;\n    }\n    if (keyAltName) {\n      if (keyId) {\n        throw new MongoCryptInvalidArgumentError(\n          `\"options\" cannot contain both \"keyId\" and \"keyAltName\"`\n        );\n      }\n      if (typeof keyAltName !== 'string') {\n        throw new MongoCryptInvalidArgumentError(\n          `\"options.keyAltName\" must be of type string, but was of type ${typeof keyAltName}`\n        );\n      }\n\n      contextOptions.keyAltName = serialize({ keyAltName });\n    }\n    if (typeof contentionFactor === 'number' || typeof contentionFactor === 'bigint') {\n      contextOptions.contentionFactor = contentionFactor;\n    }\n    if (typeof queryType === 'string') {\n      contextOptions.queryType = queryType;\n    }\n\n    if (typeof rangeOptions === 'object') {\n      contextOptions.rangeOptions = serialize(rangeOptions);\n    }\n\n    const valueBuffer = serialize({ v: value });\n    const stateMachine = new StateMachine({\n      proxyOptions: this._proxyOptions,\n      tlsOptions: this._tlsOptions,\n      socketOptions: autoSelectSocketOptions(this._client.s.options)\n    });\n    const context = this._mongoCrypt.makeExplicitEncryptionContext(valueBuffer, contextOptions);\n\n    const timeoutContext =\n      this._timeoutMS != null\n        ? TimeoutContext.create(resolveTimeoutOptions(this._client, { timeoutMS: this._timeoutMS }))\n        : undefined;\n    const { v } = deserialize(await stateMachine.execute(this, context, { timeoutContext }));\n    return v;\n  }\n}\n\n/**\n * @public\n * Options to provide when encrypting data.\n */\nexport interface ClientEncryptionEncryptOptions {\n  /**\n   * The algorithm to use for encryption.\n   */\n  algorithm:\n    | 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic'\n    | 'AEAD_AES_256_CBC_HMAC_SHA_512-Random'\n    | 'Indexed'\n    | 'Unindexed'\n    | 'Range';\n\n  /**\n   * The id of the Binary dataKey to use for encryption\n   */\n  keyId?: Binary;\n\n  /**\n   * A unique string name corresponding to an already existing dataKey.\n   */\n  keyAltName?: string;\n\n  /** The contention factor. */\n  contentionFactor?: bigint | number;\n\n  /**\n   * The query type.\n   */\n  queryType?: 'equality' | 'range';\n\n  /** The index options for a Queryable Encryption field supporting \"range\" queries.*/\n  rangeOptions?: RangeOptions;\n}\n\n/**\n * @public\n * @experimental\n */\nexport interface ClientEncryptionRewrapManyDataKeyProviderOptions {\n  provider: ClientEncryptionDataKeyProvider;\n  masterKey?:\n    | AWSEncryptionKeyOptions\n    | AzureEncryptionKeyOptions\n    | GCPEncryptionKeyOptions\n    | KMIPEncryptionKeyOptions\n    | undefined;\n}\n\n/**\n * @public\n * Additional settings to provide when creating a new `ClientEncryption` instance.\n */\nexport interface ClientEncryptionOptions {\n  /**\n   * The namespace of the key vault, used to store encryption keys\n   */\n  keyVaultNamespace: string;\n\n  /**\n   * A MongoClient used to fetch keys from a key vault. Defaults to client.\n   */\n  keyVaultClient?: MongoClient | undefined;\n\n  /**\n   * Options for specific KMS providers to use\n   */\n  kmsProviders?: KMSProviders;\n\n  /**\n   * Options for user provided custom credential providers.\n   */\n  credentialProviders?: CredentialProviders;\n\n  /**\n   * Options for specifying a Socks5 proxy to use for connecting to the KMS.\n   */\n  proxyOptions?: ProxyOptions;\n\n  /**\n   * TLS options for kms providers to use.\n   */\n  tlsOptions?: CSFLEKMSTlsOptions;\n\n  /**\n   * Sets the expiration time for the DEK in the cache in milliseconds. Defaults to 60000. 0 means no timeout.\n   */\n  keyExpirationMS?: number;\n\n  /**\n   * @experimental\n   *\n   * The timeout setting to be used for all the operations on ClientEncryption.\n   *\n   * When provided, `timeoutMS` is used as the timeout for each operation executed on\n   * the ClientEncryption object.  For example:\n   *\n   * ```typescript\n   * const clientEncryption = new ClientEncryption(client, {\n   *  timeoutMS: 1_000\n   *  kmsProviders: { local: { key: '<KEY>' } }\n   * });\n   *\n   * // `1_000` is used as the timeout for createDataKey call\n   * await clientEncryption.createDataKey('local');\n   * ```\n   *\n   * If `timeoutMS` is configured on the provided client, the client's `timeoutMS` value\n   * will be used unless `timeoutMS` is also provided as a client encryption option.\n   *\n   * ```typescript\n   * const client = new MongoClient('<uri>', { timeoutMS: 2_000 });\n   *\n   * // timeoutMS is set to 1_000 on clientEncryption\n   * const clientEncryption = new ClientEncryption(client, {\n   *  timeoutMS: 1_000\n   *  kmsProviders: { local: { key: '<KEY>' } }\n   * });\n   * ```\n   */\n  timeoutMS?: number;\n}\n\n/**\n * @public\n * Configuration options for making an AWS encryption key\n */\nexport interface AWSEncryptionKeyOptions {\n  /**\n   * The AWS region of the KMS\n   */\n  region: string;\n\n  /**\n   * The Amazon Resource Name (ARN) to the AWS customer master key (CMK)\n   */\n  key: string;\n\n  /**\n   * An alternate host to send KMS requests to. May include port number.\n   */\n  endpoint?: string | undefined;\n}\n\n/**\n * @public\n * Configuration options for making an AWS encryption key\n */\nexport interface GCPEncryptionKeyOptions {\n  /**\n   * GCP project ID\n   */\n  projectId: string;\n\n  /**\n   * Location name (e.g. \"global\")\n   */\n  location: string;\n\n  /**\n   * Key ring name\n   */\n  keyRing: string;\n\n  /**\n   * Key name\n   */\n  keyName: string;\n\n  /**\n   * Key version\n   */\n  keyVersion?: string | undefined;\n\n  /**\n   * KMS URL, defaults to `https://www.googleapis.com/auth/cloudkms`\n   */\n  endpoint?: string | undefined;\n}\n\n/**\n * @public\n * Configuration options for making an Azure encryption key\n */\nexport interface AzureEncryptionKeyOptions {\n  /**\n   * Key name\n   */\n  keyName: string;\n\n  /**\n   * Key vault URL, typically `<name>.vault.azure.net`\n   */\n  keyVaultEndpoint: string;\n\n  /**\n   * Key version\n   */\n  keyVersion?: string | undefined;\n}\n\n/**\n * @public\n * Configuration options for making a KMIP encryption key\n */\nexport interface KMIPEncryptionKeyOptions {\n  /**\n   * keyId is the KMIP Unique Identifier to a 96 byte KMIP Secret Data managed object.\n   *\n   * If keyId is omitted, a random 96 byte KMIP Secret Data managed object will be created.\n   */\n  keyId?: string;\n\n  /**\n   * Host with optional port.\n   */\n  endpoint?: string;\n\n  /**\n   * If true, this key should be decrypted by the KMIP server.\n   *\n   * Requires `mongodb-client-encryption>=6.0.1`.\n   */\n  delegated?: boolean;\n}\n\n/**\n * @public\n * Options to provide when creating a new data key.\n */\nexport interface ClientEncryptionCreateDataKeyProviderOptions {\n  /**\n   * Identifies a new KMS-specific key used to encrypt the new data key\n   */\n  masterKey?:\n    | AWSEncryptionKeyOptions\n    | AzureEncryptionKeyOptions\n    | GCPEncryptionKeyOptions\n    | KMIPEncryptionKeyOptions\n    | undefined;\n\n  /**\n   * An optional list of string alternate names used to reference a key.\n   * If a key is created with alternate names, then encryption may refer to the key by the unique alternate name instead of by _id.\n   */\n  keyAltNames?: string[] | undefined;\n\n  /** @experimental */\n  keyMaterial?: Buffer | Binary;\n\n  /** @internal */\n  timeoutContext?: CSOTTimeoutContext;\n}\n\n/**\n * @public\n * @experimental\n */\nexport interface ClientEncryptionRewrapManyDataKeyResult {\n  /** The result of rewrapping data keys. If unset, no keys matched the filter. */\n  bulkWriteResult?: BulkWriteResult;\n}\n\n/**\n * @public\n * RangeOptions specifies index options for a Queryable Encryption field supporting \"range\" queries.\n * min, max, sparsity, trimFactor and range must match the values set in the encryptedFields of the destination collection.\n * For double and decimal128, min/max/precision must all be set, or all be unset.\n */\nexport interface RangeOptions {\n  /** min is the minimum value for the encrypted index. Required if precision is set. */\n  min?: any;\n  /** max is the minimum value for the encrypted index. Required if precision is set. */\n  max?: any;\n  /** sparsity may be used to tune performance. must be non-negative. When omitted, a default value is used. */\n  sparsity?: Long | bigint;\n  /** trimFactor may be used to tune performance. must be non-negative. When omitted, a default value is used. */\n  trimFactor?: Int32 | number;\n  /* precision determines the number of significant digits after the decimal point. May only be set for double or decimal128. */\n  precision?: number;\n}\n\n/**\n * Get the socket options from the client.\n * @param baseOptions - The mongo client options.\n * @returns ClientEncryptionSocketOptions\n */\nexport function autoSelectSocketOptions(\n  baseOptions: MongoClientOptions\n): ClientEncryptionSocketOptions {\n  const options: ClientEncryptionSocketOptions = { autoSelectFamily: true };\n  if ('autoSelectFamily' in baseOptions) {\n    options.autoSelectFamily = baseOptions.autoSelectFamily;\n  }\n  if ('autoSelectFamilyAttemptTimeout' in baseOptions) {\n    options.autoSelectFamilyAttemptTimeout = baseOptions.autoSelectFamilyAttemptTimeout;\n  }\n  return options;\n}\n"],"names":[],"mappings":";;;;;AAkkCA,QAAA,uBAAA,GAAA;AA3jCA,MAAA;AAcA,MAAA;AAKA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAKA,MAAA;AAOA,MAAA;AAqBA;;;IAIA,MAAa;IAsBX,cAAA,GACA,OAAO,gBAAa;QAClB,MAAM,aAAa,CAAA,GAAA,OAAA,0BAA0B;QAC7C,IAAI,kBAAkB,YAAY;YAChC,MAAM,WAAW,YAAY;QAC/B;QACA,OAAO,WAAW,UAAU;IAC9B;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;QA4BA,YAAY,MAAmB,EAAE,OAAgC,CAAA;QAC/D,IAAI,CAAC,OAAO,GAAG;QACf,IAAI,CAAC,aAAa,GAAG,QAAQ,YAAY,IAAI,CAAA;QAC7C,IAAI,CAAC,WAAW,GAAG,QAAQ,UAAU,IAAI,CAAA;QACzC,IAAI,CAAC,aAAa,GAAG,QAAQ,YAAY,IAAI,CAAA;QAC7C,MAAM,EAAE,SAAS,EAAE,GAAG,CAAA,GAAA,QAAA,qBAAqB,EAAC,QAAQ;QACpD,IAAI,CAAC,UAAU,GAAG;QAClB,IAAI,CAAC,oBAAoB,GAAG,QAAQ,mBAAmB;QAEvD,IAAI,QAAQ,mBAAmB,EAAE,OAAO,CAAC,CAAA,GAAA,QAAA,kBAAkB,EAAC,OAAO,IAAI,CAAC,aAAa,GAAG;YACtF,MAAM,IAAI,SAAA,8BAA8B,CACtC;QAEJ;QAEA,IAAI,QAAQ,iBAAiB,IAAI,MAAM;YACrC,MAAM,IAAI,SAAA,8BAA8B,CAAC;QAC3C;QAEA,MAAM,oBAAuC;YAC3C,GAAG,OAAO;YACV;YACA,cAAc,CAAC,OAAO,QAAQ,CAAC,IAAI,CAAC,aAAa,IAC5C,CAAA,GAAA,OAAA,SAAS,EAAC,IAAI,CAAC,aAAa,IAC7B,IAAI,CAAC,aAAa;;QAGxB,IAAI,CAAC,kBAAkB,GAAG,QAAQ,iBAAiB;QACnD,IAAI,CAAC,eAAe,GAAG,QAAQ,cAAc,IAAI;QACjD,MAAM,aAAa,iBAAiB,aAAa;QACjD,IAAI,CAAC,WAAW,GAAG,IAAI,WAAW;IACpC;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;QAgCA,MAAM,cACJ,QAAyC,EACzC,UAAwD,CAAA,CAAE,EAAA;QAE1D,IAAI,QAAQ,WAAW,IAAI,CAAC,MAAM,OAAO,CAAC,QAAQ,WAAW,GAAG;YAC9D,MAAM,IAAI,SAAA,8BAA8B,CACtC,CAAA,kEAAA,EAAqE,OAAO,QAAQ,WAAW,CAAA,CAAA,CAAG;QAEtG;QAEA,IAAI,cAAc;QAClB,IAAI,QAAQ,WAAW,IAAI,QAAQ,WAAW,CAAC,MAAM,GAAG,GAAG;YACzD,cAAc,QAAQ,WAAW,CAAC,GAAG,CAAC,CAAC,YAAY;gBACjD,IAAI,OAAO,eAAe,UAAU;oBAClC,MAAM,IAAI,SAAA,8BAA8B,CACtC,CAAA,oEAAA,EAAuE,EAAC,aAAA,EAAgB,OAAO,WAAU,CAAE;gBAE/G;gBAEA,OAAO,CAAA,GAAA,OAAA,SAAS,EAAC;oBAAE;gBAAU;YAC/B;QACF;QAEA,IAAI,cAAc;QAClB,IAAI,QAAQ,WAAW,EAAE;YACvB,cAAc,CAAA,GAAA,OAAA,SAAS,EAAC;gBAAE,aAAa,QAAQ,WAAW;YAAA;QAC5D;QAEA,MAAM,cAAc,CAAA,GAAA,OAAA,SAAS,EAAC;YAC5B;YACA,GAAG,QAAQ,SAAS;;QAGtB,MAAM,UAAU,IAAI,CAAC,WAAW,CAAC,kBAAkB,CAAC,aAAa;YAC/D;YACA;;QAGF,MAAM,eAAe,IAAI,gBAAA,YAAY,CAAC;YACpC,cAAc,IAAI,CAAC,aAAa;YAChC,YAAY,IAAI,CAAC,WAAW;YAC5B,eAAe,wBAAwB,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO;;QAG/D,MAAM,iBACJ,SAAS,kBACT,UAAA,cAAc,CAAC,MAAM,CAAC,CAAA,GAAA,QAAA,qBAAqB,EAAC,IAAI,CAAC,OAAO,EAAE;YAAE,WAAW,IAAI,CAAC,UAAU;QAAA;QAExF,MAAM,UAAU,CAAA,GAAA,OAAA,WAAW,EACzB,MAAM,aAAa,OAAO,CAAC,IAAI,EAAE,SAAS;YAAE;QAAc;QAG5D,MAAM,EAAE,IAAI,MAAM,EAAE,YAAY,cAAc,EAAE,GAAG,QAAA,0BAA0B,CAAC,UAAU,CACtF,IAAI,CAAC,kBAAkB;QAGzB,MAAM,EAAE,UAAU,EAAE,GAAG,MAAM,IAAI,CAAC,eAAe,CAC9C,EAAE,CAAC,QACH,UAAU,CAAU,gBACpB,SAAS,CAAC,SAAS;YAClB,cAAc;gBAAE,GAAG;YAAU;YAC7B,WAAW,gBAAgB,gBACvB,gBAAgB,8BAChB;;QAGR,OAAO;IACT;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;;QA2BA,MAAM,kBACJ,MAAuB,EACvB,OAAyD,EAAA;QAEzD,IAAI,uBAAuB;QAC3B,IAAI,SAAS;YACX,MAAM,mBAAmB,OAAO,MAAM,CAAC;gBAAE,UAAU,QAAQ,QAAQ;YAAA,GAAI,QAAQ,SAAS;YACxF,uBAAuB,CAAA,GAAA,OAAA,SAAS,EAAC;QACnC;QACA,MAAM,aAAa,CAAA,GAAA,OAAA,SAAS,EAAC;QAC7B,MAAM,UAAU,IAAI,CAAC,WAAW,CAAC,4BAA4B,CAAC,YAAY;QAC1E,MAAM,eAAe,IAAI,gBAAA,YAAY,CAAC;YACpC,cAAc,IAAI,CAAC,aAAa;YAChC,YAAY,IAAI,CAAC,WAAW;YAC5B,eAAe,wBAAwB,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO;;QAG/D,MAAM,iBAAiB,UAAA,cAAc,CAAC,MAAM,CAC1C,CAAA,GAAA,QAAA,qBAAqB,EAAC,IAAI,CAAC,OAAO,EAAE;YAAE,WAAW,IAAI,CAAC,UAAU;QAAA;QAGlE,MAAM,EAAE,GAAG,QAAQ,EAAE,GAAG,CAAA,GAAA,OAAA,WAAW,EACjC,MAAM,aAAa,OAAO,CAAC,IAAI,EAAE,SAAS;YAAE;QAAc;QAE5D,IAAI,SAAS,MAAM,KAAK,GAAG;YACzB,OAAO,CAAA;QACT;QAEA,MAAM,EAAE,IAAI,MAAM,EAAE,YAAY,cAAc,EAAE,GAAG,QAAA,0BAA0B,CAAC,UAAU,CACtF,IAAI,CAAC,kBAAkB;QAGzB,MAAM,eAAe,SAAS,GAAG,CAC/B,CAAC,MAAiD,CAAC;gBACjD,WAAW;oBACT,QAAQ;wBAAE,KAAK,IAAI,GAAG;oBAAA;oBACtB,QAAQ;wBACN,MAAM;4BACJ,WAAW,IAAI,SAAS;4BACxB,aAAa,IAAI,WAAW;;wBAE9B,cAAc;4BACZ,YAAY;;;;aAInB;QAGH,MAAM,SAAS,MAAM,IAAI,CAAC,eAAe,CACtC,EAAE,CAAC,QACH,UAAU,CAAU,gBACpB,SAAS,CAAC,cAAc;YACvB,cAAc;gBAAE,GAAG;YAAU;YAC7B,WAAW,eAAe,WAAW,KAAK,gBAAgB,kBAAkB;;QAGhF,OAAO;YAAE,iBAAiB;QAAM;IAClC;IAEA;;;;;;;;;;;;;;QAeA,MAAM,UAAU,GAAW,EAAA;QACzB,MAAM,EAAE,IAAI,MAAM,EAAE,YAAY,cAAc,EAAE,GAAG,QAAA,0BAA0B,CAAC,UAAU,CACtF,IAAI,CAAC,kBAAkB;QAGzB,OAAO,MAAM,IAAI,CAAC,eAAe,CAC9B,EAAE,CAAC,QACH,UAAU,CAAU,gBACpB,SAAS,CAAC;YAAE;QAAG,GAAI;YAAE,cAAc;gBAAE,GAAG;YAAU;YAAI,WAAW,IAAI,CAAC,UAAU;QAAA;IACrF;IAEA;;;;;;;;;;;QAYA,UAAO;QACL,MAAM,EAAE,IAAI,MAAM,EAAE,YAAY,cAAc,EAAE,GAAG,QAAA,0BAA0B,CAAC,UAAU,CACtF,IAAI,CAAC,kBAAkB;QAGzB,OAAO,IAAI,CAAC,eAAe,CACxB,EAAE,CAAC,QACH,UAAU,CAAU,gBACpB,IAAI,CAAC,CAAA,GAAI;YAAE,aAAa;gBAAE,OAAO;YAAU;YAAI,WAAW,IAAI,CAAC,UAAU;QAAA;IAC9E;IAEA;;;;;;;;;;;;;;QAeA,MAAM,OAAO,GAAW,EAAA;QACtB,MAAM,EAAE,IAAI,MAAM,EAAE,YAAY,cAAc,EAAE,GAAG,QAAA,0BAA0B,CAAC,UAAU,CACtF,IAAI,CAAC,kBAAkB;QAGzB,OAAO,MAAM,IAAI,CAAC,eAAe,CAC9B,EAAE,CAAC,QACH,UAAU,CAAU,gBACpB,OAAO,CAAC;YAAE;QAAG,GAAI;YAAE,aAAa;gBAAE,OAAO;YAAU;YAAI,WAAW,IAAI,CAAC,UAAU;QAAA;IACtF;IAEA;;;;;;;;;;;;;;;QAgBA,MAAM,gBAAgB,UAAkB,EAAA;QACtC,MAAM,EAAE,IAAI,MAAM,EAAE,YAAY,cAAc,EAAE,GAAG,QAAA,0BAA0B,CAAC,UAAU,CACtF,IAAI,CAAC,kBAAkB;QAGzB,OAAO,MAAM,IAAI,CAAC,eAAe,CAC9B,EAAE,CAAC,QACH,UAAU,CAAU,gBACpB,OAAO,CACN;YAAE,aAAa;QAAU,GACzB;YAAE,aAAa;gBAAE,OAAO;YAAU;YAAI,WAAW,IAAI,CAAC,UAAU;QAAA;IAEtE;IAEA;;;;;;;;;;;;;;;;;;;QAoBA,MAAM,cAAc,GAAW,EAAE,UAAkB,EAAA;QACjD,MAAM,EAAE,IAAI,MAAM,EAAE,YAAY,cAAc,EAAE,GAAG,QAAA,0BAA0B,CAAC,UAAU,CACtF,IAAI,CAAC,kBAAkB;QAGzB,MAAM,QAAQ,MAAM,IAAI,CAAC,eAAe,CACrC,EAAE,CAAC,QACH,UAAU,CAAU,gBACpB,gBAAgB,CACf;YAAE;QAAG,GACL;YAAE,WAAW;gBAAE,aAAa;YAAU;QAAE,GACxC;YAAE,cAAc;gBAAE,GAAG;YAAU;YAAI,gBAAgB;YAAU,WAAW,IAAI,CAAC,UAAU;QAAA;QAG3F,OAAO;IACT;IAEA;;;;;;;;;;;;;;;;;;;;;;QAuBA,MAAM,iBAAiB,GAAW,EAAE,UAAkB,EAAA;QACpD,MAAM,EAAE,IAAI,MAAM,EAAE,YAAY,cAAc,EAAE,GAAG,QAAA,0BAA0B,CAAC,UAAU,CACtF,IAAI,CAAC,kBAAkB;QAGzB,MAAM,WAAW;YACf;gBACE,MAAM;oBACJ,aAAa;wBACX,OAAO;4BACL;gCACE,KAAK;oCAAC;oCAAgB;wCAAC;qCAAW;iCAAC;;4BAErC;4BACA;gCACE,SAAS;oCACP,OAAO;oCACP,MAAM;wCACJ,KAAK;4CAAC;4CAAU;yCAAW;;;;yBAIlC;;;;SAIR;QAED,MAAM,QAAQ,MAAM,IAAI,CAAC,eAAe,CACrC,EAAE,CAAC,QACH,UAAU,CAAU,gBACpB,gBAAgB,CAAC;YAAE;QAAG,GAAI,UAAU;YACnC,cAAc;gBAAE,GAAG;YAAU;YAC7B,gBAAgB;YAChB,WAAW,IAAI,CAAC,UAAU;;QAG9B,OAAO;IACT;IAEA;;;;;;;;;;;QAYA,MAAM,0BACJ,EAAM,EACN,IAAY,EACZ,OAMC,EAAA;QAED,MAAM,EACJ,QAAQ,EACR,SAAS,EACT,yBAAyB,EACvB,iBAAiB,EAAE,GAAG,iBAAiB,EACvC,GAAG,yBACJ,EACF,GAAG;QAEJ,MAAM,iBACJ,IAAI,CAAC,UAAU,IAAI,OACf,UAAA,cAAc,CAAC,MAAM,CAAC,CAAA,GAAA,QAAA,qBAAqB,EAAC,IAAI,CAAC,OAAO,EAAE;YAAE,WAAW,IAAI,CAAC,UAAU;QAAA,MACtF;QAEN,IAAI,MAAM,OAAO,CAAC,gBAAgB,MAAM,GAAG;YACzC,MAAM,wBAAwB,gBAAgB,MAAM,CAAC,GAAG,CAAC,OAAM,QAC7D,SAAS,QAAQ,OAAO,UAAU,YAAY,MAAM,KAAK,IAAI,OACzD,QACA;oBACE,GAAG,KAAK;oBACR,OAAO,MAAM,IAAI,CAAC,aAAa,CAAC,UAAU;wBACxC;wBACA,2BAA2B;wBAC3B,iIAAiI;wBACjI,gBAAgB,gBAAgB,gBAAgB,gBAAgB,UAAU;;;YAIpF,MAAM,2BAA2B,MAAM,QAAQ,UAAU,CAAC;YAE1D,gBAAgB,MAAM,GAAG,yBAAyB,GAAG,CAAC,CAAC,YAAY,QACjE,WAAW,MAAM,KAAK,cAAc,WAAW,KAAK,GAAG,gBAAgB,MAAM,CAAC,MAAM;YAGtF,MAAM,YAAY,yBAAyB,IAAI,CAC7C,CAAC,SAA4C,OAAO,MAAM,KAAK;YAEjE,IAAI,aAAa,MAAM;gBACrB,MAAM,IAAI,SAAA,4BAA4B,CAAC,iBAAiB;oBAAE,OAAO,UAAU,MAAM;gBAAA;YACnF;QACF;QAEA,IAAI;YACF,MAAM,aAAa,MAAM,GAAG,gBAAgB,CAAU,MAAM;gBAC1D,GAAG,uBAAuB;gBAC1B;gBACA,WAAW,gBAAgB,gBACvB,gBAAgB,8BAChB;;YAEN,OAAO;gBAAE;gBAAY;YAAe;QACtC,EAAE,OAAO,OAAO;YACd,MAAM,IAAI,SAAA,wCAAwC,CAAC,iBAAiB;gBAAE;YAAK;QAC7E;IACF;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;QA0BA,MAAM,QAAQ,KAAc,EAAE,OAAuC,EAAA;QACnE,OAAO,MAAM,IAAI,CAAC,QAAQ,CAAC,OAAO,OAAO;IAC3C;IAEA;;;;;;;;;;;;;;;QAgBA,MAAM,kBACJ,UAAoB,EACpB,OAAuC,EAAA;QAEvC,OAAO,MAAM,IAAI,CAAC,QAAQ,CAAC,YAAY,MAAM;IAC/C;IAEA;;;;;;;;;;;;;QAcA,MAAM,QAAiB,KAAa,EAAA;QAClC,MAAM,cAAc,CAAA,GAAA,OAAA,SAAS,EAAC;YAAE,GAAG;QAAK;QACxC,MAAM,UAAU,IAAI,CAAC,WAAW,CAAC,6BAA6B,CAAC;QAE/D,MAAM,eAAe,IAAI,gBAAA,YAAY,CAAC;YACpC,cAAc,IAAI,CAAC,aAAa;YAChC,YAAY,IAAI,CAAC,WAAW;YAC5B,eAAe,wBAAwB,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO;;QAG/D,MAAM,iBACJ,IAAI,CAAC,UAAU,IAAI,OACf,UAAA,cAAc,CAAC,MAAM,CAAC,CAAA,GAAA,QAAA,qBAAqB,EAAC,IAAI,CAAC,OAAO,EAAE;YAAE,WAAW,IAAI,CAAC,UAAU;QAAA,MACtF;QAEN,MAAM,EAAE,CAAC,EAAE,GAAG,CAAA,GAAA,OAAA,WAAW,EAAC,MAAM,aAAa,OAAO,CAAC,IAAI,EAAE,SAAS;YAAE;QAAc;QAEpF,OAAO;IACT;IAEA;;;;;;;QAQA,MAAM,uBAAoB;QACxB,OAAO,MAAM,CAAA,GAAA,QAAA,qBAAqB,EAAC,IAAI,CAAC,aAAa,EAAE,IAAI,CAAC,oBAAoB;IAClF;IAEA,WAAW,uBAAoB;QAC7B,OAAO,iBAAiB,aAAa,GAAG,oBAAoB;IAC9D;IAEA;;;;;;;;;;;;QAaQ,MAAM,SACZ,KAAc,EACd,cAAuB,EACvB,OAAuC,EAAA;QAEvC,MAAM,EAAE,SAAS,EAAE,KAAK,EAAE,UAAU,EAAE,gBAAgB,EAAE,SAAS,EAAE,YAAY,EAAE,GAAG;QACpF,MAAM,iBAAmD;YACvD;YACA;;QAEF,IAAI,OAAO;YACT,eAAe,KAAK,GAAG,MAAM,MAAM;QACrC;QACA,IAAI,YAAY;YACd,IAAI,OAAO;gBACT,MAAM,IAAI,SAAA,8BAA8B,CACtC,CAAA,sDAAA,CAAwD;YAE5D;YACA,IAAI,OAAO,eAAe,UAAU;gBAClC,MAAM,IAAI,SAAA,8BAA8B,CACtC,CAAA,6DAAA,EAAgE,OAAO,WAAU,CAAE;YAEvF;YAEA,eAAe,UAAU,GAAG,CAAA,GAAA,OAAA,SAAS,EAAC;gBAAE;YAAU;QACpD;QACA,IAAI,OAAO,qBAAqB,YAAY,OAAO,qBAAqB,UAAU;YAChF,eAAe,gBAAgB,GAAG;QACpC;QACA,IAAI,OAAO,cAAc,UAAU;YACjC,eAAe,SAAS,GAAG;QAC7B;QAEA,IAAI,OAAO,iBAAiB,UAAU;YACpC,eAAe,YAAY,GAAG,CAAA,GAAA,OAAA,SAAS,EAAC;QAC1C;QAEA,MAAM,cAAc,CAAA,GAAA,OAAA,SAAS,EAAC;YAAE,GAAG;QAAK;QACxC,MAAM,eAAe,IAAI,gBAAA,YAAY,CAAC;YACpC,cAAc,IAAI,CAAC,aAAa;YAChC,YAAY,IAAI,CAAC,WAAW;YAC5B,eAAe,wBAAwB,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO;;QAE/D,MAAM,UAAU,IAAI,CAAC,WAAW,CAAC,6BAA6B,CAAC,aAAa;QAE5E,MAAM,iBACJ,IAAI,CAAC,UAAU,IAAI,OACf,UAAA,cAAc,CAAC,MAAM,CAAC,CAAA,GAAA,QAAA,qBAAqB,EAAC,IAAI,CAAC,OAAO,EAAE;YAAE,WAAW,IAAI,CAAC,UAAU;QAAA,MACtF;QACN,MAAM,EAAE,CAAC,EAAE,GAAG,CAAA,GAAA,OAAA,WAAW,EAAC,MAAM,aAAa,OAAO,CAAC,IAAI,EAAE,SAAS;YAAE;QAAc;QACpF,OAAO;IACT;;AA5tBF,QAAA,gBAAA,GAAA;AA2/BA;;;;IAKA,SAAgB,wBACd,WAA+B;IAE/B,MAAM,UAAyC;QAAE,kBAAkB;IAAI;IACvE,IAAI,sBAAsB,aAAa;QACrC,QAAQ,gBAAgB,GAAG,YAAY,gBAAgB;IACzD;IACA,IAAI,oCAAoC,aAAa;QACnD,QAAQ,8BAA8B,GAAG,YAAY,8BAA8B;IACrF;IACA,OAAO;AACT"}},
    {"offset": {"line": 10183, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 10187, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/client-side-encryption/mongocryptd_manager.ts"],"sourcesContent":["import type { ChildProcess } from 'child_process';\n\nimport { MongoNetworkTimeoutError } from '../error';\nimport { type AutoEncryptionExtraOptions } from './auto_encrypter';\n\n/**\n * @internal\n * An internal class that handles spawning a mongocryptd.\n */\nexport class MongocryptdManager {\n  static DEFAULT_MONGOCRYPTD_URI = 'mongodb://localhost:27020';\n\n  uri: string;\n  bypassSpawn: boolean;\n  spawnPath = '';\n  spawnArgs: Array<string> = [];\n  _child?: ChildProcess;\n\n  constructor(extraOptions: AutoEncryptionExtraOptions = {}) {\n    this.uri =\n      typeof extraOptions.mongocryptdURI === 'string' && extraOptions.mongocryptdURI.length > 0\n        ? extraOptions.mongocryptdURI\n        : MongocryptdManager.DEFAULT_MONGOCRYPTD_URI;\n\n    this.bypassSpawn = !!extraOptions.mongocryptdBypassSpawn;\n\n    if (Object.hasOwn(extraOptions, 'mongocryptdSpawnPath') && extraOptions.mongocryptdSpawnPath) {\n      this.spawnPath = extraOptions.mongocryptdSpawnPath;\n    }\n    if (\n      Object.hasOwn(extraOptions, 'mongocryptdSpawnArgs') &&\n      Array.isArray(extraOptions.mongocryptdSpawnArgs)\n    ) {\n      this.spawnArgs = this.spawnArgs.concat(extraOptions.mongocryptdSpawnArgs);\n    }\n    if (\n      this.spawnArgs\n        .filter(arg => typeof arg === 'string')\n        .every(arg => arg.indexOf('--idleShutdownTimeoutSecs') < 0)\n    ) {\n      this.spawnArgs.push('--idleShutdownTimeoutSecs', '60');\n    }\n  }\n\n  /**\n   * Will check to see if a mongocryptd is up. If it is not up, it will attempt\n   * to spawn a mongocryptd in a detached process, and then wait for it to be up.\n   */\n  async spawn(): Promise<void> {\n    const cmdName = this.spawnPath || 'mongocryptd';\n\n    // eslint-disable-next-line @typescript-eslint/no-require-imports\n    const { spawn } = require('child_process') as typeof import('child_process');\n\n    // Spawned with stdio: ignore and detached: true\n    // to ensure child can outlive parent.\n    this._child = spawn(cmdName, this.spawnArgs, {\n      stdio: 'ignore',\n      detached: true\n    });\n\n    this._child.on('error', () => {\n      // From the FLE spec:\n      // \"The stdout and stderr of the spawned process MUST not be exposed in the driver\n      // (e.g. redirect to /dev/null). Users can pass the argument --logpath to\n      // extraOptions.mongocryptdSpawnArgs if they need to inspect mongocryptd logs.\n      // If spawning is necessary, the driver MUST spawn mongocryptd whenever server\n      // selection on the MongoClient to mongocryptd fails. If the MongoClient fails to\n      // connect after spawning, the server selection error is propagated to the user.\"\n      // The AutoEncrypter and MongoCryptdManager should work together to spawn\n      // mongocryptd whenever necessary.  Additionally, the `mongocryptd` intentionally\n      // shuts down after 60s and gets respawned when necessary.  We rely on server\n      // selection timeouts when connecting to the `mongocryptd` to inform users that something\n      // has been configured incorrectly.  For those reasons, we suppress stderr from\n      // the `mongocryptd` process and immediately unref the process.\n    });\n\n    // unref child to remove handle from event loop\n    this._child.unref();\n  }\n\n  /**\n   * @returns the result of `fn` or rejects with an error.\n   */\n  async withRespawn<T>(fn: () => Promise<T>): ReturnType<typeof fn> {\n    try {\n      const result = await fn();\n      return result;\n    } catch (err) {\n      // If we are not bypassing spawning, then we should retry once on a MongoTimeoutError (server selection error)\n      const shouldSpawn = err instanceof MongoNetworkTimeoutError && !this.bypassSpawn;\n      if (!shouldSpawn) {\n        throw err;\n      }\n    }\n    await this.spawn();\n    const result = await fn();\n    return result;\n  }\n}\n"],"names":[],"mappings":";;;;;AAEA,MAAA;AAGA;;;IAIA,MAAa;IASX,YAAY,eAA2C,CAAA,CAAE,CAAA;QAJzD,IAAA,CAAA,SAAS,GAAG;QACZ,IAAA,CAAA,SAAS,GAAkB,EAAE;QAI3B,IAAI,CAAC,GAAG,GACN,OAAO,aAAa,cAAc,KAAK,YAAY,aAAa,cAAc,CAAC,MAAM,GAAG,IACpF,aAAa,cAAc,GAC3B,mBAAmB,uBAAuB;QAEhD,IAAI,CAAC,WAAW,GAAG,CAAC,CAAC,aAAa,sBAAsB;QAExD,IAAI,OAAO,MAAM,CAAC,cAAc,2BAA2B,aAAa,oBAAoB,EAAE;YAC5F,IAAI,CAAC,SAAS,GAAG,aAAa,oBAAoB;QACpD;QACA,IACE,OAAO,MAAM,CAAC,cAAc,2BAC5B,MAAM,OAAO,CAAC,aAAa,oBAAoB,GAC/C;YACA,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,aAAa,oBAAoB;QAC1E;QACA,IACE,IAAI,CAAC,SAAS,CACX,MAAM,CAAC,CAAA,MAAO,OAAO,QAAQ,UAC7B,KAAK,CAAC,CAAA,MAAO,IAAI,OAAO,CAAC,+BAA+B,IAC3D;YACA,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,6BAA6B;QACnD;IACF;IAEA;;;QAIA,MAAM,QAAK;QACT,MAAM,UAAU,IAAI,CAAC,SAAS,IAAI;QAElC,iEAAiE;QACjE,MAAM,EAAE,KAAK,EAAE;QAEf,gDAAgD;QAChD,sCAAsC;QACtC,IAAI,CAAC,MAAM,GAAG,MAAM,SAAS,IAAI,CAAC,SAAS,EAAE;YAC3C,OAAO;YACP,UAAU;;QAGZ,IAAI,CAAC,MAAM,CAAC,EAAE,CAAC,SAAS;QACtB,qBAAqB;QACrB,kFAAkF;QAClF,yEAAyE;QACzE,8EAA8E;QAC9E,8EAA8E;QAC9E,iFAAiF;QACjF,iFAAiF;QACjF,yEAAyE;QACzE,iFAAiF;QACjF,6EAA6E;QAC7E,yFAAyF;QACzF,+EAA+E;QAC/E,+DAA+D;QACjE;QAEA,+CAA+C;QAC/C,IAAI,CAAC,MAAM,CAAC,KAAK;IACnB;IAEA;;QAGA,MAAM,YAAe,EAAoB,EAAA;QACvC,IAAI;YACF,MAAM,SAAS,MAAM;YACrB,OAAO;QACT,EAAE,OAAO,KAAK;YACZ,8GAA8G;YAC9G,MAAM,cAAc,eAAe,QAAA,wBAAwB,IAAI,CAAC,IAAI,CAAC,WAAW;YAChF,IAAI,CAAC,aAAa;gBAChB,MAAM;YACR;QACF;QACA,MAAM,IAAI,CAAC,KAAK;QAChB,MAAM,SAAS,MAAM;QACrB,OAAO;IACT;;AAzFF,QAAA,kBAAA,GAAA;AACS,mBAAA,uBAAuB,GAAG"}},
    {"offset": {"line": 10263, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 10267, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/client-side-encryption/auto_encrypter.ts"],"sourcesContent":["import {\n  type MongoCrypt,\n  type MongoCryptConstructor,\n  type MongoCryptOptions\n} from 'mongodb-client-encryption';\nimport * as net from 'net';\n\nimport { deserialize, type Document, serialize } from '../bson';\nimport { type CommandOptions, type ProxyOptions } from '../cmap/connection';\nimport { kDecorateResult } from '../constants';\nimport { getMongoDBClientEncryption } from '../deps';\nimport { MongoRuntimeError } from '../error';\nimport { MongoClient, type MongoClientOptions } from '../mongo_client';\nimport { type Abortable } from '../mongo_types';\nimport { MongoDBCollectionNamespace } from '../utils';\nimport { autoSelectSocketOptions } from './client_encryption';\nimport * as cryptoCallbacks from './crypto_callbacks';\nimport { MongoCryptInvalidArgumentError } from './errors';\nimport { MongocryptdManager } from './mongocryptd_manager';\nimport {\n  type CredentialProviders,\n  isEmptyCredentials,\n  type KMSProviders,\n  refreshKMSCredentials\n} from './providers';\nimport { type CSFLEKMSTlsOptions, StateMachine } from './state_machine';\n\n/** @public */\nexport interface AutoEncryptionOptions {\n  /** @internal client for metadata lookups */\n  metadataClient?: MongoClient;\n  /** A `MongoClient` used to fetch keys from a key vault */\n  keyVaultClient?: MongoClient;\n  /** The namespace where keys are stored in the key vault */\n  keyVaultNamespace?: string;\n  /** Configuration options that are used by specific KMS providers during key generation, encryption, and decryption. */\n  kmsProviders?: KMSProviders;\n  /** Configuration options for custom credential providers. */\n  credentialProviders?: CredentialProviders;\n  /**\n   * A map of namespaces to a local JSON schema for encryption\n   *\n   * **NOTE**: Supplying options.schemaMap provides more security than relying on JSON Schemas obtained from the server.\n   * It protects against a malicious server advertising a false JSON Schema, which could trick the client into sending decrypted data that should be encrypted.\n   * Schemas supplied in the schemaMap only apply to configuring automatic encryption for Client-Side Field Level Encryption.\n   * Other validation rules in the JSON schema will not be enforced by the driver and will result in an error.\n   */\n  schemaMap?: Document;\n  /** Supply a schema for the encrypted fields in the document  */\n  encryptedFieldsMap?: Document;\n  /** Allows the user to bypass auto encryption, maintaining implicit decryption */\n  bypassAutoEncryption?: boolean;\n  /** Allows users to bypass query analysis */\n  bypassQueryAnalysis?: boolean;\n  /**\n   * Sets the expiration time for the DEK in the cache in milliseconds. Defaults to 60000.  0 means no timeout.\n   */\n  keyExpirationMS?: number;\n  options?: {\n    /** An optional hook to catch logging messages from the underlying encryption engine */\n    logger?: (level: AutoEncryptionLoggerLevel, message: string) => void;\n  };\n  extraOptions?: {\n    /**\n     * A local process the driver communicates with to determine how to encrypt values in a command.\n     * Defaults to \"mongodb://%2Fvar%2Fmongocryptd.sock\" if domain sockets are available or \"mongodb://localhost:27020\" otherwise\n     */\n    mongocryptdURI?: string;\n    /** If true, autoEncryption will not attempt to spawn a mongocryptd before connecting  */\n    mongocryptdBypassSpawn?: boolean;\n    /** The path to the mongocryptd executable on the system */\n    mongocryptdSpawnPath?: string;\n    /** Command line arguments to use when auto-spawning a mongocryptd */\n    mongocryptdSpawnArgs?: string[];\n    /**\n     * Full path to a MongoDB Crypt shared library to be used (instead of mongocryptd).\n     *\n     * This needs to be the path to the file itself, not a directory.\n     * It can be an absolute or relative path. If the path is relative and\n     * its first component is `$ORIGIN`, it will be replaced by the directory\n     * containing the mongodb-client-encryption native addon file. Otherwise,\n     * the path will be interpreted relative to the current working directory.\n     *\n     * Currently, loading different MongoDB Crypt shared library files from different\n     * MongoClients in the same process is not supported.\n     *\n     * If this option is provided and no MongoDB Crypt shared library could be loaded\n     * from the specified location, creating the MongoClient will fail.\n     *\n     * If this option is not provided and `cryptSharedLibRequired` is not specified,\n     * the AutoEncrypter will attempt to spawn and/or use mongocryptd according\n     * to the mongocryptd-specific `extraOptions` options.\n     *\n     * Specifying a path prevents mongocryptd from being used as a fallback.\n     *\n     * Requires the MongoDB Crypt shared library, available in MongoDB 6.0 or higher.\n     */\n    cryptSharedLibPath?: string;\n    /**\n     * If specified, never use mongocryptd and instead fail when the MongoDB Crypt\n     * shared library could not be loaded.\n     *\n     * This is always true when `cryptSharedLibPath` is specified.\n     *\n     * Requires the MongoDB Crypt shared library, available in MongoDB 6.0 or higher.\n     */\n    cryptSharedLibRequired?: boolean;\n    /**\n     * Search paths for a MongoDB Crypt shared library to be used (instead of mongocryptd)\n     * Only for driver testing!\n     * @internal\n     */\n    cryptSharedLibSearchPaths?: string[];\n  };\n  proxyOptions?: ProxyOptions;\n  /** The TLS options to use connecting to the KMS provider */\n  tlsOptions?: CSFLEKMSTlsOptions;\n}\n\n/**\n * @public\n *\n * Extra options related to the mongocryptd process\n * \\* _Available in MongoDB 6.0 or higher._\n */\nexport type AutoEncryptionExtraOptions = NonNullable<AutoEncryptionOptions['extraOptions']>;\n\n/** @public */\nexport const AutoEncryptionLoggerLevel = Object.freeze({\n  FatalError: 0,\n  Error: 1,\n  Warning: 2,\n  Info: 3,\n  Trace: 4\n} as const);\n\n/**\n * @public\n * The level of severity of the log message\n *\n * | Value | Level |\n * |-------|-------|\n * | 0 | Fatal Error |\n * | 1 | Error |\n * | 2 | Warning |\n * | 3 | Info |\n * | 4 | Trace |\n */\nexport type AutoEncryptionLoggerLevel =\n  (typeof AutoEncryptionLoggerLevel)[keyof typeof AutoEncryptionLoggerLevel];\n\n/**\n * @internal An internal class to be used by the driver for auto encryption\n * **NOTE**: Not meant to be instantiated directly, this is for internal use only.\n */\nexport class AutoEncrypter {\n  _client: MongoClient;\n  _bypassEncryption: boolean;\n  _keyVaultNamespace: string;\n  _keyVaultClient: MongoClient;\n  _metaDataClient: MongoClient;\n  _proxyOptions: ProxyOptions;\n  _tlsOptions: CSFLEKMSTlsOptions;\n  _kmsProviders: KMSProviders;\n  _bypassMongocryptdAndCryptShared: boolean;\n  _contextCounter: number;\n  _credentialProviders?: CredentialProviders;\n\n  _mongocryptdManager?: MongocryptdManager;\n  _mongocryptdClient?: MongoClient;\n\n  /** @internal */\n  _mongocrypt: MongoCrypt;\n\n  /**\n   * Used by devtools to enable decorating decryption results.\n   *\n   * When set and enabled, `decrypt` will automatically recursively\n   * traverse a decrypted document and if a field has been decrypted,\n   * it will mark it as decrypted.  Compass uses this to determine which\n   * fields were decrypted.\n   */\n  [kDecorateResult] = false;\n\n  /** @internal */\n  static getMongoCrypt(): MongoCryptConstructor {\n    const encryption = getMongoDBClientEncryption();\n    if ('kModuleError' in encryption) {\n      throw encryption.kModuleError;\n    }\n    return encryption.MongoCrypt;\n  }\n\n  /**\n   * Create an AutoEncrypter\n   *\n   * **Note**: Do not instantiate this class directly. Rather, supply the relevant options to a MongoClient\n   *\n   * **Note**: Supplying `options.schemaMap` provides more security than relying on JSON Schemas obtained from the server.\n   * It protects against a malicious server advertising a false JSON Schema, which could trick the client into sending unencrypted data that should be encrypted.\n   * Schemas supplied in the schemaMap only apply to configuring automatic encryption for Client-Side Field Level Encryption.\n   * Other validation rules in the JSON schema will not be enforced by the driver and will result in an error.\n   *\n   * @example <caption>Create an AutoEncrypter that makes use of mongocryptd</caption>\n   * ```ts\n   * // Enabling autoEncryption via a MongoClient using mongocryptd\n   * const { MongoClient } = require('mongodb');\n   * const client = new MongoClient(URL, {\n   *   autoEncryption: {\n   *     kmsProviders: {\n   *       aws: {\n   *         accessKeyId: AWS_ACCESS_KEY,\n   *         secretAccessKey: AWS_SECRET_KEY\n   *       }\n   *     }\n   *   }\n   * });\n   * ```\n   *\n   * await client.connect();\n   * // From here on, the client will be encrypting / decrypting automatically\n   * @example <caption>Create an AutoEncrypter that makes use of libmongocrypt's CSFLE shared library</caption>\n   * ```ts\n   * // Enabling autoEncryption via a MongoClient using CSFLE shared library\n   * const { MongoClient } = require('mongodb');\n   * const client = new MongoClient(URL, {\n   *   autoEncryption: {\n   *     kmsProviders: {\n   *       aws: {}\n   *     },\n   *     extraOptions: {\n   *       cryptSharedLibPath: '/path/to/local/crypt/shared/lib',\n   *       cryptSharedLibRequired: true\n   *     }\n   *   }\n   * });\n   * ```\n   *\n   * await client.connect();\n   * // From here on, the client will be encrypting / decrypting automatically\n   */\n  constructor(client: MongoClient, options: AutoEncryptionOptions) {\n    this._client = client;\n    this._bypassEncryption = options.bypassAutoEncryption === true;\n\n    this._keyVaultNamespace = options.keyVaultNamespace || 'admin.datakeys';\n    this._keyVaultClient = options.keyVaultClient || client;\n    this._metaDataClient = options.metadataClient || client;\n    this._proxyOptions = options.proxyOptions || {};\n    this._tlsOptions = options.tlsOptions || {};\n    this._kmsProviders = options.kmsProviders || {};\n    this._credentialProviders = options.credentialProviders;\n\n    if (options.credentialProviders?.aws && !isEmptyCredentials('aws', this._kmsProviders)) {\n      throw new MongoCryptInvalidArgumentError(\n        'Can only provide a custom AWS credential provider when the state machine is configured for automatic AWS credential fetching'\n      );\n    }\n\n    const mongoCryptOptions: MongoCryptOptions = {\n      enableMultipleCollinfo: true,\n      cryptoCallbacks\n    };\n    if (options.schemaMap) {\n      mongoCryptOptions.schemaMap = Buffer.isBuffer(options.schemaMap)\n        ? options.schemaMap\n        : (serialize(options.schemaMap) as Buffer);\n    }\n\n    if (options.encryptedFieldsMap) {\n      mongoCryptOptions.encryptedFieldsMap = Buffer.isBuffer(options.encryptedFieldsMap)\n        ? options.encryptedFieldsMap\n        : (serialize(options.encryptedFieldsMap) as Buffer);\n    }\n\n    mongoCryptOptions.kmsProviders = !Buffer.isBuffer(this._kmsProviders)\n      ? (serialize(this._kmsProviders) as Buffer)\n      : this._kmsProviders;\n\n    if (options.options?.logger) {\n      mongoCryptOptions.logger = options.options.logger;\n    }\n\n    if (options.extraOptions && options.extraOptions.cryptSharedLibPath) {\n      mongoCryptOptions.cryptSharedLibPath = options.extraOptions.cryptSharedLibPath;\n    }\n\n    if (options.bypassQueryAnalysis) {\n      mongoCryptOptions.bypassQueryAnalysis = options.bypassQueryAnalysis;\n    }\n\n    if (options.keyExpirationMS != null) {\n      mongoCryptOptions.keyExpirationMS = options.keyExpirationMS;\n    }\n\n    this._bypassMongocryptdAndCryptShared = this._bypassEncryption || !!options.bypassQueryAnalysis;\n\n    if (options.extraOptions && options.extraOptions.cryptSharedLibSearchPaths) {\n      // Only for driver testing\n      mongoCryptOptions.cryptSharedLibSearchPaths = options.extraOptions.cryptSharedLibSearchPaths;\n    } else if (!this._bypassMongocryptdAndCryptShared) {\n      mongoCryptOptions.cryptSharedLibSearchPaths = ['$SYSTEM'];\n    }\n\n    const MongoCrypt = AutoEncrypter.getMongoCrypt();\n    this._mongocrypt = new MongoCrypt(mongoCryptOptions);\n    this._contextCounter = 0;\n\n    if (\n      options.extraOptions &&\n      options.extraOptions.cryptSharedLibRequired &&\n      !this.cryptSharedLibVersionInfo\n    ) {\n      throw new MongoCryptInvalidArgumentError(\n        '`cryptSharedLibRequired` set but no crypt_shared library loaded'\n      );\n    }\n\n    // Only instantiate mongocryptd manager/client once we know for sure\n    // that we are not using the CSFLE shared library.\n    if (!this._bypassMongocryptdAndCryptShared && !this.cryptSharedLibVersionInfo) {\n      this._mongocryptdManager = new MongocryptdManager(options.extraOptions);\n      const clientOptions: MongoClientOptions = {\n        serverSelectionTimeoutMS: 10000\n      };\n\n      if (\n        (options.extraOptions == null || typeof options.extraOptions.mongocryptdURI !== 'string') &&\n        !net.getDefaultAutoSelectFamily\n      ) {\n        // Only set family if autoSelectFamily options are not supported.\n        clientOptions.family = 4;\n      }\n\n      // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n      // @ts-ignore: TS complains as this always returns true on versions where it is present.\n      if (net.getDefaultAutoSelectFamily) {\n        // AutoEncrypter is made inside of MongoClient constructor while options are being parsed,\n        // we do not have access to the options that are in progress.\n        // TODO(NODE-6449): AutoEncrypter does not use client options for autoSelectFamily\n        Object.assign(clientOptions, autoSelectSocketOptions(this._client.s?.options ?? {}));\n      }\n\n      this._mongocryptdClient = new MongoClient(this._mongocryptdManager.uri, clientOptions);\n    }\n  }\n\n  /**\n   * Initializes the auto encrypter by spawning a mongocryptd and connecting to it.\n   *\n   * This function is a no-op when bypassSpawn is set or the crypt shared library is used.\n   */\n  async init(): Promise<MongoClient | void> {\n    if (this._bypassMongocryptdAndCryptShared || this.cryptSharedLibVersionInfo) {\n      return;\n    }\n    if (!this._mongocryptdManager) {\n      throw new MongoRuntimeError(\n        'Reached impossible state: mongocryptdManager is undefined when neither bypassSpawn nor the shared lib are specified.'\n      );\n    }\n    if (!this._mongocryptdClient) {\n      throw new MongoRuntimeError(\n        'Reached impossible state: mongocryptdClient is undefined when neither bypassSpawn nor the shared lib are specified.'\n      );\n    }\n\n    if (!this._mongocryptdManager.bypassSpawn) {\n      await this._mongocryptdManager.spawn();\n    }\n\n    try {\n      const client = await this._mongocryptdClient.connect();\n      return client;\n    } catch (error) {\n      throw new MongoRuntimeError(\n        'Unable to connect to `mongocryptd`, please make sure it is running or in your PATH for auto-spawn',\n        { cause: error }\n      );\n    }\n  }\n\n  /**\n   * Cleans up the `_mongocryptdClient`, if present.\n   */\n  async close(): Promise<void> {\n    await this._mongocryptdClient?.close();\n  }\n\n  /**\n   * Encrypt a command for a given namespace.\n   */\n  async encrypt(\n    ns: string,\n    cmd: Document,\n    options: CommandOptions & Abortable = {}\n  ): Promise<Document | Uint8Array> {\n    options.signal?.throwIfAborted();\n\n    if (this._bypassEncryption) {\n      // If `bypassAutoEncryption` has been specified, don't encrypt\n      return cmd;\n    }\n\n    const commandBuffer = Buffer.isBuffer(cmd) ? cmd : serialize(cmd, options);\n\n    const context = this._mongocrypt.makeEncryptionContext(\n      MongoDBCollectionNamespace.fromString(ns).db,\n      commandBuffer\n    );\n\n    context.id = this._contextCounter++;\n    context.ns = ns;\n    context.document = cmd;\n\n    const stateMachine = new StateMachine({\n      promoteValues: false,\n      promoteLongs: false,\n      proxyOptions: this._proxyOptions,\n      tlsOptions: this._tlsOptions,\n      socketOptions: autoSelectSocketOptions(this._client.s.options)\n    });\n\n    return deserialize(await stateMachine.execute(this, context, options), {\n      promoteValues: false,\n      promoteLongs: false\n    });\n  }\n\n  /**\n   * Decrypt a command response\n   */\n  async decrypt(\n    response: Uint8Array,\n    options: CommandOptions & Abortable = {}\n  ): Promise<Uint8Array> {\n    options.signal?.throwIfAborted();\n\n    const context = this._mongocrypt.makeDecryptionContext(response);\n\n    context.id = this._contextCounter++;\n\n    const stateMachine = new StateMachine({\n      ...options,\n      proxyOptions: this._proxyOptions,\n      tlsOptions: this._tlsOptions,\n      socketOptions: autoSelectSocketOptions(this._client.s.options)\n    });\n\n    return await stateMachine.execute(this, context, options);\n  }\n\n  /**\n   * Ask the user for KMS credentials.\n   *\n   * This returns anything that looks like the kmsProviders original input\n   * option. It can be empty, and any provider specified here will override\n   * the original ones.\n   */\n  async askForKMSCredentials(): Promise<KMSProviders> {\n    return await refreshKMSCredentials(this._kmsProviders, this._credentialProviders);\n  }\n\n  /**\n   * Return the current libmongocrypt's CSFLE shared library version\n   * as `{ version: bigint, versionStr: string }`, or `null` if no CSFLE\n   * shared library was loaded.\n   */\n  get cryptSharedLibVersionInfo(): { version: bigint; versionStr: string } | null {\n    return this._mongocrypt.cryptSharedLibVersionInfo;\n  }\n\n  static get libmongocryptVersion(): string {\n    return AutoEncrypter.getMongoCrypt().libmongocryptVersion;\n  }\n}\n"],"names":[],"mappings":";;;;;;AAKA,MAAA;AAEA,MAAA;AAEA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAEA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAMA,MAAA;AAsGA,YAAA,GACa,QAAA,yBAAyB,GAAG,OAAO,MAAM,CAAC;IACrD,YAAY;IACZ,OAAO;IACP,SAAS;IACT,MAAM;IACN,OAAO;;AAkBT;;;IAIA,MAAa;IA6BX,cAAA,GACA,OAAO,gBAAa;QAClB,MAAM,aAAa,CAAA,GAAA,OAAA,0BAA0B;QAC7C,IAAI,kBAAkB,YAAY;YAChC,MAAM,WAAW,YAAY;QAC/B;QACA,OAAO,WAAW,UAAU;IAC9B;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;QAgDA,YAAY,MAAmB,EAAE,OAA8B,CAAA;QAnE/D;;;;;;;YAQA,IAAA,CAAA,GAAiB,GAAG;QA4DlB,IAAI,CAAC,OAAO,GAAG;QACf,IAAI,CAAC,iBAAiB,GAAG,QAAQ,oBAAoB,KAAK;QAE1D,IAAI,CAAC,kBAAkB,GAAG,QAAQ,iBAAiB,IAAI;QACvD,IAAI,CAAC,eAAe,GAAG,QAAQ,cAAc,IAAI;QACjD,IAAI,CAAC,eAAe,GAAG,QAAQ,cAAc,IAAI;QACjD,IAAI,CAAC,aAAa,GAAG,QAAQ,YAAY,IAAI,CAAA;QAC7C,IAAI,CAAC,WAAW,GAAG,QAAQ,UAAU,IAAI,CAAA;QACzC,IAAI,CAAC,aAAa,GAAG,QAAQ,YAAY,IAAI,CAAA;QAC7C,IAAI,CAAC,oBAAoB,GAAG,QAAQ,mBAAmB;QAEvD,IAAI,QAAQ,mBAAmB,EAAE,OAAO,CAAC,CAAA,GAAA,YAAA,kBAAkB,EAAC,OAAO,IAAI,CAAC,aAAa,GAAG;YACtF,MAAM,IAAI,SAAA,8BAA8B,CACtC;QAEJ;QAEA,MAAM,oBAAuC;YAC3C,wBAAwB;YACxB;;QAEF,IAAI,QAAQ,SAAS,EAAE;YACrB,kBAAkB,SAAS,GAAG,OAAO,QAAQ,CAAC,QAAQ,SAAS,IAC3D,QAAQ,SAAS,GAChB,CAAA,GAAA,OAAA,SAAS,EAAC,QAAQ,SAAS;QAClC;QAEA,IAAI,QAAQ,kBAAkB,EAAE;YAC9B,kBAAkB,kBAAkB,GAAG,OAAO,QAAQ,CAAC,QAAQ,kBAAkB,IAC7E,QAAQ,kBAAkB,GACzB,CAAA,GAAA,OAAA,SAAS,EAAC,QAAQ,kBAAkB;QAC3C;QAEA,kBAAkB,YAAY,GAAG,CAAC,OAAO,QAAQ,CAAC,IAAI,CAAC,aAAa,IAC/D,CAAA,GAAA,OAAA,SAAS,EAAC,IAAI,CAAC,aAAa,IAC7B,IAAI,CAAC,aAAa;QAEtB,IAAI,QAAQ,OAAO,EAAE,QAAQ;YAC3B,kBAAkB,MAAM,GAAG,QAAQ,OAAO,CAAC,MAAM;QACnD;QAEA,IAAI,QAAQ,YAAY,IAAI,QAAQ,YAAY,CAAC,kBAAkB,EAAE;YACnE,kBAAkB,kBAAkB,GAAG,QAAQ,YAAY,CAAC,kBAAkB;QAChF;QAEA,IAAI,QAAQ,mBAAmB,EAAE;YAC/B,kBAAkB,mBAAmB,GAAG,QAAQ,mBAAmB;QACrE;QAEA,IAAI,QAAQ,eAAe,IAAI,MAAM;YACnC,kBAAkB,eAAe,GAAG,QAAQ,eAAe;QAC7D;QAEA,IAAI,CAAC,gCAAgC,GAAG,IAAI,CAAC,iBAAiB,IAAI,CAAC,CAAC,QAAQ,mBAAmB;QAE/F,IAAI,QAAQ,YAAY,IAAI,QAAQ,YAAY,CAAC,yBAAyB,EAAE;YAC1E,0BAA0B;YAC1B,kBAAkB,yBAAyB,GAAG,QAAQ,YAAY,CAAC,yBAAyB;QAC9F,OAAO,IAAI,CAAC,IAAI,CAAC,gCAAgC,EAAE;YACjD,kBAAkB,yBAAyB,GAAG;gBAAC;aAAU;QAC3D;QAEA,MAAM,aAAa,cAAc,aAAa;QAC9C,IAAI,CAAC,WAAW,GAAG,IAAI,WAAW;QAClC,IAAI,CAAC,eAAe,GAAG;QAEvB,IACE,QAAQ,YAAY,IACpB,QAAQ,YAAY,CAAC,sBAAsB,IAC3C,CAAC,IAAI,CAAC,yBAAyB,EAC/B;YACA,MAAM,IAAI,SAAA,8BAA8B,CACtC;QAEJ;QAEA,oEAAoE;QACpE,kDAAkD;QAClD,IAAI,CAAC,IAAI,CAAC,gCAAgC,IAAI,CAAC,IAAI,CAAC,yBAAyB,EAAE;YAC7E,IAAI,CAAC,mBAAmB,GAAG,IAAI,sBAAA,kBAAkB,CAAC,QAAQ,YAAY;YACtE,MAAM,gBAAoC;gBACxC,0BAA0B;;YAG5B,IACE,CAAC,QAAQ,YAAY,IAAI,QAAQ,OAAO,QAAQ,YAAY,CAAC,cAAc,KAAK,QAAQ,KACxF,CAAC,IAAI,0BAA0B,EAC/B;gBACA,iEAAiE;gBACjE,cAAc,MAAM,GAAG;YACzB;YAEA,6DAA6D;YAC7D,wFAAwF;YACxF,IAAI,IAAI,0BAA0B,EAAE;gBAClC,0FAA0F;gBAC1F,6DAA6D;gBAC7D,kFAAkF;gBAClF,OAAO,MAAM,CAAC,eAAe,CAAA,GAAA,oBAAA,uBAAuB,EAAC,IAAI,CAAC,OAAO,CAAC,CAAC,EAAE,WAAW,CAAA;YAClF;YAEA,IAAI,CAAC,kBAAkB,GAAG,IAAI,eAAA,WAAW,CAAC,IAAI,CAAC,mBAAmB,CAAC,GAAG,EAAE;QAC1E;IACF;IAEA;;;;QAKA,MAAM,OAAI;QACR,IAAI,IAAI,CAAC,gCAAgC,IAAI,IAAI,CAAC,yBAAyB,EAAE;YAC3E;QACF;QACA,IAAI,CAAC,IAAI,CAAC,mBAAmB,EAAE;YAC7B,MAAM,IAAI,QAAA,iBAAiB,CACzB;QAEJ;QACA,IAAI,CAAC,IAAI,CAAC,kBAAkB,EAAE;YAC5B,MAAM,IAAI,QAAA,iBAAiB,CACzB;QAEJ;QAEA,IAAI,CAAC,IAAI,CAAC,mBAAmB,CAAC,WAAW,EAAE;YACzC,MAAM,IAAI,CAAC,mBAAmB,CAAC,KAAK;QACtC;QAEA,IAAI;YACF,MAAM,SAAS,MAAM,IAAI,CAAC,kBAAkB,CAAC,OAAO;YACpD,OAAO;QACT,EAAE,OAAO,OAAO;YACd,MAAM,IAAI,QAAA,iBAAiB,CACzB,qGACA;gBAAE,OAAO;YAAK;QAElB;IACF;IAEA;;QAGA,MAAM,QAAK;QACT,MAAM,IAAI,CAAC,kBAAkB,EAAE;IACjC;IAEA;;QAGA,MAAM,QACJ,EAAU,EACV,GAAa,EACb,UAAsC,CAAA,CAAE,EAAA;QAExC,QAAQ,MAAM,EAAE;QAEhB,IAAI,IAAI,CAAC,iBAAiB,EAAE;YAC1B,8DAA8D;YAC9D,OAAO;QACT;QAEA,MAAM,gBAAgB,OAAO,QAAQ,CAAC,OAAO,MAAM,CAAA,GAAA,OAAA,SAAS,EAAC,KAAK;QAElE,MAAM,UAAU,IAAI,CAAC,WAAW,CAAC,qBAAqB,CACpD,QAAA,0BAA0B,CAAC,UAAU,CAAC,IAAI,EAAE,EAC5C;QAGF,QAAQ,EAAE,GAAG,IAAI,CAAC,eAAe;QACjC,QAAQ,EAAE,GAAG;QACb,QAAQ,QAAQ,GAAG;QAEnB,MAAM,eAAe,IAAI,gBAAA,YAAY,CAAC;YACpC,eAAe;YACf,cAAc;YACd,cAAc,IAAI,CAAC,aAAa;YAChC,YAAY,IAAI,CAAC,WAAW;YAC5B,eAAe,CAAA,GAAA,oBAAA,uBAAuB,EAAC,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO;;QAG/D,OAAO,CAAA,GAAA,OAAA,WAAW,EAAC,MAAM,aAAa,OAAO,CAAC,IAAI,EAAE,SAAS,UAAU;YACrE,eAAe;YACf,cAAc;;IAElB;IAEA;;QAGA,MAAM,QACJ,QAAoB,EACpB,UAAsC,CAAA,CAAE,EAAA;QAExC,QAAQ,MAAM,EAAE;QAEhB,MAAM,UAAU,IAAI,CAAC,WAAW,CAAC,qBAAqB,CAAC;QAEvD,QAAQ,EAAE,GAAG,IAAI,CAAC,eAAe;QAEjC,MAAM,eAAe,IAAI,gBAAA,YAAY,CAAC;YACpC,GAAG,OAAO;YACV,cAAc,IAAI,CAAC,aAAa;YAChC,YAAY,IAAI,CAAC,WAAW;YAC5B,eAAe,CAAA,GAAA,oBAAA,uBAAuB,EAAC,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,OAAO;;QAG/D,OAAO,MAAM,aAAa,OAAO,CAAC,IAAI,EAAE,SAAS;IACnD;IAEA;;;;;;QAOA,MAAM,uBAAoB;QACxB,OAAO,MAAM,CAAA,GAAA,YAAA,qBAAqB,EAAC,IAAI,CAAC,aAAa,EAAE,IAAI,CAAC,oBAAoB;IAClF;IAEA;;;;QAKA,IAAI,4BAAyB;QAC3B,OAAO,IAAI,CAAC,WAAW,CAAC,yBAAyB;IACnD;IAEA,WAAW,uBAAoB;QAC7B,OAAO,cAAc,aAAa,GAAG,oBAAoB;IAC3D;;AA/TF,QAAA,aAAA,GAAA;KA2BG,YAAA,eAAe"}},
    {"offset": {"line": 10524, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 10528, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/encrypter.ts"],"sourcesContent":["import { AutoEncrypter, type AutoEncryptionOptions } from './client-side-encryption/auto_encrypter';\nimport { MONGO_CLIENT_EVENTS } from './constants';\nimport { getMongoDBClientEncryption } from './deps';\nimport { MongoInvalidArgumentError, MongoMissingDependencyError } from './error';\nimport { MongoClient, type MongoClientOptions } from './mongo_client';\n\n/** @internal */\nexport interface EncrypterOptions {\n  autoEncryption: AutoEncryptionOptions;\n  maxPoolSize?: number;\n}\n\n/** @internal */\nexport class Encrypter {\n  private internalClient: MongoClient | null;\n  bypassAutoEncryption: boolean;\n  needsConnecting: boolean;\n  autoEncrypter: AutoEncrypter;\n\n  constructor(client: MongoClient, uri: string, options: MongoClientOptions) {\n    if (typeof options.autoEncryption !== 'object') {\n      throw new MongoInvalidArgumentError('Option \"autoEncryption\" must be specified');\n    }\n    // initialize to null, if we call getInternalClient, we may set this it is important to not overwrite those function calls.\n    this.internalClient = null;\n\n    this.bypassAutoEncryption = !!options.autoEncryption.bypassAutoEncryption;\n    this.needsConnecting = false;\n\n    if (options.maxPoolSize === 0 && options.autoEncryption.keyVaultClient == null) {\n      options.autoEncryption.keyVaultClient = client;\n    } else if (options.autoEncryption.keyVaultClient == null) {\n      options.autoEncryption.keyVaultClient = this.getInternalClient(client, uri, options);\n    }\n\n    if (this.bypassAutoEncryption) {\n      options.autoEncryption.metadataClient = undefined;\n    } else if (options.maxPoolSize === 0) {\n      options.autoEncryption.metadataClient = client;\n    } else {\n      options.autoEncryption.metadataClient = this.getInternalClient(client, uri, options);\n    }\n\n    if (options.proxyHost) {\n      options.autoEncryption.proxyOptions = {\n        proxyHost: options.proxyHost,\n        proxyPort: options.proxyPort,\n        proxyUsername: options.proxyUsername,\n        proxyPassword: options.proxyPassword\n      };\n    }\n\n    this.autoEncrypter = new AutoEncrypter(client, options.autoEncryption);\n  }\n\n  getInternalClient(client: MongoClient, uri: string, options: MongoClientOptions): MongoClient {\n    let internalClient = this.internalClient;\n    if (internalClient == null) {\n      const clonedOptions: MongoClientOptions = {};\n\n      for (const key of [\n        ...Object.getOwnPropertyNames(options),\n        ...Object.getOwnPropertySymbols(options)\n      ] as string[]) {\n        if (['autoEncryption', 'minPoolSize', 'servers', 'caseTranslate', 'dbName'].includes(key))\n          continue;\n        Reflect.set(clonedOptions, key, Reflect.get(options, key));\n      }\n\n      clonedOptions.minPoolSize = 0;\n\n      internalClient = new MongoClient(uri, clonedOptions);\n      this.internalClient = internalClient;\n\n      for (const eventName of MONGO_CLIENT_EVENTS) {\n        for (const listener of client.listeners(eventName)) {\n          internalClient.on(eventName, listener);\n        }\n      }\n\n      client.on('newListener', (eventName, listener) => {\n        internalClient?.on(eventName, listener);\n      });\n\n      this.needsConnecting = true;\n    }\n    return internalClient;\n  }\n\n  async connectInternalClient(): Promise<void> {\n    const internalClient = this.internalClient;\n    if (this.needsConnecting && internalClient != null) {\n      this.needsConnecting = false;\n      await internalClient.connect();\n    }\n  }\n\n  async close(client: MongoClient): Promise<void> {\n    let error;\n    try {\n      await this.autoEncrypter.close();\n    } catch (autoEncrypterError) {\n      error = autoEncrypterError;\n    }\n    const internalClient = this.internalClient;\n    if (internalClient != null && client !== internalClient) {\n      return await internalClient.close();\n    }\n    if (error != null) {\n      throw error;\n    }\n  }\n\n  static checkForMongoCrypt(): void {\n    const mongodbClientEncryption = getMongoDBClientEncryption();\n    if ('kModuleError' in mongodbClientEncryption) {\n      throw new MongoMissingDependencyError(\n        'Auto-encryption requested, but the module is not installed. ' +\n          'Please add `mongodb-client-encryption` as a dependency of your project',\n        {\n          cause: mongodbClientEncryption['kModuleError'],\n          dependencyName: 'mongodb-client-encryption'\n        }\n      );\n    }\n  }\n}\n"],"names":[],"mappings":";;;;;AAAA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAQA,cAAA,GACA,MAAa;IAMX,YAAY,MAAmB,EAAE,GAAW,EAAE,OAA2B,CAAA;QACvE,IAAI,OAAO,QAAQ,cAAc,KAAK,UAAU;YAC9C,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QACA,2HAA2H;QAC3H,IAAI,CAAC,cAAc,GAAG;QAEtB,IAAI,CAAC,oBAAoB,GAAG,CAAC,CAAC,QAAQ,cAAc,CAAC,oBAAoB;QACzE,IAAI,CAAC,eAAe,GAAG;QAEvB,IAAI,QAAQ,WAAW,KAAK,KAAK,QAAQ,cAAc,CAAC,cAAc,IAAI,MAAM;YAC9E,QAAQ,cAAc,CAAC,cAAc,GAAG;QAC1C,OAAO,IAAI,QAAQ,cAAc,CAAC,cAAc,IAAI,MAAM;YACxD,QAAQ,cAAc,CAAC,cAAc,GAAG,IAAI,CAAC,iBAAiB,CAAC,QAAQ,KAAK;QAC9E;QAEA,IAAI,IAAI,CAAC,oBAAoB,EAAE;YAC7B,QAAQ,cAAc,CAAC,cAAc,GAAG;QAC1C,OAAO,IAAI,QAAQ,WAAW,KAAK,GAAG;YACpC,QAAQ,cAAc,CAAC,cAAc,GAAG;QAC1C,OAAO;YACL,QAAQ,cAAc,CAAC,cAAc,GAAG,IAAI,CAAC,iBAAiB,CAAC,QAAQ,KAAK;QAC9E;QAEA,IAAI,QAAQ,SAAS,EAAE;YACrB,QAAQ,cAAc,CAAC,YAAY,GAAG;gBACpC,WAAW,QAAQ,SAAS;gBAC5B,WAAW,QAAQ,SAAS;gBAC5B,eAAe,QAAQ,aAAa;gBACpC,eAAe,QAAQ,aAAa;;QAExC;QAEA,IAAI,CAAC,aAAa,GAAG,IAAI,iBAAA,aAAa,CAAC,QAAQ,QAAQ,cAAc;IACvE;IAEA,kBAAkB,MAAmB,EAAE,GAAW,EAAE,OAA2B,EAAA;QAC7E,IAAI,iBAAiB,IAAI,CAAC,cAAc;QACxC,IAAI,kBAAkB,MAAM;YAC1B,MAAM,gBAAoC,CAAA;YAE1C,KAAK,MAAM,OAAO;mBACb,OAAO,mBAAmB,CAAC;mBAC3B,OAAO,qBAAqB,CAAC;aACrB,CAAE;gBACb,IAAI;oBAAC;oBAAkB;oBAAe;oBAAW;oBAAiB;iBAAS,CAAC,QAAQ,CAAC,MACnF;gBACF,QAAQ,GAAG,CAAC,eAAe,KAAK,QAAQ,GAAG,CAAC,SAAS;YACvD;YAEA,cAAc,WAAW,GAAG;YAE5B,iBAAiB,IAAI,eAAA,WAAW,CAAC,KAAK;YACtC,IAAI,CAAC,cAAc,GAAG;YAEtB,KAAK,MAAM,aAAa,YAAA,mBAAmB,CAAE;gBAC3C,KAAK,MAAM,YAAY,OAAO,SAAS,CAAC,WAAY;oBAClD,eAAe,EAAE,CAAC,WAAW;gBAC/B;YACF;YAEA,OAAO,EAAE,CAAC,eAAe,CAAC,WAAW;gBACnC,gBAAgB,GAAG,WAAW;YAChC;YAEA,IAAI,CAAC,eAAe,GAAG;QACzB;QACA,OAAO;IACT;IAEA,MAAM,wBAAqB;QACzB,MAAM,iBAAiB,IAAI,CAAC,cAAc;QAC1C,IAAI,IAAI,CAAC,eAAe,IAAI,kBAAkB,MAAM;YAClD,IAAI,CAAC,eAAe,GAAG;YACvB,MAAM,eAAe,OAAO;QAC9B;IACF;IAEA,MAAM,MAAM,MAAmB,EAAA;QAC7B,IAAI;QACJ,IAAI;YACF,MAAM,IAAI,CAAC,aAAa,CAAC,KAAK;QAChC,EAAE,OAAO,oBAAoB;YAC3B,QAAQ;QACV;QACA,MAAM,iBAAiB,IAAI,CAAC,cAAc;QAC1C,IAAI,kBAAkB,QAAQ,WAAW,gBAAgB;YACvD,OAAO,MAAM,eAAe,KAAK;QACnC;QACA,IAAI,SAAS,MAAM;YACjB,MAAM;QACR;IACF;IAEA,OAAO,qBAAkB;QACvB,MAAM,0BAA0B,CAAA,GAAA,OAAA,0BAA0B;QAC1D,IAAI,kBAAkB,yBAAyB;YAC7C,MAAM,IAAI,QAAA,2BAA2B,CACnC,iEACE,0EACF;gBACE,OAAO,uBAAuB,CAAC,eAAe;gBAC9C,gBAAgB;;QAGtB;IACF;;AAhHF,QAAA,SAAA,GAAA"}},
    {"offset": {"line": 10634, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 10638, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/transactions.ts"],"sourcesContent":["import type { Document } from './bson';\nimport { MongoRuntimeError, MongoTransactionError } from './error';\nimport type { CommandOperationOptions } from './operations/command';\nimport { ReadConcern, type ReadConcernLike } from './read_concern';\nimport { ReadPreference, type ReadPreferenceLike } from './read_preference';\nimport type { Server } from './sdam/server';\nimport { WriteConcern } from './write_concern';\n\n/** @internal */\nexport const TxnState = Object.freeze({\n  NO_TRANSACTION: 'NO_TRANSACTION',\n  STARTING_TRANSACTION: 'STARTING_TRANSACTION',\n  TRANSACTION_IN_PROGRESS: 'TRANSACTION_IN_PROGRESS',\n  TRANSACTION_COMMITTED: 'TRANSACTION_COMMITTED',\n  TRANSACTION_COMMITTED_EMPTY: 'TRANSACTION_COMMITTED_EMPTY',\n  TRANSACTION_ABORTED: 'TRANSACTION_ABORTED'\n} as const);\n\n/** @internal */\nexport type TxnState = (typeof TxnState)[keyof typeof TxnState];\n\nconst stateMachine: { [state in TxnState]: TxnState[] } = {\n  [TxnState.NO_TRANSACTION]: [TxnState.NO_TRANSACTION, TxnState.STARTING_TRANSACTION],\n  [TxnState.STARTING_TRANSACTION]: [\n    TxnState.TRANSACTION_IN_PROGRESS,\n    TxnState.TRANSACTION_COMMITTED,\n    TxnState.TRANSACTION_COMMITTED_EMPTY,\n    TxnState.TRANSACTION_ABORTED\n  ],\n  [TxnState.TRANSACTION_IN_PROGRESS]: [\n    TxnState.TRANSACTION_IN_PROGRESS,\n    TxnState.TRANSACTION_COMMITTED,\n    TxnState.TRANSACTION_ABORTED\n  ],\n  [TxnState.TRANSACTION_COMMITTED]: [\n    TxnState.TRANSACTION_COMMITTED,\n    TxnState.TRANSACTION_COMMITTED_EMPTY,\n    TxnState.STARTING_TRANSACTION,\n    TxnState.NO_TRANSACTION\n  ],\n  [TxnState.TRANSACTION_ABORTED]: [TxnState.STARTING_TRANSACTION, TxnState.NO_TRANSACTION],\n  [TxnState.TRANSACTION_COMMITTED_EMPTY]: [\n    TxnState.TRANSACTION_COMMITTED_EMPTY,\n    TxnState.NO_TRANSACTION\n  ]\n};\n\nconst ACTIVE_STATES: Set<TxnState> = new Set([\n  TxnState.STARTING_TRANSACTION,\n  TxnState.TRANSACTION_IN_PROGRESS\n]);\n\nconst COMMITTED_STATES: Set<TxnState> = new Set([\n  TxnState.TRANSACTION_COMMITTED,\n  TxnState.TRANSACTION_COMMITTED_EMPTY,\n  TxnState.TRANSACTION_ABORTED\n]);\n\n/**\n * Configuration options for a transaction.\n * @public\n */\nexport interface TransactionOptions extends Omit<CommandOperationOptions, 'timeoutMS'> {\n  // TODO(NODE-3344): These options use the proper class forms of these settings, it should accept the basic enum values too\n  /** A default read concern for commands in this transaction */\n  readConcern?: ReadConcernLike;\n  /** A default writeConcern for commands in this transaction */\n  writeConcern?: WriteConcern;\n  /** A default read preference for commands in this transaction */\n  readPreference?: ReadPreferenceLike;\n  /** Specifies the maximum amount of time to allow a commit action on a transaction to run in milliseconds */\n  maxCommitTimeMS?: number;\n}\n\n/**\n * @public\n * A class maintaining state related to a server transaction. Internal Only\n */\nexport class Transaction {\n  /** @internal */\n  state: TxnState;\n  options: TransactionOptions;\n  /** @internal */\n  _pinnedServer?: Server;\n  /** @internal */\n  _recoveryToken?: Document;\n\n  /** Create a transaction @internal */\n  constructor(options?: TransactionOptions) {\n    options = options ?? {};\n    this.state = TxnState.NO_TRANSACTION;\n    this.options = {};\n\n    const writeConcern = WriteConcern.fromOptions(options);\n    if (writeConcern) {\n      if (writeConcern.w === 0) {\n        throw new MongoTransactionError('Transactions do not support unacknowledged write concern');\n      }\n\n      this.options.writeConcern = writeConcern;\n    }\n\n    if (options.readConcern) {\n      this.options.readConcern = ReadConcern.fromOptions(options);\n    }\n\n    if (options.readPreference) {\n      this.options.readPreference = ReadPreference.fromOptions(options);\n    }\n\n    if (options.maxCommitTimeMS) {\n      this.options.maxTimeMS = options.maxCommitTimeMS;\n    }\n\n    // TODO: This isn't technically necessary\n    this._pinnedServer = undefined;\n    this._recoveryToken = undefined;\n  }\n\n  /** @internal */\n  get server(): Server | undefined {\n    return this._pinnedServer;\n  }\n\n  get recoveryToken(): Document | undefined {\n    return this._recoveryToken;\n  }\n\n  get isPinned(): boolean {\n    return !!this.server;\n  }\n\n  /** @returns Whether the transaction has started */\n  get isStarting(): boolean {\n    return this.state === TxnState.STARTING_TRANSACTION;\n  }\n\n  /**\n   * @returns Whether this session is presently in a transaction\n   */\n  get isActive(): boolean {\n    return ACTIVE_STATES.has(this.state);\n  }\n\n  get isCommitted(): boolean {\n    return COMMITTED_STATES.has(this.state);\n  }\n  /**\n   * Transition the transaction in the state machine\n   * @internal\n   * @param nextState - The new state to transition to\n   */\n  transition(nextState: TxnState): void {\n    const nextStates = stateMachine[this.state];\n    if (nextStates && nextStates.includes(nextState)) {\n      this.state = nextState;\n      if (\n        this.state === TxnState.NO_TRANSACTION ||\n        this.state === TxnState.STARTING_TRANSACTION ||\n        this.state === TxnState.TRANSACTION_ABORTED\n      ) {\n        this.unpinServer();\n      }\n      return;\n    }\n\n    throw new MongoRuntimeError(\n      `Attempted illegal state transition from [${this.state}] to [${nextState}]`\n    );\n  }\n\n  /** @internal */\n  pinServer(server: Server): void {\n    if (this.isActive) {\n      this._pinnedServer = server;\n    }\n  }\n\n  /** @internal */\n  unpinServer(): void {\n    this._pinnedServer = undefined;\n  }\n}\n\nexport function isTransactionCommand(command: Document): boolean {\n  return !!(command.commitTransaction || command.abortTransaction);\n}\n"],"names":[],"mappings":";;;;;AAwLA,QAAA,oBAAA,GAAA;AAvLA,MAAA;AAEA,MAAA;AACA,MAAA;AAEA,MAAA;AAEA,cAAA,GACa,QAAA,QAAQ,GAAG,OAAO,MAAM,CAAC;IACpC,gBAAgB;IAChB,sBAAsB;IACtB,yBAAyB;IACzB,uBAAuB;IACvB,6BAA6B;IAC7B,qBAAqB;;AAMvB,MAAM,eAAoD;IACxD,CAAC,QAAA,QAAQ,CAAC,cAAc,CAAC,EAAE;QAAC,QAAA,QAAQ,CAAC,cAAc;QAAE,QAAA,QAAQ,CAAC,oBAAoB;KAAC;IACnF,CAAC,QAAA,QAAQ,CAAC,oBAAoB,CAAC,EAAE;QAC/B,QAAA,QAAQ,CAAC,uBAAuB;QAChC,QAAA,QAAQ,CAAC,qBAAqB;QAC9B,QAAA,QAAQ,CAAC,2BAA2B;QACpC,QAAA,QAAQ,CAAC,mBAAmB;KAC7B;IACD,CAAC,QAAA,QAAQ,CAAC,uBAAuB,CAAC,EAAE;QAClC,QAAA,QAAQ,CAAC,uBAAuB;QAChC,QAAA,QAAQ,CAAC,qBAAqB;QAC9B,QAAA,QAAQ,CAAC,mBAAmB;KAC7B;IACD,CAAC,QAAA,QAAQ,CAAC,qBAAqB,CAAC,EAAE;QAChC,QAAA,QAAQ,CAAC,qBAAqB;QAC9B,QAAA,QAAQ,CAAC,2BAA2B;QACpC,QAAA,QAAQ,CAAC,oBAAoB;QAC7B,QAAA,QAAQ,CAAC,cAAc;KACxB;IACD,CAAC,QAAA,QAAQ,CAAC,mBAAmB,CAAC,EAAE;QAAC,QAAA,QAAQ,CAAC,oBAAoB;QAAE,QAAA,QAAQ,CAAC,cAAc;KAAC;IACxF,CAAC,QAAA,QAAQ,CAAC,2BAA2B,CAAC,EAAE;QACtC,QAAA,QAAQ,CAAC,2BAA2B;QACpC,QAAA,QAAQ,CAAC,cAAc;KACxB;;AAGH,MAAM,gBAA+B,IAAI,IAAI;IAC3C,QAAA,QAAQ,CAAC,oBAAoB;IAC7B,QAAA,QAAQ,CAAC,uBAAuB;CACjC;AAED,MAAM,mBAAkC,IAAI,IAAI;IAC9C,QAAA,QAAQ,CAAC,qBAAqB;IAC9B,QAAA,QAAQ,CAAC,2BAA2B;IACpC,QAAA,QAAQ,CAAC,mBAAmB;CAC7B;AAkBD;;;IAIA,MAAa;IASX,mCAAA,GACA,YAAY,OAA4B,CAAA;QACtC,UAAU,WAAW,CAAA;QACrB,IAAI,CAAC,KAAK,GAAG,QAAA,QAAQ,CAAC,cAAc;QACpC,IAAI,CAAC,OAAO,GAAG,CAAA;QAEf,MAAM,eAAe,gBAAA,YAAY,CAAC,WAAW,CAAC;QAC9C,IAAI,cAAc;YAChB,IAAI,aAAa,CAAC,KAAK,GAAG;gBACxB,MAAM,IAAI,QAAA,qBAAqB,CAAC;YAClC;YAEA,IAAI,CAAC,OAAO,CAAC,YAAY,GAAG;QAC9B;QAEA,IAAI,QAAQ,WAAW,EAAE;YACvB,IAAI,CAAC,OAAO,CAAC,WAAW,GAAG,eAAA,WAAW,CAAC,WAAW,CAAC;QACrD;QAEA,IAAI,QAAQ,cAAc,EAAE;YAC1B,IAAI,CAAC,OAAO,CAAC,cAAc,GAAG,kBAAA,cAAc,CAAC,WAAW,CAAC;QAC3D;QAEA,IAAI,QAAQ,eAAe,EAAE;YAC3B,IAAI,CAAC,OAAO,CAAC,SAAS,GAAG,QAAQ,eAAe;QAClD;QAEA,yCAAyC;QACzC,IAAI,CAAC,aAAa,GAAG;QACrB,IAAI,CAAC,cAAc,GAAG;IACxB;IAEA,cAAA,GACA,IAAI,SAAM;QACR,OAAO,IAAI,CAAC,aAAa;IAC3B;IAEA,IAAI,gBAAa;QACf,OAAO,IAAI,CAAC,cAAc;IAC5B;IAEA,IAAI,WAAQ;QACV,OAAO,CAAC,CAAC,IAAI,CAAC,MAAM;IACtB;IAEA,iDAAA,GACA,IAAI,aAAU;QACZ,OAAO,IAAI,CAAC,KAAK,KAAK,QAAA,QAAQ,CAAC,oBAAoB;IACrD;IAEA;;QAGA,IAAI,WAAQ;QACV,OAAO,cAAc,GAAG,CAAC,IAAI,CAAC,KAAK;IACrC;IAEA,IAAI,cAAW;QACb,OAAO,iBAAiB,GAAG,CAAC,IAAI,CAAC,KAAK;IACxC;IACA;;;;QAKA,WAAW,SAAmB,EAAA;QAC5B,MAAM,aAAa,YAAY,CAAC,IAAI,CAAC,KAAK,CAAC;QAC3C,IAAI,cAAc,WAAW,QAAQ,CAAC,YAAY;YAChD,IAAI,CAAC,KAAK,GAAG;YACb,IACE,IAAI,CAAC,KAAK,KAAK,QAAA,QAAQ,CAAC,cAAc,IACtC,IAAI,CAAC,KAAK,KAAK,QAAA,QAAQ,CAAC,oBAAoB,IAC5C,IAAI,CAAC,KAAK,KAAK,QAAA,QAAQ,CAAC,mBAAmB,EAC3C;gBACA,IAAI,CAAC,WAAW;YAClB;YACA;QACF;QAEA,MAAM,IAAI,QAAA,iBAAiB,CACzB,CAAA,yCAAA,EAA4C,IAAI,CAAC,KAAK,CAAA,MAAA,EAAS,UAAS,CAAA,CAAG;IAE/E;IAEA,cAAA,GACA,UAAU,MAAc,EAAA;QACtB,IAAI,IAAI,CAAC,QAAQ,EAAE;YACjB,IAAI,CAAC,aAAa,GAAG;QACvB;IACF;IAEA,cAAA,GACA,cAAW;QACT,IAAI,CAAC,aAAa,GAAG;IACvB;;AAvGF,QAAA,WAAA,GAAA;AA0GA,SAAgB,qBAAqB,OAAiB;IACpD,OAAO,CAAC,CAAC,CAAC,QAAQ,iBAAiB,IAAI,QAAQ,gBAAgB;AACjE"}},
    {"offset": {"line": 10772, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 10776, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/sessions.ts"],"sourcesContent":["import { Binary, type Document, Long, type Timestamp } from './bson';\nimport type { CommandOptions, Connection } from './cmap/connection';\nimport { ConnectionPoolMetrics } from './cmap/metrics';\nimport { type MongoDBResponse } from './cmap/wire_protocol/responses';\nimport { isSharded } from './cmap/wire_protocol/shared';\nimport { PINNED, UNPINNED } from './constants';\nimport type { AbstractCursor } from './cursor/abstract_cursor';\nimport {\n  type AnyError,\n  isRetryableWriteError,\n  MongoAPIError,\n  MongoCompatibilityError,\n  MONGODB_ERROR_CODES,\n  type MongoDriverError,\n  MongoError,\n  MongoErrorLabel,\n  MongoExpiredSessionError,\n  MongoInvalidArgumentError,\n  MongoRuntimeError,\n  MongoServerError,\n  MongoTransactionError,\n  MongoWriteConcernError\n} from './error';\nimport type { MongoClient, MongoOptions } from './mongo_client';\nimport { TypedEventEmitter } from './mongo_types';\nimport { executeOperation } from './operations/execute_operation';\nimport { RunAdminCommandOperation } from './operations/run_command';\nimport { ReadConcernLevel } from './read_concern';\nimport { ReadPreference } from './read_preference';\nimport { type AsyncDisposable, configureResourceManagement } from './resource_management';\nimport { _advanceClusterTime, type ClusterTime, TopologyType } from './sdam/common';\nimport { TimeoutContext } from './timeout';\nimport {\n  isTransactionCommand,\n  Transaction,\n  type TransactionOptions,\n  TxnState\n} from './transactions';\nimport {\n  ByteUtils,\n  calculateDurationInMs,\n  commandSupportsReadConcern,\n  isPromiseLike,\n  List,\n  maxWireVersion,\n  noop,\n  now,\n  squashError,\n  uuidV4\n} from './utils';\nimport { WriteConcern, type WriteConcernOptions, type WriteConcernSettings } from './write_concern';\n\nconst minWireVersionForShardedTransactions = 8;\n\n/** @public */\nexport interface ClientSessionOptions {\n  /** Whether causal consistency should be enabled on this session */\n  causalConsistency?: boolean;\n  /** Whether all read operations should be read from the same snapshot for this session (NOTE: not compatible with `causalConsistency=true`) */\n  snapshot?: boolean;\n  /** The default TransactionOptions to use for transactions started on this session. */\n  defaultTransactionOptions?: TransactionOptions;\n  /**\n   * @public\n   * @experimental\n   * An overriding timeoutMS value to use for a client-side timeout.\n   * If not provided the session uses the timeoutMS specified on the MongoClient.\n   */\n  defaultTimeoutMS?: number;\n\n  /** @internal */\n  owner?: symbol | AbstractCursor;\n  /** @internal */\n  explicit?: boolean;\n  /** @internal */\n  initialClusterTime?: ClusterTime;\n}\n\n/** @public */\nexport type WithTransactionCallback<T = any> = (session: ClientSession) => Promise<T>;\n\n/** @public */\nexport type ClientSessionEvents = {\n  ended(session: ClientSession): void;\n};\n\n/** @public */\nexport interface EndSessionOptions {\n  /**\n   * An optional error which caused the call to end this session\n   * @internal\n   */\n  error?: AnyError;\n  force?: boolean;\n  forceClear?: boolean;\n\n  /** Specifies the time an operation will run until it throws a timeout error */\n  timeoutMS?: number;\n}\n\n/**\n * A class representing a client session on the server\n *\n * NOTE: not meant to be instantiated directly.\n * @public\n */\nexport class ClientSession\n  extends TypedEventEmitter<ClientSessionEvents>\n  implements AsyncDisposable\n{\n  /** @internal */\n  client: MongoClient;\n  /** @internal */\n  sessionPool: ServerSessionPool;\n  hasEnded: boolean;\n  clientOptions: MongoOptions;\n  supports: { causalConsistency: boolean };\n  clusterTime?: ClusterTime;\n  operationTime?: Timestamp;\n  explicit: boolean;\n  /** @internal */\n  owner?: symbol | AbstractCursor;\n  defaultTransactionOptions: TransactionOptions;\n  transaction: Transaction;\n  /**\n   * @internal\n   * Keeps track of whether or not the current transaction has attempted to be committed. Is\n   * initially undefined. Gets set to false when startTransaction is called. When commitTransaction is sent to server, if the commitTransaction succeeds, it is then set to undefined, otherwise, set to true\n   */\n  private commitAttempted?: boolean;\n  public readonly snapshotEnabled: boolean;\n\n  /** @internal */\n  private _serverSession: ServerSession | null;\n  /** @internal */\n  public snapshotTime?: Timestamp;\n  /** @internal */\n  public pinnedConnection?: Connection;\n  /** @internal */\n  public txnNumberIncrement: number;\n  /**\n   * @experimental\n   * Specifies the time an operation in a given `ClientSession` will run until it throws a timeout error\n   */\n  timeoutMS?: number;\n\n  /** @internal */\n  public timeoutContext: TimeoutContext | null = null;\n\n  /**\n   * Create a client session.\n   * @internal\n   * @param client - The current client\n   * @param sessionPool - The server session pool (Internal Class)\n   * @param options - Optional settings\n   * @param clientOptions - Optional settings provided when creating a MongoClient\n   */\n  constructor(\n    client: MongoClient,\n    sessionPool: ServerSessionPool,\n    options: ClientSessionOptions,\n    clientOptions: MongoOptions\n  ) {\n    super();\n    this.on('error', noop);\n\n    if (client == null) {\n      // TODO(NODE-3483)\n      throw new MongoRuntimeError('ClientSession requires a MongoClient');\n    }\n\n    if (sessionPool == null || !(sessionPool instanceof ServerSessionPool)) {\n      // TODO(NODE-3483)\n      throw new MongoRuntimeError('ClientSession requires a ServerSessionPool');\n    }\n\n    options = options ?? {};\n\n    this.snapshotEnabled = options.snapshot === true;\n    if (options.causalConsistency === true && this.snapshotEnabled) {\n      throw new MongoInvalidArgumentError(\n        'Properties \"causalConsistency\" and \"snapshot\" are mutually exclusive'\n      );\n    }\n\n    this.client = client;\n    this.sessionPool = sessionPool;\n    this.hasEnded = false;\n    this.clientOptions = clientOptions;\n    this.timeoutMS = options.defaultTimeoutMS ?? client.s.options?.timeoutMS;\n\n    this.explicit = !!options.explicit;\n    this._serverSession = this.explicit ? this.sessionPool.acquire() : null;\n    this.txnNumberIncrement = 0;\n\n    const defaultCausalConsistencyValue = this.explicit && options.snapshot !== true;\n    this.supports = {\n      // if we can enable causal consistency, do so by default\n      causalConsistency: options.causalConsistency ?? defaultCausalConsistencyValue\n    };\n\n    this.clusterTime = options.initialClusterTime;\n\n    this.operationTime = undefined;\n    this.owner = options.owner;\n    this.defaultTransactionOptions = { ...options.defaultTransactionOptions };\n    this.transaction = new Transaction();\n  }\n\n  /** The server id associated with this session */\n  get id(): ServerSessionId | undefined {\n    return this.serverSession?.id;\n  }\n\n  get serverSession(): ServerSession {\n    let serverSession = this._serverSession;\n    if (serverSession == null) {\n      if (this.explicit) {\n        throw new MongoRuntimeError('Unexpected null serverSession for an explicit session');\n      }\n      if (this.hasEnded) {\n        throw new MongoRuntimeError('Unexpected null serverSession for an ended implicit session');\n      }\n      serverSession = this.sessionPool.acquire();\n      this._serverSession = serverSession;\n    }\n    return serverSession;\n  }\n\n  get loadBalanced(): boolean {\n    return this.client.topology?.description.type === TopologyType.LoadBalanced;\n  }\n\n  /** @internal */\n  pin(conn: Connection): void {\n    if (this.pinnedConnection) {\n      throw TypeError('Cannot pin multiple connections to the same session');\n    }\n\n    this.pinnedConnection = conn;\n    conn.emit(\n      PINNED,\n      this.inTransaction() ? ConnectionPoolMetrics.TXN : ConnectionPoolMetrics.CURSOR\n    );\n  }\n\n  /** @internal */\n  unpin(options?: { force?: boolean; forceClear?: boolean; error?: AnyError }): void {\n    if (this.loadBalanced) {\n      return maybeClearPinnedConnection(this, options);\n    }\n\n    this.transaction.unpinServer();\n  }\n\n  get isPinned(): boolean {\n    return this.loadBalanced ? !!this.pinnedConnection : this.transaction.isPinned;\n  }\n\n  /**\n   * Frees any client-side resources held by the current session.  If a session is in a transaction,\n   * the transaction is aborted.\n   *\n   * Does not end the session on the server.\n   *\n   * @param options - Optional settings. Currently reserved for future use\n   */\n  async endSession(options?: EndSessionOptions): Promise<void> {\n    try {\n      if (this.inTransaction()) {\n        await this.abortTransaction({ ...options, throwTimeout: true });\n      }\n    } catch (error) {\n      // spec indicates that we should ignore all errors for `endSessions`\n      if (error.name === 'MongoOperationTimeoutError') throw error;\n      squashError(error);\n    } finally {\n      if (!this.hasEnded) {\n        const serverSession = this.serverSession;\n        if (serverSession != null) {\n          // release the server session back to the pool\n          this.sessionPool.release(serverSession);\n          // Store a clone of the server session for reference (debugging)\n          this._serverSession = new ServerSession(serverSession);\n        }\n        // mark the session as ended, and emit a signal\n        this.hasEnded = true;\n        this.emit('ended', this);\n      }\n      maybeClearPinnedConnection(this, { force: true, ...options });\n    }\n  }\n  /**\n   * @beta\n   * @experimental\n   * An alias for {@link ClientSession.endSession|ClientSession.endSession()}.\n   */\n  declare [Symbol.asyncDispose]: () => Promise<void>;\n  /** @internal */\n  async asyncDispose() {\n    await this.endSession({ force: true });\n  }\n\n  /**\n   * Advances the operationTime for a ClientSession.\n   *\n   * @param operationTime - the `BSON.Timestamp` of the operation type it is desired to advance to\n   */\n  advanceOperationTime(operationTime: Timestamp): void {\n    if (this.operationTime == null) {\n      this.operationTime = operationTime;\n      return;\n    }\n\n    if (operationTime.greaterThan(this.operationTime)) {\n      this.operationTime = operationTime;\n    }\n  }\n\n  /**\n   * Advances the clusterTime for a ClientSession to the provided clusterTime of another ClientSession\n   *\n   * @param clusterTime - the $clusterTime returned by the server from another session in the form of a document containing the `BSON.Timestamp` clusterTime and signature\n   */\n  advanceClusterTime(clusterTime: ClusterTime): void {\n    if (!clusterTime || typeof clusterTime !== 'object') {\n      throw new MongoInvalidArgumentError('input cluster time must be an object');\n    }\n    if (!clusterTime.clusterTime || clusterTime.clusterTime._bsontype !== 'Timestamp') {\n      throw new MongoInvalidArgumentError(\n        'input cluster time \"clusterTime\" property must be a valid BSON Timestamp'\n      );\n    }\n    if (\n      !clusterTime.signature ||\n      clusterTime.signature.hash?._bsontype !== 'Binary' ||\n      (typeof clusterTime.signature.keyId !== 'bigint' &&\n        typeof clusterTime.signature.keyId !== 'number' &&\n        clusterTime.signature.keyId?._bsontype !== 'Long') // apparently we decode the key to number?\n    ) {\n      throw new MongoInvalidArgumentError(\n        'input cluster time must have a valid \"signature\" property with BSON Binary hash and BSON Long keyId'\n      );\n    }\n\n    _advanceClusterTime(this, clusterTime);\n  }\n\n  /**\n   * Used to determine if this session equals another\n   *\n   * @param session - The session to compare to\n   */\n  equals(session: ClientSession): boolean {\n    if (!(session instanceof ClientSession)) {\n      return false;\n    }\n\n    if (this.id == null || session.id == null) {\n      return false;\n    }\n\n    return ByteUtils.equals(this.id.id.buffer, session.id.id.buffer);\n  }\n\n  /**\n   * Increment the transaction number on the internal ServerSession\n   *\n   * @privateRemarks\n   * This helper increments a value stored on the client session that will be\n   * added to the serverSession's txnNumber upon applying it to a command.\n   * This is because the serverSession is lazily acquired after a connection is obtained\n   */\n  incrementTransactionNumber(): void {\n    this.txnNumberIncrement += 1;\n  }\n\n  /** @returns whether this session is currently in a transaction or not */\n  inTransaction(): boolean {\n    return this.transaction.isActive;\n  }\n\n  /**\n   * Starts a new transaction with the given options.\n   *\n   * @remarks\n   * **IMPORTANT**: Running operations in parallel is not supported during a transaction. The use of `Promise.all`,\n   * `Promise.allSettled`, `Promise.race`, etc to parallelize operations inside a transaction is\n   * undefined behaviour.\n   *\n   * @param options - Options for the transaction\n   */\n  startTransaction(options?: TransactionOptions): void {\n    if (this.snapshotEnabled) {\n      throw new MongoCompatibilityError('Transactions are not supported in snapshot sessions');\n    }\n\n    if (this.inTransaction()) {\n      throw new MongoTransactionError('Transaction already in progress');\n    }\n\n    if (this.isPinned && this.transaction.isCommitted) {\n      this.unpin();\n    }\n\n    const topologyMaxWireVersion = maxWireVersion(this.client.topology);\n    if (\n      isSharded(this.client.topology) &&\n      topologyMaxWireVersion != null &&\n      topologyMaxWireVersion < minWireVersionForShardedTransactions\n    ) {\n      throw new MongoCompatibilityError(\n        'Transactions are not supported on sharded clusters in MongoDB < 4.2.'\n      );\n    }\n\n    this.commitAttempted = false;\n    // increment txnNumber\n    this.incrementTransactionNumber();\n    // create transaction state\n    this.transaction = new Transaction({\n      readConcern:\n        options?.readConcern ??\n        this.defaultTransactionOptions.readConcern ??\n        this.clientOptions?.readConcern,\n      writeConcern:\n        options?.writeConcern ??\n        this.defaultTransactionOptions.writeConcern ??\n        this.clientOptions?.writeConcern,\n      readPreference:\n        options?.readPreference ??\n        this.defaultTransactionOptions.readPreference ??\n        this.clientOptions?.readPreference,\n      maxCommitTimeMS: options?.maxCommitTimeMS ?? this.defaultTransactionOptions.maxCommitTimeMS\n    });\n\n    this.transaction.transition(TxnState.STARTING_TRANSACTION);\n  }\n\n  /**\n   * Commits the currently active transaction in this session.\n   *\n   * @param options - Optional options, can be used to override `defaultTimeoutMS`.\n   */\n  async commitTransaction(options?: { timeoutMS?: number }): Promise<void> {\n    if (this.transaction.state === TxnState.NO_TRANSACTION) {\n      throw new MongoTransactionError('No transaction started');\n    }\n\n    if (\n      this.transaction.state === TxnState.STARTING_TRANSACTION ||\n      this.transaction.state === TxnState.TRANSACTION_COMMITTED_EMPTY\n    ) {\n      // the transaction was never started, we can safely exit here\n      this.transaction.transition(TxnState.TRANSACTION_COMMITTED_EMPTY);\n      return;\n    }\n\n    if (this.transaction.state === TxnState.TRANSACTION_ABORTED) {\n      throw new MongoTransactionError(\n        'Cannot call commitTransaction after calling abortTransaction'\n      );\n    }\n\n    const command: {\n      commitTransaction: 1;\n      writeConcern?: WriteConcernSettings;\n      recoveryToken?: Document;\n      maxTimeMS?: number;\n    } = { commitTransaction: 1 };\n\n    const timeoutMS =\n      typeof options?.timeoutMS === 'number'\n        ? options.timeoutMS\n        : typeof this.timeoutMS === 'number'\n          ? this.timeoutMS\n          : null;\n\n    const wc = this.transaction.options.writeConcern ?? this.clientOptions?.writeConcern;\n    if (wc != null) {\n      if (timeoutMS == null && this.timeoutContext == null) {\n        WriteConcern.apply(command, { wtimeoutMS: 10000, w: 'majority', ...wc });\n      } else {\n        const wcKeys = Object.keys(wc);\n        if (wcKeys.length > 2 || (!wcKeys.includes('wtimeoutMS') && !wcKeys.includes('wTimeoutMS')))\n          // if the write concern was specified with wTimeoutMS, then we set both wtimeoutMS and wTimeoutMS, guaranteeing at least two keys, so if we have more than two keys, then we can automatically assume that we should add the write concern to the command. If it has 2 or fewer keys, we need to check that those keys aren't the wtimeoutMS or wTimeoutMS options before we add the write concern to the command\n          WriteConcern.apply(command, { ...wc, wtimeoutMS: undefined });\n      }\n    }\n\n    if (this.transaction.state === TxnState.TRANSACTION_COMMITTED || this.commitAttempted) {\n      if (timeoutMS == null && this.timeoutContext == null) {\n        WriteConcern.apply(command, { wtimeoutMS: 10000, ...wc, w: 'majority' });\n      } else {\n        WriteConcern.apply(command, { w: 'majority', ...wc, wtimeoutMS: undefined });\n      }\n    }\n\n    if (typeof this.transaction.options.maxTimeMS === 'number') {\n      command.maxTimeMS = this.transaction.options.maxTimeMS;\n    }\n\n    if (this.transaction.recoveryToken) {\n      command.recoveryToken = this.transaction.recoveryToken;\n    }\n\n    const operation = new RunAdminCommandOperation(command, {\n      session: this,\n      readPreference: ReadPreference.primary,\n      bypassPinningCheck: true\n    });\n\n    const timeoutContext =\n      this.timeoutContext ??\n      (typeof timeoutMS === 'number'\n        ? TimeoutContext.create({\n            serverSelectionTimeoutMS: this.clientOptions.serverSelectionTimeoutMS,\n            socketTimeoutMS: this.clientOptions.socketTimeoutMS,\n            timeoutMS\n          })\n        : null);\n\n    try {\n      await executeOperation(this.client, operation, timeoutContext);\n      this.commitAttempted = undefined;\n      return;\n    } catch (firstCommitError) {\n      this.commitAttempted = true;\n      if (firstCommitError instanceof MongoError && isRetryableWriteError(firstCommitError)) {\n        // SPEC-1185: apply majority write concern when retrying commitTransaction\n        WriteConcern.apply(command, { wtimeoutMS: 10000, ...wc, w: 'majority' });\n        // per txns spec, must unpin session in this case\n        this.unpin({ force: true });\n\n        try {\n          await executeOperation(\n            this.client,\n            new RunAdminCommandOperation(command, {\n              session: this,\n              readPreference: ReadPreference.primary,\n              bypassPinningCheck: true\n            }),\n            timeoutContext\n          );\n          return;\n        } catch (retryCommitError) {\n          // If the retry failed, we process that error instead of the original\n          if (shouldAddUnknownTransactionCommitResultLabel(retryCommitError)) {\n            retryCommitError.addErrorLabel(MongoErrorLabel.UnknownTransactionCommitResult);\n          }\n\n          if (shouldUnpinAfterCommitError(retryCommitError)) {\n            this.unpin({ error: retryCommitError });\n          }\n\n          throw retryCommitError;\n        }\n      }\n\n      if (shouldAddUnknownTransactionCommitResultLabel(firstCommitError)) {\n        firstCommitError.addErrorLabel(MongoErrorLabel.UnknownTransactionCommitResult);\n      }\n\n      if (shouldUnpinAfterCommitError(firstCommitError)) {\n        this.unpin({ error: firstCommitError });\n      }\n\n      throw firstCommitError;\n    } finally {\n      this.transaction.transition(TxnState.TRANSACTION_COMMITTED);\n    }\n  }\n\n  /**\n   * Aborts the currently active transaction in this session.\n   *\n   * @param options - Optional options, can be used to override `defaultTimeoutMS`.\n   */\n  async abortTransaction(options?: { timeoutMS?: number }): Promise<void>;\n  /** @internal */\n  async abortTransaction(options?: { timeoutMS?: number; throwTimeout?: true }): Promise<void>;\n  async abortTransaction(options?: { timeoutMS?: number; throwTimeout?: true }): Promise<void> {\n    if (this.transaction.state === TxnState.NO_TRANSACTION) {\n      throw new MongoTransactionError('No transaction started');\n    }\n\n    if (this.transaction.state === TxnState.STARTING_TRANSACTION) {\n      // the transaction was never started, we can safely exit here\n      this.transaction.transition(TxnState.TRANSACTION_ABORTED);\n      return;\n    }\n\n    if (this.transaction.state === TxnState.TRANSACTION_ABORTED) {\n      throw new MongoTransactionError('Cannot call abortTransaction twice');\n    }\n\n    if (\n      this.transaction.state === TxnState.TRANSACTION_COMMITTED ||\n      this.transaction.state === TxnState.TRANSACTION_COMMITTED_EMPTY\n    ) {\n      throw new MongoTransactionError(\n        'Cannot call abortTransaction after calling commitTransaction'\n      );\n    }\n\n    const command: {\n      abortTransaction: 1;\n      writeConcern?: WriteConcernOptions;\n      recoveryToken?: Document;\n    } = { abortTransaction: 1 };\n\n    const timeoutMS =\n      typeof options?.timeoutMS === 'number'\n        ? options.timeoutMS\n        : this.timeoutContext?.csotEnabled()\n          ? this.timeoutContext.timeoutMS // refresh timeoutMS for abort operation\n          : typeof this.timeoutMS === 'number'\n            ? this.timeoutMS\n            : null;\n\n    const timeoutContext =\n      timeoutMS != null\n        ? TimeoutContext.create({\n            timeoutMS,\n            serverSelectionTimeoutMS: this.clientOptions.serverSelectionTimeoutMS,\n            socketTimeoutMS: this.clientOptions.socketTimeoutMS\n          })\n        : null;\n\n    const wc = this.transaction.options.writeConcern ?? this.clientOptions?.writeConcern;\n    if (wc != null && timeoutMS == null) {\n      WriteConcern.apply(command, { wtimeoutMS: 10000, w: 'majority', ...wc });\n    }\n\n    if (this.transaction.recoveryToken) {\n      command.recoveryToken = this.transaction.recoveryToken;\n    }\n\n    const operation = new RunAdminCommandOperation(command, {\n      session: this,\n      readPreference: ReadPreference.primary,\n      bypassPinningCheck: true\n    });\n\n    try {\n      await executeOperation(this.client, operation, timeoutContext);\n      this.unpin();\n      return;\n    } catch (firstAbortError) {\n      this.unpin();\n\n      if (firstAbortError.name === 'MongoRuntimeError') throw firstAbortError;\n      if (options?.throwTimeout && firstAbortError.name === 'MongoOperationTimeoutError') {\n        throw firstAbortError;\n      }\n\n      if (firstAbortError instanceof MongoError && isRetryableWriteError(firstAbortError)) {\n        try {\n          await executeOperation(this.client, operation, timeoutContext);\n          return;\n        } catch (secondAbortError) {\n          if (secondAbortError.name === 'MongoRuntimeError') throw secondAbortError;\n          if (options?.throwTimeout && secondAbortError.name === 'MongoOperationTimeoutError') {\n            throw secondAbortError;\n          }\n          // we do not retry the retry\n        }\n      }\n\n      // The spec indicates that if the operation times out or fails with a non-retryable error, we should ignore all errors on `abortTransaction`\n    } finally {\n      this.transaction.transition(TxnState.TRANSACTION_ABORTED);\n      if (this.loadBalanced) {\n        maybeClearPinnedConnection(this, { force: false });\n      }\n    }\n  }\n\n  /**\n   * This is here to ensure that ClientSession is never serialized to BSON.\n   */\n  toBSON(): never {\n    throw new MongoRuntimeError('ClientSession cannot be serialized to BSON.');\n  }\n\n  /**\n   * Starts a transaction and runs a provided function, ensuring the commitTransaction is always attempted when all operations run in the function have completed.\n   *\n   * **IMPORTANT:** This method requires the function passed in to return a Promise. That promise must be made by `await`-ing all operations in such a way that rejections are propagated to the returned promise.\n   *\n   * **IMPORTANT:** Running operations in parallel is not supported during a transaction. The use of `Promise.all`,\n   * `Promise.allSettled`, `Promise.race`, etc to parallelize operations inside a transaction is\n   * undefined behaviour.\n   *\n   * **IMPORTANT:** When running an operation inside a `withTransaction` callback, if it is not\n   * provided the explicit session in its options, it will not be part of the transaction and it will not respect timeoutMS.\n   *\n   *\n   * @remarks\n   * - If all operations successfully complete and the `commitTransaction` operation is successful, then the provided function will return the result of the provided function.\n   * - If the transaction is unable to complete or an error is thrown from within the provided function, then the provided function will throw an error.\n   *   - If the transaction is manually aborted within the provided function it will not throw.\n   * - If the driver needs to attempt to retry the operations, the provided function may be called multiple times.\n   *\n   * Checkout a descriptive example here:\n   * @see https://www.mongodb.com/blog/post/quick-start-nodejs--mongodb--how-to-implement-transactions\n   *\n   * If a command inside withTransaction fails:\n   * - It may cause the transaction on the server to be aborted.\n   * - This situation is normally handled transparently by the driver.\n   * - However, if the application catches such an error and does not rethrow it, the driver will not be able to determine whether the transaction was aborted or not.\n   * - The driver will then retry the transaction indefinitely.\n   *\n   * To avoid this situation, the application must not silently handle errors within the provided function.\n   * If the application needs to handle errors within, it must await all operations such that if an operation is rejected it becomes the rejection of the callback function passed into withTransaction.\n   *\n   * @param fn - callback to run within a transaction\n   * @param options - optional settings for the transaction\n   * @returns A raw command response or undefined\n   */\n  async withTransaction<T = any>(\n    fn: WithTransactionCallback<T>,\n    options?: TransactionOptions & {\n      /**\n       * Configures a timeoutMS expiry for the entire withTransactionCallback.\n       *\n       * @remarks\n       * - The remaining timeout will not be applied to callback operations that do not use the ClientSession.\n       * - Overriding timeoutMS for operations executed using the explicit session inside the provided callback will result in a client-side error.\n       */\n      timeoutMS?: number;\n    }\n  ): Promise<T> {\n    const MAX_TIMEOUT = 120000;\n\n    const timeoutMS = options?.timeoutMS ?? this.timeoutMS ?? null;\n    this.timeoutContext =\n      timeoutMS != null\n        ? TimeoutContext.create({\n            timeoutMS,\n            serverSelectionTimeoutMS: this.clientOptions.serverSelectionTimeoutMS,\n            socketTimeoutMS: this.clientOptions.socketTimeoutMS\n          })\n        : null;\n\n    const startTime = this.timeoutContext?.csotEnabled() ? this.timeoutContext.start : now();\n\n    let committed = false;\n    let result: any;\n\n    try {\n      while (!committed) {\n        this.startTransaction(options); // may throw on error\n\n        try {\n          const promise = fn(this);\n          if (!isPromiseLike(promise)) {\n            throw new MongoInvalidArgumentError(\n              'Function provided to `withTransaction` must return a Promise'\n            );\n          }\n\n          result = await promise;\n\n          if (\n            this.transaction.state === TxnState.NO_TRANSACTION ||\n            this.transaction.state === TxnState.TRANSACTION_COMMITTED ||\n            this.transaction.state === TxnState.TRANSACTION_ABORTED\n          ) {\n            // Assume callback intentionally ended the transaction\n            return result;\n          }\n        } catch (fnError) {\n          if (!(fnError instanceof MongoError) || fnError instanceof MongoInvalidArgumentError) {\n            await this.abortTransaction();\n            throw fnError;\n          }\n\n          if (\n            this.transaction.state === TxnState.STARTING_TRANSACTION ||\n            this.transaction.state === TxnState.TRANSACTION_IN_PROGRESS\n          ) {\n            await this.abortTransaction();\n          }\n\n          if (\n            fnError.hasErrorLabel(MongoErrorLabel.TransientTransactionError) &&\n            (this.timeoutContext != null || now() - startTime < MAX_TIMEOUT)\n          ) {\n            continue;\n          }\n\n          throw fnError;\n        }\n\n        while (!committed) {\n          try {\n            /*\n             * We will rely on ClientSession.commitTransaction() to\n             * apply a majority write concern if commitTransaction is\n             * being retried (see: DRIVERS-601)\n             */\n            await this.commitTransaction();\n            committed = true;\n          } catch (commitError) {\n            /*\n             * Note: a maxTimeMS error will have the MaxTimeMSExpired\n             * code (50) and can be reported as a top-level error or\n             * inside writeConcernError, ex.\n             * { ok:0, code: 50, codeName: 'MaxTimeMSExpired' }\n             * { ok:1, writeConcernError: { code: 50, codeName: 'MaxTimeMSExpired' } }\n             */\n            if (\n              !isMaxTimeMSExpiredError(commitError) &&\n              commitError.hasErrorLabel(MongoErrorLabel.UnknownTransactionCommitResult) &&\n              (this.timeoutContext != null || now() - startTime < MAX_TIMEOUT)\n            ) {\n              continue;\n            }\n\n            if (\n              commitError.hasErrorLabel(MongoErrorLabel.TransientTransactionError) &&\n              (this.timeoutContext != null || now() - startTime < MAX_TIMEOUT)\n            ) {\n              break;\n            }\n\n            throw commitError;\n          }\n        }\n      }\n      return result;\n    } finally {\n      this.timeoutContext = null;\n    }\n  }\n}\n\nconfigureResourceManagement(ClientSession.prototype);\n\nconst NON_DETERMINISTIC_WRITE_CONCERN_ERRORS = new Set([\n  'CannotSatisfyWriteConcern',\n  'UnknownReplWriteConcern',\n  'UnsatisfiableWriteConcern'\n]);\n\nfunction shouldUnpinAfterCommitError(commitError: Error) {\n  if (commitError instanceof MongoError) {\n    if (\n      isRetryableWriteError(commitError) ||\n      commitError instanceof MongoWriteConcernError ||\n      isMaxTimeMSExpiredError(commitError)\n    ) {\n      if (isUnknownTransactionCommitResult(commitError)) {\n        // per txns spec, must unpin session in this case\n        return true;\n      }\n    } else if (commitError.hasErrorLabel(MongoErrorLabel.TransientTransactionError)) {\n      return true;\n    }\n  }\n  return false;\n}\n\nfunction shouldAddUnknownTransactionCommitResultLabel(commitError: MongoError) {\n  let ok = isRetryableWriteError(commitError);\n  ok ||= commitError instanceof MongoWriteConcernError;\n  ok ||= isMaxTimeMSExpiredError(commitError);\n  ok &&= isUnknownTransactionCommitResult(commitError);\n  return ok;\n}\n\nfunction isUnknownTransactionCommitResult(err: MongoError): err is MongoError {\n  const isNonDeterministicWriteConcernError =\n    err instanceof MongoServerError &&\n    err.codeName &&\n    NON_DETERMINISTIC_WRITE_CONCERN_ERRORS.has(err.codeName);\n\n  return (\n    isMaxTimeMSExpiredError(err) ||\n    (!isNonDeterministicWriteConcernError &&\n      err.code !== MONGODB_ERROR_CODES.UnsatisfiableWriteConcern &&\n      err.code !== MONGODB_ERROR_CODES.UnknownReplWriteConcern)\n  );\n}\n\nexport function maybeClearPinnedConnection(\n  session: ClientSession,\n  options?: EndSessionOptions\n): void {\n  // unpin a connection if it has been pinned\n  const conn = session.pinnedConnection;\n  const error = options?.error;\n\n  if (\n    session.inTransaction() &&\n    error &&\n    error instanceof MongoError &&\n    error.hasErrorLabel(MongoErrorLabel.TransientTransactionError)\n  ) {\n    return;\n  }\n\n  const topology = session.client.topology;\n  // NOTE: the spec talks about what to do on a network error only, but the tests seem to\n  //       to validate that we don't unpin on _all_ errors?\n  if (conn && topology != null) {\n    const servers = Array.from(topology.s.servers.values());\n    const loadBalancer = servers[0];\n\n    if (options?.error == null || options?.force) {\n      loadBalancer.pool.checkIn(conn);\n      session.pinnedConnection = undefined;\n      conn.emit(\n        UNPINNED,\n        session.transaction.state !== TxnState.NO_TRANSACTION\n          ? ConnectionPoolMetrics.TXN\n          : ConnectionPoolMetrics.CURSOR\n      );\n\n      if (options?.forceClear) {\n        loadBalancer.pool.clear({ serviceId: conn.serviceId });\n      }\n    }\n  }\n}\n\nfunction isMaxTimeMSExpiredError(err: MongoError): boolean {\n  if (err == null || !(err instanceof MongoServerError)) {\n    return false;\n  }\n\n  return (\n    err.code === MONGODB_ERROR_CODES.MaxTimeMSExpired ||\n    err.writeConcernError?.code === MONGODB_ERROR_CODES.MaxTimeMSExpired\n  );\n}\n\n/** @public */\nexport type ServerSessionId = { id: Binary };\n\n/**\n * Reflects the existence of a session on the server. Can be reused by the session pool.\n * WARNING: not meant to be instantiated directly. For internal use only.\n * @public\n */\nexport class ServerSession {\n  id: ServerSessionId;\n  lastUse: number;\n  txnNumber: number;\n  isDirty: boolean;\n\n  /** @internal */\n  constructor(cloned?: ServerSession | null) {\n    if (cloned != null) {\n      const idBytes = Buffer.allocUnsafe(16);\n      idBytes.set(cloned.id.id.buffer);\n      this.id = { id: new Binary(idBytes, cloned.id.id.sub_type) };\n      this.lastUse = cloned.lastUse;\n      this.txnNumber = cloned.txnNumber;\n      this.isDirty = cloned.isDirty;\n      return;\n    }\n    this.id = { id: new Binary(uuidV4(), Binary.SUBTYPE_UUID) };\n    this.lastUse = now();\n    this.txnNumber = 0;\n    this.isDirty = false;\n  }\n\n  /**\n   * Determines if the server session has timed out.\n   *\n   * @param sessionTimeoutMinutes - The server's \"logicalSessionTimeoutMinutes\"\n   */\n  hasTimedOut(sessionTimeoutMinutes: number): boolean {\n    // Take the difference of the lastUse timestamp and now, which will result in a value in\n    // milliseconds, and then convert milliseconds to minutes to compare to `sessionTimeoutMinutes`\n    const idleTimeMinutes = Math.round(\n      ((calculateDurationInMs(this.lastUse) % 86400000) % 3600000) / 60000\n    );\n\n    return idleTimeMinutes > sessionTimeoutMinutes - 1;\n  }\n}\n\n/**\n * Maintains a pool of Server Sessions.\n * For internal use only\n * @internal\n */\nexport class ServerSessionPool {\n  client: MongoClient;\n  sessions: List<ServerSession>;\n\n  constructor(client: MongoClient) {\n    if (client == null) {\n      throw new MongoRuntimeError('ServerSessionPool requires a MongoClient');\n    }\n\n    this.client = client;\n    this.sessions = new List<ServerSession>();\n  }\n\n  /**\n   * Acquire a Server Session from the pool.\n   * Iterates through each session in the pool, removing any stale sessions\n   * along the way. The first non-stale session found is removed from the\n   * pool and returned. If no non-stale session is found, a new ServerSession is created.\n   */\n  acquire(): ServerSession {\n    const sessionTimeoutMinutes = this.client.topology?.logicalSessionTimeoutMinutes ?? 10;\n\n    let session: ServerSession | null = null;\n\n    // Try to obtain from session pool\n    while (this.sessions.length > 0) {\n      const potentialSession = this.sessions.shift();\n      if (\n        potentialSession != null &&\n        (!!this.client.topology?.loadBalanced ||\n          !potentialSession.hasTimedOut(sessionTimeoutMinutes))\n      ) {\n        session = potentialSession;\n        break;\n      }\n    }\n\n    // If nothing valid came from the pool make a new one\n    if (session == null) {\n      session = new ServerSession();\n    }\n\n    return session;\n  }\n\n  /**\n   * Release a session to the session pool\n   * Adds the session back to the session pool if the session has not timed out yet.\n   * This method also removes any stale sessions from the pool.\n   *\n   * @param session - The session to release to the pool\n   */\n  release(session: ServerSession): void {\n    const sessionTimeoutMinutes = this.client.topology?.logicalSessionTimeoutMinutes ?? 10;\n\n    if (this.client.topology?.loadBalanced && !sessionTimeoutMinutes) {\n      this.sessions.unshift(session);\n    }\n\n    if (!sessionTimeoutMinutes) {\n      return;\n    }\n\n    this.sessions.prune(session => session.hasTimedOut(sessionTimeoutMinutes));\n\n    if (!session.hasTimedOut(sessionTimeoutMinutes)) {\n      if (session.isDirty) {\n        return;\n      }\n\n      // otherwise, readd this session to the session pool\n      this.sessions.unshift(session);\n    }\n  }\n}\n\n/**\n * Optionally decorate a command with sessions specific keys\n *\n * @param session - the session tracking transaction state\n * @param command - the command to decorate\n * @param options - Optional settings passed to calling operation\n *\n * @internal\n */\nexport function applySession(\n  session: ClientSession,\n  command: Document,\n  options: CommandOptions\n): MongoDriverError | undefined {\n  if (session.hasEnded) {\n    return new MongoExpiredSessionError();\n  }\n\n  // May acquire serverSession here\n  const serverSession = session.serverSession;\n  if (serverSession == null) {\n    return new MongoRuntimeError('Unable to acquire server session');\n  }\n\n  if (options.writeConcern?.w === 0) {\n    if (session && session.explicit) {\n      // Error if user provided an explicit session to an unacknowledged write (SPEC-1019)\n      return new MongoAPIError('Cannot have explicit session with unacknowledged writes');\n    }\n    return;\n  }\n\n  // mark the last use of this session, and apply the `lsid`\n  serverSession.lastUse = now();\n  command.lsid = serverSession.id;\n\n  const inTxnOrTxnCommand = session.inTransaction() || isTransactionCommand(command);\n  const isRetryableWrite = !!options.willRetryWrite;\n\n  if (isRetryableWrite || inTxnOrTxnCommand) {\n    serverSession.txnNumber += session.txnNumberIncrement;\n    session.txnNumberIncrement = 0;\n    // TODO(NODE-2674): Preserve int64 sent from MongoDB\n    command.txnNumber = Long.fromNumber(serverSession.txnNumber);\n  }\n\n  if (!inTxnOrTxnCommand) {\n    if (session.transaction.state !== TxnState.NO_TRANSACTION) {\n      session.transaction.transition(TxnState.NO_TRANSACTION);\n    }\n\n    if (\n      session.supports.causalConsistency &&\n      session.operationTime &&\n      commandSupportsReadConcern(command)\n    ) {\n      command.readConcern = command.readConcern || {};\n      Object.assign(command.readConcern, { afterClusterTime: session.operationTime });\n    } else if (session.snapshotEnabled) {\n      command.readConcern = command.readConcern || { level: ReadConcernLevel.snapshot };\n      if (session.snapshotTime != null) {\n        Object.assign(command.readConcern, { atClusterTime: session.snapshotTime });\n      }\n    }\n\n    return;\n  }\n\n  // now attempt to apply transaction-specific sessions data\n\n  // `autocommit` must always be false to differentiate from retryable writes\n  command.autocommit = false;\n\n  if (session.transaction.state === TxnState.STARTING_TRANSACTION) {\n    session.transaction.transition(TxnState.TRANSACTION_IN_PROGRESS);\n    command.startTransaction = true;\n\n    const readConcern =\n      session.transaction.options.readConcern || session?.clientOptions?.readConcern;\n    if (readConcern) {\n      command.readConcern = readConcern;\n    }\n\n    if (session.supports.causalConsistency && session.operationTime) {\n      command.readConcern = command.readConcern || {};\n      Object.assign(command.readConcern, { afterClusterTime: session.operationTime });\n    }\n  }\n  return;\n}\n\nexport function updateSessionFromResponse(session: ClientSession, document: MongoDBResponse): void {\n  if (document.$clusterTime) {\n    _advanceClusterTime(session, document.$clusterTime);\n  }\n\n  if (document.operationTime && session && session.supports.causalConsistency) {\n    session.advanceOperationTime(document.operationTime);\n  }\n\n  if (document.recoveryToken && session && session.inTransaction()) {\n    session.transaction._recoveryToken = document.recoveryToken;\n  }\n\n  if (session?.snapshotEnabled && session.snapshotTime == null) {\n    // find and aggregate commands return atClusterTime on the cursor\n    // distinct includes it in the response body\n    const atClusterTime = document.atClusterTime;\n    if (atClusterTime) {\n      session.snapshotTime = atClusterTime;\n    }\n  }\n}\n"],"names":[],"mappings":";;;;;AAs3BA,QAAA,0BAAA,GAAA;AA6LA,QAAA,YAAA,GAAA;AAkFA,QAAA,yBAAA,GAAA;AAroCA,MAAA;AAEA,MAAA;AAEA,MAAA;AACA,MAAA;AAEA,MAAA;AAiBA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAMA,MAAA;AAYA,MAAA;AAEA,MAAM,uCAAuC;AAgD7C;;;;;IAMA,MAAa,sBACH,cAAA,iBAAsC;IA0C9C;;;;;;;QAQA,YACE,MAAmB,EACnB,WAA8B,EAC9B,OAA6B,EAC7B,aAA2B,CAAA;QAE3B,KAAK;QAjBP,cAAA,GACO,IAAA,CAAA,cAAc,GAA0B;QAiB7C,IAAI,CAAC,EAAE,CAAC,SAAS,QAAA,IAAI;QAErB,IAAI,UAAU,MAAM;YAClB,kBAAkB;YAClB,MAAM,IAAI,QAAA,iBAAiB,CAAC;QAC9B;QAEA,IAAI,eAAe,QAAQ,CAAC,CAAC,uBAAuB,iBAAiB,GAAG;YACtE,kBAAkB;YAClB,MAAM,IAAI,QAAA,iBAAiB,CAAC;QAC9B;QAEA,UAAU,WAAW,CAAA;QAErB,IAAI,CAAC,eAAe,GAAG,QAAQ,QAAQ,KAAK;QAC5C,IAAI,QAAQ,iBAAiB,KAAK,QAAQ,IAAI,CAAC,eAAe,EAAE;YAC9D,MAAM,IAAI,QAAA,yBAAyB,CACjC;QAEJ;QAEA,IAAI,CAAC,MAAM,GAAG;QACd,IAAI,CAAC,WAAW,GAAG;QACnB,IAAI,CAAC,QAAQ,GAAG;QAChB,IAAI,CAAC,aAAa,GAAG;QACrB,IAAI,CAAC,SAAS,GAAG,QAAQ,gBAAgB,IAAI,OAAO,CAAC,CAAC,OAAO,EAAE;QAE/D,IAAI,CAAC,QAAQ,GAAG,CAAC,CAAC,QAAQ,QAAQ;QAClC,IAAI,CAAC,cAAc,GAAG,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,WAAW,CAAC,OAAO,KAAK;QACnE,IAAI,CAAC,kBAAkB,GAAG;QAE1B,MAAM,gCAAgC,IAAI,CAAC,QAAQ,IAAI,QAAQ,QAAQ,KAAK;QAC5E,IAAI,CAAC,QAAQ,GAAG;YACd,wDAAwD;YACxD,mBAAmB,QAAQ,iBAAiB,IAAI;;QAGlD,IAAI,CAAC,WAAW,GAAG,QAAQ,kBAAkB;QAE7C,IAAI,CAAC,aAAa,GAAG;QACrB,IAAI,CAAC,KAAK,GAAG,QAAQ,KAAK;QAC1B,IAAI,CAAC,yBAAyB,GAAG;YAAE,GAAG,QAAQ,yBAAyB;QAAA;QACvE,IAAI,CAAC,WAAW,GAAG,IAAI,eAAA,WAAW;IACpC;IAEA,+CAAA,GACA,IAAI,KAAE;QACJ,OAAO,IAAI,CAAC,aAAa,EAAE;IAC7B;IAEA,IAAI,gBAAa;QACf,IAAI,gBAAgB,IAAI,CAAC,cAAc;QACvC,IAAI,iBAAiB,MAAM;YACzB,IAAI,IAAI,CAAC,QAAQ,EAAE;gBACjB,MAAM,IAAI,QAAA,iBAAiB,CAAC;YAC9B;YACA,IAAI,IAAI,CAAC,QAAQ,EAAE;gBACjB,MAAM,IAAI,QAAA,iBAAiB,CAAC;YAC9B;YACA,gBAAgB,IAAI,CAAC,WAAW,CAAC,OAAO;YACxC,IAAI,CAAC,cAAc,GAAG;QACxB;QACA,OAAO;IACT;IAEA,IAAI,eAAY;QACd,OAAO,IAAI,CAAC,MAAM,CAAC,QAAQ,EAAE,YAAY,SAAS,SAAA,YAAY,CAAC,YAAY;IAC7E;IAEA,cAAA,GACA,IAAI,IAAgB,EAAA;QAClB,IAAI,IAAI,CAAC,gBAAgB,EAAE;YACzB,MAAM,UAAU;QAClB;QAEA,IAAI,CAAC,gBAAgB,GAAG;QACxB,KAAK,IAAI,CACP,YAAA,MAAM,EACN,IAAI,CAAC,aAAa,KAAK,UAAA,qBAAqB,CAAC,GAAG,GAAG,UAAA,qBAAqB,CAAC,MAAM;IAEnF;IAEA,cAAA,GACA,MAAM,OAAqE,EAAA;QACzE,IAAI,IAAI,CAAC,YAAY,EAAE;YACrB,OAAO,2BAA2B,IAAI,EAAE;QAC1C;QAEA,IAAI,CAAC,WAAW,CAAC,WAAW;IAC9B;IAEA,IAAI,WAAQ;QACV,OAAO,IAAI,CAAC,YAAY,GAAG,CAAC,CAAC,IAAI,CAAC,gBAAgB,GAAG,IAAI,CAAC,WAAW,CAAC,QAAQ;IAChF;IAEA;;;;;;;QAQA,MAAM,WAAW,OAA2B,EAAA;QAC1C,IAAI;YACF,IAAI,IAAI,CAAC,aAAa,IAAI;gBACxB,MAAM,IAAI,CAAC,gBAAgB,CAAC;oBAAE,GAAG,OAAO;oBAAE,cAAc;gBAAI;YAC9D;QACF,EAAE,OAAO,OAAO;YACd,oEAAoE;YACpE,IAAI,MAAM,IAAI,KAAK,8BAA8B,MAAM;YACvD,CAAA,GAAA,QAAA,WAAW,EAAC;QACd,SAAU;YACR,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE;gBAClB,MAAM,gBAAgB,IAAI,CAAC,aAAa;gBACxC,IAAI,iBAAiB,MAAM;oBACzB,8CAA8C;oBAC9C,IAAI,CAAC,WAAW,CAAC,OAAO,CAAC;oBACzB,gEAAgE;oBAChE,IAAI,CAAC,cAAc,GAAG,IAAI,cAAc;gBAC1C;gBACA,+CAA+C;gBAC/C,IAAI,CAAC,QAAQ,GAAG;gBAChB,IAAI,CAAC,IAAI,CAAC,SAAS,IAAI;YACzB;YACA,2BAA2B,IAAI,EAAE;gBAAE,OAAO;gBAAM,GAAG,OAAO;YAAA;QAC5D;IACF;IAOA,cAAA,GACA,MAAM,eAAY;QAChB,MAAM,IAAI,CAAC,UAAU,CAAC;YAAE,OAAO;QAAI;IACrC;IAEA;;;;QAKA,qBAAqB,aAAwB,EAAA;QAC3C,IAAI,IAAI,CAAC,aAAa,IAAI,MAAM;YAC9B,IAAI,CAAC,aAAa,GAAG;YACrB;QACF;QAEA,IAAI,cAAc,WAAW,CAAC,IAAI,CAAC,aAAa,GAAG;YACjD,IAAI,CAAC,aAAa,GAAG;QACvB;IACF;IAEA;;;;QAKA,mBAAmB,WAAwB,EAAA;QACzC,IAAI,CAAC,eAAe,OAAO,gBAAgB,UAAU;YACnD,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QACA,IAAI,CAAC,YAAY,WAAW,IAAI,YAAY,WAAW,CAAC,SAAS,KAAK,aAAa;YACjF,MAAM,IAAI,QAAA,yBAAyB,CACjC;QAEJ;QACA,IACE,CAAC,YAAY,SAAS,IACtB,YAAY,SAAS,CAAC,IAAI,EAAE,cAAc,YACzC,OAAO,YAAY,SAAS,CAAC,KAAK,KAAK,YACtC,OAAO,YAAY,SAAS,CAAC,KAAK,KAAK,YACvC,YAAY,SAAS,CAAC,KAAK,EAAE,cAAc,OAAQ,0CAA0C;UAC/F;YACA,MAAM,IAAI,QAAA,yBAAyB,CACjC;QAEJ;QAEA,CAAA,GAAA,SAAA,mBAAmB,EAAC,IAAI,EAAE;IAC5B;IAEA;;;;QAKA,OAAO,OAAsB,EAAA;QAC3B,IAAI,CAAC,CAAC,mBAAmB,aAAa,GAAG;YACvC,OAAO;QACT;QAEA,IAAI,IAAI,CAAC,EAAE,IAAI,QAAQ,QAAQ,EAAE,IAAI,MAAM;YACzC,OAAO;QACT;QAEA,OAAO,QAAA,SAAS,CAAC,MAAM,CAAC,IAAI,CAAC,EAAE,CAAC,EAAE,CAAC,MAAM,EAAE,QAAQ,EAAE,CAAC,EAAE,CAAC,MAAM;IACjE;IAEA;;;;;;;QAQA,6BAA0B;QACxB,IAAI,CAAC,kBAAkB,IAAI;IAC7B;IAEA,uEAAA,GACA,gBAAa;QACX,OAAO,IAAI,CAAC,WAAW,CAAC,QAAQ;IAClC;IAEA;;;;;;;;;QAUA,iBAAiB,OAA4B,EAAA;QAC3C,IAAI,IAAI,CAAC,eAAe,EAAE;YACxB,MAAM,IAAI,QAAA,uBAAuB,CAAC;QACpC;QAEA,IAAI,IAAI,CAAC,aAAa,IAAI;YACxB,MAAM,IAAI,QAAA,qBAAqB,CAAC;QAClC;QAEA,IAAI,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,WAAW,CAAC,WAAW,EAAE;YACjD,IAAI,CAAC,KAAK;QACZ;QAEA,MAAM,yBAAyB,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,CAAC,MAAM,CAAC,QAAQ;QAClE,IACE,CAAA,GAAA,SAAA,SAAS,EAAC,IAAI,CAAC,MAAM,CAAC,QAAQ,KAC9B,0BAA0B,QAC1B,yBAAyB,sCACzB;YACA,MAAM,IAAI,QAAA,uBAAuB,CAC/B;QAEJ;QAEA,IAAI,CAAC,eAAe,GAAG;QACvB,sBAAsB;QACtB,IAAI,CAAC,0BAA0B;QAC/B,2BAA2B;QAC3B,IAAI,CAAC,WAAW,GAAG,IAAI,eAAA,WAAW,CAAC;YACjC,aACE,SAAS,eACT,IAAI,CAAC,yBAAyB,CAAC,WAAW,IAC1C,IAAI,CAAC,aAAa,EAAE;YACtB,cACE,SAAS,gBACT,IAAI,CAAC,yBAAyB,CAAC,YAAY,IAC3C,IAAI,CAAC,aAAa,EAAE;YACtB,gBACE,SAAS,kBACT,IAAI,CAAC,yBAAyB,CAAC,cAAc,IAC7C,IAAI,CAAC,aAAa,EAAE;YACtB,iBAAiB,SAAS,mBAAmB,IAAI,CAAC,yBAAyB,CAAC,eAAe;;QAG7F,IAAI,CAAC,WAAW,CAAC,UAAU,CAAC,eAAA,QAAQ,CAAC,oBAAoB;IAC3D;IAEA;;;;QAKA,MAAM,kBAAkB,OAAgC,EAAA;QACtD,IAAI,IAAI,CAAC,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,cAAc,EAAE;YACtD,MAAM,IAAI,QAAA,qBAAqB,CAAC;QAClC;QAEA,IACE,IAAI,CAAC,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,oBAAoB,IACxD,IAAI,CAAC,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,2BAA2B,EAC/D;YACA,6DAA6D;YAC7D,IAAI,CAAC,WAAW,CAAC,UAAU,CAAC,eAAA,QAAQ,CAAC,2BAA2B;YAChE;QACF;QAEA,IAAI,IAAI,CAAC,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,mBAAmB,EAAE;YAC3D,MAAM,IAAI,QAAA,qBAAqB,CAC7B;QAEJ;QAEA,MAAM,UAKF;YAAE,mBAAmB;QAAC;QAE1B,MAAM,YACJ,OAAO,SAAS,cAAc,WAC1B,QAAQ,SAAS,GACjB,OAAO,IAAI,CAAC,SAAS,KAAK,WACxB,IAAI,CAAC,SAAS,GACd;QAER,MAAM,KAAK,IAAI,CAAC,WAAW,CAAC,OAAO,CAAC,YAAY,IAAI,IAAI,CAAC,aAAa,EAAE;QACxE,IAAI,MAAM,MAAM;YACd,IAAI,aAAa,QAAQ,IAAI,CAAC,cAAc,IAAI,MAAM;gBACpD,gBAAA,YAAY,CAAC,KAAK,CAAC,SAAS;oBAAE,YAAY;oBAAO,GAAG;oBAAY,GAAG,EAAE;gBAAA;YACvE,OAAO;gBACL,MAAM,SAAS,OAAO,IAAI,CAAC;gBAC3B,IAAI,OAAO,MAAM,GAAG,KAAM,CAAC,OAAO,QAAQ,CAAC,iBAAiB,CAAC,OAAO,QAAQ,CAAC,eAC3E,iZAAiZ;gBACjZ,gBAAA,YAAY,CAAC,KAAK,CAAC,SAAS;oBAAE,GAAG,EAAE;oBAAE,YAAY;gBAAS;YAC9D;QACF;QAEA,IAAI,IAAI,CAAC,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,qBAAqB,IAAI,IAAI,CAAC,eAAe,EAAE;YACrF,IAAI,aAAa,QAAQ,IAAI,CAAC,cAAc,IAAI,MAAM;gBACpD,gBAAA,YAAY,CAAC,KAAK,CAAC,SAAS;oBAAE,YAAY;oBAAO,GAAG,EAAE;oBAAE,GAAG;gBAAU;YACvE,OAAO;gBACL,gBAAA,YAAY,CAAC,KAAK,CAAC,SAAS;oBAAE,GAAG;oBAAY,GAAG,EAAE;oBAAE,YAAY;gBAAS;YAC3E;QACF;QAEA,IAAI,OAAO,IAAI,CAAC,WAAW,CAAC,OAAO,CAAC,SAAS,KAAK,UAAU;YAC1D,QAAQ,SAAS,GAAG,IAAI,CAAC,WAAW,CAAC,OAAO,CAAC,SAAS;QACxD;QAEA,IAAI,IAAI,CAAC,WAAW,CAAC,aAAa,EAAE;YAClC,QAAQ,aAAa,GAAG,IAAI,CAAC,WAAW,CAAC,aAAa;QACxD;QAEA,MAAM,YAAY,IAAI,cAAA,wBAAwB,CAAC,SAAS;YACtD,SAAS,IAAI;YACb,gBAAgB,kBAAA,cAAc,CAAC,OAAO;YACtC,oBAAoB;;QAGtB,MAAM,iBACJ,IAAI,CAAC,cAAc,IACnB,CAAC,OAAO,cAAc,WAClB,UAAA,cAAc,CAAC,MAAM,CAAC;YACpB,0BAA0B,IAAI,CAAC,aAAa,CAAC,wBAAwB;YACrE,iBAAiB,IAAI,CAAC,aAAa,CAAC,eAAe;YACnD;aAEF,IAAI;QAEV,IAAI;YACF,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAAC,IAAI,CAAC,MAAM,EAAE,WAAW;YAC/C,IAAI,CAAC,eAAe,GAAG;YACvB;QACF,EAAE,OAAO,kBAAkB;YACzB,IAAI,CAAC,eAAe,GAAG;YACvB,IAAI,4BAA4B,QAAA,UAAU,IAAI,CAAA,GAAA,QAAA,qBAAqB,EAAC,mBAAmB;gBACrF,0EAA0E;gBAC1E,gBAAA,YAAY,CAAC,KAAK,CAAC,SAAS;oBAAE,YAAY;oBAAO,GAAG,EAAE;oBAAE,GAAG;gBAAU;gBACrE,iDAAiD;gBACjD,IAAI,CAAC,KAAK,CAAC;oBAAE,OAAO;gBAAI;gBAExB,IAAI;oBACF,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EACpB,IAAI,CAAC,MAAM,EACX,IAAI,cAAA,wBAAwB,CAAC,SAAS;wBACpC,SAAS,IAAI;wBACb,gBAAgB,kBAAA,cAAc,CAAC,OAAO;wBACtC,oBAAoB;wBAEtB;oBAEF;gBACF,EAAE,OAAO,kBAAkB;oBACzB,qEAAqE;oBACrE,IAAI,6CAA6C,mBAAmB;wBAClE,iBAAiB,aAAa,CAAC,QAAA,eAAe,CAAC,8BAA8B;oBAC/E;oBAEA,IAAI,4BAA4B,mBAAmB;wBACjD,IAAI,CAAC,KAAK,CAAC;4BAAE,OAAO;wBAAgB;oBACtC;oBAEA,MAAM;gBACR;YACF;YAEA,IAAI,6CAA6C,mBAAmB;gBAClE,iBAAiB,aAAa,CAAC,QAAA,eAAe,CAAC,8BAA8B;YAC/E;YAEA,IAAI,4BAA4B,mBAAmB;gBACjD,IAAI,CAAC,KAAK,CAAC;oBAAE,OAAO;gBAAgB;YACtC;YAEA,MAAM;QACR,SAAU;YACR,IAAI,CAAC,WAAW,CAAC,UAAU,CAAC,eAAA,QAAQ,CAAC,qBAAqB;QAC5D;IACF;IAUA,MAAM,iBAAiB,OAAqD,EAAA;QAC1E,IAAI,IAAI,CAAC,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,cAAc,EAAE;YACtD,MAAM,IAAI,QAAA,qBAAqB,CAAC;QAClC;QAEA,IAAI,IAAI,CAAC,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,oBAAoB,EAAE;YAC5D,6DAA6D;YAC7D,IAAI,CAAC,WAAW,CAAC,UAAU,CAAC,eAAA,QAAQ,CAAC,mBAAmB;YACxD;QACF;QAEA,IAAI,IAAI,CAAC,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,mBAAmB,EAAE;YAC3D,MAAM,IAAI,QAAA,qBAAqB,CAAC;QAClC;QAEA,IACE,IAAI,CAAC,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,qBAAqB,IACzD,IAAI,CAAC,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,2BAA2B,EAC/D;YACA,MAAM,IAAI,QAAA,qBAAqB,CAC7B;QAEJ;QAEA,MAAM,UAIF;YAAE,kBAAkB;QAAC;QAEzB,MAAM,YACJ,OAAO,SAAS,cAAc,WAC1B,QAAQ,SAAS,GACjB,IAAI,CAAC,cAAc,EAAE,gBACnB,IAAI,CAAC,cAAc,CAAC,SAAS,CAAC,wCAAwC;WACtE,OAAO,IAAI,CAAC,SAAS,KAAK,WACxB,IAAI,CAAC,SAAS,GACd;QAEV,MAAM,iBACJ,aAAa,OACT,UAAA,cAAc,CAAC,MAAM,CAAC;YACpB;YACA,0BAA0B,IAAI,CAAC,aAAa,CAAC,wBAAwB;YACrE,iBAAiB,IAAI,CAAC,aAAa,CAAC,eAAe;aAErD;QAEN,MAAM,KAAK,IAAI,CAAC,WAAW,CAAC,OAAO,CAAC,YAAY,IAAI,IAAI,CAAC,aAAa,EAAE;QACxE,IAAI,MAAM,QAAQ,aAAa,MAAM;YACnC,gBAAA,YAAY,CAAC,KAAK,CAAC,SAAS;gBAAE,YAAY;gBAAO,GAAG;gBAAY,GAAG,EAAE;YAAA;QACvE;QAEA,IAAI,IAAI,CAAC,WAAW,CAAC,aAAa,EAAE;YAClC,QAAQ,aAAa,GAAG,IAAI,CAAC,WAAW,CAAC,aAAa;QACxD;QAEA,MAAM,YAAY,IAAI,cAAA,wBAAwB,CAAC,SAAS;YACtD,SAAS,IAAI;YACb,gBAAgB,kBAAA,cAAc,CAAC,OAAO;YACtC,oBAAoB;;QAGtB,IAAI;YACF,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAAC,IAAI,CAAC,MAAM,EAAE,WAAW;YAC/C,IAAI,CAAC,KAAK;YACV;QACF,EAAE,OAAO,iBAAiB;YACxB,IAAI,CAAC,KAAK;YAEV,IAAI,gBAAgB,IAAI,KAAK,qBAAqB,MAAM;YACxD,IAAI,SAAS,gBAAgB,gBAAgB,IAAI,KAAK,8BAA8B;gBAClF,MAAM;YACR;YAEA,IAAI,2BAA2B,QAAA,UAAU,IAAI,CAAA,GAAA,QAAA,qBAAqB,EAAC,kBAAkB;gBACnF,IAAI;oBACF,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAAC,IAAI,CAAC,MAAM,EAAE,WAAW;oBAC/C;gBACF,EAAE,OAAO,kBAAkB;oBACzB,IAAI,iBAAiB,IAAI,KAAK,qBAAqB,MAAM;oBACzD,IAAI,SAAS,gBAAgB,iBAAiB,IAAI,KAAK,8BAA8B;wBACnF,MAAM;oBACR;gBACA,4BAA4B;gBAC9B;YACF;QAEA,4IAA4I;QAC9I,SAAU;YACR,IAAI,CAAC,WAAW,CAAC,UAAU,CAAC,eAAA,QAAQ,CAAC,mBAAmB;YACxD,IAAI,IAAI,CAAC,YAAY,EAAE;gBACrB,2BAA2B,IAAI,EAAE;oBAAE,OAAO;gBAAK;YACjD;QACF;IACF;IAEA;;QAGA,SAAM;QACJ,MAAM,IAAI,QAAA,iBAAiB,CAAC;IAC9B;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;QAmCA,MAAM,gBACJ,EAA8B,EAC9B,OASC,EAAA;QAED,MAAM,cAAc;QAEpB,MAAM,YAAY,SAAS,aAAa,IAAI,CAAC,SAAS,IAAI;QAC1D,IAAI,CAAC,cAAc,GACjB,aAAa,OACT,UAAA,cAAc,CAAC,MAAM,CAAC;YACpB;YACA,0BAA0B,IAAI,CAAC,aAAa,CAAC,wBAAwB;YACrE,iBAAiB,IAAI,CAAC,aAAa,CAAC,eAAe;aAErD;QAEN,MAAM,YAAY,IAAI,CAAC,cAAc,EAAE,gBAAgB,IAAI,CAAC,cAAc,CAAC,KAAK,GAAG,CAAA,GAAA,QAAA,GAAG;QAEtF,IAAI,YAAY;QAChB,IAAI;QAEJ,IAAI;YACF,MAAO,CAAC,UAAW;gBACjB,IAAI,CAAC,gBAAgB,CAAC,UAAU,qBAAqB;gBAErD,IAAI;oBACF,MAAM,UAAU,GAAG,IAAI;oBACvB,IAAI,CAAC,CAAA,GAAA,QAAA,aAAa,EAAC,UAAU;wBAC3B,MAAM,IAAI,QAAA,yBAAyB,CACjC;oBAEJ;oBAEA,SAAS,MAAM;oBAEf,IACE,IAAI,CAAC,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,cAAc,IAClD,IAAI,CAAC,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,qBAAqB,IACzD,IAAI,CAAC,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,mBAAmB,EACvD;wBACA,sDAAsD;wBACtD,OAAO;oBACT;gBACF,EAAE,OAAO,SAAS;oBAChB,IAAI,CAAC,CAAC,mBAAmB,QAAA,UAAU,KAAK,mBAAmB,QAAA,yBAAyB,EAAE;wBACpF,MAAM,IAAI,CAAC,gBAAgB;wBAC3B,MAAM;oBACR;oBAEA,IACE,IAAI,CAAC,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,oBAAoB,IACxD,IAAI,CAAC,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,uBAAuB,EAC3D;wBACA,MAAM,IAAI,CAAC,gBAAgB;oBAC7B;oBAEA,IACE,QAAQ,aAAa,CAAC,QAAA,eAAe,CAAC,yBAAyB,KAC/D,CAAC,IAAI,CAAC,cAAc,IAAI,QAAQ,CAAA,GAAA,QAAA,GAAG,MAAK,YAAY,WAAW,GAC/D;wBACA;oBACF;oBAEA,MAAM;gBACR;gBAEA,MAAO,CAAC,UAAW;oBACjB,IAAI;wBACF;;;;4BAKA,MAAM,IAAI,CAAC,iBAAiB;wBAC5B,YAAY;oBACd,EAAE,OAAO,aAAa;wBACpB;;;;;;4BAOA,IACE,CAAC,wBAAwB,gBACzB,YAAY,aAAa,CAAC,QAAA,eAAe,CAAC,8BAA8B,KACxE,CAAC,IAAI,CAAC,cAAc,IAAI,QAAQ,CAAA,GAAA,QAAA,GAAG,MAAK,YAAY,WAAW,GAC/D;4BACA;wBACF;wBAEA,IACE,YAAY,aAAa,CAAC,QAAA,eAAe,CAAC,yBAAyB,KACnE,CAAC,IAAI,CAAC,cAAc,IAAI,QAAQ,CAAA,GAAA,QAAA,GAAG,MAAK,YAAY,WAAW,GAC/D;4BACA;wBACF;wBAEA,MAAM;oBACR;gBACF;YACF;YACA,OAAO;QACT,SAAU;YACR,IAAI,CAAC,cAAc,GAAG;QACxB;IACF;;AAztBF,QAAA,aAAA,GAAA;AA4tBA,CAAA,GAAA,sBAAA,2BAA2B,EAAC,cAAc,SAAS;AAEnD,MAAM,yCAAyC,IAAI,IAAI;IACrD;IACA;IACA;CACD;AAED,SAAS,4BAA4B,WAAkB;IACrD,IAAI,uBAAuB,QAAA,UAAU,EAAE;QACrC,IACE,CAAA,GAAA,QAAA,qBAAqB,EAAC,gBACtB,uBAAuB,QAAA,sBAAsB,IAC7C,wBAAwB,cACxB;YACA,IAAI,iCAAiC,cAAc;gBACjD,iDAAiD;gBACjD,OAAO;YACT;QACF,OAAO,IAAI,YAAY,aAAa,CAAC,QAAA,eAAe,CAAC,yBAAyB,GAAG;YAC/E,OAAO;QACT;IACF;IACA,OAAO;AACT;AAEA,SAAS,6CAA6C,WAAuB;IAC3E,IAAI,KAAK,CAAA,GAAA,QAAA,qBAAqB,EAAC;IAC/B,OAAO,uBAAuB,QAAA,sBAAsB;IACpD,OAAO,wBAAwB;IAC/B,OAAO,iCAAiC;IACxC,OAAO;AACT;AAEA,SAAS,iCAAiC,GAAe;IACvD,MAAM,sCACJ,eAAe,QAAA,gBAAgB,IAC/B,IAAI,QAAQ,IACZ,uCAAuC,GAAG,CAAC,IAAI,QAAQ;IAEzD,OACE,wBAAwB,QACvB,CAAC,uCACA,IAAI,IAAI,KAAK,QAAA,mBAAmB,CAAC,yBAAyB,IAC1D,IAAI,IAAI,KAAK,QAAA,mBAAmB,CAAC,uBAAuB;AAE9D;AAEA,SAAgB,2BACd,OAAsB,EACtB,OAA2B;IAE3B,2CAA2C;IAC3C,MAAM,OAAO,QAAQ,gBAAgB;IACrC,MAAM,QAAQ,SAAS;IAEvB,IACE,QAAQ,aAAa,MACrB,SACA,iBAAiB,QAAA,UAAU,IAC3B,MAAM,aAAa,CAAC,QAAA,eAAe,CAAC,yBAAyB,GAC7D;QACA;IACF;IAEA,MAAM,WAAW,QAAQ,MAAM,CAAC,QAAQ;IACxC,uFAAuF;IACvF,yDAAyD;IACzD,IAAI,QAAQ,YAAY,MAAM;QAC5B,MAAM,UAAU,MAAM,IAAI,CAAC,SAAS,CAAC,CAAC,OAAO,CAAC,MAAM;QACpD,MAAM,eAAe,OAAO,CAAC,EAAE;QAE/B,IAAI,SAAS,SAAS,QAAQ,SAAS,OAAO;YAC5C,aAAa,IAAI,CAAC,OAAO,CAAC;YAC1B,QAAQ,gBAAgB,GAAG;YAC3B,KAAK,IAAI,CACP,YAAA,QAAQ,EACR,QAAQ,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,cAAc,GACjD,UAAA,qBAAqB,CAAC,GAAG,GACzB,UAAA,qBAAqB,CAAC,MAAM;YAGlC,IAAI,SAAS,YAAY;gBACvB,aAAa,IAAI,CAAC,KAAK,CAAC;oBAAE,WAAW,KAAK,SAAS;gBAAA;YACrD;QACF;IACF;AACF;AAEA,SAAS,wBAAwB,GAAe;IAC9C,IAAI,OAAO,QAAQ,CAAC,CAAC,eAAe,QAAA,gBAAgB,GAAG;QACrD,OAAO;IACT;IAEA,OACE,IAAI,IAAI,KAAK,QAAA,mBAAmB,CAAC,gBAAgB,IACjD,IAAI,iBAAiB,EAAE,SAAS,QAAA,mBAAmB,CAAC,gBAAgB;AAExE;AAKA;;;;IAKA,MAAa;IAMX,cAAA,GACA,YAAY,MAA6B,CAAA;QACvC,IAAI,UAAU,MAAM;YAClB,MAAM,UAAU,OAAO,WAAW,CAAC;YACnC,QAAQ,GAAG,CAAC,OAAO,EAAE,CAAC,EAAE,CAAC,MAAM;YAC/B,IAAI,CAAC,EAAE,GAAG;gBAAE,IAAI,IAAI,OAAA,MAAM,CAAC,SAAS,OAAO,EAAE,CAAC,EAAE,CAAC,QAAQ;YAAC;YAC1D,IAAI,CAAC,OAAO,GAAG,OAAO,OAAO;YAC7B,IAAI,CAAC,SAAS,GAAG,OAAO,SAAS;YACjC,IAAI,CAAC,OAAO,GAAG,OAAO,OAAO;YAC7B;QACF;QACA,IAAI,CAAC,EAAE,GAAG;YAAE,IAAI,IAAI,OAAA,MAAM,CAAC,CAAA,GAAA,QAAA,MAAM,KAAI,OAAA,MAAM,CAAC,YAAY;QAAC;QACzD,IAAI,CAAC,OAAO,GAAG,CAAA,GAAA,QAAA,GAAG;QAClB,IAAI,CAAC,SAAS,GAAG;QACjB,IAAI,CAAC,OAAO,GAAG;IACjB;IAEA;;;;QAKA,YAAY,qBAA6B,EAAA;QACvC,wFAAwF;QACxF,+FAA+F;QAC/F,MAAM,kBAAkB,KAAK,KAAK,CAChC,AAAE,CAAA,GAAA,QAAA,qBAAqB,EAAC,IAAI,CAAC,OAAO,IAAI,WAAY,UAAW;QAGjE,OAAO,kBAAkB,wBAAwB;IACnD;;AApCF,QAAA,aAAA,GAAA;AAuCA;;;;IAKA,MAAa;IAIX,YAAY,MAAmB,CAAA;QAC7B,IAAI,UAAU,MAAM;YAClB,MAAM,IAAI,QAAA,iBAAiB,CAAC;QAC9B;QAEA,IAAI,CAAC,MAAM,GAAG;QACd,IAAI,CAAC,QAAQ,GAAG,IAAI,QAAA,IAAI;IAC1B;IAEA;;;;;QAMA,UAAO;QACL,MAAM,wBAAwB,IAAI,CAAC,MAAM,CAAC,QAAQ,EAAE,gCAAgC;QAEpF,IAAI,UAAgC;QAEpC,kCAAkC;QAClC,MAAO,IAAI,CAAC,QAAQ,CAAC,MAAM,GAAG,EAAG;YAC/B,MAAM,mBAAmB,IAAI,CAAC,QAAQ,CAAC,KAAK;YAC5C,IACE,oBAAoB,QACpB,CAAC,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,QAAQ,EAAE,gBACvB,CAAC,iBAAiB,WAAW,CAAC,sBAAsB,GACtD;gBACA,UAAU;gBACV;YACF;QACF;QAEA,qDAAqD;QACrD,IAAI,WAAW,MAAM;YACnB,UAAU,IAAI;QAChB;QAEA,OAAO;IACT;IAEA;;;;;;QAOA,QAAQ,OAAsB,EAAA;QAC5B,MAAM,wBAAwB,IAAI,CAAC,MAAM,CAAC,QAAQ,EAAE,gCAAgC;QAEpF,IAAI,IAAI,CAAC,MAAM,CAAC,QAAQ,EAAE,gBAAgB,CAAC,uBAAuB;YAChE,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC;QACxB;QAEA,IAAI,CAAC,uBAAuB;YAC1B;QACF;QAEA,IAAI,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAA,UAAW,QAAQ,WAAW,CAAC;QAEnD,IAAI,CAAC,QAAQ,WAAW,CAAC,wBAAwB;YAC/C,IAAI,QAAQ,OAAO,EAAE;gBACnB;YACF;YAEA,oDAAoD;YACpD,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC;QACxB;IACF;;AAzEF,QAAA,iBAAA,GAAA;AA4EA;;;;;;;;IASA,SAAgB,aACd,OAAsB,EACtB,OAAiB,EACjB,OAAuB;IAEvB,IAAI,QAAQ,QAAQ,EAAE;QACpB,OAAO,IAAI,QAAA,wBAAwB;IACrC;IAEA,iCAAiC;IACjC,MAAM,gBAAgB,QAAQ,aAAa;IAC3C,IAAI,iBAAiB,MAAM;QACzB,OAAO,IAAI,QAAA,iBAAiB,CAAC;IAC/B;IAEA,IAAI,QAAQ,YAAY,EAAE,MAAM,GAAG;QACjC,IAAI,WAAW,QAAQ,QAAQ,EAAE;YAC/B,oFAAoF;YACpF,OAAO,IAAI,QAAA,aAAa,CAAC;QAC3B;QACA;IACF;IAEA,0DAA0D;IAC1D,cAAc,OAAO,GAAG,CAAA,GAAA,QAAA,GAAG;IAC3B,QAAQ,IAAI,GAAG,cAAc,EAAE;IAE/B,MAAM,oBAAoB,QAAQ,aAAa,MAAM,CAAA,GAAA,eAAA,oBAAoB,EAAC;IAC1E,MAAM,mBAAmB,CAAC,CAAC,QAAQ,cAAc;IAEjD,IAAI,oBAAoB,mBAAmB;QACzC,cAAc,SAAS,IAAI,QAAQ,kBAAkB;QACrD,QAAQ,kBAAkB,GAAG;QAC7B,oDAAoD;QACpD,QAAQ,SAAS,GAAG,OAAA,IAAI,CAAC,UAAU,CAAC,cAAc,SAAS;IAC7D;IAEA,IAAI,CAAC,mBAAmB;QACtB,IAAI,QAAQ,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,cAAc,EAAE;YACzD,QAAQ,WAAW,CAAC,UAAU,CAAC,eAAA,QAAQ,CAAC,cAAc;QACxD;QAEA,IACE,QAAQ,QAAQ,CAAC,iBAAiB,IAClC,QAAQ,aAAa,IACrB,CAAA,GAAA,QAAA,0BAA0B,EAAC,UAC3B;YACA,QAAQ,WAAW,GAAG,QAAQ,WAAW,IAAI,CAAA;YAC7C,OAAO,MAAM,CAAC,QAAQ,WAAW,EAAE;gBAAE,kBAAkB,QAAQ,aAAa;YAAA;QAC9E,OAAO,IAAI,QAAQ,eAAe,EAAE;YAClC,QAAQ,WAAW,GAAG,QAAQ,WAAW,IAAI;gBAAE,OAAO,eAAA,gBAAgB,CAAC,QAAQ;YAAA;YAC/E,IAAI,QAAQ,YAAY,IAAI,MAAM;gBAChC,OAAO,MAAM,CAAC,QAAQ,WAAW,EAAE;oBAAE,eAAe,QAAQ,YAAY;gBAAA;YAC1E;QACF;QAEA;IACF;IAEA,0DAA0D;IAE1D,2EAA2E;IAC3E,QAAQ,UAAU,GAAG;IAErB,IAAI,QAAQ,WAAW,CAAC,KAAK,KAAK,eAAA,QAAQ,CAAC,oBAAoB,EAAE;QAC/D,QAAQ,WAAW,CAAC,UAAU,CAAC,eAAA,QAAQ,CAAC,uBAAuB;QAC/D,QAAQ,gBAAgB,GAAG;QAE3B,MAAM,cACJ,QAAQ,WAAW,CAAC,OAAO,CAAC,WAAW,IAAI,SAAS,eAAe;QACrE,IAAI,aAAa;YACf,QAAQ,WAAW,GAAG;QACxB;QAEA,IAAI,QAAQ,QAAQ,CAAC,iBAAiB,IAAI,QAAQ,aAAa,EAAE;YAC/D,QAAQ,WAAW,GAAG,QAAQ,WAAW,IAAI,CAAA;YAC7C,OAAO,MAAM,CAAC,QAAQ,WAAW,EAAE;gBAAE,kBAAkB,QAAQ,aAAa;YAAA;QAC9E;IACF;IACA;AACF;AAEA,SAAgB,0BAA0B,OAAsB,EAAE,QAAyB;IACzF,IAAI,SAAS,YAAY,EAAE;QACzB,CAAA,GAAA,SAAA,mBAAmB,EAAC,SAAS,SAAS,YAAY;IACpD;IAEA,IAAI,SAAS,aAAa,IAAI,WAAW,QAAQ,QAAQ,CAAC,iBAAiB,EAAE;QAC3E,QAAQ,oBAAoB,CAAC,SAAS,aAAa;IACrD;IAEA,IAAI,SAAS,aAAa,IAAI,WAAW,QAAQ,aAAa,IAAI;QAChE,QAAQ,WAAW,CAAC,cAAc,GAAG,SAAS,aAAa;IAC7D;IAEA,IAAI,SAAS,mBAAmB,QAAQ,YAAY,IAAI,MAAM;QAC5D,iEAAiE;QACjE,4CAA4C;QAC5C,MAAM,gBAAgB,SAAS,aAAa;QAC5C,IAAI,eAAe;YACjB,QAAQ,YAAY,GAAG;QACzB;IACF;AACF"}},
    {"offset": {"line": 11571, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 11575, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/connection_string.ts"],"sourcesContent":["import * as dns from 'dns';\nimport ConnectionString from 'mongodb-connection-string-url';\nimport { URLSearchParams } from 'url';\n\nimport type { Document } from './bson';\nimport { MongoCredentials } from './cmap/auth/mongo_credentials';\nimport { AUTH_MECHS_AUTH_SRC_EXTERNAL, AuthMechanism } from './cmap/auth/providers';\nimport { addContainerMetadata, makeClientMetadata } from './cmap/handshake/client_metadata';\nimport { Compressor, type CompressorName } from './cmap/wire_protocol/compression';\nimport { Encrypter } from './encrypter';\nimport {\n  MongoAPIError,\n  MongoInvalidArgumentError,\n  MongoMissingCredentialsError,\n  MongoParseError\n} from './error';\nimport {\n  MongoClient,\n  type MongoClientOptions,\n  type MongoOptions,\n  type PkFactory,\n  type ServerApi,\n  ServerApiVersion\n} from './mongo_client';\nimport { MongoLoggableComponent, MongoLogger, SeverityLevel } from './mongo_logger';\nimport { ReadConcern, type ReadConcernLevel } from './read_concern';\nimport { ReadPreference, type ReadPreferenceMode } from './read_preference';\nimport { ServerMonitoringMode } from './sdam/monitor';\nimport type { TagSet } from './sdam/server_description';\nimport {\n  checkParentDomainMatch,\n  DEFAULT_PK_FACTORY,\n  emitWarning,\n  HostAddress,\n  isRecord,\n  parseInteger,\n  setDifference,\n  squashError\n} from './utils';\nimport { type W, WriteConcern } from './write_concern';\n\nconst VALID_TXT_RECORDS = ['authSource', 'replicaSet', 'loadBalanced'];\n\nconst LB_SINGLE_HOST_ERROR = 'loadBalanced option only supported with a single host in the URI';\nconst LB_REPLICA_SET_ERROR = 'loadBalanced option not supported with a replicaSet option';\nconst LB_DIRECT_CONNECTION_ERROR =\n  'loadBalanced option not supported when directConnection is provided';\n\nfunction retryDNSTimeoutFor(api: 'resolveSrv'): (a: string) => Promise<dns.SrvRecord[]>;\nfunction retryDNSTimeoutFor(api: 'resolveTxt'): (a: string) => Promise<string[][]>;\nfunction retryDNSTimeoutFor(\n  api: 'resolveSrv' | 'resolveTxt'\n): (a: string) => Promise<dns.SrvRecord[] | string[][]> {\n  return async function dnsReqRetryTimeout(lookupAddress: string) {\n    try {\n      return await dns.promises[api](lookupAddress);\n    } catch (firstDNSError) {\n      if (firstDNSError.code === dns.TIMEOUT) {\n        return await dns.promises[api](lookupAddress);\n      } else {\n        throw firstDNSError;\n      }\n    }\n  };\n}\n\nconst resolveSrv = retryDNSTimeoutFor('resolveSrv');\nconst resolveTxt = retryDNSTimeoutFor('resolveTxt');\n\n/**\n * Lookup a `mongodb+srv` connection string, combine the parts and reparse it as a normal\n * connection string.\n *\n * @param uri - The connection string to parse\n * @param options - Optional user provided connection string options\n */\nexport async function resolveSRVRecord(options: MongoOptions): Promise<HostAddress[]> {\n  if (typeof options.srvHost !== 'string') {\n    throw new MongoAPIError('Option \"srvHost\" must not be empty');\n  }\n\n  // Asynchronously start TXT resolution so that we do not have to wait until\n  // the SRV record is resolved before starting a second DNS query.\n  const lookupAddress = options.srvHost;\n  const txtResolutionPromise = resolveTxt(lookupAddress);\n\n  txtResolutionPromise.then(undefined, squashError); // rejections will be handled later\n\n  const hostname = `_${options.srvServiceName}._tcp.${lookupAddress}`;\n  // Resolve the SRV record and use the result as the list of hosts to connect to.\n  const addresses = await resolveSrv(hostname);\n\n  if (addresses.length === 0) {\n    throw new MongoAPIError('No addresses found at host');\n  }\n\n  for (const { name } of addresses) {\n    checkParentDomainMatch(name, lookupAddress);\n  }\n\n  const hostAddresses = addresses.map(r => HostAddress.fromString(`${r.name}:${r.port ?? 27017}`));\n\n  validateLoadBalancedOptions(hostAddresses, options, true);\n\n  // Use the result of resolving the TXT record and add options from there if they exist.\n  let record;\n  try {\n    record = await txtResolutionPromise;\n  } catch (error) {\n    if (error.code !== 'ENODATA' && error.code !== 'ENOTFOUND') {\n      throw error;\n    }\n    return hostAddresses;\n  }\n\n  if (record.length > 1) {\n    throw new MongoParseError('Multiple text records not allowed');\n  }\n\n  const txtRecordOptions = new URLSearchParams(record[0].join(''));\n  const txtRecordOptionKeys = [...txtRecordOptions.keys()];\n  if (txtRecordOptionKeys.some(key => !VALID_TXT_RECORDS.includes(key))) {\n    throw new MongoParseError(`Text record may only set any of: ${VALID_TXT_RECORDS.join(', ')}`);\n  }\n\n  if (VALID_TXT_RECORDS.some(option => txtRecordOptions.get(option) === '')) {\n    throw new MongoParseError('Cannot have empty URI params in DNS TXT Record');\n  }\n\n  const source = txtRecordOptions.get('authSource') ?? undefined;\n  const replicaSet = txtRecordOptions.get('replicaSet') ?? undefined;\n  const loadBalanced = txtRecordOptions.get('loadBalanced') ?? undefined;\n\n  if (\n    !options.userSpecifiedAuthSource &&\n    source &&\n    options.credentials &&\n    !AUTH_MECHS_AUTH_SRC_EXTERNAL.has(options.credentials.mechanism)\n  ) {\n    options.credentials = MongoCredentials.merge(options.credentials, { source });\n  }\n\n  if (!options.userSpecifiedReplicaSet && replicaSet) {\n    options.replicaSet = replicaSet;\n  }\n\n  if (loadBalanced === 'true') {\n    options.loadBalanced = true;\n  }\n\n  if (options.replicaSet && options.srvMaxHosts > 0) {\n    throw new MongoParseError('Cannot combine replicaSet option with srvMaxHosts');\n  }\n\n  validateLoadBalancedOptions(hostAddresses, options, true);\n\n  return hostAddresses;\n}\n\n/**\n * Checks if TLS options are valid\n *\n * @param allOptions - All options provided by user or included in default options map\n * @throws MongoAPIError if TLS options are invalid\n */\nfunction checkTLSOptions(allOptions: CaseInsensitiveMap): void {\n  if (!allOptions) return;\n  const check = (a: string, b: string) => {\n    if (allOptions.has(a) && allOptions.has(b)) {\n      throw new MongoAPIError(`The '${a}' option cannot be used with the '${b}' option`);\n    }\n  };\n  check('tlsInsecure', 'tlsAllowInvalidCertificates');\n  check('tlsInsecure', 'tlsAllowInvalidHostnames');\n  check('tlsInsecure', 'tlsDisableCertificateRevocationCheck');\n  check('tlsInsecure', 'tlsDisableOCSPEndpointCheck');\n  check('tlsAllowInvalidCertificates', 'tlsDisableCertificateRevocationCheck');\n  check('tlsAllowInvalidCertificates', 'tlsDisableOCSPEndpointCheck');\n  check('tlsDisableCertificateRevocationCheck', 'tlsDisableOCSPEndpointCheck');\n}\nfunction getBoolean(name: string, value: unknown): boolean {\n  if (typeof value === 'boolean') return value;\n  switch (value) {\n    case 'true':\n      return true;\n    case 'false':\n      return false;\n    default:\n      throw new MongoParseError(`${name} must be either \"true\" or \"false\"`);\n  }\n}\n\nfunction getIntFromOptions(name: string, value: unknown): number {\n  const parsedInt = parseInteger(value);\n  if (parsedInt != null) {\n    return parsedInt;\n  }\n  throw new MongoParseError(`Expected ${name} to be stringified int value, got: ${value}`);\n}\n\nfunction getUIntFromOptions(name: string, value: unknown): number {\n  const parsedValue = getIntFromOptions(name, value);\n  if (parsedValue < 0) {\n    throw new MongoParseError(`${name} can only be a positive int value, got: ${value}`);\n  }\n  return parsedValue;\n}\n\nfunction* entriesFromString(value: string): Generator<[string, string]> {\n  if (value === '') {\n    return;\n  }\n  const keyValuePairs = value.split(',');\n  for (const keyValue of keyValuePairs) {\n    const [key, value] = keyValue.split(/:(.*)/);\n    if (value == null) {\n      throw new MongoParseError('Cannot have undefined values in key value pairs');\n    }\n\n    yield [key, value];\n  }\n}\n\nclass CaseInsensitiveMap<Value = any> extends Map<string, Value> {\n  constructor(entries: Array<[string, any]> = []) {\n    super(entries.map(([k, v]) => [k.toLowerCase(), v]));\n  }\n  override has(k: string) {\n    return super.has(k.toLowerCase());\n  }\n  override get(k: string) {\n    return super.get(k.toLowerCase());\n  }\n  override set(k: string, v: any) {\n    return super.set(k.toLowerCase(), v);\n  }\n  override delete(k: string): boolean {\n    return super.delete(k.toLowerCase());\n  }\n}\n\nexport function parseOptions(\n  uri: string,\n  mongoClient: MongoClient | MongoClientOptions | undefined = undefined,\n  options: MongoClientOptions = {}\n): MongoOptions {\n  if (mongoClient != null && !(mongoClient instanceof MongoClient)) {\n    options = mongoClient;\n    mongoClient = undefined;\n  }\n\n  // validate BSONOptions\n  if (options.useBigInt64 && typeof options.promoteLongs === 'boolean' && !options.promoteLongs) {\n    throw new MongoAPIError('Must request either bigint or Long for int64 deserialization');\n  }\n\n  if (options.useBigInt64 && typeof options.promoteValues === 'boolean' && !options.promoteValues) {\n    throw new MongoAPIError('Must request either bigint or Long for int64 deserialization');\n  }\n\n  const url = new ConnectionString(uri);\n  const { hosts, isSRV } = url;\n\n  const mongoOptions = Object.create(null);\n\n  mongoOptions.hosts = isSRV ? [] : hosts.map(HostAddress.fromString);\n\n  const urlOptions = new CaseInsensitiveMap<unknown[]>();\n\n  if (url.pathname !== '/' && url.pathname !== '') {\n    const dbName = decodeURIComponent(\n      url.pathname[0] === '/' ? url.pathname.slice(1) : url.pathname\n    );\n    if (dbName) {\n      urlOptions.set('dbName', [dbName]);\n    }\n  }\n\n  if (url.username !== '') {\n    const auth: Document = {\n      username: decodeURIComponent(url.username)\n    };\n\n    if (typeof url.password === 'string') {\n      auth.password = decodeURIComponent(url.password);\n    }\n\n    urlOptions.set('auth', [auth]);\n  }\n\n  for (const key of url.searchParams.keys()) {\n    const values = url.searchParams.getAll(key);\n\n    const isReadPreferenceTags = /readPreferenceTags/i.test(key);\n\n    if (!isReadPreferenceTags && values.length > 1) {\n      throw new MongoInvalidArgumentError(\n        `URI option \"${key}\" cannot appear more than once in the connection string`\n      );\n    }\n\n    if (!isReadPreferenceTags && values.includes('')) {\n      throw new MongoAPIError(`URI option \"${key}\" cannot be specified with no value`);\n    }\n\n    if (!urlOptions.has(key)) {\n      urlOptions.set(key, values);\n    }\n  }\n\n  const objectOptions = new CaseInsensitiveMap<unknown>(\n    Object.entries(options).filter(([, v]) => v != null)\n  );\n\n  // Validate options that can only be provided by one of uri or object\n\n  if (urlOptions.has('serverApi')) {\n    throw new MongoParseError(\n      'URI cannot contain `serverApi`, it can only be passed to the client'\n    );\n  }\n\n  const uriMechanismProperties = urlOptions.get('authMechanismProperties');\n  if (uriMechanismProperties) {\n    for (const property of uriMechanismProperties) {\n      if (/(^|,)ALLOWED_HOSTS:/.test(property as string)) {\n        throw new MongoParseError(\n          'Auth mechanism property ALLOWED_HOSTS is not allowed in the connection string.'\n        );\n      }\n    }\n  }\n\n  if (objectOptions.has('loadBalanced')) {\n    throw new MongoParseError('loadBalanced is only a valid option in the URI');\n  }\n\n  // All option collection\n\n  const allProvidedOptions = new CaseInsensitiveMap<unknown[]>();\n\n  const allProvidedKeys = new Set<string>([...urlOptions.keys(), ...objectOptions.keys()]);\n\n  for (const key of allProvidedKeys) {\n    const values = [];\n    const objectOptionValue = objectOptions.get(key);\n    if (objectOptionValue != null) {\n      values.push(objectOptionValue);\n    }\n\n    const urlValues = urlOptions.get(key) ?? [];\n    values.push(...urlValues);\n    allProvidedOptions.set(key, values);\n  }\n\n  if (allProvidedOptions.has('tls') || allProvidedOptions.has('ssl')) {\n    const tlsAndSslOpts = (allProvidedOptions.get('tls') || [])\n      .concat(allProvidedOptions.get('ssl') || [])\n      .map(getBoolean.bind(null, 'tls/ssl'));\n    if (new Set(tlsAndSslOpts).size !== 1) {\n      throw new MongoParseError('All values of tls/ssl must be the same.');\n    }\n  }\n\n  checkTLSOptions(allProvidedOptions);\n\n  const unsupportedOptions = setDifference(\n    allProvidedKeys,\n    Array.from(Object.keys(OPTIONS)).map(s => s.toLowerCase())\n  );\n  if (unsupportedOptions.size !== 0) {\n    const optionWord = unsupportedOptions.size > 1 ? 'options' : 'option';\n    const isOrAre = unsupportedOptions.size > 1 ? 'are' : 'is';\n    throw new MongoParseError(\n      `${optionWord} ${Array.from(unsupportedOptions).join(', ')} ${isOrAre} not supported`\n    );\n  }\n\n  // Option parsing and setting\n\n  for (const [key, descriptor] of Object.entries(OPTIONS)) {\n    const values = allProvidedOptions.get(key);\n    if (!values || values.length === 0) {\n      if (DEFAULT_OPTIONS.has(key)) {\n        setOption(mongoOptions, key, descriptor, [DEFAULT_OPTIONS.get(key)]);\n      }\n    } else {\n      const { deprecated } = descriptor;\n      if (deprecated) {\n        const deprecatedMsg = typeof deprecated === 'string' ? `: ${deprecated}` : '';\n        emitWarning(`${key} is a deprecated option${deprecatedMsg}`);\n      }\n\n      setOption(mongoOptions, key, descriptor, values);\n    }\n  }\n\n  if (mongoOptions.credentials) {\n    const isGssapi = mongoOptions.credentials.mechanism === AuthMechanism.MONGODB_GSSAPI;\n    const isX509 = mongoOptions.credentials.mechanism === AuthMechanism.MONGODB_X509;\n    const isAws = mongoOptions.credentials.mechanism === AuthMechanism.MONGODB_AWS;\n    const isOidc = mongoOptions.credentials.mechanism === AuthMechanism.MONGODB_OIDC;\n    if (\n      (isGssapi || isX509) &&\n      allProvidedOptions.has('authSource') &&\n      mongoOptions.credentials.source !== '$external'\n    ) {\n      // If authSource was explicitly given and its incorrect, we error\n      throw new MongoParseError(\n        `authMechanism ${mongoOptions.credentials.mechanism} requires an authSource of '$external'`\n      );\n    }\n\n    if (\n      !(isGssapi || isX509 || isAws || isOidc) &&\n      mongoOptions.dbName &&\n      !allProvidedOptions.has('authSource')\n    ) {\n      // inherit the dbName unless GSSAPI or X509, then silently ignore dbName\n      // and there was no specific authSource given\n      mongoOptions.credentials = MongoCredentials.merge(mongoOptions.credentials, {\n        source: mongoOptions.dbName\n      });\n    }\n\n    if (isAws && mongoOptions.credentials.username && !mongoOptions.credentials.password) {\n      throw new MongoMissingCredentialsError(\n        `When using ${mongoOptions.credentials.mechanism} password must be set when a username is specified`\n      );\n    }\n\n    mongoOptions.credentials.validate();\n\n    // Check if the only auth related option provided was authSource, if so we can remove credentials\n    if (\n      mongoOptions.credentials.password === '' &&\n      mongoOptions.credentials.username === '' &&\n      mongoOptions.credentials.mechanism === AuthMechanism.MONGODB_DEFAULT &&\n      Object.keys(mongoOptions.credentials.mechanismProperties).length === 0\n    ) {\n      delete mongoOptions.credentials;\n    }\n  }\n\n  if (!mongoOptions.dbName) {\n    // dbName default is applied here because of the credential validation above\n    mongoOptions.dbName = 'test';\n  }\n\n  validateLoadBalancedOptions(hosts, mongoOptions, isSRV);\n\n  if (mongoClient && mongoOptions.autoEncryption) {\n    Encrypter.checkForMongoCrypt();\n    mongoOptions.encrypter = new Encrypter(mongoClient, uri, options);\n    mongoOptions.autoEncrypter = mongoOptions.encrypter.autoEncrypter;\n  }\n\n  // Potential SRV Overrides and SRV connection string validations\n\n  mongoOptions.userSpecifiedAuthSource =\n    objectOptions.has('authSource') || urlOptions.has('authSource');\n  mongoOptions.userSpecifiedReplicaSet =\n    objectOptions.has('replicaSet') || urlOptions.has('replicaSet');\n\n  if (isSRV) {\n    // SRV Record is resolved upon connecting\n    mongoOptions.srvHost = hosts[0];\n\n    if (mongoOptions.directConnection) {\n      throw new MongoAPIError('SRV URI does not support directConnection');\n    }\n\n    if (mongoOptions.srvMaxHosts > 0 && typeof mongoOptions.replicaSet === 'string') {\n      throw new MongoParseError('Cannot use srvMaxHosts option with replicaSet');\n    }\n\n    // SRV turns on TLS by default, but users can override and turn it off\n    const noUserSpecifiedTLS = !objectOptions.has('tls') && !urlOptions.has('tls');\n    const noUserSpecifiedSSL = !objectOptions.has('ssl') && !urlOptions.has('ssl');\n    if (noUserSpecifiedTLS && noUserSpecifiedSSL) {\n      mongoOptions.tls = true;\n    }\n  } else {\n    const userSpecifiedSrvOptions =\n      urlOptions.has('srvMaxHosts') ||\n      objectOptions.has('srvMaxHosts') ||\n      urlOptions.has('srvServiceName') ||\n      objectOptions.has('srvServiceName');\n\n    if (userSpecifiedSrvOptions) {\n      throw new MongoParseError(\n        'Cannot use srvMaxHosts or srvServiceName with a non-srv connection string'\n      );\n    }\n  }\n\n  if (mongoOptions.directConnection && mongoOptions.hosts.length !== 1) {\n    throw new MongoParseError('directConnection option requires exactly one host');\n  }\n\n  if (\n    !mongoOptions.proxyHost &&\n    (mongoOptions.proxyPort || mongoOptions.proxyUsername || mongoOptions.proxyPassword)\n  ) {\n    throw new MongoParseError('Must specify proxyHost if other proxy options are passed');\n  }\n\n  if (\n    (mongoOptions.proxyUsername && !mongoOptions.proxyPassword) ||\n    (!mongoOptions.proxyUsername && mongoOptions.proxyPassword)\n  ) {\n    throw new MongoParseError('Can only specify both of proxy username/password or neither');\n  }\n\n  const proxyOptions = ['proxyHost', 'proxyPort', 'proxyUsername', 'proxyPassword'].map(\n    key => urlOptions.get(key) ?? []\n  );\n\n  if (proxyOptions.some(options => options.length > 1)) {\n    throw new MongoParseError(\n      'Proxy options cannot be specified multiple times in the connection string'\n    );\n  }\n\n  mongoOptions.mongoLoggerOptions = MongoLogger.resolveOptions(\n    {\n      MONGODB_LOG_COMMAND: process.env.MONGODB_LOG_COMMAND,\n      MONGODB_LOG_TOPOLOGY: process.env.MONGODB_LOG_TOPOLOGY,\n      MONGODB_LOG_SERVER_SELECTION: process.env.MONGODB_LOG_SERVER_SELECTION,\n      MONGODB_LOG_CONNECTION: process.env.MONGODB_LOG_CONNECTION,\n      MONGODB_LOG_CLIENT: process.env.MONGODB_LOG_CLIENT,\n      MONGODB_LOG_ALL: process.env.MONGODB_LOG_ALL,\n      MONGODB_LOG_MAX_DOCUMENT_LENGTH: process.env.MONGODB_LOG_MAX_DOCUMENT_LENGTH,\n      MONGODB_LOG_PATH: process.env.MONGODB_LOG_PATH\n    },\n    {\n      mongodbLogPath: mongoOptions.mongodbLogPath,\n      mongodbLogComponentSeverities: mongoOptions.mongodbLogComponentSeverities,\n      mongodbLogMaxDocumentLength: mongoOptions.mongodbLogMaxDocumentLength\n    }\n  );\n\n  mongoOptions.metadata = makeClientMetadata(mongoOptions);\n\n  mongoOptions.extendedMetadata = addContainerMetadata(mongoOptions.metadata).then(\n    undefined,\n    squashError\n  ); // rejections will be handled later\n\n  return mongoOptions;\n}\n\n/**\n * #### Throws if LB mode is true:\n * - hosts contains more than one host\n * - there is a replicaSet name set\n * - directConnection is set\n * - if srvMaxHosts is used when an srv connection string is passed in\n *\n * @throws MongoParseError\n */\nfunction validateLoadBalancedOptions(\n  hosts: HostAddress[] | string[],\n  mongoOptions: MongoOptions,\n  isSrv: boolean\n): void {\n  if (mongoOptions.loadBalanced) {\n    if (hosts.length > 1) {\n      throw new MongoParseError(LB_SINGLE_HOST_ERROR);\n    }\n    if (mongoOptions.replicaSet) {\n      throw new MongoParseError(LB_REPLICA_SET_ERROR);\n    }\n    if (mongoOptions.directConnection) {\n      throw new MongoParseError(LB_DIRECT_CONNECTION_ERROR);\n    }\n\n    if (isSrv && mongoOptions.srvMaxHosts > 0) {\n      throw new MongoParseError('Cannot limit srv hosts with loadBalanced enabled');\n    }\n  }\n  return;\n}\n\nfunction setOption(\n  mongoOptions: any,\n  key: string,\n  descriptor: OptionDescriptor,\n  values: unknown[]\n) {\n  const { target, type, transform } = descriptor;\n  const name = target ?? key;\n\n  switch (type) {\n    case 'boolean':\n      mongoOptions[name] = getBoolean(name, values[0]);\n      break;\n    case 'int':\n      mongoOptions[name] = getIntFromOptions(name, values[0]);\n      break;\n    case 'uint':\n      mongoOptions[name] = getUIntFromOptions(name, values[0]);\n      break;\n    case 'string':\n      if (values[0] == null) {\n        break;\n      }\n      // eslint-disable-next-line @typescript-eslint/no-base-to-string\n      mongoOptions[name] = String(values[0]);\n      break;\n    case 'record':\n      if (!isRecord(values[0])) {\n        throw new MongoParseError(`${name} must be an object`);\n      }\n      mongoOptions[name] = values[0];\n      break;\n    case 'any':\n      mongoOptions[name] = values[0];\n      break;\n    default: {\n      if (!transform) {\n        throw new MongoParseError('Descriptors missing a type must define a transform');\n      }\n      const transformValue = transform({ name, options: mongoOptions, values });\n      mongoOptions[name] = transformValue;\n      break;\n    }\n  }\n}\n\ninterface OptionDescriptor {\n  target?: string;\n  type?: 'boolean' | 'int' | 'uint' | 'record' | 'string' | 'any';\n  default?: any;\n\n  deprecated?: boolean | string;\n  /**\n   * @param name - the original option name\n   * @param options - the options so far for resolution\n   * @param values - the possible values in precedence order\n   */\n  transform?: (args: { name: string; options: MongoOptions; values: unknown[] }) => unknown;\n}\n\nexport const OPTIONS = {\n  appName: {\n    type: 'string'\n  },\n  auth: {\n    target: 'credentials',\n    transform({ name, options, values: [value] }): MongoCredentials {\n      if (!isRecord(value, ['username', 'password'] as const)) {\n        throw new MongoParseError(\n          `${name} must be an object with 'username' and 'password' properties`\n        );\n      }\n      return MongoCredentials.merge(options.credentials, {\n        username: value.username,\n        password: value.password\n      });\n    }\n  },\n  authMechanism: {\n    target: 'credentials',\n    transform({ options, values: [value] }): MongoCredentials {\n      const mechanisms = Object.values(AuthMechanism);\n      const [mechanism] = mechanisms.filter(m => m.match(RegExp(String.raw`\\b${value}\\b`, 'i')));\n      if (!mechanism) {\n        throw new MongoParseError(`authMechanism one of ${mechanisms}, got ${value}`);\n      }\n      let source = options.credentials?.source;\n      if (\n        mechanism === AuthMechanism.MONGODB_PLAIN ||\n        AUTH_MECHS_AUTH_SRC_EXTERNAL.has(mechanism)\n      ) {\n        // some mechanisms have '$external' as the Auth Source\n        source = '$external';\n      }\n\n      let password = options.credentials?.password;\n      if (mechanism === AuthMechanism.MONGODB_X509 && password === '') {\n        password = undefined;\n      }\n      return MongoCredentials.merge(options.credentials, {\n        mechanism,\n        source,\n        password\n      });\n    }\n  },\n  // Note that if the authMechanismProperties contain a TOKEN_RESOURCE that has a\n  // comma in it, it MUST be supplied as a MongoClient option instead of in the\n  // connection string.\n  authMechanismProperties: {\n    target: 'credentials',\n    transform({ options, values }): MongoCredentials {\n      // We can have a combination of options passed in the URI and options passed\n      // as an object to the MongoClient. So we must transform the string options\n      // as well as merge them together with a potentially provided object.\n      let mechanismProperties = Object.create(null);\n\n      for (const optionValue of values) {\n        if (typeof optionValue === 'string') {\n          for (const [key, value] of entriesFromString(optionValue)) {\n            try {\n              mechanismProperties[key] = getBoolean(key, value);\n            } catch {\n              mechanismProperties[key] = value;\n            }\n          }\n        } else {\n          if (!isRecord(optionValue)) {\n            throw new MongoParseError('AuthMechanismProperties must be an object');\n          }\n          mechanismProperties = { ...optionValue };\n        }\n      }\n      return MongoCredentials.merge(options.credentials, {\n        mechanismProperties\n      });\n    }\n  },\n  authSource: {\n    target: 'credentials',\n    transform({ options, values: [value] }): MongoCredentials {\n      const source = String(value);\n      return MongoCredentials.merge(options.credentials, { source });\n    }\n  },\n  autoEncryption: {\n    type: 'record'\n  },\n  autoSelectFamily: {\n    type: 'boolean',\n    default: true\n  },\n  autoSelectFamilyAttemptTimeout: {\n    type: 'uint'\n  },\n  bsonRegExp: {\n    type: 'boolean'\n  },\n  serverApi: {\n    target: 'serverApi',\n    transform({ values: [version] }): ServerApi {\n      const serverApiToValidate =\n        typeof version === 'string' ? ({ version } as ServerApi) : (version as ServerApi);\n      const versionToValidate = serverApiToValidate && serverApiToValidate.version;\n      if (!versionToValidate) {\n        throw new MongoParseError(\n          `Invalid \\`serverApi\\` property; must specify a version from the following enum: [\"${Object.values(\n            ServerApiVersion\n          ).join('\", \"')}\"]`\n        );\n      }\n      if (!Object.values(ServerApiVersion).some(v => v === versionToValidate)) {\n        throw new MongoParseError(\n          `Invalid server API version=${versionToValidate}; must be in the following enum: [\"${Object.values(\n            ServerApiVersion\n          ).join('\", \"')}\"]`\n        );\n      }\n      return serverApiToValidate;\n    }\n  },\n  checkKeys: {\n    type: 'boolean'\n  },\n  compressors: {\n    default: 'none',\n    target: 'compressors',\n    transform({ values }) {\n      const compressionList = new Set();\n      for (const compVal of values as (CompressorName[] | string)[]) {\n        const compValArray = typeof compVal === 'string' ? compVal.split(',') : compVal;\n        if (!Array.isArray(compValArray)) {\n          throw new MongoInvalidArgumentError(\n            'compressors must be an array or a comma-delimited list of strings'\n          );\n        }\n        for (const c of compValArray) {\n          if (Object.keys(Compressor).includes(String(c))) {\n            compressionList.add(String(c));\n          } else {\n            throw new MongoInvalidArgumentError(\n              `${c} is not a valid compression mechanism. Must be one of: ${Object.keys(\n                Compressor\n              )}.`\n            );\n          }\n        }\n      }\n      return [...compressionList];\n    }\n  },\n  connectTimeoutMS: {\n    default: 30000,\n    type: 'uint'\n  },\n  dbName: {\n    type: 'string'\n  },\n  directConnection: {\n    default: false,\n    type: 'boolean'\n  },\n  driverInfo: {\n    default: {},\n    type: 'record'\n  },\n  enableUtf8Validation: { type: 'boolean', default: true },\n  family: {\n    transform({ name, values: [value] }): 4 | 6 {\n      const transformValue = getIntFromOptions(name, value);\n      if (transformValue === 4 || transformValue === 6) {\n        return transformValue;\n      }\n      throw new MongoParseError(`Option 'family' must be 4 or 6 got ${transformValue}.`);\n    }\n  },\n  fieldsAsRaw: {\n    type: 'record'\n  },\n  forceServerObjectId: {\n    default: false,\n    type: 'boolean'\n  },\n  fsync: {\n    deprecated: 'Please use journal instead',\n    target: 'writeConcern',\n    transform({ name, options, values: [value] }): WriteConcern {\n      const wc = WriteConcern.fromOptions({\n        writeConcern: {\n          ...options.writeConcern,\n          fsync: getBoolean(name, value)\n        }\n      });\n      if (!wc) throw new MongoParseError(`Unable to make a writeConcern from fsync=${value}`);\n      return wc;\n    }\n  } as OptionDescriptor,\n  heartbeatFrequencyMS: {\n    default: 10000,\n    type: 'uint'\n  },\n  ignoreUndefined: {\n    type: 'boolean'\n  },\n  j: {\n    deprecated: 'Please use journal instead',\n    target: 'writeConcern',\n    transform({ name, options, values: [value] }): WriteConcern {\n      const wc = WriteConcern.fromOptions({\n        writeConcern: {\n          ...options.writeConcern,\n          journal: getBoolean(name, value)\n        }\n      });\n      if (!wc) throw new MongoParseError(`Unable to make a writeConcern from journal=${value}`);\n      return wc;\n    }\n  } as OptionDescriptor,\n  journal: {\n    target: 'writeConcern',\n    transform({ name, options, values: [value] }): WriteConcern {\n      const wc = WriteConcern.fromOptions({\n        writeConcern: {\n          ...options.writeConcern,\n          journal: getBoolean(name, value)\n        }\n      });\n      if (!wc) throw new MongoParseError(`Unable to make a writeConcern from journal=${value}`);\n      return wc;\n    }\n  },\n  loadBalanced: {\n    default: false,\n    type: 'boolean'\n  },\n  localThresholdMS: {\n    default: 15,\n    type: 'uint'\n  },\n  maxConnecting: {\n    default: 2,\n    transform({ name, values: [value] }): number {\n      const maxConnecting = getUIntFromOptions(name, value);\n      if (maxConnecting === 0) {\n        throw new MongoInvalidArgumentError('maxConnecting must be > 0 if specified');\n      }\n      return maxConnecting;\n    }\n  },\n  maxIdleTimeMS: {\n    default: 0,\n    type: 'uint'\n  },\n  maxPoolSize: {\n    default: 100,\n    type: 'uint'\n  },\n  maxStalenessSeconds: {\n    target: 'readPreference',\n    transform({ name, options, values: [value] }) {\n      const maxStalenessSeconds = getUIntFromOptions(name, value);\n      if (options.readPreference) {\n        return ReadPreference.fromOptions({\n          readPreference: { ...options.readPreference, maxStalenessSeconds }\n        });\n      } else {\n        return new ReadPreference('secondary', undefined, { maxStalenessSeconds });\n      }\n    }\n  },\n  minInternalBufferSize: {\n    type: 'uint'\n  },\n  minPoolSize: {\n    default: 0,\n    type: 'uint'\n  },\n  minHeartbeatFrequencyMS: {\n    default: 500,\n    type: 'uint'\n  },\n  monitorCommands: {\n    default: false,\n    type: 'boolean'\n  },\n  name: {\n    target: 'driverInfo',\n    transform({ values: [value], options }) {\n      return { ...options.driverInfo, name: String(value) };\n    }\n  } as OptionDescriptor,\n  noDelay: {\n    default: true,\n    type: 'boolean'\n  },\n  pkFactory: {\n    default: DEFAULT_PK_FACTORY,\n    transform({ values: [value] }): PkFactory {\n      if (isRecord(value, ['createPk'] as const) && typeof value.createPk === 'function') {\n        return value as PkFactory;\n      }\n      throw new MongoParseError(\n        `Option pkFactory must be an object with a createPk function, got ${value}`\n      );\n    }\n  },\n  promoteBuffers: {\n    type: 'boolean'\n  },\n  promoteLongs: {\n    type: 'boolean'\n  },\n  promoteValues: {\n    type: 'boolean'\n  },\n  useBigInt64: {\n    type: 'boolean'\n  },\n  proxyHost: {\n    type: 'string'\n  },\n  proxyPassword: {\n    type: 'string'\n  },\n  proxyPort: {\n    type: 'uint'\n  },\n  proxyUsername: {\n    type: 'string'\n  },\n  raw: {\n    default: false,\n    type: 'boolean'\n  },\n  readConcern: {\n    transform({ values: [value], options }) {\n      if (value instanceof ReadConcern || isRecord(value, ['level'] as const)) {\n        return ReadConcern.fromOptions({ ...options.readConcern, ...value } as any);\n      }\n      throw new MongoParseError(`ReadConcern must be an object, got ${JSON.stringify(value)}`);\n    }\n  },\n  readConcernLevel: {\n    target: 'readConcern',\n    transform({ values: [level], options }) {\n      return ReadConcern.fromOptions({\n        ...options.readConcern,\n        level: level as ReadConcernLevel\n      });\n    }\n  },\n  readPreference: {\n    default: ReadPreference.primary,\n    transform({ values: [value], options }) {\n      if (value instanceof ReadPreference) {\n        return ReadPreference.fromOptions({\n          readPreference: { ...options.readPreference, ...value },\n          ...value\n        } as any);\n      }\n      if (isRecord(value, ['mode'] as const)) {\n        const rp = ReadPreference.fromOptions({\n          readPreference: { ...options.readPreference, ...value },\n          ...value\n        } as any);\n        if (rp) return rp;\n        else throw new MongoParseError(`Cannot make read preference from ${JSON.stringify(value)}`);\n      }\n      if (typeof value === 'string') {\n        const rpOpts = {\n          hedge: options.readPreference?.hedge,\n          maxStalenessSeconds: options.readPreference?.maxStalenessSeconds\n        };\n        return new ReadPreference(\n          value as ReadPreferenceMode,\n          options.readPreference?.tags,\n          rpOpts\n        );\n      }\n      throw new MongoParseError(`Unknown ReadPreference value: ${value}`);\n    }\n  },\n  readPreferenceTags: {\n    target: 'readPreference',\n    transform({\n      values,\n      options\n    }: {\n      values: Array<string | Record<string, string>[]>;\n      options: MongoClientOptions;\n    }) {\n      const tags: Array<string | Record<string, string>> = Array.isArray(values[0])\n        ? values[0]\n        : (values as Array<string>);\n      const readPreferenceTags = [];\n      for (const tag of tags) {\n        const readPreferenceTag: TagSet = Object.create(null);\n        if (typeof tag === 'string') {\n          for (const [k, v] of entriesFromString(tag)) {\n            readPreferenceTag[k] = v;\n          }\n        }\n        if (isRecord(tag)) {\n          for (const [k, v] of Object.entries(tag)) {\n            readPreferenceTag[k] = v;\n          }\n        }\n        readPreferenceTags.push(readPreferenceTag);\n      }\n      return ReadPreference.fromOptions({\n        readPreference: options.readPreference,\n        readPreferenceTags\n      });\n    }\n  },\n  replicaSet: {\n    type: 'string'\n  },\n  retryReads: {\n    default: true,\n    type: 'boolean'\n  },\n  retryWrites: {\n    default: true,\n    type: 'boolean'\n  },\n  serializeFunctions: {\n    type: 'boolean'\n  },\n  serverMonitoringMode: {\n    default: 'auto',\n    transform({ values: [value] }) {\n      if (!Object.values(ServerMonitoringMode).includes(value as any)) {\n        throw new MongoParseError(\n          'serverMonitoringMode must be one of `auto`, `poll`, or `stream`'\n        );\n      }\n      return value;\n    }\n  },\n  serverSelectionTimeoutMS: {\n    default: 30000,\n    type: 'uint'\n  },\n  servername: {\n    type: 'string'\n  },\n  socketTimeoutMS: {\n    // TODO(NODE-6491): deprecated: 'Please use timeoutMS instead',\n    default: 0,\n    type: 'uint'\n  },\n  srvMaxHosts: {\n    type: 'uint',\n    default: 0\n  },\n  srvServiceName: {\n    type: 'string',\n    default: 'mongodb'\n  },\n  ssl: {\n    target: 'tls',\n    type: 'boolean'\n  },\n  timeoutMS: {\n    type: 'uint'\n  },\n  tls: {\n    type: 'boolean'\n  },\n  tlsAllowInvalidCertificates: {\n    target: 'rejectUnauthorized',\n    transform({ name, values: [value] }) {\n      // allowInvalidCertificates is the inverse of rejectUnauthorized\n      return !getBoolean(name, value);\n    }\n  },\n  tlsAllowInvalidHostnames: {\n    target: 'checkServerIdentity',\n    transform({ name, values: [value] }) {\n      // tlsAllowInvalidHostnames means setting the checkServerIdentity function to a noop\n      return getBoolean(name, value) ? () => undefined : undefined;\n    }\n  },\n  tlsCAFile: {\n    type: 'string'\n  },\n  tlsCRLFile: {\n    type: 'string'\n  },\n  tlsCertificateKeyFile: {\n    type: 'string'\n  },\n  tlsCertificateKeyFilePassword: {\n    target: 'passphrase',\n    type: 'any'\n  },\n  tlsInsecure: {\n    transform({ name, options, values: [value] }) {\n      const tlsInsecure = getBoolean(name, value);\n      if (tlsInsecure) {\n        options.checkServerIdentity = () => undefined;\n        options.rejectUnauthorized = false;\n      } else {\n        options.checkServerIdentity = options.tlsAllowInvalidHostnames\n          ? () => undefined\n          : undefined;\n        options.rejectUnauthorized = options.tlsAllowInvalidCertificates ? false : true;\n      }\n      return tlsInsecure;\n    }\n  },\n  w: {\n    target: 'writeConcern',\n    transform({ values: [value], options }) {\n      return WriteConcern.fromOptions({ writeConcern: { ...options.writeConcern, w: value as W } });\n    }\n  },\n  waitQueueTimeoutMS: {\n    // TODO(NODE-6491): deprecated: 'Please use timeoutMS instead',\n    default: 0,\n    type: 'uint'\n  },\n  writeConcern: {\n    target: 'writeConcern',\n    transform({ values: [value], options }) {\n      if (isRecord(value) || value instanceof WriteConcern) {\n        return WriteConcern.fromOptions({\n          writeConcern: {\n            ...options.writeConcern,\n            ...value\n          }\n        });\n      } else if (value === 'majority' || typeof value === 'number') {\n        return WriteConcern.fromOptions({\n          writeConcern: {\n            ...options.writeConcern,\n            w: value\n          }\n        });\n      }\n\n      throw new MongoParseError(`Invalid WriteConcern cannot parse: ${JSON.stringify(value)}`);\n    }\n  },\n  wtimeout: {\n    deprecated: 'Please use wtimeoutMS instead',\n    target: 'writeConcern',\n    transform({ values: [value], options }) {\n      const wc = WriteConcern.fromOptions({\n        writeConcern: {\n          ...options.writeConcern,\n          wtimeout: getUIntFromOptions('wtimeout', value)\n        }\n      });\n      if (wc) return wc;\n      throw new MongoParseError(`Cannot make WriteConcern from wtimeout`);\n    }\n  } as OptionDescriptor,\n  wtimeoutMS: {\n    target: 'writeConcern',\n    transform({ values: [value], options }) {\n      const wc = WriteConcern.fromOptions({\n        writeConcern: {\n          ...options.writeConcern,\n          wtimeoutMS: getUIntFromOptions('wtimeoutMS', value)\n        }\n      });\n      if (wc) return wc;\n      throw new MongoParseError(`Cannot make WriteConcern from wtimeout`);\n    }\n  },\n  zlibCompressionLevel: {\n    default: 0,\n    type: 'int'\n  },\n  mongodbLogPath: {\n    transform({ values: [value] }) {\n      if (\n        !(\n          (typeof value === 'string' && ['stderr', 'stdout'].includes(value)) ||\n          (value &&\n            typeof value === 'object' &&\n            'write' in value &&\n            typeof value.write === 'function')\n        )\n      ) {\n        throw new MongoAPIError(\n          `Option 'mongodbLogPath' must be of type 'stderr' | 'stdout' | MongoDBLogWritable`\n        );\n      }\n      return value;\n    }\n  },\n  mongodbLogComponentSeverities: {\n    transform({ values: [value] }) {\n      if (typeof value !== 'object' || !value) {\n        throw new MongoAPIError(`Option 'mongodbLogComponentSeverities' must be a non-null object`);\n      }\n      for (const [k, v] of Object.entries(value)) {\n        if (typeof v !== 'string' || typeof k !== 'string') {\n          throw new MongoAPIError(\n            `User input for option 'mongodbLogComponentSeverities' object cannot include a non-string key or value`\n          );\n        }\n        if (!Object.values(MongoLoggableComponent).some(val => val === k) && k !== 'default') {\n          throw new MongoAPIError(\n            `User input for option 'mongodbLogComponentSeverities' contains invalid key: ${k}`\n          );\n        }\n        if (!Object.values(SeverityLevel).some(val => val === v)) {\n          throw new MongoAPIError(\n            `Option 'mongodbLogComponentSeverities' does not support ${v} as a value for ${k}`\n          );\n        }\n      }\n      return value;\n    }\n  },\n  mongodbLogMaxDocumentLength: { type: 'uint' },\n  // Custom types for modifying core behavior\n  connectionType: { type: 'any' },\n  srvPoller: { type: 'any' },\n  // Accepted Node.js Options\n  allowPartialTrustChain: { type: 'any' },\n  minDHSize: { type: 'any' },\n  pskCallback: { type: 'any' },\n  secureContext: { type: 'any' },\n  enableTrace: { type: 'any' },\n  requestCert: { type: 'any' },\n  rejectUnauthorized: { type: 'any' },\n  checkServerIdentity: { type: 'any' },\n  keepAliveInitialDelay: { type: 'any' },\n  ALPNProtocols: { type: 'any' },\n  SNICallback: { type: 'any' },\n  session: { type: 'any' },\n  requestOCSP: { type: 'any' },\n  localAddress: { type: 'any' },\n  localPort: { type: 'any' },\n  hints: { type: 'any' },\n  lookup: { type: 'any' },\n  ca: { type: 'any' },\n  cert: { type: 'any' },\n  ciphers: { type: 'any' },\n  crl: { type: 'any' },\n  ecdhCurve: { type: 'any' },\n  key: { type: 'any' },\n  passphrase: { type: 'any' },\n  pfx: { type: 'any' },\n  secureProtocol: { type: 'any' },\n  index: { type: 'any' },\n  // Legacy options from v3 era\n  useNewUrlParser: {\n    type: 'boolean',\n    deprecated:\n      'useNewUrlParser has no effect since Node.js Driver version 4.0.0 and will be removed in the next major version'\n  } as OptionDescriptor,\n  useUnifiedTopology: {\n    type: 'boolean',\n    deprecated:\n      'useUnifiedTopology has no effect since Node.js Driver version 4.0.0 and will be removed in the next major version'\n  } as OptionDescriptor,\n  __skipPingOnConnect: { type: 'boolean' }\n} as Record<keyof MongoClientOptions, OptionDescriptor>;\n\nexport const DEFAULT_OPTIONS = new CaseInsensitiveMap(\n  Object.entries(OPTIONS)\n    .filter(([, descriptor]) => descriptor.default != null)\n    .map(([k, d]) => [k, d.default])\n);\n"],"names":[],"mappings":";;;;;AA4EA,QAAA,gBAAA,GAAA;AAqKA,QAAA,YAAA,GAAA;AAjPA,MAAA;AACA,MAAA;AACA,MAAA;AAGA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAMA,MAAA;AAQA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAEA,MAAA;AAUA,MAAA;AAEA,MAAM,oBAAoB;IAAC;IAAc;IAAc;CAAe;AAEtE,MAAM,uBAAuB;AAC7B,MAAM,uBAAuB;AAC7B,MAAM,6BACJ;AAIF,SAAS,mBACP,GAAgC;IAEhC,OAAO,eAAe,mBAAmB,aAAqB;QAC5D,IAAI;YACF,OAAO,MAAM,IAAI,QAAQ,CAAC,IAAI,CAAC;QACjC,EAAE,OAAO,eAAe;YACtB,IAAI,cAAc,IAAI,KAAK,IAAI,OAAO,EAAE;gBACtC,OAAO,MAAM,IAAI,QAAQ,CAAC,IAAI,CAAC;YACjC,OAAO;gBACL,MAAM;YACR;QACF;IACF;AACF;AAEA,MAAM,aAAa,mBAAmB;AACtC,MAAM,aAAa,mBAAmB;AAEtC;;;;;;IAOO,eAAe,iBAAiB,OAAqB;IAC1D,IAAI,OAAO,QAAQ,OAAO,KAAK,UAAU;QACvC,MAAM,IAAI,QAAA,aAAa,CAAC;IAC1B;IAEA,2EAA2E;IAC3E,iEAAiE;IACjE,MAAM,gBAAgB,QAAQ,OAAO;IACrC,MAAM,uBAAuB,WAAW;IAExC,qBAAqB,IAAI,CAAC,WAAW,QAAA,WAAW,GAAG,mCAAmC;IAEtF,MAAM,WAAW,CAAA,CAAA,EAAI,QAAQ,cAAc,CAAA,MAAA,EAAS,cAAa,CAAE;IACnE,gFAAgF;IAChF,MAAM,YAAY,MAAM,WAAW;IAEnC,IAAI,UAAU,MAAM,KAAK,GAAG;QAC1B,MAAM,IAAI,QAAA,aAAa,CAAC;IAC1B;IAEA,KAAK,MAAM,EAAE,IAAI,EAAE,IAAI,UAAW;QAChC,CAAA,GAAA,QAAA,sBAAsB,EAAC,MAAM;IAC/B;IAEA,MAAM,gBAAgB,UAAU,GAAG,CAAC,CAAA,IAAK,QAAA,WAAW,CAAC,UAAU,CAAC,CAAA,EAAG,EAAE,IAAI,CAAA,CAAA,EAAI,EAAE,IAAI,IAAI,MAAK,CAAE;IAE9F,4BAA4B,eAAe,SAAS;IAEpD,uFAAuF;IACvF,IAAI;IACJ,IAAI;QACF,SAAS,MAAM;IACjB,EAAE,OAAO,OAAO;QACd,IAAI,MAAM,IAAI,KAAK,aAAa,MAAM,IAAI,KAAK,aAAa;YAC1D,MAAM;QACR;QACA,OAAO;IACT;IAEA,IAAI,OAAO,MAAM,GAAG,GAAG;QACrB,MAAM,IAAI,QAAA,eAAe,CAAC;IAC5B;IAEA,MAAM,mBAAmB,IAAI,MAAA,eAAe,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC;IAC5D,MAAM,sBAAsB;WAAI,iBAAiB,IAAI;KAAG;IACxD,IAAI,oBAAoB,IAAI,CAAC,CAAA,MAAO,CAAC,kBAAkB,QAAQ,CAAC,OAAO;QACrE,MAAM,IAAI,QAAA,eAAe,CAAC,CAAA,iCAAA,EAAoC,kBAAkB,IAAI,CAAC,MAAK,CAAE;IAC9F;IAEA,IAAI,kBAAkB,IAAI,CAAC,CAAA,SAAU,iBAAiB,GAAG,CAAC,YAAY,KAAK;QACzE,MAAM,IAAI,QAAA,eAAe,CAAC;IAC5B;IAEA,MAAM,SAAS,iBAAiB,GAAG,CAAC,iBAAiB;IACrD,MAAM,aAAa,iBAAiB,GAAG,CAAC,iBAAiB;IACzD,MAAM,eAAe,iBAAiB,GAAG,CAAC,mBAAmB;IAE7D,IACE,CAAC,QAAQ,uBAAuB,IAChC,UACA,QAAQ,WAAW,IACnB,CAAC,YAAA,4BAA4B,CAAC,GAAG,CAAC,QAAQ,WAAW,CAAC,SAAS,GAC/D;QACA,QAAQ,WAAW,GAAG,oBAAA,gBAAgB,CAAC,KAAK,CAAC,QAAQ,WAAW,EAAE;YAAE;QAAM;IAC5E;IAEA,IAAI,CAAC,QAAQ,uBAAuB,IAAI,YAAY;QAClD,QAAQ,UAAU,GAAG;IACvB;IAEA,IAAI,iBAAiB,QAAQ;QAC3B,QAAQ,YAAY,GAAG;IACzB;IAEA,IAAI,QAAQ,UAAU,IAAI,QAAQ,WAAW,GAAG,GAAG;QACjD,MAAM,IAAI,QAAA,eAAe,CAAC;IAC5B;IAEA,4BAA4B,eAAe,SAAS;IAEpD,OAAO;AACT;AAEA;;;;;IAMA,SAAS,gBAAgB,UAA8B;IACrD,IAAI,CAAC,YAAY;IACjB,MAAM,QAAQ,CAAC,GAAW;QACxB,IAAI,WAAW,GAAG,CAAC,MAAM,WAAW,GAAG,CAAC,IAAI;YAC1C,MAAM,IAAI,QAAA,aAAa,CAAC,CAAA,KAAA,EAAQ,EAAC,kCAAA,EAAqC,EAAC,QAAA,CAAU;QACnF;IACF;IACA,MAAM,eAAe;IACrB,MAAM,eAAe;IACrB,MAAM,eAAe;IACrB,MAAM,eAAe;IACrB,MAAM,+BAA+B;IACrC,MAAM,+BAA+B;IACrC,MAAM,wCAAwC;AAChD;AACA,SAAS,WAAW,IAAY,EAAE,KAAc;IAC9C,IAAI,OAAO,UAAU,WAAW,OAAO;IACvC,OAAQ;QACN,KAAK;YACH,OAAO;QACT,KAAK;YACH,OAAO;QACT;YACE,MAAM,IAAI,QAAA,eAAe,CAAC,CAAA,EAAG,KAAI,iCAAA,CAAmC;IACxE;AACF;AAEA,SAAS,kBAAkB,IAAY,EAAE,KAAc;IACrD,MAAM,YAAY,CAAA,GAAA,QAAA,YAAY,EAAC;IAC/B,IAAI,aAAa,MAAM;QACrB,OAAO;IACT;IACA,MAAM,IAAI,QAAA,eAAe,CAAC,CAAA,SAAA,EAAY,KAAI,mCAAA,EAAsC,MAAK,CAAE;AACzF;AAEA,SAAS,mBAAmB,IAAY,EAAE,KAAc;IACtD,MAAM,cAAc,kBAAkB,MAAM;IAC5C,IAAI,cAAc,GAAG;QACnB,MAAM,IAAI,QAAA,eAAe,CAAC,CAAA,EAAG,KAAI,wCAAA,EAA2C,MAAK,CAAE;IACrF;IACA,OAAO;AACT;AAEA,UAAU,kBAAkB,KAAa;IACvC,IAAI,UAAU,IAAI;QAChB;IACF;IACA,MAAM,gBAAgB,MAAM,KAAK,CAAC;IAClC,KAAK,MAAM,YAAY,cAAe;QACpC,MAAM,CAAC,KAAK,MAAM,GAAG,SAAS,KAAK,CAAC;QACpC,IAAI,SAAS,MAAM;YACjB,MAAM,IAAI,QAAA,eAAe,CAAC;QAC5B;QAEA,MAAM;YAAC;YAAK;SAAM;IACpB;AACF;AAEA,MAAM,2BAAwC;IAC5C,YAAY,UAAgC,EAAE,CAAA;QAC5C,KAAK,CAAC,QAAQ,GAAG,CAAC,CAAC,CAAC,GAAG,EAAE,GAAK;gBAAC,EAAE,WAAW;gBAAI;aAAE;IACpD;IACS,IAAI,CAAS,EAAA;QACpB,OAAO,KAAK,CAAC,IAAI,EAAE,WAAW;IAChC;IACS,IAAI,CAAS,EAAA;QACpB,OAAO,KAAK,CAAC,IAAI,EAAE,WAAW;IAChC;IACS,IAAI,CAAS,EAAE,CAAM,EAAA;QAC5B,OAAO,KAAK,CAAC,IAAI,EAAE,WAAW,IAAI;IACpC;IACS,OAAO,CAAS,EAAA;QACvB,OAAO,KAAK,CAAC,OAAO,EAAE,WAAW;IACnC;;AAGF,SAAgB,aACd,GAAW,EACX,cAA4D,SAAS,EACrE,UAA8B,CAAA,CAAE;IAEhC,IAAI,eAAe,QAAQ,CAAC,CAAC,uBAAuB,eAAA,WAAW,GAAG;QAChE,UAAU;QACV,cAAc;IAChB;IAEA,uBAAuB;IACvB,IAAI,QAAQ,WAAW,IAAI,OAAO,QAAQ,YAAY,KAAK,aAAa,CAAC,QAAQ,YAAY,EAAE;QAC7F,MAAM,IAAI,QAAA,aAAa,CAAC;IAC1B;IAEA,IAAI,QAAQ,WAAW,IAAI,OAAO,QAAQ,aAAa,KAAK,aAAa,CAAC,QAAQ,aAAa,EAAE;QAC/F,MAAM,IAAI,QAAA,aAAa,CAAC;IAC1B;IAEA,MAAM,MAAM,IAAI,gCAAA,OAAgB,CAAC;IACjC,MAAM,EAAE,KAAK,EAAE,KAAK,EAAE,GAAG;IAEzB,MAAM,eAAe,OAAO,MAAM,CAAC;IAEnC,aAAa,KAAK,GAAG,QAAQ,EAAE,GAAG,MAAM,GAAG,CAAC,QAAA,WAAW,CAAC,UAAU;IAElE,MAAM,aAAa,IAAI;IAEvB,IAAI,IAAI,QAAQ,KAAK,OAAO,IAAI,QAAQ,KAAK,IAAI;QAC/C,MAAM,SAAS,mBACb,IAAI,QAAQ,CAAC,EAAE,KAAK,MAAM,IAAI,QAAQ,CAAC,KAAK,CAAC,KAAK,IAAI,QAAQ;QAEhE,IAAI,QAAQ;YACV,WAAW,GAAG,CAAC,UAAU;gBAAC;aAAO;QACnC;IACF;IAEA,IAAI,IAAI,QAAQ,KAAK,IAAI;QACvB,MAAM,OAAiB;YACrB,UAAU,mBAAmB,IAAI,QAAQ;;QAG3C,IAAI,OAAO,IAAI,QAAQ,KAAK,UAAU;YACpC,KAAK,QAAQ,GAAG,mBAAmB,IAAI,QAAQ;QACjD;QAEA,WAAW,GAAG,CAAC,QAAQ;YAAC;SAAK;IAC/B;IAEA,KAAK,MAAM,OAAO,IAAI,YAAY,CAAC,IAAI,GAAI;QACzC,MAAM,SAAS,IAAI,YAAY,CAAC,MAAM,CAAC;QAEvC,MAAM,uBAAuB,sBAAsB,IAAI,CAAC;QAExD,IAAI,CAAC,wBAAwB,OAAO,MAAM,GAAG,GAAG;YAC9C,MAAM,IAAI,QAAA,yBAAyB,CACjC,CAAA,YAAA,EAAe,IAAG,uDAAA,CAAyD;QAE/E;QAEA,IAAI,CAAC,wBAAwB,OAAO,QAAQ,CAAC,KAAK;YAChD,MAAM,IAAI,QAAA,aAAa,CAAC,CAAA,YAAA,EAAe,IAAG,mCAAA,CAAqC;QACjF;QAEA,IAAI,CAAC,WAAW,GAAG,CAAC,MAAM;YACxB,WAAW,GAAG,CAAC,KAAK;QACtB;IACF;IAEA,MAAM,gBAAgB,IAAI,mBACxB,OAAO,OAAO,CAAC,SAAS,MAAM,CAAC,CAAC,GAAG,EAAE,GAAK,KAAK;IAGjD,qEAAqE;IAErE,IAAI,WAAW,GAAG,CAAC,cAAc;QAC/B,MAAM,IAAI,QAAA,eAAe,CACvB;IAEJ;IAEA,MAAM,yBAAyB,WAAW,GAAG,CAAC;IAC9C,IAAI,wBAAwB;QAC1B,KAAK,MAAM,YAAY,uBAAwB;YAC7C,IAAI,sBAAsB,IAAI,CAAC,WAAqB;gBAClD,MAAM,IAAI,QAAA,eAAe,CACvB;YAEJ;QACF;IACF;IAEA,IAAI,cAAc,GAAG,CAAC,iBAAiB;QACrC,MAAM,IAAI,QAAA,eAAe,CAAC;IAC5B;IAEA,wBAAwB;IAExB,MAAM,qBAAqB,IAAI;IAE/B,MAAM,kBAAkB,IAAI,IAAY;WAAI,WAAW,IAAI;WAAO,cAAc,IAAI;KAAG;IAEvF,KAAK,MAAM,OAAO,gBAAiB;QACjC,MAAM,SAAS,EAAE;QACjB,MAAM,oBAAoB,cAAc,GAAG,CAAC;QAC5C,IAAI,qBAAqB,MAAM;YAC7B,OAAO,IAAI,CAAC;QACd;QAEA,MAAM,YAAY,WAAW,GAAG,CAAC,QAAQ,EAAE;QAC3C,OAAO,IAAI,IAAI;QACf,mBAAmB,GAAG,CAAC,KAAK;IAC9B;IAEA,IAAI,mBAAmB,GAAG,CAAC,UAAU,mBAAmB,GAAG,CAAC,QAAQ;QAClE,MAAM,gBAAgB,CAAC,mBAAmB,GAAG,CAAC,UAAU,EAAE,EACvD,MAAM,CAAC,mBAAmB,GAAG,CAAC,UAAU,EAAE,EAC1C,GAAG,CAAC,WAAW,IAAI,CAAC,MAAM;QAC7B,IAAI,IAAI,IAAI,eAAe,IAAI,KAAK,GAAG;YACrC,MAAM,IAAI,QAAA,eAAe,CAAC;QAC5B;IACF;IAEA,gBAAgB;IAEhB,MAAM,qBAAqB,CAAA,GAAA,QAAA,aAAa,EACtC,iBACA,MAAM,IAAI,CAAC,OAAO,IAAI,CAAC,QAAA,OAAO,GAAG,GAAG,CAAC,CAAA,IAAK,EAAE,WAAW;IAEzD,IAAI,mBAAmB,IAAI,KAAK,GAAG;QACjC,MAAM,aAAa,mBAAmB,IAAI,GAAG,IAAI,YAAY;QAC7D,MAAM,UAAU,mBAAmB,IAAI,GAAG,IAAI,QAAQ;QACtD,MAAM,IAAI,QAAA,eAAe,CACvB,CAAA,EAAG,WAAU,CAAA,EAAI,MAAM,IAAI,CAAC,oBAAoB,IAAI,CAAC,MAAK,CAAA,EAAI,QAAO,cAAA,CAAgB;IAEzF;IAEA,6BAA6B;IAE7B,KAAK,MAAM,CAAC,KAAK,WAAW,IAAI,OAAO,OAAO,CAAC,QAAA,OAAO,EAAG;QACvD,MAAM,SAAS,mBAAmB,GAAG,CAAC;QACtC,IAAI,CAAC,UAAU,OAAO,MAAM,KAAK,GAAG;YAClC,IAAI,QAAA,eAAe,CAAC,GAAG,CAAC,MAAM;gBAC5B,UAAU,cAAc,KAAK,YAAY;oBAAC,QAAA,eAAe,CAAC,GAAG,CAAC;iBAAK;YACrE;QACF,OAAO;YACL,MAAM,EAAE,UAAU,EAAE,GAAG;YACvB,IAAI,YAAY;gBACd,MAAM,gBAAgB,OAAO,eAAe,WAAW,CAAA,EAAA,EAAK,WAAU,CAAE,GAAG;gBAC3E,CAAA,GAAA,QAAA,WAAW,EAAC,CAAA,EAAG,IAAG,uBAAA,EAA0B,cAAa,CAAE;YAC7D;YAEA,UAAU,cAAc,KAAK,YAAY;QAC3C;IACF;IAEA,IAAI,aAAa,WAAW,EAAE;QAC5B,MAAM,WAAW,aAAa,WAAW,CAAC,SAAS,KAAK,YAAA,aAAa,CAAC,cAAc;QACpF,MAAM,SAAS,aAAa,WAAW,CAAC,SAAS,KAAK,YAAA,aAAa,CAAC,YAAY;QAChF,MAAM,QAAQ,aAAa,WAAW,CAAC,SAAS,KAAK,YAAA,aAAa,CAAC,WAAW;QAC9E,MAAM,SAAS,aAAa,WAAW,CAAC,SAAS,KAAK,YAAA,aAAa,CAAC,YAAY;QAChF,IACE,CAAC,YAAY,MAAM,KACnB,mBAAmB,GAAG,CAAC,iBACvB,aAAa,WAAW,CAAC,MAAM,KAAK,aACpC;YACA,iEAAiE;YACjE,MAAM,IAAI,QAAA,eAAe,CACvB,CAAA,cAAA,EAAiB,aAAa,WAAW,CAAC,SAAS,CAAA,sCAAA,CAAwC;QAE/F;QAEA,IACE,CAAC,CAAC,YAAY,UAAU,SAAS,MAAM,KACvC,aAAa,MAAM,IACnB,CAAC,mBAAmB,GAAG,CAAC,eACxB;YACA,wEAAwE;YACxE,6CAA6C;YAC7C,aAAa,WAAW,GAAG,oBAAA,gBAAgB,CAAC,KAAK,CAAC,aAAa,WAAW,EAAE;gBAC1E,QAAQ,aAAa,MAAM;;QAE/B;QAEA,IAAI,SAAS,aAAa,WAAW,CAAC,QAAQ,IAAI,CAAC,aAAa,WAAW,CAAC,QAAQ,EAAE;YACpF,MAAM,IAAI,QAAA,4BAA4B,CACpC,CAAA,WAAA,EAAc,aAAa,WAAW,CAAC,SAAS,CAAA,kDAAA,CAAoD;QAExG;QAEA,aAAa,WAAW,CAAC,QAAQ;QAEjC,iGAAiG;QACjG,IACE,aAAa,WAAW,CAAC,QAAQ,KAAK,MACtC,aAAa,WAAW,CAAC,QAAQ,KAAK,MACtC,aAAa,WAAW,CAAC,SAAS,KAAK,YAAA,aAAa,CAAC,eAAe,IACpE,OAAO,IAAI,CAAC,aAAa,WAAW,CAAC,mBAAmB,EAAE,MAAM,KAAK,GACrE;YACA,OAAO,aAAa,WAAW;QACjC;IACF;IAEA,IAAI,CAAC,aAAa,MAAM,EAAE;QACxB,4EAA4E;QAC5E,aAAa,MAAM,GAAG;IACxB;IAEA,4BAA4B,OAAO,cAAc;IAEjD,IAAI,eAAe,aAAa,cAAc,EAAE;QAC9C,YAAA,SAAS,CAAC,kBAAkB;QAC5B,aAAa,SAAS,GAAG,IAAI,YAAA,SAAS,CAAC,aAAa,KAAK;QACzD,aAAa,aAAa,GAAG,aAAa,SAAS,CAAC,aAAa;IACnE;IAEA,gEAAgE;IAEhE,aAAa,uBAAuB,GAClC,cAAc,GAAG,CAAC,iBAAiB,WAAW,GAAG,CAAC;IACpD,aAAa,uBAAuB,GAClC,cAAc,GAAG,CAAC,iBAAiB,WAAW,GAAG,CAAC;IAEpD,IAAI,OAAO;QACT,yCAAyC;QACzC,aAAa,OAAO,GAAG,KAAK,CAAC,EAAE;QAE/B,IAAI,aAAa,gBAAgB,EAAE;YACjC,MAAM,IAAI,QAAA,aAAa,CAAC;QAC1B;QAEA,IAAI,aAAa,WAAW,GAAG,KAAK,OAAO,aAAa,UAAU,KAAK,UAAU;YAC/E,MAAM,IAAI,QAAA,eAAe,CAAC;QAC5B;QAEA,sEAAsE;QACtE,MAAM,qBAAqB,CAAC,cAAc,GAAG,CAAC,UAAU,CAAC,WAAW,GAAG,CAAC;QACxE,MAAM,qBAAqB,CAAC,cAAc,GAAG,CAAC,UAAU,CAAC,WAAW,GAAG,CAAC;QACxE,IAAI,sBAAsB,oBAAoB;YAC5C,aAAa,GAAG,GAAG;QACrB;IACF,OAAO;QACL,MAAM,0BACJ,WAAW,GAAG,CAAC,kBACf,cAAc,GAAG,CAAC,kBAClB,WAAW,GAAG,CAAC,qBACf,cAAc,GAAG,CAAC;QAEpB,IAAI,yBAAyB;YAC3B,MAAM,IAAI,QAAA,eAAe,CACvB;QAEJ;IACF;IAEA,IAAI,aAAa,gBAAgB,IAAI,aAAa,KAAK,CAAC,MAAM,KAAK,GAAG;QACpE,MAAM,IAAI,QAAA,eAAe,CAAC;IAC5B;IAEA,IACE,CAAC,aAAa,SAAS,IACvB,CAAC,aAAa,SAAS,IAAI,aAAa,aAAa,IAAI,aAAa,aAAa,GACnF;QACA,MAAM,IAAI,QAAA,eAAe,CAAC;IAC5B;IAEA,IACE,AAAC,aAAa,aAAa,IAAI,CAAC,aAAa,aAAa,IACzD,CAAC,aAAa,aAAa,IAAI,aAAa,aAAa,EAC1D;QACA,MAAM,IAAI,QAAA,eAAe,CAAC;IAC5B;IAEA,MAAM,eAAe;QAAC;QAAa;QAAa;QAAiB;KAAgB,CAAC,GAAG,CACnF,CAAA,MAAO,WAAW,GAAG,CAAC,QAAQ,EAAE;IAGlC,IAAI,aAAa,IAAI,CAAC,CAAA,UAAW,QAAQ,MAAM,GAAG,IAAI;QACpD,MAAM,IAAI,QAAA,eAAe,CACvB;IAEJ;IAEA,aAAa,kBAAkB,GAAG,eAAA,WAAW,CAAC,cAAc,CAC1D;QACE,qBAAqB,QAAQ,GAAG,CAAC,mBAAmB;QACpD,sBAAsB,QAAQ,GAAG,CAAC,oBAAoB;QACtD,8BAA8B,QAAQ,GAAG,CAAC,4BAA4B;QACtE,wBAAwB,QAAQ,GAAG,CAAC,sBAAsB;QAC1D,oBAAoB,QAAQ,GAAG,CAAC,kBAAkB;QAClD,iBAAiB,QAAQ,GAAG,CAAC,eAAe;QAC5C,iCAAiC,QAAQ,GAAG,CAAC,+BAA+B;QAC5E,kBAAkB,QAAQ,GAAG,CAAC,gBAAgB;OAEhD;QACE,gBAAgB,aAAa,cAAc;QAC3C,+BAA+B,aAAa,6BAA6B;QACzE,6BAA6B,aAAa,2BAA2B;;IAIzE,aAAa,QAAQ,GAAG,CAAA,GAAA,kBAAA,kBAAkB,EAAC;IAE3C,aAAa,gBAAgB,GAAG,CAAA,GAAA,kBAAA,oBAAoB,EAAC,aAAa,QAAQ,EAAE,IAAI,CAC9E,WACA,QAAA,WAAW,GACV,mCAAmC;IAEtC,OAAO;AACT;AAEA;;;;;;;;IASA,SAAS,4BACP,KAA+B,EAC/B,YAA0B,EAC1B,KAAc;IAEd,IAAI,aAAa,YAAY,EAAE;QAC7B,IAAI,MAAM,MAAM,GAAG,GAAG;YACpB,MAAM,IAAI,QAAA,eAAe,CAAC;QAC5B;QACA,IAAI,aAAa,UAAU,EAAE;YAC3B,MAAM,IAAI,QAAA,eAAe,CAAC;QAC5B;QACA,IAAI,aAAa,gBAAgB,EAAE;YACjC,MAAM,IAAI,QAAA,eAAe,CAAC;QAC5B;QAEA,IAAI,SAAS,aAAa,WAAW,GAAG,GAAG;YACzC,MAAM,IAAI,QAAA,eAAe,CAAC;QAC5B;IACF;IACA;AACF;AAEA,SAAS,UACP,YAAiB,EACjB,GAAW,EACX,UAA4B,EAC5B,MAAiB;IAEjB,MAAM,EAAE,MAAM,EAAE,IAAI,EAAE,SAAS,EAAE,GAAG;IACpC,MAAM,OAAO,UAAU;IAEvB,OAAQ;QACN,KAAK;YACH,YAAY,CAAC,KAAK,GAAG,WAAW,MAAM,MAAM,CAAC,EAAE;YAC/C;QACF,KAAK;YACH,YAAY,CAAC,KAAK,GAAG,kBAAkB,MAAM,MAAM,CAAC,EAAE;YACtD;QACF,KAAK;YACH,YAAY,CAAC,KAAK,GAAG,mBAAmB,MAAM,MAAM,CAAC,EAAE;YACvD;QACF,KAAK;YACH,IAAI,MAAM,CAAC,EAAE,IAAI,MAAM;gBACrB;YACF;YACA,gEAAgE;YAChE,YAAY,CAAC,KAAK,GAAG,OAAO,MAAM,CAAC,EAAE;YACrC;QACF,KAAK;YACH,IAAI,CAAC,CAAA,GAAA,QAAA,QAAQ,EAAC,MAAM,CAAC,EAAE,GAAG;gBACxB,MAAM,IAAI,QAAA,eAAe,CAAC,CAAA,EAAG,KAAI,kBAAA,CAAoB;YACvD;YACA,YAAY,CAAC,KAAK,GAAG,MAAM,CAAC,EAAE;YAC9B;QACF,KAAK;YACH,YAAY,CAAC,KAAK,GAAG,MAAM,CAAC,EAAE;YAC9B;QACF;YAAS;gBACP,IAAI,CAAC,WAAW;oBACd,MAAM,IAAI,QAAA,eAAe,CAAC;gBAC5B;gBACA,MAAM,iBAAiB,UAAU;oBAAE;oBAAM,SAAS;oBAAc;gBAAM;gBACtE,YAAY,CAAC,KAAK,GAAG;gBACrB;YACF;IACF;AACF;AAgBa,QAAA,OAAO,GAAG;IACrB,SAAS;QACP,MAAM;;IAER,MAAM;QACJ,QAAQ;QACR,WAAU,EAAE,IAAI,EAAE,OAAO,EAAE,QAAQ,CAAC,MAAM,EAAE;YAC1C,IAAI,CAAC,CAAA,GAAA,QAAA,QAAQ,EAAC,OAAO;gBAAC;gBAAY;aAAoB,GAAG;gBACvD,MAAM,IAAI,QAAA,eAAe,CACvB,CAAA,EAAG,KAAI,4DAAA,CAA8D;YAEzE;YACA,OAAO,oBAAA,gBAAgB,CAAC,KAAK,CAAC,QAAQ,WAAW,EAAE;gBACjD,UAAU,MAAM,QAAQ;gBACxB,UAAU,MAAM,QAAQ;;QAE5B;;IAEF,eAAe;QACb,QAAQ;QACR,WAAU,EAAE,OAAO,EAAE,QAAQ,CAAC,MAAM,EAAE;YACpC,MAAM,aAAa,OAAO,MAAM,CAAC,YAAA,aAAa;YAC9C,MAAM,CAAC,UAAU,GAAG,WAAW,MAAM,CAAC,CAAA,IAAK,EAAE,KAAK,CAAC,OAAO,OAAO,GAAG,CAAA,EAAA,EAAK,MAAK,EAAA,CAAI,EAAE;YACpF,IAAI,CAAC,WAAW;gBACd,MAAM,IAAI,QAAA,eAAe,CAAC,CAAA,qBAAA,EAAwB,WAAU,MAAA,EAAS,MAAK,CAAE;YAC9E;YACA,IAAI,SAAS,QAAQ,WAAW,EAAE;YAClC,IACE,cAAc,YAAA,aAAa,CAAC,aAAa,IACzC,YAAA,4BAA4B,CAAC,GAAG,CAAC,YACjC;gBACA,sDAAsD;gBACtD,SAAS;YACX;YAEA,IAAI,WAAW,QAAQ,WAAW,EAAE;YACpC,IAAI,cAAc,YAAA,aAAa,CAAC,YAAY,IAAI,aAAa,IAAI;gBAC/D,WAAW;YACb;YACA,OAAO,oBAAA,gBAAgB,CAAC,KAAK,CAAC,QAAQ,WAAW,EAAE;gBACjD;gBACA;gBACA;;QAEJ;;IAEF,+EAA+E;IAC/E,6EAA6E;IAC7E,qBAAqB;IACrB,yBAAyB;QACvB,QAAQ;QACR,WAAU,EAAE,OAAO,EAAE,MAAM,EAAE;YAC3B,4EAA4E;YAC5E,2EAA2E;YAC3E,qEAAqE;YACrE,IAAI,sBAAsB,OAAO,MAAM,CAAC;YAExC,KAAK,MAAM,eAAe,OAAQ;gBAChC,IAAI,OAAO,gBAAgB,UAAU;oBACnC,KAAK,MAAM,CAAC,KAAK,MAAM,IAAI,kBAAkB,aAAc;wBACzD,IAAI;4BACF,mBAAmB,CAAC,IAAI,GAAG,WAAW,KAAK;wBAC7C,EAAE,OAAM;4BACN,mBAAmB,CAAC,IAAI,GAAG;wBAC7B;oBACF;gBACF,OAAO;oBACL,IAAI,CAAC,CAAA,GAAA,QAAA,QAAQ,EAAC,cAAc;wBAC1B,MAAM,IAAI,QAAA,eAAe,CAAC;oBAC5B;oBACA,sBAAsB;wBAAE,GAAG,WAAW;oBAAA;gBACxC;YACF;YACA,OAAO,oBAAA,gBAAgB,CAAC,KAAK,CAAC,QAAQ,WAAW,EAAE;gBACjD;;QAEJ;;IAEF,YAAY;QACV,QAAQ;QACR,WAAU,EAAE,OAAO,EAAE,QAAQ,CAAC,MAAM,EAAE;YACpC,MAAM,SAAS,OAAO;YACtB,OAAO,oBAAA,gBAAgB,CAAC,KAAK,CAAC,QAAQ,WAAW,EAAE;gBAAE;YAAM;QAC7D;;IAEF,gBAAgB;QACd,MAAM;;IAER,kBAAkB;QAChB,MAAM;QACN,SAAS;;IAEX,gCAAgC;QAC9B,MAAM;;IAER,YAAY;QACV,MAAM;;IAER,WAAW;QACT,QAAQ;QACR,WAAU,EAAE,QAAQ,CAAC,QAAQ,EAAE;YAC7B,MAAM,sBACJ,OAAO,YAAY,WAAY;gBAAE;YAAO,IAAoB;YAC9D,MAAM,oBAAoB,uBAAuB,oBAAoB,OAAO;YAC5E,IAAI,CAAC,mBAAmB;gBACtB,MAAM,IAAI,QAAA,eAAe,CACvB,CAAA,kFAAA,EAAqF,OAAO,MAAM,CAChG,eAAA,gBAAgB,EAChB,IAAI,CAAC,QAAO,EAAA,CAAI;YAEtB;YACA,IAAI,CAAC,OAAO,MAAM,CAAC,eAAA,gBAAgB,EAAE,IAAI,CAAC,CAAA,IAAK,MAAM,oBAAoB;gBACvE,MAAM,IAAI,QAAA,eAAe,CACvB,CAAA,2BAAA,EAA8B,kBAAiB,mCAAA,EAAsC,OAAO,MAAM,CAChG,eAAA,gBAAgB,EAChB,IAAI,CAAC,QAAO,EAAA,CAAI;YAEtB;YACA,OAAO;QACT;;IAEF,WAAW;QACT,MAAM;;IAER,aAAa;QACX,SAAS;QACT,QAAQ;QACR,WAAU,EAAE,MAAM,EAAE;YAClB,MAAM,kBAAkB,IAAI;YAC5B,KAAK,MAAM,WAAW,OAAyC;gBAC7D,MAAM,eAAe,OAAO,YAAY,WAAW,QAAQ,KAAK,CAAC,OAAO;gBACxE,IAAI,CAAC,MAAM,OAAO,CAAC,eAAe;oBAChC,MAAM,IAAI,QAAA,yBAAyB,CACjC;gBAEJ;gBACA,KAAK,MAAM,KAAK,aAAc;oBAC5B,IAAI,OAAO,IAAI,CAAC,cAAA,UAAU,EAAE,QAAQ,CAAC,OAAO,KAAK;wBAC/C,gBAAgB,GAAG,CAAC,OAAO;oBAC7B,OAAO;wBACL,MAAM,IAAI,QAAA,yBAAyB,CACjC,CAAA,EAAG,EAAC,uDAAA,EAA0D,OAAO,IAAI,CACvE,cAAA,UAAU,EACX,CAAA,CAAG;oBAER;gBACF;YACF;YACA,OAAO;mBAAI;aAAgB;QAC7B;;IAEF,kBAAkB;QAChB,SAAS;QACT,MAAM;;IAER,QAAQ;QACN,MAAM;;IAER,kBAAkB;QAChB,SAAS;QACT,MAAM;;IAER,YAAY;QACV,SAAS,CAAA;QACT,MAAM;;IAER,sBAAsB;QAAE,MAAM;QAAW,SAAS;IAAI;IACtD,QAAQ;QACN,WAAU,EAAE,IAAI,EAAE,QAAQ,CAAC,MAAM,EAAE;YACjC,MAAM,iBAAiB,kBAAkB,MAAM;YAC/C,IAAI,mBAAmB,KAAK,mBAAmB,GAAG;gBAChD,OAAO;YACT;YACA,MAAM,IAAI,QAAA,eAAe,CAAC,CAAA,mCAAA,EAAsC,eAAc,CAAA,CAAG;QACnF;;IAEF,aAAa;QACX,MAAM;;IAER,qBAAqB;QACnB,SAAS;QACT,MAAM;;IAER,OAAO;QACL,YAAY;QACZ,QAAQ;QACR,WAAU,EAAE,IAAI,EAAE,OAAO,EAAE,QAAQ,CAAC,MAAM,EAAE;YAC1C,MAAM,KAAK,gBAAA,YAAY,CAAC,WAAW,CAAC;gBAClC,cAAc;oBACZ,GAAG,QAAQ,YAAY;oBACvB,OAAO,WAAW,MAAM;;;YAG5B,IAAI,CAAC,IAAI,MAAM,IAAI,QAAA,eAAe,CAAC,CAAA,yCAAA,EAA4C,MAAK,CAAE;YACtF,OAAO;QACT;;IAEF,sBAAsB;QACpB,SAAS;QACT,MAAM;;IAER,iBAAiB;QACf,MAAM;;IAER,GAAG;QACD,YAAY;QACZ,QAAQ;QACR,WAAU,EAAE,IAAI,EAAE,OAAO,EAAE,QAAQ,CAAC,MAAM,EAAE;YAC1C,MAAM,KAAK,gBAAA,YAAY,CAAC,WAAW,CAAC;gBAClC,cAAc;oBACZ,GAAG,QAAQ,YAAY;oBACvB,SAAS,WAAW,MAAM;;;YAG9B,IAAI,CAAC,IAAI,MAAM,IAAI,QAAA,eAAe,CAAC,CAAA,2CAAA,EAA8C,MAAK,CAAE;YACxF,OAAO;QACT;;IAEF,SAAS;QACP,QAAQ;QACR,WAAU,EAAE,IAAI,EAAE,OAAO,EAAE,QAAQ,CAAC,MAAM,EAAE;YAC1C,MAAM,KAAK,gBAAA,YAAY,CAAC,WAAW,CAAC;gBAClC,cAAc;oBACZ,GAAG,QAAQ,YAAY;oBACvB,SAAS,WAAW,MAAM;;;YAG9B,IAAI,CAAC,IAAI,MAAM,IAAI,QAAA,eAAe,CAAC,CAAA,2CAAA,EAA8C,MAAK,CAAE;YACxF,OAAO;QACT;;IAEF,cAAc;QACZ,SAAS;QACT,MAAM;;IAER,kBAAkB;QAChB,SAAS;QACT,MAAM;;IAER,eAAe;QACb,SAAS;QACT,WAAU,EAAE,IAAI,EAAE,QAAQ,CAAC,MAAM,EAAE;YACjC,MAAM,gBAAgB,mBAAmB,MAAM;YAC/C,IAAI,kBAAkB,GAAG;gBACvB,MAAM,IAAI,QAAA,yBAAyB,CAAC;YACtC;YACA,OAAO;QACT;;IAEF,eAAe;QACb,SAAS;QACT,MAAM;;IAER,aAAa;QACX,SAAS;QACT,MAAM;;IAER,qBAAqB;QACnB,QAAQ;QACR,WAAU,EAAE,IAAI,EAAE,OAAO,EAAE,QAAQ,CAAC,MAAM,EAAE;YAC1C,MAAM,sBAAsB,mBAAmB,MAAM;YACrD,IAAI,QAAQ,cAAc,EAAE;gBAC1B,OAAO,kBAAA,cAAc,CAAC,WAAW,CAAC;oBAChC,gBAAgB;wBAAE,GAAG,QAAQ,cAAc;wBAAE;oBAAmB;;YAEpE,OAAO;gBACL,OAAO,IAAI,kBAAA,cAAc,CAAC,aAAa,WAAW;oBAAE;gBAAmB;YACzE;QACF;;IAEF,uBAAuB;QACrB,MAAM;;IAER,aAAa;QACX,SAAS;QACT,MAAM;;IAER,yBAAyB;QACvB,SAAS;QACT,MAAM;;IAER,iBAAiB;QACf,SAAS;QACT,MAAM;;IAER,MAAM;QACJ,QAAQ;QACR,WAAU,EAAE,QAAQ,CAAC,MAAM,EAAE,OAAO,EAAE;YACpC,OAAO;gBAAE,GAAG,QAAQ,UAAU;gBAAE,MAAM,OAAO;YAAM;QACrD;;IAEF,SAAS;QACP,SAAS;QACT,MAAM;;IAER,WAAW;QACT,SAAS,QAAA,kBAAkB;QAC3B,WAAU,EAAE,QAAQ,CAAC,MAAM,EAAE;YAC3B,IAAI,CAAA,GAAA,QAAA,QAAQ,EAAC,OAAO;gBAAC;aAAoB,KAAK,OAAO,MAAM,QAAQ,KAAK,YAAY;gBAClF,OAAO;YACT;YACA,MAAM,IAAI,QAAA,eAAe,CACvB,CAAA,iEAAA,EAAoE,MAAK,CAAE;QAE/E;;IAEF,gBAAgB;QACd,MAAM;;IAER,cAAc;QACZ,MAAM;;IAER,eAAe;QACb,MAAM;;IAER,aAAa;QACX,MAAM;;IAER,WAAW;QACT,MAAM;;IAER,eAAe;QACb,MAAM;;IAER,WAAW;QACT,MAAM;;IAER,eAAe;QACb,MAAM;;IAER,KAAK;QACH,SAAS;QACT,MAAM;;IAER,aAAa;QACX,WAAU,EAAE,QAAQ,CAAC,MAAM,EAAE,OAAO,EAAE;YACpC,IAAI,iBAAiB,eAAA,WAAW,IAAI,CAAA,GAAA,QAAA,QAAQ,EAAC,OAAO;gBAAC;aAAiB,GAAG;gBACvE,OAAO,eAAA,WAAW,CAAC,WAAW,CAAC;oBAAE,GAAG,QAAQ,WAAW;oBAAE,GAAG,KAAK;gBAAA;YACnE;YACA,MAAM,IAAI,QAAA,eAAe,CAAC,CAAA,mCAAA,EAAsC,KAAK,SAAS,CAAC,OAAM,CAAE;QACzF;;IAEF,kBAAkB;QAChB,QAAQ;QACR,WAAU,EAAE,QAAQ,CAAC,MAAM,EAAE,OAAO,EAAE;YACpC,OAAO,eAAA,WAAW,CAAC,WAAW,CAAC;gBAC7B,GAAG,QAAQ,WAAW;gBACtB,OAAO;;QAEX;;IAEF,gBAAgB;QACd,SAAS,kBAAA,cAAc,CAAC,OAAO;QAC/B,WAAU,EAAE,QAAQ,CAAC,MAAM,EAAE,OAAO,EAAE;YACpC,IAAI,iBAAiB,kBAAA,cAAc,EAAE;gBACnC,OAAO,kBAAA,cAAc,CAAC,WAAW,CAAC;oBAChC,gBAAgB;wBAAE,GAAG,QAAQ,cAAc;wBAAE,GAAG,KAAK;oBAAA;oBACrD,GAAG,KAAK;;YAEZ;YACA,IAAI,CAAA,GAAA,QAAA,QAAQ,EAAC,OAAO;gBAAC;aAAgB,GAAG;gBACtC,MAAM,KAAK,kBAAA,cAAc,CAAC,WAAW,CAAC;oBACpC,gBAAgB;wBAAE,GAAG,QAAQ,cAAc;wBAAE,GAAG,KAAK;oBAAA;oBACrD,GAAG,KAAK;;gBAEV,IAAI,IAAI,OAAO;qBACV,MAAM,IAAI,QAAA,eAAe,CAAC,CAAA,iCAAA,EAAoC,KAAK,SAAS,CAAC,OAAM,CAAE;YAC5F;YACA,IAAI,OAAO,UAAU,UAAU;gBAC7B,MAAM,SAAS;oBACb,OAAO,QAAQ,cAAc,EAAE;oBAC/B,qBAAqB,QAAQ,cAAc,EAAE;;gBAE/C,OAAO,IAAI,kBAAA,cAAc,CACvB,OACA,QAAQ,cAAc,EAAE,MACxB;YAEJ;YACA,MAAM,IAAI,QAAA,eAAe,CAAC,CAAA,8BAAA,EAAiC,MAAK,CAAE;QACpE;;IAEF,oBAAoB;QAClB,QAAQ;QACR,WAAU,EACR,MAAM,EACN,OAAO,EAIR;YACC,MAAM,OAA+C,MAAM,OAAO,CAAC,MAAM,CAAC,EAAE,IACxE,MAAM,CAAC,EAAE,GACR;YACL,MAAM,qBAAqB,EAAE;YAC7B,KAAK,MAAM,OAAO,KAAM;gBACtB,MAAM,oBAA4B,OAAO,MAAM,CAAC;gBAChD,IAAI,OAAO,QAAQ,UAAU;oBAC3B,KAAK,MAAM,CAAC,GAAG,EAAE,IAAI,kBAAkB,KAAM;wBAC3C,iBAAiB,CAAC,EAAE,GAAG;oBACzB;gBACF;gBACA,IAAI,CAAA,GAAA,QAAA,QAAQ,EAAC,MAAM;oBACjB,KAAK,MAAM,CAAC,GAAG,EAAE,IAAI,OAAO,OAAO,CAAC,KAAM;wBACxC,iBAAiB,CAAC,EAAE,GAAG;oBACzB;gBACF;gBACA,mBAAmB,IAAI,CAAC;YAC1B;YACA,OAAO,kBAAA,cAAc,CAAC,WAAW,CAAC;gBAChC,gBAAgB,QAAQ,cAAc;gBACtC;;QAEJ;;IAEF,YAAY;QACV,MAAM;;IAER,YAAY;QACV,SAAS;QACT,MAAM;;IAER,aAAa;QACX,SAAS;QACT,MAAM;;IAER,oBAAoB;QAClB,MAAM;;IAER,sBAAsB;QACpB,SAAS;QACT,WAAU,EAAE,QAAQ,CAAC,MAAM,EAAE;YAC3B,IAAI,CAAC,OAAO,MAAM,CAAC,UAAA,oBAAoB,EAAE,QAAQ,CAAC,QAAe;gBAC/D,MAAM,IAAI,QAAA,eAAe,CACvB;YAEJ;YACA,OAAO;QACT;;IAEF,0BAA0B;QACxB,SAAS;QACT,MAAM;;IAER,YAAY;QACV,MAAM;;IAER,iBAAiB;QACf,+DAA+D;QAC/D,SAAS;QACT,MAAM;;IAER,aAAa;QACX,MAAM;QACN,SAAS;;IAEX,gBAAgB;QACd,MAAM;QACN,SAAS;;IAEX,KAAK;QACH,QAAQ;QACR,MAAM;;IAER,WAAW;QACT,MAAM;;IAER,KAAK;QACH,MAAM;;IAER,6BAA6B;QAC3B,QAAQ;QACR,WAAU,EAAE,IAAI,EAAE,QAAQ,CAAC,MAAM,EAAE;YACjC,gEAAgE;YAChE,OAAO,CAAC,WAAW,MAAM;QAC3B;;IAEF,0BAA0B;QACxB,QAAQ;QACR,WAAU,EAAE,IAAI,EAAE,QAAQ,CAAC,MAAM,EAAE;YACjC,oFAAoF;YACpF,OAAO,WAAW,MAAM,SAAS,IAAM,YAAY;QACrD;;IAEF,WAAW;QACT,MAAM;;IAER,YAAY;QACV,MAAM;;IAER,uBAAuB;QACrB,MAAM;;IAER,+BAA+B;QAC7B,QAAQ;QACR,MAAM;;IAER,aAAa;QACX,WAAU,EAAE,IAAI,EAAE,OAAO,EAAE,QAAQ,CAAC,MAAM,EAAE;YAC1C,MAAM,cAAc,WAAW,MAAM;YACrC,IAAI,aAAa;gBACf,QAAQ,mBAAmB,GAAG,IAAM;gBACpC,QAAQ,kBAAkB,GAAG;YAC/B,OAAO;gBACL,QAAQ,mBAAmB,GAAG,QAAQ,wBAAwB,GAC1D,IAAM,YACN;gBACJ,QAAQ,kBAAkB,GAAG,QAAQ,2BAA2B,GAAG,QAAQ;YAC7E;YACA,OAAO;QACT;;IAEF,GAAG;QACD,QAAQ;QACR,WAAU,EAAE,QAAQ,CAAC,MAAM,EAAE,OAAO,EAAE;YACpC,OAAO,gBAAA,YAAY,CAAC,WAAW,CAAC;gBAAE,cAAc;oBAAE,GAAG,QAAQ,YAAY;oBAAE,GAAG;gBAAU;YAAE;QAC5F;;IAEF,oBAAoB;QAClB,+DAA+D;QAC/D,SAAS;QACT,MAAM;;IAER,cAAc;QACZ,QAAQ;QACR,WAAU,EAAE,QAAQ,CAAC,MAAM,EAAE,OAAO,EAAE;YACpC,IAAI,CAAA,GAAA,QAAA,QAAQ,EAAC,UAAU,iBAAiB,gBAAA,YAAY,EAAE;gBACpD,OAAO,gBAAA,YAAY,CAAC,WAAW,CAAC;oBAC9B,cAAc;wBACZ,GAAG,QAAQ,YAAY;wBACvB,GAAG,KAAK;;;YAGd,OAAO,IAAI,UAAU,cAAc,OAAO,UAAU,UAAU;gBAC5D,OAAO,gBAAA,YAAY,CAAC,WAAW,CAAC;oBAC9B,cAAc;wBACZ,GAAG,QAAQ,YAAY;wBACvB,GAAG;;;YAGT;YAEA,MAAM,IAAI,QAAA,eAAe,CAAC,CAAA,mCAAA,EAAsC,KAAK,SAAS,CAAC,OAAM,CAAE;QACzF;;IAEF,UAAU;QACR,YAAY;QACZ,QAAQ;QACR,WAAU,EAAE,QAAQ,CAAC,MAAM,EAAE,OAAO,EAAE;YACpC,MAAM,KAAK,gBAAA,YAAY,CAAC,WAAW,CAAC;gBAClC,cAAc;oBACZ,GAAG,QAAQ,YAAY;oBACvB,UAAU,mBAAmB,YAAY;;;YAG7C,IAAI,IAAI,OAAO;YACf,MAAM,IAAI,QAAA,eAAe,CAAC,CAAA,sCAAA,CAAwC;QACpE;;IAEF,YAAY;QACV,QAAQ;QACR,WAAU,EAAE,QAAQ,CAAC,MAAM,EAAE,OAAO,EAAE;YACpC,MAAM,KAAK,gBAAA,YAAY,CAAC,WAAW,CAAC;gBAClC,cAAc;oBACZ,GAAG,QAAQ,YAAY;oBACvB,YAAY,mBAAmB,cAAc;;;YAGjD,IAAI,IAAI,OAAO;YACf,MAAM,IAAI,QAAA,eAAe,CAAC,CAAA,sCAAA,CAAwC;QACpE;;IAEF,sBAAsB;QACpB,SAAS;QACT,MAAM;;IAER,gBAAgB;QACd,WAAU,EAAE,QAAQ,CAAC,MAAM,EAAE;YAC3B,IACE,CAAC,CACC,AAAC,OAAO,UAAU,YAAY;gBAAC;gBAAU;aAAS,CAAC,QAAQ,CAAC,UAC3D,SACC,OAAO,UAAU,YACjB,WAAW,SACX,OAAO,MAAM,KAAK,KAAK,UAAW,GAEtC;gBACA,MAAM,IAAI,QAAA,aAAa,CACrB,CAAA,gFAAA,CAAkF;YAEtF;YACA,OAAO;QACT;;IAEF,+BAA+B;QAC7B,WAAU,EAAE,QAAQ,CAAC,MAAM,EAAE;YAC3B,IAAI,OAAO,UAAU,YAAY,CAAC,OAAO;gBACvC,MAAM,IAAI,QAAA,aAAa,CAAC,CAAA,gEAAA,CAAkE;YAC5F;YACA,KAAK,MAAM,CAAC,GAAG,EAAE,IAAI,OAAO,OAAO,CAAC,OAAQ;gBAC1C,IAAI,OAAO,MAAM,YAAY,OAAO,MAAM,UAAU;oBAClD,MAAM,IAAI,QAAA,aAAa,CACrB,CAAA,qGAAA,CAAuG;gBAE3G;gBACA,IAAI,CAAC,OAAO,MAAM,CAAC,eAAA,sBAAsB,EAAE,IAAI,CAAC,CAAA,MAAO,QAAQ,MAAM,MAAM,WAAW;oBACpF,MAAM,IAAI,QAAA,aAAa,CACrB,CAAA,4EAAA,EAA+E,EAAC,CAAE;gBAEtF;gBACA,IAAI,CAAC,OAAO,MAAM,CAAC,eAAA,aAAa,EAAE,IAAI,CAAC,CAAA,MAAO,QAAQ,IAAI;oBACxD,MAAM,IAAI,QAAA,aAAa,CACrB,CAAA,wDAAA,EAA2D,EAAC,gBAAA,EAAmB,EAAC,CAAE;gBAEtF;YACF;YACA,OAAO;QACT;;IAEF,6BAA6B;QAAE,MAAM;IAAM;IAC3C,2CAA2C;IAC3C,gBAAgB;QAAE,MAAM;IAAK;IAC7B,WAAW;QAAE,MAAM;IAAK;IACxB,2BAA2B;IAC3B,wBAAwB;QAAE,MAAM;IAAK;IACrC,WAAW;QAAE,MAAM;IAAK;IACxB,aAAa;QAAE,MAAM;IAAK;IAC1B,eAAe;QAAE,MAAM;IAAK;IAC5B,aAAa;QAAE,MAAM;IAAK;IAC1B,aAAa;QAAE,MAAM;IAAK;IAC1B,oBAAoB;QAAE,MAAM;IAAK;IACjC,qBAAqB;QAAE,MAAM;IAAK;IAClC,uBAAuB;QAAE,MAAM;IAAK;IACpC,eAAe;QAAE,MAAM;IAAK;IAC5B,aAAa;QAAE,MAAM;IAAK;IAC1B,SAAS;QAAE,MAAM;IAAK;IACtB,aAAa;QAAE,MAAM;IAAK;IAC1B,cAAc;QAAE,MAAM;IAAK;IAC3B,WAAW;QAAE,MAAM;IAAK;IACxB,OAAO;QAAE,MAAM;IAAK;IACpB,QAAQ;QAAE,MAAM;IAAK;IACrB,IAAI;QAAE,MAAM;IAAK;IACjB,MAAM;QAAE,MAAM;IAAK;IACnB,SAAS;QAAE,MAAM;IAAK;IACtB,KAAK;QAAE,MAAM;IAAK;IAClB,WAAW;QAAE,MAAM;IAAK;IACxB,KAAK;QAAE,MAAM;IAAK;IAClB,YAAY;QAAE,MAAM;IAAK;IACzB,KAAK;QAAE,MAAM;IAAK;IAClB,gBAAgB;QAAE,MAAM;IAAK;IAC7B,OAAO;QAAE,MAAM;IAAK;IACpB,6BAA6B;IAC7B,iBAAiB;QACf,MAAM;QACN,YACE;;IAEJ,oBAAoB;QAClB,MAAM;QACN,YACE;;IAEJ,qBAAqB;QAAE,MAAM;IAAS;;AAG3B,QAAA,eAAe,GAAG,IAAI,mBACjC,OAAO,OAAO,CAAC,QAAA,OAAO,EACnB,MAAM,CAAC,CAAC,GAAG,WAAW,GAAK,WAAW,OAAO,IAAI,MACjD,GAAG,CAAC,CAAC,CAAC,GAAG,EAAE,GAAK;QAAC;QAAG,EAAE,OAAO;KAAC"}},
    {"offset": {"line": 12763, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 12767, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/mongo_client_auth_providers.ts"],"sourcesContent":["import { type AuthProvider } from './cmap/auth/auth_provider';\nimport { GSSAPI } from './cmap/auth/gssapi';\nimport { type AuthMechanismProperties } from './cmap/auth/mongo_credentials';\nimport { MongoDBAWS } from './cmap/auth/mongodb_aws';\nimport { MongoDBOIDC, OIDC_WORKFLOWS, type Workflow } from './cmap/auth/mongodb_oidc';\nimport { AutomatedCallbackWorkflow } from './cmap/auth/mongodb_oidc/automated_callback_workflow';\nimport { HumanCallbackWorkflow } from './cmap/auth/mongodb_oidc/human_callback_workflow';\nimport { TokenCache } from './cmap/auth/mongodb_oidc/token_cache';\nimport { Plain } from './cmap/auth/plain';\nimport { AuthMechanism } from './cmap/auth/providers';\nimport { ScramSHA1, ScramSHA256 } from './cmap/auth/scram';\nimport { X509 } from './cmap/auth/x509';\nimport { MongoInvalidArgumentError } from './error';\n\n/** @internal */\nconst AUTH_PROVIDERS = new Map<\n  AuthMechanism | string,\n  (authMechanismProperties: AuthMechanismProperties) => AuthProvider\n>([\n  [\n    AuthMechanism.MONGODB_AWS,\n    ({ AWS_CREDENTIAL_PROVIDER }) => new MongoDBAWS(AWS_CREDENTIAL_PROVIDER)\n  ],\n  [\n    AuthMechanism.MONGODB_CR,\n    () => {\n      throw new MongoInvalidArgumentError(\n        'MONGODB-CR is no longer a supported auth mechanism in MongoDB 4.0+'\n      );\n    }\n  ],\n  [AuthMechanism.MONGODB_GSSAPI, () => new GSSAPI()],\n  [AuthMechanism.MONGODB_OIDC, properties => new MongoDBOIDC(getWorkflow(properties))],\n  [AuthMechanism.MONGODB_PLAIN, () => new Plain()],\n  [AuthMechanism.MONGODB_SCRAM_SHA1, () => new ScramSHA1()],\n  [AuthMechanism.MONGODB_SCRAM_SHA256, () => new ScramSHA256()],\n  [AuthMechanism.MONGODB_X509, () => new X509()]\n]);\n\n/**\n * Create a set of providers per client\n * to avoid sharing the provider's cache between different clients.\n * @internal\n */\nexport class MongoClientAuthProviders {\n  private existingProviders: Map<AuthMechanism | string, AuthProvider> = new Map();\n\n  /**\n   * Get or create an authentication provider based on the provided mechanism.\n   * We don't want to create all providers at once, as some providers may not be used.\n   * @param name - The name of the provider to get or create.\n   * @param credentials - The credentials.\n   * @returns The provider.\n   * @throws MongoInvalidArgumentError if the mechanism is not supported.\n   * @internal\n   */\n  getOrCreateProvider(\n    name: AuthMechanism | string,\n    authMechanismProperties: AuthMechanismProperties\n  ): AuthProvider {\n    const authProvider = this.existingProviders.get(name);\n    if (authProvider) {\n      return authProvider;\n    }\n\n    const providerFunction = AUTH_PROVIDERS.get(name);\n    if (!providerFunction) {\n      throw new MongoInvalidArgumentError(`authMechanism ${name} not supported`);\n    }\n\n    const provider = providerFunction(authMechanismProperties);\n    this.existingProviders.set(name, provider);\n    return provider;\n  }\n}\n\n/**\n * Gets either a device workflow or callback workflow.\n */\nfunction getWorkflow(authMechanismProperties: AuthMechanismProperties): Workflow {\n  if (authMechanismProperties.OIDC_HUMAN_CALLBACK) {\n    return new HumanCallbackWorkflow(new TokenCache(), authMechanismProperties.OIDC_HUMAN_CALLBACK);\n  } else if (authMechanismProperties.OIDC_CALLBACK) {\n    return new AutomatedCallbackWorkflow(new TokenCache(), authMechanismProperties.OIDC_CALLBACK);\n  } else {\n    const environment = authMechanismProperties.ENVIRONMENT;\n    const workflow = OIDC_WORKFLOWS.get(environment)?.();\n    if (!workflow) {\n      throw new MongoInvalidArgumentError(\n        `Could not load workflow for environment ${authMechanismProperties.ENVIRONMENT}`\n      );\n    }\n    return workflow;\n  }\n}\n"],"names":[],"mappings":";;;;;AACA,MAAA;AAEA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AAEA,cAAA,GACA,MAAM,iBAAiB,IAAI,IAGzB;IACA;QACE,YAAA,aAAa,CAAC,WAAW;QACzB,CAAC,EAAE,uBAAuB,EAAE,GAAK,IAAI,cAAA,UAAU,CAAC;KACjD;IACD;QACE,YAAA,aAAa,CAAC,UAAU;QACxB;YACE,MAAM,IAAI,QAAA,yBAAyB,CACjC;QAEJ;KACD;IACD;QAAC,YAAA,aAAa,CAAC,cAAc;QAAE,IAAM,IAAI,SAAA,MAAM;KAAG;IAClD;QAAC,YAAA,aAAa,CAAC,YAAY;QAAE,CAAA,aAAc,IAAI,eAAA,WAAW,CAAC,YAAY;KAAa;IACpF;QAAC,YAAA,aAAa,CAAC,aAAa;QAAE,IAAM,IAAI,QAAA,KAAK;KAAG;IAChD;QAAC,YAAA,aAAa,CAAC,kBAAkB;QAAE,IAAM,IAAI,QAAA,SAAS;KAAG;IACzD;QAAC,YAAA,aAAa,CAAC,oBAAoB;QAAE,IAAM,IAAI,QAAA,WAAW;KAAG;IAC7D;QAAC,YAAA,aAAa,CAAC,YAAY;QAAE,IAAM,IAAI,OAAA,IAAI;KAAG;CAC/C;AAED;;;;IAKA,MAAa;IAAb,aAAA;QACU,IAAA,CAAA,iBAAiB,GAA8C,IAAI;IA6B7E;IA3BE;;;;;;;;QASA,oBACE,IAA4B,EAC5B,uBAAgD,EAAA;QAEhD,MAAM,eAAe,IAAI,CAAC,iBAAiB,CAAC,GAAG,CAAC;QAChD,IAAI,cAAc;YAChB,OAAO;QACT;QAEA,MAAM,mBAAmB,eAAe,GAAG,CAAC;QAC5C,IAAI,CAAC,kBAAkB;YACrB,MAAM,IAAI,QAAA,yBAAyB,CAAC,CAAA,cAAA,EAAiB,KAAI,cAAA,CAAgB;QAC3E;QAEA,MAAM,WAAW,iBAAiB;QAClC,IAAI,CAAC,iBAAiB,CAAC,GAAG,CAAC,MAAM;QACjC,OAAO;IACT;;AA7BF,QAAA,wBAAA,GAAA;AAgCA;;IAGA,SAAS,YAAY,uBAAgD;IACnE,IAAI,wBAAwB,mBAAmB,EAAE;QAC/C,OAAO,IAAI,0BAAA,qBAAqB,CAAC,IAAI,cAAA,UAAU,IAAI,wBAAwB,mBAAmB;IAChG,OAAO,IAAI,wBAAwB,aAAa,EAAE;QAChD,OAAO,IAAI,8BAAA,yBAAyB,CAAC,IAAI,cAAA,UAAU,IAAI,wBAAwB,aAAa;IAC9F,OAAO;QACL,MAAM,cAAc,wBAAwB,WAAW;QACvD,MAAM,WAAW,eAAA,cAAc,CAAC,GAAG,CAAC;QACpC,IAAI,CAAC,UAAU;YACb,MAAM,IAAI,QAAA,yBAAyB,CACjC,CAAA,wCAAA,EAA2C,wBAAwB,WAAW,CAAA,CAAE;QAEpF;QACA,OAAO;IACT;AACF"}},
    {"offset": {"line": 12866, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 12870, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/beta.ts"],"sourcesContent":["import { type Document } from './bson';\n\nexport * from './index';\n\n/**\n * @internal\n *\n * Since we don't bundle tslib helpers, we need to polyfill this method.\n *\n * This is used in the generated JS.  Adapted from https://github.com/microsoft/TypeScript/blob/aafdfe5b3f76f5c41abeec412ce73c86da94c75f/src/compiler/factory/emitHelpers.ts#L1202.\n */\n\nfunction __exportStar(mod: Document) {\n  for (const key of Object.keys(mod)) {\n    Object.defineProperty(exports, key, {\n      enumerable: true,\n      get: function () {\n        return mod[key];\n      }\n    });\n  }\n}\n"],"names":[],"mappings":";;;;AAEA,4GAAA;AAEA;;;;;;IAQA,SAAS,aAAa,GAAa;IACjC,KAAK,MAAM,OAAO,OAAO,IAAI,CAAC,KAAM;QAClC,OAAO,cAAc,CAAC,SAAS,KAAK;YAClC,YAAY;YACZ,KAAK;gBACH,OAAO,GAAG,CAAC,IAAI;YACjB;;IAEJ;AACF"}},
    {"offset": {"line": 12891, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 12895, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/mongo_client.ts"],"sourcesContent":["import { promises as fs } from 'fs';\nimport type { TcpNetConnectOpts } from 'net';\nimport type { ConnectionOptions as TLSConnectionOptions, TLSSocketOptions } from 'tls';\n\nimport { type BSONSerializeOptions, type Document, resolveBSONOptions } from './bson';\nimport { ChangeStream, type ChangeStreamDocument, type ChangeStreamOptions } from './change_stream';\nimport type { AutoEncrypter, AutoEncryptionOptions } from './client-side-encryption/auto_encrypter';\nimport {\n  type AuthMechanismProperties,\n  DEFAULT_ALLOWED_HOSTS,\n  type MongoCredentials\n} from './cmap/auth/mongo_credentials';\nimport { type TokenCache } from './cmap/auth/mongodb_oidc/token_cache';\nimport { AuthMechanism } from './cmap/auth/providers';\nimport type { LEGAL_TCP_SOCKET_OPTIONS, LEGAL_TLS_SOCKET_OPTIONS } from './cmap/connect';\nimport type { Connection } from './cmap/connection';\nimport type { ClientMetadata } from './cmap/handshake/client_metadata';\nimport type { CompressorName } from './cmap/wire_protocol/compression';\nimport { parseOptions, resolveSRVRecord } from './connection_string';\nimport { MONGO_CLIENT_EVENTS } from './constants';\nimport { type AbstractCursor } from './cursor/abstract_cursor';\nimport { Db, type DbOptions } from './db';\nimport type { Encrypter } from './encrypter';\nimport { MongoInvalidArgumentError } from './error';\nimport { MongoClientAuthProviders } from './mongo_client_auth_providers';\nimport {\n  type LogComponentSeveritiesClientOptions,\n  type MongoDBLogWritable,\n  MongoLogger,\n  type MongoLoggerOptions,\n  SeverityLevel\n} from './mongo_logger';\nimport { TypedEventEmitter } from './mongo_types';\nimport {\n  type ClientBulkWriteModel,\n  type ClientBulkWriteOptions,\n  type ClientBulkWriteResult\n} from './operations/client_bulk_write/common';\nimport { ClientBulkWriteExecutor } from './operations/client_bulk_write/executor';\nimport { executeOperation } from './operations/execute_operation';\nimport { RunAdminCommandOperation } from './operations/run_command';\nimport type { ReadConcern, ReadConcernLevel, ReadConcernLike } from './read_concern';\nimport { ReadPreference, type ReadPreferenceMode } from './read_preference';\nimport { type AsyncDisposable, configureResourceManagement } from './resource_management';\nimport type { ServerMonitoringMode } from './sdam/monitor';\nimport type { TagSet } from './sdam/server_description';\nimport { readPreferenceServerSelector } from './sdam/server_selection';\nimport type { SrvPoller } from './sdam/srv_polling';\nimport { Topology, type TopologyEvents } from './sdam/topology';\nimport { ClientSession, type ClientSessionOptions, ServerSessionPool } from './sessions';\nimport {\n  COSMOS_DB_CHECK,\n  COSMOS_DB_MSG,\n  DOCUMENT_DB_CHECK,\n  DOCUMENT_DB_MSG,\n  type HostAddress,\n  hostMatchesWildcards,\n  isHostMatch,\n  type MongoDBNamespace,\n  noop,\n  ns,\n  resolveOptions,\n  squashError\n} from './utils';\nimport type { W, WriteConcern, WriteConcernSettings } from './write_concern';\n\n/** @public */\nexport const ServerApiVersion = Object.freeze({\n  v1: '1'\n} as const);\n\n/** @public */\nexport type ServerApiVersion = (typeof ServerApiVersion)[keyof typeof ServerApiVersion];\n\n/** @public */\nexport interface ServerApi {\n  version: ServerApiVersion;\n  strict?: boolean;\n  deprecationErrors?: boolean;\n}\n\n/** @public */\nexport interface DriverInfo {\n  name?: string;\n  version?: string;\n  platform?: string;\n}\n\n/** @public */\nexport interface Auth {\n  /** The username for auth */\n  username?: string;\n  /** The password for auth */\n  password?: string;\n}\n\n/** @public */\nexport interface PkFactory {\n  createPk(): any;\n}\n\n/** @public */\nexport type SupportedTLSConnectionOptions = Pick<\n  TLSConnectionOptions & {\n    allowPartialTrustChain?: boolean;\n  },\n  (typeof LEGAL_TLS_SOCKET_OPTIONS)[number]\n>;\n\n/** @public */\nexport type SupportedTLSSocketOptions = Pick<\n  TLSSocketOptions,\n  Extract<keyof TLSSocketOptions, (typeof LEGAL_TLS_SOCKET_OPTIONS)[number]>\n>;\n\n/** @public */\nexport type SupportedSocketOptions = Pick<\n  TcpNetConnectOpts & {\n    autoSelectFamily?: boolean;\n    autoSelectFamilyAttemptTimeout?: number;\n    /** Node.JS socket option to set the time the first keepalive probe is sent on an idle socket. Defaults to 120000ms */\n    keepAliveInitialDelay?: number;\n  },\n  (typeof LEGAL_TCP_SOCKET_OPTIONS)[number]\n>;\n\n/** @public */\nexport type SupportedNodeConnectionOptions = SupportedTLSConnectionOptions &\n  SupportedTLSSocketOptions &\n  SupportedSocketOptions;\n\n/**\n * Describes all possible URI query options for the mongo client\n * @public\n * @see https://www.mongodb.com/docs/manual/reference/connection-string\n */\nexport interface MongoClientOptions extends BSONSerializeOptions, SupportedNodeConnectionOptions {\n  /** Specifies the name of the replica set, if the mongod is a member of a replica set. */\n  replicaSet?: string;\n  /**\n   * @experimental\n   * Specifies the time an operation will run until it throws a timeout error\n   */\n  timeoutMS?: number;\n  /** Enables or disables TLS/SSL for the connection. */\n  tls?: boolean;\n  /** A boolean to enable or disables TLS/SSL for the connection. (The ssl option is equivalent to the tls option.) */\n  ssl?: boolean;\n  /** Specifies the location of a local .pem file that contains either the client's TLS/SSL certificate and key. */\n  tlsCertificateKeyFile?: string;\n  /** Specifies the password to de-crypt the tlsCertificateKeyFile. */\n  tlsCertificateKeyFilePassword?: string;\n  /** Specifies the location of a local .pem file that contains the root certificate chain from the Certificate Authority. This file is used to validate the certificate presented by the mongod/mongos instance. */\n  tlsCAFile?: string;\n  /** Specifies the location of a local CRL .pem file that contains the client revokation list. */\n  tlsCRLFile?: string;\n  /** Bypasses validation of the certificates presented by the mongod/mongos instance */\n  tlsAllowInvalidCertificates?: boolean;\n  /** Disables hostname validation of the certificate presented by the mongod/mongos instance. */\n  tlsAllowInvalidHostnames?: boolean;\n  /** Disables various certificate validations. */\n  tlsInsecure?: boolean;\n  /** The time in milliseconds to attempt a connection before timing out. */\n  connectTimeoutMS?: number;\n  /** The time in milliseconds to attempt a send or receive on a socket before the attempt times out. */\n  socketTimeoutMS?: number;\n  /** An array or comma-delimited string of compressors to enable network compression for communication between this client and a mongod/mongos instance. */\n  compressors?: CompressorName[] | string;\n  /** An integer that specifies the compression level if using zlib for network compression. */\n  zlibCompressionLevel?: 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | undefined;\n  /** The maximum number of hosts to connect to when using an srv connection string, a setting of `0` means unlimited hosts */\n  srvMaxHosts?: number;\n  /**\n   * Modifies the srv URI to look like:\n   *\n   * `_{srvServiceName}._tcp.{hostname}.{domainname}`\n   *\n   * Querying this DNS URI is expected to respond with SRV records\n   */\n  srvServiceName?: string;\n  /** The maximum number of connections in the connection pool. */\n  maxPoolSize?: number;\n  /** The minimum number of connections in the connection pool. */\n  minPoolSize?: number;\n  /** The maximum number of connections that may be in the process of being established concurrently by the connection pool. */\n  maxConnecting?: number;\n  /** The maximum number of milliseconds that a connection can remain idle in the pool before being removed and closed. */\n  maxIdleTimeMS?: number;\n  /** The maximum time in milliseconds that a thread can wait for a connection to become available. */\n  waitQueueTimeoutMS?: number;\n  /** Specify a read concern for the collection (only MongoDB 3.2 or higher supported) */\n  readConcern?: ReadConcernLike;\n  /** The level of isolation */\n  readConcernLevel?: ReadConcernLevel;\n  /** Specifies the read preferences for this connection */\n  readPreference?: ReadPreferenceMode | ReadPreference;\n  /** Specifies, in seconds, how stale a secondary can be before the client stops using it for read operations. */\n  maxStalenessSeconds?: number;\n  /** Specifies the tags document as a comma-separated list of colon-separated key-value pairs.  */\n  readPreferenceTags?: TagSet[];\n  /** The auth settings for when connection to server. */\n  auth?: Auth;\n  /** Specify the database name associated with the users credentials. */\n  authSource?: string;\n  /** Specify the authentication mechanism that MongoDB will use to authenticate the connection. */\n  authMechanism?: AuthMechanism;\n  /** Specify properties for the specified authMechanism as a comma-separated list of colon-separated key-value pairs. */\n  authMechanismProperties?: AuthMechanismProperties;\n  /** The size (in milliseconds) of the latency window for selecting among multiple suitable MongoDB instances. */\n  localThresholdMS?: number;\n  /** Specifies how long (in milliseconds) to block for server selection before throwing an exception.  */\n  serverSelectionTimeoutMS?: number;\n  /** heartbeatFrequencyMS controls when the driver checks the state of the MongoDB deployment. Specify the interval (in milliseconds) between checks, counted from the end of the previous check until the beginning of the next one. */\n  heartbeatFrequencyMS?: number;\n  /** Sets the minimum heartbeat frequency. In the event that the driver has to frequently re-check a server's availability, it will wait at least this long since the previous check to avoid wasted effort. */\n  minHeartbeatFrequencyMS?: number;\n  /** The name of the application that created this MongoClient instance. MongoDB 3.4 and newer will print this value in the server log upon establishing each connection. It is also recorded in the slow query log and profile collections */\n  appName?: string;\n  /** Enables retryable reads. */\n  retryReads?: boolean;\n  /** Enable retryable writes. */\n  retryWrites?: boolean;\n  /** Allow a driver to force a Single topology type with a connection string containing one host */\n  directConnection?: boolean;\n  /** Instruct the driver it is connecting to a load balancer fronting a mongos like service */\n  loadBalanced?: boolean;\n  /**\n   * The write concern w value\n   * @deprecated Please use the `writeConcern` option instead\n   */\n  w?: W;\n  /**\n   * The write concern timeout\n   * @deprecated Please use the `writeConcern` option instead\n   */\n  wtimeoutMS?: number;\n  /**\n   * The journal write concern\n   * @deprecated Please use the `writeConcern` option instead\n   */\n  journal?: boolean;\n  /**\n   * A MongoDB WriteConcern, which describes the level of acknowledgement\n   * requested from MongoDB for write operations.\n   *\n   * @see https://www.mongodb.com/docs/manual/reference/write-concern/\n   */\n  writeConcern?: WriteConcern | WriteConcernSettings;\n  /** TCP Connection no delay */\n  noDelay?: boolean;\n  /** Force server to assign `_id` values instead of driver */\n  forceServerObjectId?: boolean;\n  /** A primary key factory function for generation of custom `_id` keys */\n  pkFactory?: PkFactory;\n  /** Enable command monitoring for this client */\n  monitorCommands?: boolean;\n  /** Server API version */\n  serverApi?: ServerApi | ServerApiVersion;\n  /**\n   * Optionally enable in-use auto encryption\n   *\n   * @remarks\n   *  Automatic encryption is an enterprise only feature that only applies to operations on a collection. Automatic encryption is not supported for operations on a database or view, and operations that are not bypassed will result in error\n   *  (see [libmongocrypt: Auto Encryption Allow-List](https://github.com/mongodb/specifications/blob/master/source/client-side-encryption/client-side-encryption.md#libmongocrypt-auto-encryption-allow-list)). To bypass automatic encryption for all operations, set bypassAutoEncryption=true in AutoEncryptionOpts.\n   *\n   *  Automatic encryption requires the authenticated user to have the [listCollections privilege action](https://www.mongodb.com/docs/manual/reference/command/listCollections/#dbcmd.listCollections).\n   *\n   *  If a MongoClient with a limited connection pool size (i.e a non-zero maxPoolSize) is configured with AutoEncryptionOptions, a separate internal MongoClient is created if any of the following are true:\n   *  - AutoEncryptionOptions.keyVaultClient is not passed.\n   *  - AutoEncryptionOptions.bypassAutomaticEncryption is false.\n   *\n   * If an internal MongoClient is created, it is configured with the same options as the parent MongoClient except minPoolSize is set to 0 and AutoEncryptionOptions is omitted.\n   */\n  autoEncryption?: AutoEncryptionOptions;\n  /** Allows a wrapping driver to amend the client metadata generated by the driver to include information about the wrapping driver */\n  driverInfo?: DriverInfo;\n  /** Configures a Socks5 proxy host used for creating TCP connections. */\n  proxyHost?: string;\n  /** Configures a Socks5 proxy port used for creating TCP connections. */\n  proxyPort?: number;\n  /** Configures a Socks5 proxy username when the proxy in proxyHost requires username/password authentication. */\n  proxyUsername?: string;\n  /** Configures a Socks5 proxy password when the proxy in proxyHost requires username/password authentication. */\n  proxyPassword?: string;\n  /** Instructs the driver monitors to use a specific monitoring mode */\n  serverMonitoringMode?: ServerMonitoringMode;\n  /**\n   * @public\n   * Specifies the destination of the driver's logging. The default is stderr.\n   */\n  mongodbLogPath?: 'stderr' | 'stdout' | MongoDBLogWritable;\n  /**\n   * @public\n   * Enable logging level per component or use `default` to control any unset components.\n   */\n  mongodbLogComponentSeverities?: LogComponentSeveritiesClientOptions;\n  /**\n   * @public\n   * All BSON documents are stringified to EJSON. This controls the maximum length of those strings.\n   * It is defaulted to 1000.\n   */\n  mongodbLogMaxDocumentLength?: number;\n\n  /** @internal */\n  srvPoller?: SrvPoller;\n  /** @internal */\n  connectionType?: typeof Connection;\n  /** @internal */\n  __skipPingOnConnect?: boolean;\n}\n\n/** @public */\nexport type WithSessionCallback<T = unknown> = (session: ClientSession) => Promise<T>;\n\n/** @internal */\nexport interface MongoClientPrivate {\n  url: string;\n  bsonOptions: BSONSerializeOptions;\n  namespace: MongoDBNamespace;\n  hasBeenClosed: boolean;\n  authProviders: MongoClientAuthProviders;\n  /**\n   * We keep a reference to the sessions that are acquired from the pool.\n   * - used to track and close all sessions in client.close() (which is non-standard behavior)\n   * - used to notify the leak checker in our tests if test author forgot to clean up explicit sessions\n   */\n  readonly activeSessions: Set<ClientSession>;\n  /**\n   * We keep a reference to the cursors that are created from this client.\n   * - used to track and close all cursors in client.close().\n   *   Cursors in this set are ones that still need to have their close method invoked (no other conditions are considered)\n   */\n  readonly activeCursors: Set<AbstractCursor>;\n  readonly sessionPool: ServerSessionPool;\n  readonly options: MongoOptions;\n  readonly readConcern?: ReadConcern;\n  readonly writeConcern?: WriteConcern;\n  readonly readPreference: ReadPreference;\n  readonly isMongoClient: true;\n}\n\n/** @public */\nexport type MongoClientEvents = Pick<TopologyEvents, (typeof MONGO_CLIENT_EVENTS)[number]> & {\n  // In previous versions the open event emitted a topology, in an effort to no longer\n  // expose internals but continue to expose this useful event API, it now emits a mongoClient\n  open(mongoClient: MongoClient): void;\n};\n\n/**\n * @public\n *\n * The **MongoClient** class is a class that allows for making Connections to MongoDB.\n *\n * **NOTE:** The programmatically provided options take precedence over the URI options.\n *\n * @remarks\n *\n * A MongoClient is the entry point to connecting to a MongoDB server.\n *\n * It handles a multitude of features on your application's behalf:\n * - **Server Host Connection Configuration**: A MongoClient is responsible for reading TLS cert, ca, and crl files if provided.\n * - **SRV Record Polling**: A \"`mongodb+srv`\" style connection string is used to have the MongoClient resolve DNS SRV records of all server hostnames which the driver periodically monitors for changes and adjusts its current view of hosts correspondingly.\n * - **Server Monitoring**: The MongoClient automatically keeps monitoring the health of server nodes in your cluster to reach out to the correct and lowest latency one available.\n * - **Connection Pooling**: To avoid paying the cost of rebuilding a connection to the server on every operation the MongoClient keeps idle connections preserved for reuse.\n * - **Session Pooling**: The MongoClient creates logical sessions that enable retryable writes, causal consistency, and transactions. It handles pooling these sessions for reuse in subsequent operations.\n * - **Cursor Operations**: A MongoClient's cursors use the health monitoring system to send the request for more documents to the same server the query began on.\n * - **Mongocryptd process**: When using auto encryption, a MongoClient will launch a `mongocryptd` instance for handling encryption if the mongocrypt shared library isn't in use.\n *\n * There are many more features of a MongoClient that are not listed above.\n *\n * In order to enable these features, a number of asynchronous Node.js resources are established by the driver: Timers, FS Requests, Sockets, etc.\n * For details on cleanup, please refer to the MongoClient `close()` documentation.\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n * // Enable command monitoring for debugging\n * const client = new MongoClient('mongodb://localhost:27017?appName=mflix', { monitorCommands: true });\n * ```\n */\nexport class MongoClient extends TypedEventEmitter<MongoClientEvents> implements AsyncDisposable {\n  /** @internal */\n  s: MongoClientPrivate;\n  /** @internal */\n  topology?: Topology;\n  /** @internal */\n  override readonly mongoLogger: MongoLogger | undefined;\n  /** @internal */\n  private connectionLock?: Promise<this>;\n  /** @internal */\n  private closeLock?: Promise<void>;\n\n  /**\n   * The consolidate, parsed, transformed and merged options.\n   */\n  public readonly options: Readonly<\n    Omit<MongoOptions, 'monitorCommands' | 'ca' | 'crl' | 'key' | 'cert'>\n  > &\n    Pick<MongoOptions, 'monitorCommands' | 'ca' | 'crl' | 'key' | 'cert'>;\n\n  constructor(url: string, options?: MongoClientOptions) {\n    super();\n    this.on('error', noop);\n\n    this.options = parseOptions(url, this, options);\n\n    const shouldSetLogger = Object.values(this.options.mongoLoggerOptions.componentSeverities).some(\n      value => value !== SeverityLevel.OFF\n    );\n    this.mongoLogger = shouldSetLogger\n      ? new MongoLogger(this.options.mongoLoggerOptions)\n      : undefined;\n\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\n    const client = this;\n\n    // The internal state\n    this.s = {\n      url,\n      bsonOptions: resolveBSONOptions(this.options),\n      namespace: ns('admin'),\n      hasBeenClosed: false,\n      sessionPool: new ServerSessionPool(this),\n      activeSessions: new Set(),\n      activeCursors: new Set(),\n      authProviders: new MongoClientAuthProviders(),\n\n      get options() {\n        return client.options;\n      },\n      get readConcern() {\n        return client.options.readConcern;\n      },\n      get writeConcern() {\n        return client.options.writeConcern;\n      },\n      get readPreference() {\n        return client.options.readPreference;\n      },\n      get isMongoClient(): true {\n        return true;\n      }\n    };\n    this.checkForNonGenuineHosts();\n  }\n\n  /**\n   * @beta\n   * @experimental\n   * An alias for {@link MongoClient.close|MongoClient.close()}.\n   */\n  declare [Symbol.asyncDispose]: () => Promise<void>;\n  /** @internal */\n  async asyncDispose() {\n    await this.close();\n  }\n\n  /** @internal */\n  private checkForNonGenuineHosts() {\n    const documentDBHostnames = this.options.hosts.filter((hostAddress: HostAddress) =>\n      isHostMatch(DOCUMENT_DB_CHECK, hostAddress.host)\n    );\n    const srvHostIsDocumentDB = isHostMatch(DOCUMENT_DB_CHECK, this.options.srvHost);\n\n    const cosmosDBHostnames = this.options.hosts.filter((hostAddress: HostAddress) =>\n      isHostMatch(COSMOS_DB_CHECK, hostAddress.host)\n    );\n    const srvHostIsCosmosDB = isHostMatch(COSMOS_DB_CHECK, this.options.srvHost);\n\n    if (documentDBHostnames.length !== 0 || srvHostIsDocumentDB) {\n      this.mongoLogger?.info('client', DOCUMENT_DB_MSG);\n    } else if (cosmosDBHostnames.length !== 0 || srvHostIsCosmosDB) {\n      this.mongoLogger?.info('client', COSMOS_DB_MSG);\n    }\n  }\n\n  get serverApi(): Readonly<ServerApi | undefined> {\n    return this.options.serverApi && Object.freeze({ ...this.options.serverApi });\n  }\n  /**\n   * Intended for APM use only\n   * @internal\n   */\n  get monitorCommands(): boolean {\n    return this.options.monitorCommands;\n  }\n  set monitorCommands(value: boolean) {\n    this.options.monitorCommands = value;\n  }\n\n  /** @internal */\n  get autoEncrypter(): AutoEncrypter | undefined {\n    return this.options.autoEncrypter;\n  }\n\n  get readConcern(): ReadConcern | undefined {\n    return this.s.readConcern;\n  }\n\n  get writeConcern(): WriteConcern | undefined {\n    return this.s.writeConcern;\n  }\n\n  get readPreference(): ReadPreference {\n    return this.s.readPreference;\n  }\n\n  get bsonOptions(): BSONSerializeOptions {\n    return this.s.bsonOptions;\n  }\n\n  get timeoutMS(): number | undefined {\n    return this.s.options.timeoutMS;\n  }\n\n  /**\n   * Executes a client bulk write operation, available on server 8.0+.\n   * @param models - The client bulk write models.\n   * @param options - The client bulk write options.\n   * @returns A ClientBulkWriteResult for acknowledged writes and ok: 1 for unacknowledged writes.\n   */\n  async bulkWrite<SchemaMap extends Record<string, Document> = Record<string, Document>>(\n    models: ReadonlyArray<ClientBulkWriteModel<SchemaMap>>,\n    options?: ClientBulkWriteOptions\n  ): Promise<ClientBulkWriteResult> {\n    if (this.autoEncrypter) {\n      throw new MongoInvalidArgumentError(\n        'MongoClient bulkWrite does not currently support automatic encryption.'\n      );\n    }\n    // We do not need schema type information past this point (\"as any\" is fine)\n    return await new ClientBulkWriteExecutor(\n      this,\n      models as any,\n      resolveOptions(this, options)\n    ).execute();\n  }\n\n  /**\n   * Connect to MongoDB using a url\n   *\n   * @remarks\n   * Calling `connect` is optional since the first operation you perform will call `connect` if it's needed.\n   * `timeoutMS` will bound the time any operation can take before throwing a timeout error.\n   * However, when the operation being run is automatically connecting your `MongoClient` the `timeoutMS` will not apply to the time taken to connect the MongoClient.\n   * This means the time to setup the `MongoClient` does not count against `timeoutMS`.\n   * If you are using `timeoutMS` we recommend connecting your client explicitly in advance of any operation to avoid this inconsistent execution time.\n   *\n   * @remarks\n   * The driver will look up corresponding SRV and TXT records if the connection string starts with `mongodb+srv://`.\n   * If those look ups throw a DNS Timeout error, the driver will retry the look up once.\n   *\n   * @see docs.mongodb.org/manual/reference/connection-string/\n   */\n  async connect(): Promise<this> {\n    if (this.connectionLock) {\n      return await this.connectionLock;\n    }\n\n    try {\n      this.connectionLock = this._connect();\n      await this.connectionLock;\n    } finally {\n      // release\n      this.connectionLock = undefined;\n    }\n\n    return this;\n  }\n\n  /**\n   * Create a topology to open the connection, must be locked to avoid topology leaks in concurrency scenario.\n   * Locking is enforced by the connect method.\n   *\n   * @internal\n   */\n  private async _connect(): Promise<this> {\n    if (this.topology && this.topology.isConnected()) {\n      return this;\n    }\n\n    const options = this.options;\n\n    if (options.tls) {\n      if (typeof options.tlsCAFile === 'string') {\n        options.ca ??= await fs.readFile(options.tlsCAFile);\n      }\n      if (typeof options.tlsCRLFile === 'string') {\n        options.crl ??= await fs.readFile(options.tlsCRLFile);\n      }\n      if (typeof options.tlsCertificateKeyFile === 'string') {\n        if (!options.key || !options.cert) {\n          const contents = await fs.readFile(options.tlsCertificateKeyFile);\n          options.key ??= contents;\n          options.cert ??= contents;\n        }\n      }\n    }\n    if (typeof options.srvHost === 'string') {\n      const hosts = await resolveSRVRecord(options);\n\n      for (const [index, host] of hosts.entries()) {\n        options.hosts[index] = host;\n      }\n    }\n\n    // It is important to perform validation of hosts AFTER SRV resolution, to check the real hostname,\n    // but BEFORE we even attempt connecting with a potentially not allowed hostname\n    if (options.credentials?.mechanism === AuthMechanism.MONGODB_OIDC) {\n      const allowedHosts =\n        options.credentials?.mechanismProperties?.ALLOWED_HOSTS || DEFAULT_ALLOWED_HOSTS;\n      const isServiceAuth = !!options.credentials?.mechanismProperties?.ENVIRONMENT;\n      if (!isServiceAuth) {\n        for (const host of options.hosts) {\n          if (!hostMatchesWildcards(host.toHostPort().host, allowedHosts)) {\n            throw new MongoInvalidArgumentError(\n              `Host '${host}' is not valid for OIDC authentication with ALLOWED_HOSTS of '${allowedHosts.join(\n                ','\n              )}'`\n            );\n          }\n        }\n      }\n    }\n\n    this.topology = new Topology(this, options.hosts, options);\n    // Events can be emitted before initialization is complete so we have to\n    // save the reference to the topology on the client ASAP if the event handlers need to access it\n\n    this.topology.once(Topology.OPEN, () => this.emit('open', this));\n\n    for (const event of MONGO_CLIENT_EVENTS) {\n      this.topology.on(event, (...args: any[]) => this.emit(event, ...(args as any)));\n    }\n\n    const topologyConnect = async () => {\n      try {\n        await this.topology?.connect(options);\n      } catch (error) {\n        this.topology?.close();\n        throw error;\n      }\n    };\n\n    if (this.autoEncrypter) {\n      await this.autoEncrypter?.init();\n      await topologyConnect();\n      await options.encrypter.connectInternalClient();\n    } else {\n      await topologyConnect();\n    }\n\n    return this;\n  }\n\n  /**\n   * Cleans up resources managed by the MongoClient.\n   *\n   * The close method clears and closes all resources whose lifetimes are managed by the MongoClient.\n   * Please refer to the `MongoClient` class documentation for a high level overview of the client's key features and responsibilities.\n   *\n   * **However,** the close method does not handle the cleanup of resources explicitly created by the user.\n   * Any user-created driver resource with its own `close()` method should be explicitly closed by the user before calling MongoClient.close().\n   * This method is written as a \"best effort\" attempt to leave behind the least amount of resources server-side when possible.\n   *\n   * The following list defines ideal preconditions and consequent pitfalls if they are not met.\n   * The MongoClient, ClientSession, Cursors and ChangeStreams all support [explicit resource management](https://www.typescriptlang.org/docs/handbook/release-notes/typescript-5-2.html).\n   * By using explicit resource management to manage the lifetime of driver resources instead of manually managing their lifetimes, the pitfalls outlined below can be avoided.\n   *\n   * The close method performs the following in the order listed:\n   * - Client-side:\n   *   - **Close in-use connections**: Any connections that are currently waiting on a response from the server will be closed.\n   *     This is performed _first_ to avoid reaching the next step (server-side clean up) and having no available connections to check out.\n   *     - _Ideal_: All operations have been awaited or cancelled, and the outcomes, regardless of success or failure, have been processed before closing the client servicing the operation.\n   *     - _Pitfall_: When `client.close()` is called and all connections are in use, after closing them, the client must create new connections for cleanup operations, which comes at the cost of new TLS/TCP handshakes and authentication steps.\n   * - Server-side:\n   *   - **Close active cursors**: All cursors that haven't been completed will have a `killCursor` operation sent to the server they were initialized on, freeing the server-side resource.\n   *     - _Ideal_: Cursors are explicitly closed or completed before `client.close()` is called.\n   *     - _Pitfall_: `killCursors` may have to build a new connection if the in-use closure ended all pooled connections.\n   *   - **End active sessions**: In-use sessions created with `client.startSession()` or `client.withSession()` or implicitly by the driver will have their `.endSession()` method called.\n   *     Contrary to the name of the method, `endSession()` returns the session to the client's pool of sessions rather than end them on the server.\n   *     - _Ideal_: Transaction outcomes are awaited and their corresponding explicit sessions are ended before `client.close()` is called.\n   *     - _Pitfall_: **This step aborts in-progress transactions**. It is advisable to observe the outcome of a transaction before closing your client.\n   *   - **End all pooled sessions**: The `endSessions` command with all session IDs the client has pooled is sent to the server to inform the cluster it can clean them up.\n   *     - _Ideal_: No user intervention is expected.\n   *     - _Pitfall_: None.\n   *\n   * The remaining shutdown is of the MongoClient resources that are intended to be entirely internal but is documented here as their existence relates to the JS event loop.\n   *\n   * - Client-side (again):\n   *   - **Stop all server monitoring**: Connections kept live for detecting cluster changes and roundtrip time measurements are shutdown.\n   *   - **Close all pooled connections**: Each server node in the cluster has a corresponding connection pool and all connections in the pool are closed. Any operations waiting to check out a connection will have an error thrown instead of a connection returned.\n   *   - **Clear out server selection queue**: Any operations that are in the process of waiting for a server to be selected will have an error thrown instead of a server returned.\n   *   - **Close encryption-related resources**: An internal MongoClient created for communicating with `mongocryptd` or other encryption purposes is closed. (Using this same method of course!)\n   *\n   * After the close method completes there should be no MongoClient related resources [ref-ed in Node.js' event loop](https://docs.libuv.org/en/v1.x/handle.html#reference-counting).\n   * This should allow Node.js to exit gracefully if MongoClient resources were the only active handles in the event loop.\n   *\n   * @param _force - currently an unused flag that has no effect. Defaults to `false`.\n   */\n  async close(_force = false): Promise<void> {\n    if (this.closeLock) {\n      return await this.closeLock;\n    }\n\n    try {\n      this.closeLock = this._close();\n      await this.closeLock;\n    } finally {\n      // release\n      this.closeLock = undefined;\n    }\n  }\n\n  /* @internal */\n  private async _close(): Promise<void> {\n    // There's no way to set hasBeenClosed back to false\n    Object.defineProperty(this.s, 'hasBeenClosed', {\n      value: true,\n      enumerable: true,\n      configurable: false,\n      writable: false\n    });\n\n    this.topology?.closeCheckedOutConnections();\n\n    const activeCursorCloses = Array.from(this.s.activeCursors, cursor => cursor.close());\n    this.s.activeCursors.clear();\n\n    await Promise.all(activeCursorCloses);\n\n    const activeSessionEnds = Array.from(this.s.activeSessions, session => session.endSession());\n    this.s.activeSessions.clear();\n\n    await Promise.all(activeSessionEnds);\n\n    if (this.topology == null) {\n      return;\n    }\n\n    // If we would attempt to select a server and get nothing back we short circuit\n    // to avoid the server selection timeout.\n    const selector = readPreferenceServerSelector(ReadPreference.primaryPreferred);\n    const topologyDescription = this.topology.description;\n    const serverDescriptions = Array.from(topologyDescription.servers.values());\n    const servers = selector(topologyDescription, serverDescriptions);\n    if (servers.length !== 0) {\n      const endSessions = Array.from(this.s.sessionPool.sessions, ({ id }) => id);\n      if (endSessions.length !== 0) {\n        try {\n          await executeOperation(\n            this,\n            new RunAdminCommandOperation(\n              { endSessions },\n              { readPreference: ReadPreference.primaryPreferred, noResponse: true }\n            )\n          );\n        } catch (error) {\n          squashError(error);\n        }\n      }\n    }\n\n    // clear out references to old topology\n    const topology = this.topology;\n    this.topology = undefined;\n\n    topology.close();\n\n    const { encrypter } = this.options;\n    if (encrypter) {\n      await encrypter.close(this);\n    }\n  }\n\n  /**\n   * Create a new Db instance sharing the current socket connections.\n   *\n   * @param dbName - The name of the database we want to use. If not provided, use database name from connection string.\n   * @param options - Optional settings for Db construction\n   */\n  db(dbName?: string, options?: DbOptions): Db {\n    options = options ?? {};\n\n    // Default to db from connection string if not provided\n    if (!dbName) {\n      dbName = this.s.options.dbName;\n    }\n\n    // Copy the options and add out internal override of the not shared flag\n    const finalOptions = Object.assign({}, this.options, options);\n\n    // Return the db object\n    const db = new Db(this, dbName, finalOptions);\n\n    // Return the database\n    return db;\n  }\n\n  /**\n   * Connect to MongoDB using a url\n   *\n   * @remarks\n   * Calling `connect` is optional since the first operation you perform will call `connect` if it's needed.\n   * `timeoutMS` will bound the time any operation can take before throwing a timeout error.\n   * However, when the operation being run is automatically connecting your `MongoClient` the `timeoutMS` will not apply to the time taken to connect the MongoClient.\n   * This means the time to setup the `MongoClient` does not count against `timeoutMS`.\n   * If you are using `timeoutMS` we recommend connecting your client explicitly in advance of any operation to avoid this inconsistent execution time.\n   *\n   * @remarks\n   * The programmatically provided options take precedence over the URI options.\n   *\n   * @remarks\n   * The driver will look up corresponding SRV and TXT records if the connection string starts with `mongodb+srv://`.\n   * If those look ups throw a DNS Timeout error, the driver will retry the look up once.\n   *\n   * @see https://www.mongodb.com/docs/manual/reference/connection-string/\n   */\n  static async connect(url: string, options?: MongoClientOptions): Promise<MongoClient> {\n    const client = new this(url, options);\n    return await client.connect();\n  }\n\n  /**\n   * Creates a new ClientSession. When using the returned session in an operation\n   * a corresponding ServerSession will be created.\n   *\n   * @remarks\n   * A ClientSession instance may only be passed to operations being performed on the same\n   * MongoClient it was started from.\n   */\n  startSession(options?: ClientSessionOptions): ClientSession {\n    const session = new ClientSession(\n      this,\n      this.s.sessionPool,\n      { explicit: true, ...options },\n      this.options\n    );\n    this.s.activeSessions.add(session);\n    session.once('ended', () => {\n      this.s.activeSessions.delete(session);\n    });\n    return session;\n  }\n\n  /**\n   * A convenience method for creating and handling the clean up of a ClientSession.\n   * The session will always be ended when the executor finishes.\n   *\n   * @param executor - An executor function that all operations using the provided session must be invoked in\n   * @param options - optional settings for the session\n   */\n  async withSession<T = any>(executor: WithSessionCallback<T>): Promise<T>;\n  async withSession<T = any>(\n    options: ClientSessionOptions,\n    executor: WithSessionCallback<T>\n  ): Promise<T>;\n  async withSession<T = any>(\n    optionsOrExecutor: ClientSessionOptions | WithSessionCallback<T>,\n    executor?: WithSessionCallback<T>\n  ): Promise<T> {\n    const options = {\n      // Always define an owner\n      owner: Symbol(),\n      // If it's an object inherit the options\n      ...(typeof optionsOrExecutor === 'object' ? optionsOrExecutor : {})\n    };\n\n    const withSessionCallback =\n      typeof optionsOrExecutor === 'function' ? optionsOrExecutor : executor;\n\n    if (withSessionCallback == null) {\n      throw new MongoInvalidArgumentError('Missing required callback parameter');\n    }\n\n    const session = this.startSession(options);\n\n    try {\n      return await withSessionCallback(session);\n    } finally {\n      try {\n        await session.endSession();\n      } catch (error) {\n        squashError(error);\n      }\n    }\n  }\n\n  /**\n   * Create a new Change Stream, watching for new changes (insertions, updates,\n   * replacements, deletions, and invalidations) in this cluster. Will ignore all\n   * changes to system collections, as well as the local, admin, and config databases.\n   *\n   * @remarks\n   * watch() accepts two generic arguments for distinct use cases:\n   * - The first is to provide the schema that may be defined for all the data within the current cluster\n   * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n   *\n   * @remarks\n   * When `timeoutMS` is configured for a change stream, it will have different behaviour depending\n   * on whether the change stream is in iterator mode or emitter mode. In both cases, a change\n   * stream will time out if it does not receive a change event within `timeoutMS` of the last change\n   * event.\n   *\n   * Note that if a change stream is consistently timing out when watching a collection, database or\n   * client that is being changed, then this may be due to the server timing out before it can finish\n   * processing the existing oplog. To address this, restart the change stream with a higher\n   * `timeoutMS`.\n   *\n   * If the change stream times out the initial aggregate operation to establish the change stream on\n   * the server, then the client will close the change stream. If the getMore calls to the server\n   * time out, then the change stream will be left open, but will throw a MongoOperationTimeoutError\n   * when in iterator mode and emit an error event that returns a MongoOperationTimeoutError in\n   * emitter mode.\n   *\n   * To determine whether or not the change stream is still open following a timeout, check the\n   * {@link ChangeStream.closed} getter.\n   *\n   * @example\n   * In iterator mode, if a next() call throws a timeout error, it will attempt to resume the change stream.\n   * The next call can just be retried after this succeeds.\n   * ```ts\n   * const changeStream = collection.watch([], { timeoutMS: 100 });\n   * try {\n   *     await changeStream.next();\n   * } catch (e) {\n   *     if (e instanceof MongoOperationTimeoutError && !changeStream.closed) {\n   *       await changeStream.next();\n   *     }\n   *     throw e;\n   * }\n   * ```\n   *\n   * @example\n   * In emitter mode, if the change stream goes `timeoutMS` without emitting a change event, it will\n   * emit an error event that returns a MongoOperationTimeoutError, but will not close the change\n   * stream unless the resume attempt fails. There is no need to re-establish change listeners as\n   * this will automatically continue emitting change events once the resume attempt completes.\n   *\n   * ```ts\n   * const changeStream = collection.watch([], { timeoutMS: 100 });\n   * changeStream.on('change', console.log);\n   * changeStream.on('error', e => {\n   *     if (e instanceof MongoOperationTimeoutError && !changeStream.closed) {\n   *         // do nothing\n   *     } else {\n   *         changeStream.close();\n   *     }\n   * });\n   * ```\n   * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n   * @param options - Optional settings for the command\n   * @typeParam TSchema - Type of the data being detected by the change stream\n   * @typeParam TChange - Type of the whole change stream document emitted\n   */\n  watch<\n    TSchema extends Document = Document,\n    TChange extends Document = ChangeStreamDocument<TSchema>\n  >(pipeline: Document[] = [], options: ChangeStreamOptions = {}): ChangeStream<TSchema, TChange> {\n    // Allow optionally not specifying a pipeline\n    if (!Array.isArray(pipeline)) {\n      options = pipeline;\n      pipeline = [];\n    }\n\n    return new ChangeStream<TSchema, TChange>(this, pipeline, resolveOptions(this, options));\n  }\n}\n\nconfigureResourceManagement(MongoClient.prototype);\n\n/**\n * Parsed Mongo Client Options.\n *\n * User supplied options are documented by `MongoClientOptions`.\n *\n * **NOTE:** The client's options parsing is subject to change to support new features.\n * This type is provided to aid with inspection of options after parsing, it should not be relied upon programmatically.\n *\n * Options are sourced from:\n * - connection string\n * - options object passed to the MongoClient constructor\n * - file system (ex. tls settings)\n * - environment variables\n * - DNS SRV records and TXT records\n *\n * Not all options may be present after client construction as some are obtained from asynchronous operations.\n *\n * @public\n */\nexport interface MongoOptions\n  extends Required<\n      Pick<\n        MongoClientOptions,\n        | 'autoEncryption'\n        | 'connectTimeoutMS'\n        | 'directConnection'\n        | 'driverInfo'\n        | 'forceServerObjectId'\n        | 'minHeartbeatFrequencyMS'\n        | 'heartbeatFrequencyMS'\n        | 'localThresholdMS'\n        | 'maxConnecting'\n        | 'maxIdleTimeMS'\n        | 'maxPoolSize'\n        | 'minPoolSize'\n        | 'monitorCommands'\n        | 'noDelay'\n        | 'pkFactory'\n        | 'raw'\n        | 'replicaSet'\n        | 'retryReads'\n        | 'retryWrites'\n        | 'serverSelectionTimeoutMS'\n        | 'socketTimeoutMS'\n        | 'srvMaxHosts'\n        | 'srvServiceName'\n        | 'tlsAllowInvalidCertificates'\n        | 'tlsAllowInvalidHostnames'\n        | 'tlsInsecure'\n        | 'waitQueueTimeoutMS'\n        | 'zlibCompressionLevel'\n      >\n    >,\n    SupportedNodeConnectionOptions {\n  appName?: string;\n  hosts: HostAddress[];\n  srvHost?: string;\n  credentials?: MongoCredentials;\n  readPreference: ReadPreference;\n  readConcern: ReadConcern;\n  loadBalanced: boolean;\n  directConnection: boolean;\n  serverApi: ServerApi;\n  compressors: CompressorName[];\n  writeConcern: WriteConcern;\n  dbName: string;\n  metadata: ClientMetadata;\n  /** @internal */\n  extendedMetadata: Promise<Document>;\n  /** @internal */\n  autoEncrypter?: AutoEncrypter;\n  /** @internal */\n  tokenCache?: TokenCache;\n  proxyHost?: string;\n  proxyPort?: number;\n  proxyUsername?: string;\n  proxyPassword?: string;\n  serverMonitoringMode: ServerMonitoringMode;\n  /** @internal */\n  connectionType?: typeof Connection;\n  /** @internal */\n  authProviders: MongoClientAuthProviders;\n  /** @internal */\n  encrypter: Encrypter;\n  /** @internal */\n  userSpecifiedAuthSource: boolean;\n  /** @internal */\n  userSpecifiedReplicaSet: boolean;\n\n  /**\n   * # NOTE ABOUT TLS Options\n   *\n   * If `tls` is provided as an option, it is equivalent to setting the `ssl` option.\n   *\n   * NodeJS native TLS options are passed through to the socket and retain their original types.\n   *\n   * ### Additional options:\n   *\n   * | nodejs native option  | driver spec equivalent option name            | driver option type |\n   * |:----------------------|:----------------------------------------------|:-------------------|\n   * | `ca`                  | `tlsCAFile`                                   | `string`           |\n   * | `crl`                 | `tlsCRLFile`                                  | `string`           |\n   * | `cert`                | `tlsCertificateKeyFile`                       | `string`           |\n   * | `key`                 | `tlsCertificateKeyFile`                       | `string`           |\n   * | `passphrase`          | `tlsCertificateKeyFilePassword`               | `string`           |\n   * | `rejectUnauthorized`  | `tlsAllowInvalidCertificates`                 | `boolean`          |\n   * | `checkServerIdentity` | `tlsAllowInvalidHostnames`                    | `boolean`          |\n   * | see note below        | `tlsInsecure`                                 | `boolean`          |\n   *\n   * If `tlsInsecure` is set to `true`, then it will set the node native options `checkServerIdentity`\n   * to a no-op and `rejectUnauthorized` to `false`.\n   *\n   * If `tlsInsecure` is set to `false`, then it will set the node native options `checkServerIdentity`\n   * to a no-op and `rejectUnauthorized` to the inverse value of `tlsAllowInvalidCertificates`. If\n   * `tlsAllowInvalidCertificates` is not set, then `rejectUnauthorized` will be set to `true`.\n   *\n   * ### Note on `tlsCAFile`, `tlsCertificateKeyFile` and `tlsCRLFile`\n   *\n   * The files specified by the paths passed in to the `tlsCAFile`, `tlsCertificateKeyFile` and `tlsCRLFile`\n   * fields are read lazily on the first call to `MongoClient.connect`. Once these files have been read and\n   * the `ca`, `cert`, `crl` and `key` fields are populated, they will not be read again on subsequent calls to\n   * `MongoClient.connect`. As a result, until the first call to `MongoClient.connect`, the `ca`,\n   * `cert`, `crl` and `key` fields will be undefined.\n   */\n  tls: boolean;\n  tlsCAFile?: string;\n  tlsCRLFile?: string;\n  tlsCertificateKeyFile?: string;\n\n  /**\n   * @internal\n   * TODO: NODE-5671 - remove internal flag\n   */\n  mongoLoggerOptions: MongoLoggerOptions;\n  /**\n   * @internal\n   * TODO: NODE-5671 - remove internal flag\n   */\n  mongodbLogPath?: 'stderr' | 'stdout' | MongoDBLogWritable;\n  timeoutMS?: number;\n  /** @internal */\n  __skipPingOnConnect?: boolean;\n}\n"],"names":[],"mappings":";;;;;AAAA,MAAA;AAIA,MAAA;AACA,MAAA;AAEA,MAAA;AAMA,MAAA;AAKA,MAAA;AACA,MAAA;AAEA,MAAA;AAEA,MAAA;AACA,MAAA;AACA,MAAA;AAOA,MAAA;AAMA,MAAA;AACA,MAAA;AACA,MAAA;AAEA,MAAA;AACA,MAAA;AAGA,MAAA;AAEA,MAAA;AACA,MAAA;AACA,MAAA;AAgBA,YAAA,GACa,QAAA,gBAAgB,GAAG,OAAO,MAAM,CAAC;IAC5C,IAAI;;AAwRN;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAgCA,MAAa,oBAAoB,cAAA,iBAAoC;IAoBnE,YAAY,GAAW,EAAE,OAA4B,CAAA;QACnD,KAAK;QACL,IAAI,CAAC,EAAE,CAAC,SAAS,QAAA,IAAI;QAErB,IAAI,CAAC,OAAO,GAAG,CAAA,GAAA,oBAAA,YAAY,EAAC,KAAK,IAAI,EAAE;QAEvC,MAAM,kBAAkB,OAAO,MAAM,CAAC,IAAI,CAAC,OAAO,CAAC,kBAAkB,CAAC,mBAAmB,EAAE,IAAI,CAC7F,CAAA,QAAS,UAAU,eAAA,aAAa,CAAC,GAAG;QAEtC,IAAI,CAAC,WAAW,GAAG,kBACf,IAAI,eAAA,WAAW,CAAC,IAAI,CAAC,OAAO,CAAC,kBAAkB,IAC/C;QAEJ,4DAA4D;QAC5D,MAAM,SAAS,IAAI;QAEnB,qBAAqB;QACrB,IAAI,CAAC,CAAC,GAAG;YACP;YACA,aAAa,CAAA,GAAA,OAAA,kBAAkB,EAAC,IAAI,CAAC,OAAO;YAC5C,WAAW,CAAA,GAAA,QAAA,EAAE,EAAC;YACd,eAAe;YACf,aAAa,IAAI,WAAA,iBAAiB,CAAC,IAAI;YACvC,gBAAgB,IAAI;YACpB,eAAe,IAAI;YACnB,eAAe,IAAI,8BAAA,wBAAwB;YAE3C,IAAI,WAAO;gBACT,OAAO,OAAO,OAAO;YACvB;YACA,IAAI,eAAW;gBACb,OAAO,OAAO,OAAO,CAAC,WAAW;YACnC;YACA,IAAI,gBAAY;gBACd,OAAO,OAAO,OAAO,CAAC,YAAY;YACpC;YACA,IAAI,kBAAc;gBAChB,OAAO,OAAO,OAAO,CAAC,cAAc;YACtC;YACA,IAAI,iBAAa;gBACf,OAAO;YACT;;QAEF,IAAI,CAAC,uBAAuB;IAC9B;IAQA,cAAA,GACA,MAAM,eAAY;QAChB,MAAM,IAAI,CAAC,KAAK;IAClB;IAEA,cAAA,GACQ,0BAAuB;QAC7B,MAAM,sBAAsB,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,cACrD,CAAA,GAAA,QAAA,WAAW,EAAC,QAAA,iBAAiB,EAAE,YAAY,IAAI;QAEjD,MAAM,sBAAsB,CAAA,GAAA,QAAA,WAAW,EAAC,QAAA,iBAAiB,EAAE,IAAI,CAAC,OAAO,CAAC,OAAO;QAE/E,MAAM,oBAAoB,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,cACnD,CAAA,GAAA,QAAA,WAAW,EAAC,QAAA,eAAe,EAAE,YAAY,IAAI;QAE/C,MAAM,oBAAoB,CAAA,GAAA,QAAA,WAAW,EAAC,QAAA,eAAe,EAAE,IAAI,CAAC,OAAO,CAAC,OAAO;QAE3E,IAAI,oBAAoB,MAAM,KAAK,KAAK,qBAAqB;YAC3D,IAAI,CAAC,WAAW,EAAE,KAAK,UAAU,QAAA,eAAe;QAClD,OAAO,IAAI,kBAAkB,MAAM,KAAK,KAAK,mBAAmB;YAC9D,IAAI,CAAC,WAAW,EAAE,KAAK,UAAU,QAAA,aAAa;QAChD;IACF;IAEA,IAAI,YAAS;QACX,OAAO,IAAI,CAAC,OAAO,CAAC,SAAS,IAAI,OAAO,MAAM,CAAC;YAAE,GAAG,IAAI,CAAC,OAAO,CAAC,SAAS;QAAA;IAC5E;IACA;;;QAIA,IAAI,kBAAe;QACjB,OAAO,IAAI,CAAC,OAAO,CAAC,eAAe;IACrC;IACA,IAAI,gBAAgB,KAAc,EAAA;QAChC,IAAI,CAAC,OAAO,CAAC,eAAe,GAAG;IACjC;IAEA,cAAA,GACA,IAAI,gBAAa;QACf,OAAO,IAAI,CAAC,OAAO,CAAC,aAAa;IACnC;IAEA,IAAI,cAAW;QACb,OAAO,IAAI,CAAC,CAAC,CAAC,WAAW;IAC3B;IAEA,IAAI,eAAY;QACd,OAAO,IAAI,CAAC,CAAC,CAAC,YAAY;IAC5B;IAEA,IAAI,iBAAc;QAChB,OAAO,IAAI,CAAC,CAAC,CAAC,cAAc;IAC9B;IAEA,IAAI,cAAW;QACb,OAAO,IAAI,CAAC,CAAC,CAAC,WAAW;IAC3B;IAEA,IAAI,YAAS;QACX,OAAO,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,SAAS;IACjC;IAEA;;;;;QAMA,MAAM,UACJ,MAAsD,EACtD,OAAgC,EAAA;QAEhC,IAAI,IAAI,CAAC,aAAa,EAAE;YACtB,MAAM,IAAI,QAAA,yBAAyB,CACjC;QAEJ;QACA,4EAA4E;QAC5E,OAAO,MAAM,IAAI,WAAA,uBAAuB,CACtC,IAAI,EACJ,QACA,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE,UACrB,OAAO;IACX;IAEA;;;;;;;;;;;;;;;QAgBA,MAAM,UAAO;QACX,IAAI,IAAI,CAAC,cAAc,EAAE;YACvB,OAAO,MAAM,IAAI,CAAC,cAAc;QAClC;QAEA,IAAI;YACF,IAAI,CAAC,cAAc,GAAG,IAAI,CAAC,QAAQ;YACnC,MAAM,IAAI,CAAC,cAAc;QAC3B,SAAU;YACR,UAAU;YACV,IAAI,CAAC,cAAc,GAAG;QACxB;QAEA,OAAO,IAAI;IACb;IAEA;;;;;QAMQ,MAAM,WAAQ;QACpB,IAAI,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,QAAQ,CAAC,WAAW,IAAI;YAChD,OAAO,IAAI;QACb;QAEA,MAAM,UAAU,IAAI,CAAC,OAAO;QAE5B,IAAI,QAAQ,GAAG,EAAE;YACf,IAAI,OAAO,QAAQ,SAAS,KAAK,UAAU;gBACzC,QAAQ,EAAE,KAAK,MAAM,KAAA,QAAE,CAAC,QAAQ,CAAC,QAAQ,SAAS;YACpD;YACA,IAAI,OAAO,QAAQ,UAAU,KAAK,UAAU;gBAC1C,QAAQ,GAAG,KAAK,MAAM,KAAA,QAAE,CAAC,QAAQ,CAAC,QAAQ,UAAU;YACtD;YACA,IAAI,OAAO,QAAQ,qBAAqB,KAAK,UAAU;gBACrD,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,IAAI,EAAE;oBACjC,MAAM,WAAW,MAAM,KAAA,QAAE,CAAC,QAAQ,CAAC,QAAQ,qBAAqB;oBAChE,QAAQ,GAAG,KAAK;oBAChB,QAAQ,IAAI,KAAK;gBACnB;YACF;QACF;QACA,IAAI,OAAO,QAAQ,OAAO,KAAK,UAAU;YACvC,MAAM,QAAQ,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAAC;YAErC,KAAK,MAAM,CAAC,OAAO,KAAK,IAAI,MAAM,OAAO,GAAI;gBAC3C,QAAQ,KAAK,CAAC,MAAM,GAAG;YACzB;QACF;QAEA,mGAAmG;QACnG,gFAAgF;QAChF,IAAI,QAAQ,WAAW,EAAE,cAAc,YAAA,aAAa,CAAC,YAAY,EAAE;YACjE,MAAM,eACJ,QAAQ,WAAW,EAAE,qBAAqB,iBAAiB,oBAAA,qBAAqB;YAClF,MAAM,gBAAgB,CAAC,CAAC,QAAQ,WAAW,EAAE,qBAAqB;YAClE,IAAI,CAAC,eAAe;gBAClB,KAAK,MAAM,QAAQ,QAAQ,KAAK,CAAE;oBAChC,IAAI,CAAC,CAAA,GAAA,QAAA,oBAAoB,EAAC,KAAK,UAAU,GAAG,IAAI,EAAE,eAAe;wBAC/D,MAAM,IAAI,QAAA,yBAAyB,CACjC,CAAA,MAAA,EAAS,KAAI,8DAAA,EAAiE,aAAa,IAAI,CAC7F,KACD,CAAA,CAAG;oBAER;gBACF;YACF;QACF;QAEA,IAAI,CAAC,QAAQ,GAAG,IAAI,WAAA,QAAQ,CAAC,IAAI,EAAE,QAAQ,KAAK,EAAE;QAClD,wEAAwE;QACxE,gGAAgG;QAEhG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,WAAA,QAAQ,CAAC,IAAI,EAAE,IAAM,IAAI,CAAC,IAAI,CAAC,QAAQ,IAAI;QAE9D,KAAK,MAAM,SAAS,YAAA,mBAAmB,CAAE;YACvC,IAAI,CAAC,QAAQ,CAAC,EAAE,CAAC,OAAO,CAAC,GAAG,OAAgB,IAAI,CAAC,IAAI,CAAC,UAAW;QACnE;QAEA,MAAM,kBAAkB;YACtB,IAAI;gBACF,MAAM,IAAI,CAAC,QAAQ,EAAE,QAAQ;YAC/B,EAAE,OAAO,OAAO;gBACd,IAAI,CAAC,QAAQ,EAAE;gBACf,MAAM;YACR;QACF;QAEA,IAAI,IAAI,CAAC,aAAa,EAAE;YACtB,MAAM,IAAI,CAAC,aAAa,EAAE;YAC1B,MAAM;YACN,MAAM,QAAQ,SAAS,CAAC,qBAAqB;QAC/C,OAAO;YACL,MAAM;QACR;QAEA,OAAO,IAAI;IACb;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;QA6CA,MAAM,MAAM,SAAS,KAAK,EAAA;QACxB,IAAI,IAAI,CAAC,SAAS,EAAE;YAClB,OAAO,MAAM,IAAI,CAAC,SAAS;QAC7B;QAEA,IAAI;YACF,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,MAAM;YAC5B,MAAM,IAAI,CAAC,SAAS;QACtB,SAAU;YACR,UAAU;YACV,IAAI,CAAC,SAAS,GAAG;QACnB;IACF;IAEA,aAAA,GACQ,MAAM,SAAM;QAClB,oDAAoD;QACpD,OAAO,cAAc,CAAC,IAAI,CAAC,CAAC,EAAE,iBAAiB;YAC7C,OAAO;YACP,YAAY;YACZ,cAAc;YACd,UAAU;;QAGZ,IAAI,CAAC,QAAQ,EAAE;QAEf,MAAM,qBAAqB,MAAM,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,aAAa,EAAE,CAAA,SAAU,OAAO,KAAK;QAClF,IAAI,CAAC,CAAC,CAAC,aAAa,CAAC,KAAK;QAE1B,MAAM,QAAQ,GAAG,CAAC;QAElB,MAAM,oBAAoB,MAAM,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,cAAc,EAAE,CAAA,UAAW,QAAQ,UAAU;QACzF,IAAI,CAAC,CAAC,CAAC,cAAc,CAAC,KAAK;QAE3B,MAAM,QAAQ,GAAG,CAAC;QAElB,IAAI,IAAI,CAAC,QAAQ,IAAI,MAAM;YACzB;QACF;QAEA,+EAA+E;QAC/E,yCAAyC;QACzC,MAAM,WAAW,CAAA,GAAA,mBAAA,4BAA4B,EAAC,kBAAA,cAAc,CAAC,gBAAgB;QAC7E,MAAM,sBAAsB,IAAI,CAAC,QAAQ,CAAC,WAAW;QACrD,MAAM,qBAAqB,MAAM,IAAI,CAAC,oBAAoB,OAAO,CAAC,MAAM;QACxE,MAAM,UAAU,SAAS,qBAAqB;QAC9C,IAAI,QAAQ,MAAM,KAAK,GAAG;YACxB,MAAM,cAAc,MAAM,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,WAAW,CAAC,QAAQ,EAAE,CAAC,EAAE,EAAE,EAAE,GAAK;YACxE,IAAI,YAAY,MAAM,KAAK,GAAG;gBAC5B,IAAI;oBACF,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EACpB,IAAI,EACJ,IAAI,cAAA,wBAAwB,CAC1B;wBAAE;oBAAW,GACb;wBAAE,gBAAgB,kBAAA,cAAc,CAAC,gBAAgB;wBAAE,YAAY;oBAAI;gBAGzE,EAAE,OAAO,OAAO;oBACd,CAAA,GAAA,QAAA,WAAW,EAAC;gBACd;YACF;QACF;QAEA,uCAAuC;QACvC,MAAM,WAAW,IAAI,CAAC,QAAQ;QAC9B,IAAI,CAAC,QAAQ,GAAG;QAEhB,SAAS,KAAK;QAEd,MAAM,EAAE,SAAS,EAAE,GAAG,IAAI,CAAC,OAAO;QAClC,IAAI,WAAW;YACb,MAAM,UAAU,KAAK,CAAC,IAAI;QAC5B;IACF;IAEA;;;;;QAMA,GAAG,MAAe,EAAE,OAAmB,EAAA;QACrC,UAAU,WAAW,CAAA;QAErB,uDAAuD;QACvD,IAAI,CAAC,QAAQ;YACX,SAAS,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,MAAM;QAChC;QAEA,wEAAwE;QACxE,MAAM,eAAe,OAAO,MAAM,CAAC,CAAA,GAAI,IAAI,CAAC,OAAO,EAAE;QAErD,uBAAuB;QACvB,MAAM,KAAK,IAAI,KAAA,EAAE,CAAC,IAAI,EAAE,QAAQ;QAEhC,sBAAsB;QACtB,OAAO;IACT;IAEA;;;;;;;;;;;;;;;;;;QAmBA,aAAa,QAAQ,GAAW,EAAE,OAA4B,EAAA;QAC5D,MAAM,SAAS,IAAI,IAAI,CAAC,KAAK;QAC7B,OAAO,MAAM,OAAO,OAAO;IAC7B;IAEA;;;;;;;QAQA,aAAa,OAA8B,EAAA;QACzC,MAAM,UAAU,IAAI,WAAA,aAAa,CAC/B,IAAI,EACJ,IAAI,CAAC,CAAC,CAAC,WAAW,EAClB;YAAE,UAAU;YAAM,GAAG,OAAO;QAAA,GAC5B,IAAI,CAAC,OAAO;QAEd,IAAI,CAAC,CAAC,CAAC,cAAc,CAAC,GAAG,CAAC;QAC1B,QAAQ,IAAI,CAAC,SAAS;YACpB,IAAI,CAAC,CAAC,CAAC,cAAc,CAAC,MAAM,CAAC;QAC/B;QACA,OAAO;IACT;IAcA,MAAM,YACJ,iBAAgE,EAChE,QAAiC,EAAA;QAEjC,MAAM,UAAU;YACd,yBAAyB;YACzB,OAAO;YACP,wCAAwC;YACxC,GAAI,OAAO,sBAAsB,WAAW,oBAAoB,CAAA,CAAE;;QAGpE,MAAM,sBACJ,OAAO,sBAAsB,aAAa,oBAAoB;QAEhE,IAAI,uBAAuB,MAAM;YAC/B,MAAM,IAAI,QAAA,yBAAyB,CAAC;QACtC;QAEA,MAAM,UAAU,IAAI,CAAC,YAAY,CAAC;QAElC,IAAI;YACF,OAAO,MAAM,oBAAoB;QACnC,SAAU;YACR,IAAI;gBACF,MAAM,QAAQ,UAAU;YAC1B,EAAE,OAAO,OAAO;gBACd,CAAA,GAAA,QAAA,WAAW,EAAC;YACd;QACF;IACF;IAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;QAmEA,MAGE,WAAuB,EAAE,EAAE,UAA+B,CAAA,CAAE,EAAA;QAC5D,6CAA6C;QAC7C,IAAI,CAAC,MAAM,OAAO,CAAC,WAAW;YAC5B,UAAU;YACV,WAAW,EAAE;QACf;QAEA,OAAO,IAAI,gBAAA,YAAY,CAAmB,IAAI,EAAE,UAAU,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,EAAE;IACjF;;AA1kBF,QAAA,WAAA,GAAA;AA6kBA,CAAA,GAAA,sBAAA,2BAA2B,EAAC,YAAY,SAAS"}},
    {"offset": {"line": 13407, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 13411, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/resource_management.ts"],"sourcesContent":["/**\n * @public\n */\nexport interface AsyncDisposable {\n  /**\n   * @beta\n   * @experimental\n   */\n  [Symbol.asyncDispose](): Promise<void>;\n\n  /**\n   * @internal\n   *\n   * A method that wraps disposal semantics for a given resource in the class.\n   */\n  asyncDispose(): Promise<void>;\n}\n\n/** @internal */\nexport function configureResourceManagement(target: AsyncDisposable) {\n  Symbol.asyncDispose &&\n    Object.defineProperty(target, Symbol.asyncDispose, {\n      value: async function asyncDispose(this: AsyncDisposable) {\n        await this.asyncDispose();\n      },\n      enumerable: false,\n      configurable: true,\n      writable: true\n    });\n}\n\n/**\n * @beta\n * @experimental\n *\n * Attaches `Symbol.asyncDispose` methods to the MongoClient, Cursors, sessions and change streams\n * if Symbol.asyncDispose is defined.\n *\n * It's usually not necessary to call this method - the driver attempts to attach these methods\n * itself when its loaded.  However, sometimes the driver may be loaded before `Symbol.asyncDispose`\n * is defined, in which case it is necessary to call this method directly.  This can happen if the\n * application is polyfilling `Symbol.asyncDispose`.\n *\n * Example:\n *\n * ```typescript\n * import { configureExplicitResourceManagement, MongoClient } from 'mongodb/lib/beta';\n *\n * Symbol.asyncDispose ??= Symbol('dispose');\n * load();\n *\n * await using client = new MongoClient(...);\n * ```\n */\nexport function configureExplicitResourceManagement() {\n  // We must import lazily here, because there's a circular dependency between the resource management\n  // file and each resources' file.  We could move `configureResourceManagement` to a separate\n  // function, but keeping all resource-management related code together seemed preferable and I chose\n  // lazy requiring of resources instead.\n\n  // eslint-disable-next-line @typescript-eslint/no-require-imports\n  const { MongoClient } = require('./mongo_client');\n  // eslint-disable-next-line @typescript-eslint/no-require-imports\n  const { ClientSession } = require('./sessions');\n  // eslint-disable-next-line @typescript-eslint/no-require-imports\n  const { AbstractCursor } = require('./cursor/abstract_cursor');\n  // eslint-disable-next-line @typescript-eslint/no-require-imports\n  const { ChangeStream } = require('./change_stream');\n\n  configureResourceManagement(MongoClient.prototype);\n  configureResourceManagement(ClientSession.prototype);\n  configureResourceManagement(AbstractCursor.prototype);\n  configureResourceManagement(ChangeStream.prototype);\n}\n"],"names":[],"mappings":";;;;AAmBA,QAAA,2BAAA,GAAA;AAmCA,QAAA,mCAAA,GAAA;AApCA,cAAA,GACA,SAAgB,4BAA4B,MAAuB;IACjE,OAAO,YAAY,IACjB,OAAO,cAAc,CAAC,QAAQ,OAAO,YAAY,EAAE;QACjD,OAAO,eAAe;YACpB,MAAM,IAAI,CAAC,YAAY;QACzB;QACA,YAAY;QACZ,cAAc;QACd,UAAU;;AAEhB;AAEA;;;;;;;;;;;;;;;;;;;;;;IAuBA,SAAgB;IACd,oGAAoG;IACpG,4FAA4F;IAC5F,oGAAoG;IACpG,uCAAuC;IAEvC,iEAAiE;IACjE,MAAM,EAAE,WAAW,EAAE;IACrB,iEAAiE;IACjE,MAAM,EAAE,aAAa,EAAE;IACvB,iEAAiE;IACjE,MAAM,EAAE,cAAc,EAAE;IACxB,iEAAiE;IACjE,MAAM,EAAE,YAAY,EAAE;IAEtB,4BAA4B,YAAY,SAAS;IACjD,4BAA4B,cAAc,SAAS;IACnD,4BAA4B,eAAe,SAAS;IACpD,4BAA4B,aAAa,SAAS;AACpD"}},
    {"offset": {"line": 13467, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 13471, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/explain.ts"],"sourcesContent":["import { type Document } from './bson';\nimport { AbstractCursor } from './cursor/abstract_cursor';\nimport { MongoAPIError } from './error';\n\n/** @public */\nexport const ExplainVerbosity = Object.freeze({\n  queryPlanner: 'queryPlanner',\n  queryPlannerExtended: 'queryPlannerExtended',\n  executionStats: 'executionStats',\n  allPlansExecution: 'allPlansExecution'\n} as const);\n\n/** @public */\nexport type ExplainVerbosity = string;\n\n/**\n * For backwards compatibility, true is interpreted as \"allPlansExecution\"\n * and false as \"queryPlanner\".\n * @public\n */\nexport type ExplainVerbosityLike = ExplainVerbosity | boolean;\n\n/** @public */\nexport interface ExplainCommandOptions {\n  /** The explain verbosity for the command. */\n  verbosity: ExplainVerbosity;\n  /** The maxTimeMS setting for the command. */\n  maxTimeMS?: number;\n}\n\n/**\n * @public\n *\n * When set, this configures an explain command.  Valid values are boolean (for legacy compatibility,\n * see {@link ExplainVerbosityLike}), a string containing the explain verbosity, or an object containing the verbosity and\n * an optional maxTimeMS.\n *\n * Examples of valid usage:\n *\n * ```typescript\n * collection.find({ name: 'john doe' }, { explain: true });\n * collection.find({ name: 'john doe' }, { explain: false });\n * collection.find({ name: 'john doe' }, { explain: 'queryPlanner' });\n * collection.find({ name: 'john doe' }, { explain: { verbosity: 'queryPlanner' } });\n * ```\n *\n * maxTimeMS can be configured to limit the amount of time the server\n * spends executing an explain by providing an object:\n *\n * ```typescript\n * // limits the `explain` command to no more than 2 seconds\n * collection.find({ name: 'john doe' }, {\n *   explain:  {\n *    verbosity: 'queryPlanner',\n *    maxTimeMS: 2000\n *  }\n * });\n * ```\n */\nexport interface ExplainOptions {\n  /** Specifies the verbosity mode for the explain output. */\n  explain?: ExplainVerbosityLike | ExplainCommandOptions;\n}\n\n/** @internal */\nexport class Explain {\n  readonly verbosity: ExplainVerbosity;\n  readonly maxTimeMS?: number;\n\n  private constructor(verbosity: ExplainVerbosityLike, maxTimeMS?: number) {\n    if (typeof verbosity === 'boolean') {\n      this.verbosity = verbosity\n        ? ExplainVerbosity.allPlansExecution\n        : ExplainVerbosity.queryPlanner;\n    } else {\n      this.verbosity = verbosity;\n    }\n\n    this.maxTimeMS = maxTimeMS;\n  }\n\n  static fromOptions({ explain }: ExplainOptions = {}): Explain | undefined {\n    if (explain == null) return;\n\n    if (typeof explain === 'boolean' || typeof explain === 'string') {\n      return new Explain(explain);\n    }\n\n    const { verbosity, maxTimeMS } = explain;\n    return new Explain(verbosity, maxTimeMS);\n  }\n}\n\nexport function validateExplainTimeoutOptions(options: Document, explain?: Explain) {\n  const { maxTimeMS, timeoutMS } = options;\n  if (timeoutMS != null && (maxTimeMS != null || explain?.maxTimeMS != null)) {\n    throw new MongoAPIError('Cannot use maxTimeMS with timeoutMS for explain commands.');\n  }\n}\n\n/**\n * Applies an explain to a given command.\n * @internal\n *\n * @param command - the command on which to apply the explain\n * @param options - the options containing the explain verbosity\n */\nexport function decorateWithExplain(\n  command: Document,\n  explain: Explain\n): {\n  explain: Document;\n  verbosity: ExplainVerbosity;\n  maxTimeMS?: number;\n} {\n  type ExplainCommand = ReturnType<typeof decorateWithExplain>;\n  const { verbosity, maxTimeMS } = explain;\n  const baseCommand: ExplainCommand = { explain: command, verbosity };\n\n  if (typeof maxTimeMS === 'number') {\n    baseCommand.maxTimeMS = maxTimeMS;\n  }\n\n  return baseCommand;\n}\n\n/**\n * @public\n *\n * A base class for any cursors that have `explain()` methods.\n */\nexport abstract class ExplainableCursor<TSchema> extends AbstractCursor<TSchema> {\n  /** Execute the explain for the cursor */\n  abstract explain(): Promise<Document>;\n  abstract explain(verbosity: ExplainVerbosityLike | ExplainCommandOptions): Promise<Document>;\n  abstract explain(options: { timeoutMS?: number }): Promise<Document>;\n  abstract explain(\n    verbosity: ExplainVerbosityLike | ExplainCommandOptions,\n    options: { timeoutMS?: number }\n  ): Promise<Document>;\n  abstract explain(\n    verbosity?: ExplainVerbosityLike | ExplainCommandOptions | { timeoutMS?: number },\n    options?: { timeoutMS?: number }\n  ): Promise<Document>;\n\n  protected resolveExplainTimeoutOptions(\n    verbosity?: ExplainVerbosityLike | ExplainCommandOptions | { timeoutMS?: number },\n    options?: { timeoutMS?: number }\n  ): { timeout?: { timeoutMS?: number }; explain?: ExplainVerbosityLike | ExplainCommandOptions } {\n    let explain: ExplainVerbosityLike | ExplainCommandOptions | undefined;\n    let timeout: { timeoutMS?: number } | undefined;\n\n    if (verbosity == null && options == null) {\n      explain = undefined;\n      timeout = undefined;\n    } else if (verbosity != null && options == null) {\n      explain =\n        typeof verbosity !== 'object'\n          ? verbosity\n          : 'verbosity' in verbosity\n            ? verbosity\n            : undefined;\n\n      timeout = typeof verbosity === 'object' && 'timeoutMS' in verbosity ? verbosity : undefined;\n    } else {\n      // @ts-expect-error TS isn't smart enough to determine that if both options are provided, the first is explain options\n      explain = verbosity;\n      timeout = options;\n    }\n\n    return { timeout, explain };\n  }\n}\n"],"names":[],"mappings":";;;;;AA6FA,QAAA,6BAAA,GAAA;AAcA,QAAA,mBAAA,GAAA;AA1GA,MAAA;AACA,MAAA;AAEA,YAAA,GACa,QAAA,gBAAgB,GAAG,OAAO,MAAM,CAAC;IAC5C,cAAc;IACd,sBAAsB;IACtB,gBAAgB;IAChB,mBAAmB;;AAuDrB,cAAA,GACA,MAAa;IAIX,YAAoB,SAA+B,EAAE,SAAkB,CAAA;QACrE,IAAI,OAAO,cAAc,WAAW;YAClC,IAAI,CAAC,SAAS,GAAG,YACb,QAAA,gBAAgB,CAAC,iBAAiB,GAClC,QAAA,gBAAgB,CAAC,YAAY;QACnC,OAAO;YACL,IAAI,CAAC,SAAS,GAAG;QACnB;QAEA,IAAI,CAAC,SAAS,GAAG;IACnB;IAEA,OAAO,YAAY,EAAE,OAAO,EAAA,GAAqB,CAAA,CAAE,EAAA;QACjD,IAAI,WAAW,MAAM;QAErB,IAAI,OAAO,YAAY,aAAa,OAAO,YAAY,UAAU;YAC/D,OAAO,IAAI,QAAQ;QACrB;QAEA,MAAM,EAAE,SAAS,EAAE,SAAS,EAAE,GAAG;QACjC,OAAO,IAAI,QAAQ,WAAW;IAChC;;AAzBF,QAAA,OAAA,GAAA;AA4BA,SAAgB,8BAA8B,OAAiB,EAAE,OAAiB;IAChF,MAAM,EAAE,SAAS,EAAE,SAAS,EAAE,GAAG;IACjC,IAAI,aAAa,QAAQ,CAAC,aAAa,QAAQ,SAAS,aAAa,IAAI,GAAG;QAC1E,MAAM,IAAI,QAAA,aAAa,CAAC;IAC1B;AACF;AAEA;;;;;;IAOA,SAAgB,oBACd,OAAiB,EACjB,OAAgB;IAOhB,MAAM,EAAE,SAAS,EAAE,SAAS,EAAE,GAAG;IACjC,MAAM,cAA8B;QAAE,SAAS;QAAS;IAAS;IAEjE,IAAI,OAAO,cAAc,UAAU;QACjC,YAAY,SAAS,GAAG;IAC1B;IAEA,OAAO;AACT;AAEA;;;;IAKA,MAAsB,0BAAmC,kBAAA,cAAuB;IAcpE,6BACR,SAAiF,EACjF,OAAgC,EAAA;QAEhC,IAAI;QACJ,IAAI;QAEJ,IAAI,aAAa,QAAQ,WAAW,MAAM;YACxC,UAAU;YACV,UAAU;QACZ,OAAO,IAAI,aAAa,QAAQ,WAAW,MAAM;YAC/C,UACE,OAAO,cAAc,WACjB,YACA,eAAe,YACb,YACA;YAER,UAAU,OAAO,cAAc,YAAY,eAAe,YAAY,YAAY;QACpF,OAAO;YACL,sHAAsH;YACtH,UAAU;YACV,UAAU;QACZ;QAEA,OAAO;YAAE;YAAS;QAAO;IAC3B;;AAxCF,QAAA,iBAAA,GAAA"}},
    {"offset": {"line": 13554, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 13558, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/admin.ts"],"sourcesContent":["import { type Document, resolveBSONOptions } from './bson';\nimport type { Db } from './db';\nimport type { CommandOperationOptions } from './operations/command';\nimport { executeOperation } from './operations/execute_operation';\nimport {\n  ListDatabasesOperation,\n  type ListDatabasesOptions,\n  type ListDatabasesResult\n} from './operations/list_databases';\nimport { RemoveUserOperation, type RemoveUserOptions } from './operations/remove_user';\nimport { RunAdminCommandOperation, type RunCommandOptions } from './operations/run_command';\nimport {\n  ValidateCollectionOperation,\n  type ValidateCollectionOptions\n} from './operations/validate_collection';\n\n/** @internal */\nexport interface AdminPrivate {\n  db: Db;\n}\n\n/**\n * The **Admin** class is an internal class that allows convenient access to\n * the admin functionality and commands for MongoDB.\n *\n * **ADMIN Cannot directly be instantiated**\n * @public\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * const client = new MongoClient('mongodb://localhost:27017');\n * const admin = client.db().admin();\n * const dbInfo = await admin.listDatabases();\n * for (const db of dbInfo.databases) {\n *   console.log(db.name);\n * }\n * ```\n */\nexport class Admin {\n  /** @internal */\n  s: AdminPrivate;\n\n  /**\n   * Create a new Admin instance\n   * @internal\n   */\n  constructor(db: Db) {\n    this.s = { db };\n  }\n\n  /**\n   * Execute a command\n   *\n   * The driver will ensure the following fields are attached to the command sent to the server:\n   * - `lsid` - sourced from an implicit session or options.session\n   * - `$readPreference` - defaults to primary or can be configured by options.readPreference\n   * - `$db` - sourced from the name of this database\n   *\n   * If the client has a serverApi setting:\n   * - `apiVersion`\n   * - `apiStrict`\n   * - `apiDeprecationErrors`\n   *\n   * When in a transaction:\n   * - `readConcern` - sourced from readConcern set on the TransactionOptions\n   * - `writeConcern` - sourced from writeConcern set on the TransactionOptions\n   *\n   * Attaching any of the above fields to the command will have no effect as the driver will overwrite the value.\n   *\n   * @param command - The command to execute\n   * @param options - Optional settings for the command\n   */\n  async command(command: Document, options?: RunCommandOptions): Promise<Document> {\n    return await executeOperation(\n      this.s.db.client,\n      new RunAdminCommandOperation(command, {\n        ...resolveBSONOptions(options),\n        session: options?.session,\n        readPreference: options?.readPreference,\n        timeoutMS: options?.timeoutMS ?? this.s.db.timeoutMS\n      })\n    );\n  }\n\n  /**\n   * Retrieve the server build information\n   *\n   * @param options - Optional settings for the command\n   */\n  async buildInfo(options?: CommandOperationOptions): Promise<Document> {\n    return await this.command({ buildinfo: 1 }, options);\n  }\n\n  /**\n   * Retrieve the server build information\n   *\n   * @param options - Optional settings for the command\n   */\n  async serverInfo(options?: CommandOperationOptions): Promise<Document> {\n    return await this.command({ buildinfo: 1 }, options);\n  }\n\n  /**\n   * Retrieve this db's server status.\n   *\n   * @param options - Optional settings for the command\n   */\n  async serverStatus(options?: CommandOperationOptions): Promise<Document> {\n    return await this.command({ serverStatus: 1 }, options);\n  }\n\n  /**\n   * Ping the MongoDB server and retrieve results\n   *\n   * @param options - Optional settings for the command\n   */\n  async ping(options?: CommandOperationOptions): Promise<Document> {\n    return await this.command({ ping: 1 }, options);\n  }\n\n  /**\n   * Remove a user from a database\n   *\n   * @param username - The username to remove\n   * @param options - Optional settings for the command\n   */\n  async removeUser(username: string, options?: RemoveUserOptions): Promise<boolean> {\n    return await executeOperation(\n      this.s.db.client,\n      new RemoveUserOperation(this.s.db, username, { dbName: 'admin', ...options })\n    );\n  }\n\n  /**\n   * Validate an existing collection\n   *\n   * @param collectionName - The name of the collection to validate.\n   * @param options - Optional settings for the command\n   */\n  async validateCollection(\n    collectionName: string,\n    options: ValidateCollectionOptions = {}\n  ): Promise<Document> {\n    return await executeOperation(\n      this.s.db.client,\n      new ValidateCollectionOperation(this, collectionName, options)\n    );\n  }\n\n  /**\n   * List the available databases\n   *\n   * @param options - Optional settings for the command\n   */\n  async listDatabases(options?: ListDatabasesOptions): Promise<ListDatabasesResult> {\n    return await executeOperation(\n      this.s.db.client,\n      new ListDatabasesOperation(this.s.db, { timeoutMS: this.s.db.timeoutMS, ...options })\n    );\n  }\n\n  /**\n   * Get ReplicaSet status\n   *\n   * @param options - Optional settings for the command\n   */\n  async replSetGetStatus(options?: CommandOperationOptions): Promise<Document> {\n    return await this.command({ replSetGetStatus: 1 }, options);\n  }\n}\n"],"names":[],"mappings":";;;;;AAAA,MAAA;AAGA,MAAA;AACA,MAAA;AAKA,MAAA;AACA,MAAA;AACA,MAAA;AAUA;;;;;;;;;;;;;;;;;;IAmBA,MAAa;IAIX;;;QAIA,YAAY,EAAM,CAAA;QAChB,IAAI,CAAC,CAAC,GAAG;YAAE;QAAE;IACf;IAEA;;;;;;;;;;;;;;;;;;;;;QAsBA,MAAM,QAAQ,OAAiB,EAAE,OAA2B,EAAA;QAC1D,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,MAAM,EAChB,IAAI,cAAA,wBAAwB,CAAC,SAAS;YACpC,GAAG,CAAA,GAAA,OAAA,kBAAkB,EAAC,QAAQ;YAC9B,SAAS,SAAS;YAClB,gBAAgB,SAAS;YACzB,WAAW,SAAS,aAAa,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,SAAS;;IAG1D;IAEA;;;;QAKA,MAAM,UAAU,OAAiC,EAAA;QAC/C,OAAO,MAAM,IAAI,CAAC,OAAO,CAAC;YAAE,WAAW;QAAC,GAAI;IAC9C;IAEA;;;;QAKA,MAAM,WAAW,OAAiC,EAAA;QAChD,OAAO,MAAM,IAAI,CAAC,OAAO,CAAC;YAAE,WAAW;QAAC,GAAI;IAC9C;IAEA;;;;QAKA,MAAM,aAAa,OAAiC,EAAA;QAClD,OAAO,MAAM,IAAI,CAAC,OAAO,CAAC;YAAE,cAAc;QAAC,GAAI;IACjD;IAEA;;;;QAKA,MAAM,KAAK,OAAiC,EAAA;QAC1C,OAAO,MAAM,IAAI,CAAC,OAAO,CAAC;YAAE,MAAM;QAAC,GAAI;IACzC;IAEA;;;;;QAMA,MAAM,WAAW,QAAgB,EAAE,OAA2B,EAAA;QAC5D,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,MAAM,EAChB,IAAI,cAAA,mBAAmB,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,UAAU;YAAE,QAAQ;YAAS,GAAG,OAAO;QAAA;IAE9E;IAEA;;;;;QAMA,MAAM,mBACJ,cAAsB,EACtB,UAAqC,CAAA,CAAE,EAAA;QAEvC,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,MAAM,EAChB,IAAI,sBAAA,2BAA2B,CAAC,IAAI,EAAE,gBAAgB;IAE1D;IAEA;;;;QAKA,MAAM,cAAc,OAA8B,EAAA;QAChD,OAAO,MAAM,CAAA,GAAA,oBAAA,gBAAgB,EAC3B,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,MAAM,EAChB,IAAI,iBAAA,sBAAsB,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE;YAAE,WAAW,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,SAAS;YAAE,GAAG,OAAO;QAAA;IAEtF;IAEA;;;;QAKA,MAAM,iBAAiB,OAAiC,EAAA;QACtD,OAAO,MAAM,IAAI,CAAC,OAAO,CAAC;YAAE,kBAAkB;QAAC,GAAI;IACrD;;AAlIF,QAAA,KAAA,GAAA"}},
    {"offset": {"line": 13701, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 13705, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/gridfs/download.ts"],"sourcesContent":["import { Readable } from 'stream';\n\nimport type { Document, ObjectId } from '../bson';\nimport type { Collection } from '../collection';\nimport { CursorTimeoutMode } from '../cursor/abstract_cursor';\nimport type { FindCursor } from '../cursor/find_cursor';\nimport {\n  MongoGridFSChunkError,\n  MongoGridFSStreamError,\n  MongoInvalidArgumentError,\n  MongoRuntimeError\n} from '../error';\nimport type { FindOptions } from '../operations/find';\nimport type { ReadPreference } from '../read_preference';\nimport type { Sort } from '../sort';\nimport { CSOTTimeoutContext } from '../timeout';\nimport type { Callback } from '../utils';\nimport type { GridFSChunk } from './upload';\n\n/** @public */\nexport interface GridFSBucketReadStreamOptions {\n  sort?: Sort;\n  skip?: number;\n  /**\n   * 0-indexed non-negative byte offset from the beginning of the file\n   */\n  start?: number;\n  /**\n   * 0-indexed non-negative byte offset to the end of the file contents\n   * to be returned by the stream. `end` is non-inclusive\n   */\n  end?: number;\n  /**\n   * @experimental\n   * Specifies the time an operation will run until it throws a timeout error\n   */\n  timeoutMS?: number;\n}\n\n/** @public */\nexport interface GridFSBucketReadStreamOptionsWithRevision extends GridFSBucketReadStreamOptions {\n  /** The revision number relative to the oldest file with the given filename. 0\n   * gets you the oldest file, 1 gets you the 2nd oldest, -1 gets you the\n   * newest. */\n  revision?: number;\n}\n\n/** @public */\nexport interface GridFSFile {\n  _id: ObjectId;\n  length: number;\n  chunkSize: number;\n  filename: string;\n  metadata?: Document;\n  uploadDate: Date;\n  /** @deprecated Will be removed in the next major version. */\n  contentType?: string;\n  /** @deprecated Will be removed in the next major version. */\n  aliases?: string[];\n}\n\n/** @internal */\nexport interface GridFSBucketReadStreamPrivate {\n  /**\n   * The running total number of bytes read from the chunks collection.\n   */\n  bytesRead: number;\n  /**\n   * The number of bytes to remove from the last chunk read in the file.  This is non-zero\n   * if `end` is not equal to the length of the document and `end` is not a multiple\n   * of the chunkSize.\n   */\n  bytesToTrim: number;\n\n  /**\n   * The number of bytes to remove from the first chunk read in the file.  This is non-zero\n   * if `start` is not equal to the 0  and `start` is not a multiple\n   * of the chunkSize.\n   */\n  bytesToSkip: number;\n\n  files: Collection<GridFSFile>;\n  chunks: Collection<GridFSChunk>;\n  cursor?: FindCursor<GridFSChunk>;\n\n  /** The running total number of chunks read from the chunks collection. */\n  expected: number;\n\n  /**\n   * The filter used to search in the _files_ collection (i.e., `{ _id: <> }`)\n   * This is not the same filter used when reading chunks from the chunks collection.\n   */\n  filter: Document;\n\n  /** Indicates whether or not download has started. */\n  init: boolean;\n\n  /** The expected number of chunks to read, calculated from start, end, chunkSize and file length. */\n  expectedEnd: number;\n  file?: GridFSFile;\n  options: {\n    sort?: Sort;\n    skip?: number;\n    start: number;\n    end: number;\n    timeoutMS?: number;\n  };\n  readPreference?: ReadPreference;\n  timeoutContext?: CSOTTimeoutContext;\n}\n\n/**\n * A readable stream that enables you to read buffers from GridFS.\n *\n * Do not instantiate this class directly. Use `openDownloadStream()` instead.\n * @public\n */\nexport class GridFSBucketReadStream extends Readable {\n  /** @internal */\n  s: GridFSBucketReadStreamPrivate;\n\n  /**\n   * Fires when the stream loaded the file document corresponding to the provided id.\n   * @event\n   */\n  static readonly FILE = 'file' as const;\n\n  /**\n   * @param chunks - Handle for chunks collection\n   * @param files - Handle for files collection\n   * @param readPreference - The read preference to use\n   * @param filter - The filter to use to find the file document\n   * @internal\n   */\n  constructor(\n    chunks: Collection<GridFSChunk>,\n    files: Collection<GridFSFile>,\n    readPreference: ReadPreference | undefined,\n    filter: Document,\n    options?: GridFSBucketReadStreamOptions\n  ) {\n    super({ emitClose: true });\n    this.s = {\n      bytesToTrim: 0,\n      bytesToSkip: 0,\n      bytesRead: 0,\n      chunks,\n      expected: 0,\n      files,\n      filter,\n      init: false,\n      expectedEnd: 0,\n      options: {\n        start: 0,\n        end: 0,\n        ...options\n      },\n      readPreference,\n      timeoutContext:\n        options?.timeoutMS != null\n          ? new CSOTTimeoutContext({ timeoutMS: options.timeoutMS, serverSelectionTimeoutMS: 0 })\n          : undefined\n    };\n  }\n\n  /**\n   * Reads from the cursor and pushes to the stream.\n   * Private Impl, do not call directly\n   * @internal\n   */\n  override _read(): void {\n    if (this.destroyed) return;\n    waitForFile(this, () => doRead(this));\n  }\n\n  /**\n   * Sets the 0-based offset in bytes to start streaming from. Throws\n   * an error if this stream has entered flowing mode\n   * (e.g. if you've already called `on('data')`)\n   *\n   * @param start - 0-based offset in bytes to start streaming from\n   */\n  start(start = 0): this {\n    throwIfInitialized(this);\n    this.s.options.start = start;\n    return this;\n  }\n\n  /**\n   * Sets the 0-based offset in bytes to start streaming from. Throws\n   * an error if this stream has entered flowing mode\n   * (e.g. if you've already called `on('data')`)\n   *\n   * @param end - Offset in bytes to stop reading at\n   */\n  end(end = 0): this {\n    throwIfInitialized(this);\n    this.s.options.end = end;\n    return this;\n  }\n\n  /**\n   * Marks this stream as aborted (will never push another `data` event)\n   * and kills the underlying cursor. Will emit the 'end' event, and then\n   * the 'close' event once the cursor is successfully killed.\n   */\n  async abort(): Promise<void> {\n    this.push(null);\n    this.destroy();\n    const remainingTimeMS = this.s.timeoutContext?.getRemainingTimeMSOrThrow();\n    await this.s.cursor?.close({ timeoutMS: remainingTimeMS });\n  }\n}\n\nfunction throwIfInitialized(stream: GridFSBucketReadStream): void {\n  if (stream.s.init) {\n    throw new MongoGridFSStreamError('Options cannot be changed after the stream is initialized');\n  }\n}\n\nfunction doRead(stream: GridFSBucketReadStream): void {\n  if (stream.destroyed) return;\n  if (!stream.s.cursor) return;\n  if (!stream.s.file) return;\n\n  const handleReadResult = (doc: Document | null) => {\n    if (stream.destroyed) return;\n\n    if (!doc) {\n      stream.push(null);\n\n      stream.s.cursor?.close().then(undefined, error => stream.destroy(error));\n      return;\n    }\n\n    if (!stream.s.file) return;\n\n    const bytesRemaining = stream.s.file.length - stream.s.bytesRead;\n    const expectedN = stream.s.expected++;\n    const expectedLength = Math.min(stream.s.file.chunkSize, bytesRemaining);\n    if (doc.n > expectedN) {\n      return stream.destroy(\n        new MongoGridFSChunkError(\n          `ChunkIsMissing: Got unexpected n: ${doc.n}, expected: ${expectedN}`\n        )\n      );\n    }\n\n    if (doc.n < expectedN) {\n      return stream.destroy(\n        new MongoGridFSChunkError(`ExtraChunk: Got unexpected n: ${doc.n}, expected: ${expectedN}`)\n      );\n    }\n\n    let buf = Buffer.isBuffer(doc.data) ? doc.data : doc.data.buffer;\n\n    if (buf.byteLength !== expectedLength) {\n      if (bytesRemaining <= 0) {\n        return stream.destroy(\n          new MongoGridFSChunkError(\n            `ExtraChunk: Got unexpected n: ${doc.n}, expected file length ${stream.s.file.length} bytes but already read ${stream.s.bytesRead} bytes`\n          )\n        );\n      }\n\n      return stream.destroy(\n        new MongoGridFSChunkError(\n          `ChunkIsWrongSize: Got unexpected length: ${buf.byteLength}, expected: ${expectedLength}`\n        )\n      );\n    }\n\n    stream.s.bytesRead += buf.byteLength;\n\n    if (buf.byteLength === 0) {\n      return stream.push(null);\n    }\n\n    let sliceStart = null;\n    let sliceEnd = null;\n\n    if (stream.s.bytesToSkip != null) {\n      sliceStart = stream.s.bytesToSkip;\n      stream.s.bytesToSkip = 0;\n    }\n\n    const atEndOfStream = expectedN === stream.s.expectedEnd - 1;\n    const bytesLeftToRead = stream.s.options.end - stream.s.bytesToSkip;\n    if (atEndOfStream && stream.s.bytesToTrim != null) {\n      sliceEnd = stream.s.file.chunkSize - stream.s.bytesToTrim;\n    } else if (stream.s.options.end && bytesLeftToRead < doc.data.byteLength) {\n      sliceEnd = bytesLeftToRead;\n    }\n\n    if (sliceStart != null || sliceEnd != null) {\n      buf = buf.slice(sliceStart || 0, sliceEnd || buf.byteLength);\n    }\n\n    stream.push(buf);\n    return;\n  };\n\n  stream.s.cursor.next().then(handleReadResult, error => {\n    if (stream.destroyed) return;\n    stream.destroy(error);\n  });\n}\n\nfunction init(stream: GridFSBucketReadStream): void {\n  const findOneOptions: FindOptions = {};\n  if (stream.s.readPreference) {\n    findOneOptions.readPreference = stream.s.readPreference;\n  }\n  if (stream.s.options && stream.s.options.sort) {\n    findOneOptions.sort = stream.s.options.sort;\n  }\n  if (stream.s.options && stream.s.options.skip) {\n    findOneOptions.skip = stream.s.options.skip;\n  }\n\n  const handleReadResult = (doc: Document | null) => {\n    if (stream.destroyed) return;\n\n    if (!doc) {\n      const identifier = stream.s.filter._id\n        ? stream.s.filter._id.toString()\n        : stream.s.filter.filename;\n      const errmsg = `FileNotFound: file ${identifier} was not found`;\n      // TODO(NODE-3483)\n      const err = new MongoRuntimeError(errmsg);\n      err.code = 'ENOENT'; // TODO: NODE-3338 set property as part of constructor\n      return stream.destroy(err);\n    }\n\n    // If document is empty, kill the stream immediately and don't\n    // execute any reads\n    if (doc.length <= 0) {\n      stream.push(null);\n      return;\n    }\n\n    if (stream.destroyed) {\n      // If user destroys the stream before we have a cursor, wait\n      // until the query is done to say we're 'closed' because we can't\n      // cancel a query.\n      stream.destroy();\n      return;\n    }\n\n    try {\n      stream.s.bytesToSkip = handleStartOption(stream, doc, stream.s.options);\n    } catch (error) {\n      return stream.destroy(error);\n    }\n\n    const filter: Document = { files_id: doc._id };\n\n    // Currently (MongoDB 3.4.4) skip function does not support the index,\n    // it needs to retrieve all the documents first and then skip them. (CS-25811)\n    // As work around we use $gte on the \"n\" field.\n    if (stream.s.options && stream.s.options.start != null) {\n      const skip = Math.floor(stream.s.options.start / doc.chunkSize);\n      if (skip > 0) {\n        filter['n'] = { $gte: skip };\n      }\n    }\n\n    let remainingTimeMS: number | undefined;\n    try {\n      remainingTimeMS = stream.s.timeoutContext?.getRemainingTimeMSOrThrow(\n        `Download timed out after ${stream.s.timeoutContext?.timeoutMS}ms`\n      );\n    } catch (error) {\n      return stream.destroy(error);\n    }\n\n    stream.s.cursor = stream.s.chunks\n      .find(filter, {\n        timeoutMode: stream.s.options.timeoutMS != null ? CursorTimeoutMode.LIFETIME : undefined,\n        timeoutMS: remainingTimeMS\n      })\n      .sort({ n: 1 });\n\n    if (stream.s.readPreference) {\n      stream.s.cursor.withReadPreference(stream.s.readPreference);\n    }\n\n    stream.s.expectedEnd = Math.ceil(doc.length / doc.chunkSize);\n    stream.s.file = doc as GridFSFile;\n\n    try {\n      stream.s.bytesToTrim = handleEndOption(stream, doc, stream.s.cursor, stream.s.options);\n    } catch (error) {\n      return stream.destroy(error);\n    }\n\n    stream.emit(GridFSBucketReadStream.FILE, doc);\n    return;\n  };\n\n  let remainingTimeMS: number | undefined;\n  try {\n    remainingTimeMS = stream.s.timeoutContext?.getRemainingTimeMSOrThrow(\n      `Download timed out after ${stream.s.timeoutContext?.timeoutMS}ms`\n    );\n  } catch (error) {\n    if (!stream.destroyed) stream.destroy(error);\n    return;\n  }\n\n  findOneOptions.timeoutMS = remainingTimeMS;\n\n  stream.s.files.findOne(stream.s.filter, findOneOptions).then(handleReadResult, error => {\n    if (stream.destroyed) return;\n    stream.destroy(error);\n  });\n}\n\nfunction waitForFile(stream: GridFSBucketReadStream, callback: Callback): void {\n  if (stream.s.file) {\n    return callback();\n  }\n\n  if (!stream.s.init) {\n    init(stream);\n    stream.s.init = true;\n  }\n\n  stream.once('file', () => {\n    callback();\n  });\n}\n\nfunction handleStartOption(\n  stream: GridFSBucketReadStream,\n  doc: Document,\n  options: GridFSBucketReadStreamOptions\n): number {\n  if (options && options.start != null) {\n    if (options.start > doc.length) {\n      throw new MongoInvalidArgumentError(\n        `Stream start (${options.start}) must not be more than the length of the file (${doc.length})`\n      );\n    }\n    if (options.start < 0) {\n      throw new MongoInvalidArgumentError(`Stream start (${options.start}) must not be negative`);\n    }\n    if (options.end != null && options.end < options.start) {\n      throw new MongoInvalidArgumentError(\n        `Stream start (${options.start}) must not be greater than stream end (${options.end})`\n      );\n    }\n\n    stream.s.bytesRead = Math.floor(options.start / doc.chunkSize) * doc.chunkSize;\n    stream.s.expected = Math.floor(options.start / doc.chunkSize);\n\n    return options.start - stream.s.bytesRead;\n  }\n  throw new MongoInvalidArgumentError('Start option must be defined');\n}\n\nfunction handleEndOption(\n  stream: GridFSBucketReadStream,\n  doc: Document,\n  cursor: FindCursor<GridFSChunk>,\n  options: GridFSBucketReadStreamOptions\n) {\n  if (options && options.end != null) {\n    if (options.end > doc.length) {\n      throw new MongoInvalidArgumentError(\n        `Stream end (${options.end}) must not be more than the length of the file (${doc.length})`\n      );\n    }\n    if (options.start == null || options.start < 0) {\n      throw new MongoInvalidArgumentError(`Stream end (${options.end}) must not be negative`);\n    }\n\n    const start = options.start != null ? Math.floor(options.start / doc.chunkSize) : 0;\n\n    cursor.limit(Math.ceil(options.end / doc.chunkSize) - start);\n\n    stream.s.expectedEnd = Math.ceil(options.end / doc.chunkSize);\n\n    return Math.ceil(options.end / doc.chunkSize) * doc.chunkSize - options.end;\n  }\n  throw new MongoInvalidArgumentError('End option must be defined');\n}\n"],"names":[],"mappings":";;;;;AAAA,MAAA;AAIA,MAAA;AAEA,MAAA;AASA,MAAA;AAgGA;;;;;IAMA,MAAa,+BAA+B,SAAA,QAAQ;IAUlD;;;;;;QAOA,YACE,MAA+B,EAC/B,KAA6B,EAC7B,cAA0C,EAC1C,MAAgB,EAChB,OAAuC,CAAA;QAEvC,KAAK,CAAC;YAAE,WAAW;QAAI;QACvB,IAAI,CAAC,CAAC,GAAG;YACP,aAAa;YACb,aAAa;YACb,WAAW;YACX;YACA,UAAU;YACV;YACA;YACA,MAAM;YACN,aAAa;YACb,SAAS;gBACP,OAAO;gBACP,KAAK;gBACL,GAAG,OAAO;;YAEZ;YACA,gBACE,SAAS,aAAa,OAClB,IAAI,UAAA,kBAAkB,CAAC;gBAAE,WAAW,QAAQ,SAAS;gBAAE,0BAA0B;YAAC,KAClF;;IAEV;IAEA;;;;QAKS,QAAK;QACZ,IAAI,IAAI,CAAC,SAAS,EAAE;QACpB,YAAY,IAAI,EAAE,IAAM,OAAO,IAAI;IACrC;IAEA;;;;;;QAOA,MAAM,QAAQ,CAAC,EAAA;QACb,mBAAmB,IAAI;QACvB,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,GAAG;QACvB,OAAO,IAAI;IACb;IAEA;;;;;;QAOA,IAAI,MAAM,CAAC,EAAA;QACT,mBAAmB,IAAI;QACvB,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,GAAG,GAAG;QACrB,OAAO,IAAI;IACb;IAEA;;;;QAKA,MAAM,QAAK;QACT,IAAI,CAAC,IAAI,CAAC;QACV,IAAI,CAAC,OAAO;QACZ,MAAM,kBAAkB,IAAI,CAAC,CAAC,CAAC,cAAc,EAAE;QAC/C,MAAM,IAAI,CAAC,CAAC,CAAC,MAAM,EAAE,MAAM;YAAE,WAAW;QAAe;IACzD;;AA9FF,QAAA,sBAAA,GAAA;AAIE;;;IAIgB,uBAAA,IAAI,GAAG;AAyFzB,SAAS,mBAAmB,MAA8B;IACxD,IAAI,OAAO,CAAC,CAAC,IAAI,EAAE;QACjB,MAAM,IAAI,QAAA,sBAAsB,CAAC;IACnC;AACF;AAEA,SAAS,OAAO,MAA8B;IAC5C,IAAI,OAAO,SAAS,EAAE;IACtB,IAAI,CAAC,OAAO,CAAC,CAAC,MAAM,EAAE;IACtB,IAAI,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE;IAEpB,MAAM,mBAAmB,CAAC;QACxB,IAAI,OAAO,SAAS,EAAE;QAEtB,IAAI,CAAC,KAAK;YACR,OAAO,IAAI,CAAC;YAEZ,OAAO,CAAC,CAAC,MAAM,EAAE,QAAQ,KAAK,WAAW,CAAA,QAAS,OAAO,OAAO,CAAC;YACjE;QACF;QAEA,IAAI,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE;QAEpB,MAAM,iBAAiB,OAAO,CAAC,CAAC,IAAI,CAAC,MAAM,GAAG,OAAO,CAAC,CAAC,SAAS;QAChE,MAAM,YAAY,OAAO,CAAC,CAAC,QAAQ;QACnC,MAAM,iBAAiB,KAAK,GAAG,CAAC,OAAO,CAAC,CAAC,IAAI,CAAC,SAAS,EAAE;QACzD,IAAI,IAAI,CAAC,GAAG,WAAW;YACrB,OAAO,OAAO,OAAO,CACnB,IAAI,QAAA,qBAAqB,CACvB,CAAA,kCAAA,EAAqC,IAAI,CAAC,CAAA,YAAA,EAAe,UAAS,CAAE;QAG1E;QAEA,IAAI,IAAI,CAAC,GAAG,WAAW;YACrB,OAAO,OAAO,OAAO,CACnB,IAAI,QAAA,qBAAqB,CAAC,CAAA,8BAAA,EAAiC,IAAI,CAAC,CAAA,YAAA,EAAe,UAAS,CAAE;QAE9F;QAEA,IAAI,MAAM,OAAO,QAAQ,CAAC,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,IAAI,IAAI,CAAC,MAAM;QAEhE,IAAI,IAAI,UAAU,KAAK,gBAAgB;YACrC,IAAI,kBAAkB,GAAG;gBACvB,OAAO,OAAO,OAAO,CACnB,IAAI,QAAA,qBAAqB,CACvB,CAAA,8BAAA,EAAiC,IAAI,CAAC,CAAA,uBAAA,EAA0B,OAAO,CAAC,CAAC,IAAI,CAAC,MAAM,CAAA,wBAAA,EAA2B,OAAO,CAAC,CAAC,SAAS,CAAA,MAAA,CAAQ;YAG/I;YAEA,OAAO,OAAO,OAAO,CACnB,IAAI,QAAA,qBAAqB,CACvB,CAAA,yCAAA,EAA4C,IAAI,UAAU,CAAA,YAAA,EAAe,eAAc,CAAE;QAG/F;QAEA,OAAO,CAAC,CAAC,SAAS,IAAI,IAAI,UAAU;QAEpC,IAAI,IAAI,UAAU,KAAK,GAAG;YACxB,OAAO,OAAO,IAAI,CAAC;QACrB;QAEA,IAAI,aAAa;QACjB,IAAI,WAAW;QAEf,IAAI,OAAO,CAAC,CAAC,WAAW,IAAI,MAAM;YAChC,aAAa,OAAO,CAAC,CAAC,WAAW;YACjC,OAAO,CAAC,CAAC,WAAW,GAAG;QACzB;QAEA,MAAM,gBAAgB,cAAc,OAAO,CAAC,CAAC,WAAW,GAAG;QAC3D,MAAM,kBAAkB,OAAO,CAAC,CAAC,OAAO,CAAC,GAAG,GAAG,OAAO,CAAC,CAAC,WAAW;QACnE,IAAI,iBAAiB,OAAO,CAAC,CAAC,WAAW,IAAI,MAAM;YACjD,WAAW,OAAO,CAAC,CAAC,IAAI,CAAC,SAAS,GAAG,OAAO,CAAC,CAAC,WAAW;QAC3D,OAAO,IAAI,OAAO,CAAC,CAAC,OAAO,CAAC,GAAG,IAAI,kBAAkB,IAAI,IAAI,CAAC,UAAU,EAAE;YACxE,WAAW;QACb;QAEA,IAAI,cAAc,QAAQ,YAAY,MAAM;YAC1C,MAAM,IAAI,KAAK,CAAC,cAAc,GAAG,YAAY,IAAI,UAAU;QAC7D;QAEA,OAAO,IAAI,CAAC;QACZ;IACF;IAEA,OAAO,CAAC,CAAC,MAAM,CAAC,IAAI,GAAG,IAAI,CAAC,kBAAkB,CAAA;QAC5C,IAAI,OAAO,SAAS,EAAE;QACtB,OAAO,OAAO,CAAC;IACjB;AACF;AAEA,SAAS,KAAK,MAA8B;IAC1C,MAAM,iBAA8B,CAAA;IACpC,IAAI,OAAO,CAAC,CAAC,cAAc,EAAE;QAC3B,eAAe,cAAc,GAAG,OAAO,CAAC,CAAC,cAAc;IACzD;IACA,IAAI,OAAO,CAAC,CAAC,OAAO,IAAI,OAAO,CAAC,CAAC,OAAO,CAAC,IAAI,EAAE;QAC7C,eAAe,IAAI,GAAG,OAAO,CAAC,CAAC,OAAO,CAAC,IAAI;IAC7C;IACA,IAAI,OAAO,CAAC,CAAC,OAAO,IAAI,OAAO,CAAC,CAAC,OAAO,CAAC,IAAI,EAAE;QAC7C,eAAe,IAAI,GAAG,OAAO,CAAC,CAAC,OAAO,CAAC,IAAI;IAC7C;IAEA,MAAM,mBAAmB,CAAC;QACxB,IAAI,OAAO,SAAS,EAAE;QAEtB,IAAI,CAAC,KAAK;YACR,MAAM,aAAa,OAAO,CAAC,CAAC,MAAM,CAAC,GAAG,GAClC,OAAO,CAAC,CAAC,MAAM,CAAC,GAAG,CAAC,QAAQ,KAC5B,OAAO,CAAC,CAAC,MAAM,CAAC,QAAQ;YAC5B,MAAM,SAAS,CAAA,mBAAA,EAAsB,WAAU,cAAA,CAAgB;YAC/D,kBAAkB;YAClB,MAAM,MAAM,IAAI,QAAA,iBAAiB,CAAC;YAClC,IAAI,IAAI,GAAG,UAAU,sDAAsD;YAC3E,OAAO,OAAO,OAAO,CAAC;QACxB;QAEA,8DAA8D;QAC9D,oBAAoB;QACpB,IAAI,IAAI,MAAM,IAAI,GAAG;YACnB,OAAO,IAAI,CAAC;YACZ;QACF;QAEA,IAAI,OAAO,SAAS,EAAE;YACpB,4DAA4D;YAC5D,iEAAiE;YACjE,kBAAkB;YAClB,OAAO,OAAO;YACd;QACF;QAEA,IAAI;YACF,OAAO,CAAC,CAAC,WAAW,GAAG,kBAAkB,QAAQ,KAAK,OAAO,CAAC,CAAC,OAAO;QACxE,EAAE,OAAO,OAAO;YACd,OAAO,OAAO,OAAO,CAAC;QACxB;QAEA,MAAM,SAAmB;YAAE,UAAU,IAAI,GAAG;QAAA;QAE5C,sEAAsE;QACtE,8EAA8E;QAC9E,+CAA+C;QAC/C,IAAI,OAAO,CAAC,CAAC,OAAO,IAAI,OAAO,CAAC,CAAC,OAAO,CAAC,KAAK,IAAI,MAAM;YACtD,MAAM,OAAO,KAAK,KAAK,CAAC,OAAO,CAAC,CAAC,OAAO,CAAC,KAAK,GAAG,IAAI,SAAS;YAC9D,IAAI,OAAO,GAAG;gBACZ,MAAM,CAAC,IAAI,GAAG;oBAAE,MAAM;gBAAI;YAC5B;QACF;QAEA,IAAI;QACJ,IAAI;YACF,kBAAkB,OAAO,CAAC,CAAC,cAAc,EAAE,0BACzC,CAAA,yBAAA,EAA4B,OAAO,CAAC,CAAC,cAAc,EAAE,UAAS,EAAA,CAAI;QAEtE,EAAE,OAAO,OAAO;YACd,OAAO,OAAO,OAAO,CAAC;QACxB;QAEA,OAAO,CAAC,CAAC,MAAM,GAAG,OAAO,CAAC,CAAC,MAAM,CAC9B,IAAI,CAAC,QAAQ;YACZ,aAAa,OAAO,CAAC,CAAC,OAAO,CAAC,SAAS,IAAI,OAAO,kBAAA,iBAAiB,CAAC,QAAQ,GAAG;YAC/E,WAAW;WAEZ,IAAI,CAAC;YAAE,GAAG;QAAC;QAEd,IAAI,OAAO,CAAC,CAAC,cAAc,EAAE;YAC3B,OAAO,CAAC,CAAC,MAAM,CAAC,kBAAkB,CAAC,OAAO,CAAC,CAAC,cAAc;QAC5D;QAEA,OAAO,CAAC,CAAC,WAAW,GAAG,KAAK,IAAI,CAAC,IAAI,MAAM,GAAG,IAAI,SAAS;QAC3D,OAAO,CAAC,CAAC,IAAI,GAAG;QAEhB,IAAI;YACF,OAAO,CAAC,CAAC,WAAW,GAAG,gBAAgB,QAAQ,KAAK,OAAO,CAAC,CAAC,MAAM,EAAE,OAAO,CAAC,CAAC,OAAO;QACvF,EAAE,OAAO,OAAO;YACd,OAAO,OAAO,OAAO,CAAC;QACxB;QAEA,OAAO,IAAI,CAAC,uBAAuB,IAAI,EAAE;QACzC;IACF;IAEA,IAAI;IACJ,IAAI;QACF,kBAAkB,OAAO,CAAC,CAAC,cAAc,EAAE,0BACzC,CAAA,yBAAA,EAA4B,OAAO,CAAC,CAAC,cAAc,EAAE,UAAS,EAAA,CAAI;IAEtE,EAAE,OAAO,OAAO;QACd,IAAI,CAAC,OAAO,SAAS,EAAE,OAAO,OAAO,CAAC;QACtC;IACF;IAEA,eAAe,SAAS,GAAG;IAE3B,OAAO,CAAC,CAAC,KAAK,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,MAAM,EAAE,gBAAgB,IAAI,CAAC,kBAAkB,CAAA;QAC7E,IAAI,OAAO,SAAS,EAAE;QACtB,OAAO,OAAO,CAAC;IACjB;AACF;AAEA,SAAS,YAAY,MAA8B,EAAE,QAAkB;IACrE,IAAI,OAAO,CAAC,CAAC,IAAI,EAAE;QACjB,OAAO;IACT;IAEA,IAAI,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE;QAClB,KAAK;QACL,OAAO,CAAC,CAAC,IAAI,GAAG;IAClB;IAEA,OAAO,IAAI,CAAC,QAAQ;QAClB;IACF;AACF;AAEA,SAAS,kBACP,MAA8B,EAC9B,GAAa,EACb,OAAsC;IAEtC,IAAI,WAAW,QAAQ,KAAK,IAAI,MAAM;QACpC,IAAI,QAAQ,KAAK,GAAG,IAAI,MAAM,EAAE;YAC9B,MAAM,IAAI,QAAA,yBAAyB,CACjC,CAAA,cAAA,EAAiB,QAAQ,KAAK,CAAA,gDAAA,EAAmD,IAAI,MAAM,CAAA,CAAA,CAAG;QAElG;QACA,IAAI,QAAQ,KAAK,GAAG,GAAG;YACrB,MAAM,IAAI,QAAA,yBAAyB,CAAC,CAAA,cAAA,EAAiB,QAAQ,KAAK,CAAA,sBAAA,CAAwB;QAC5F;QACA,IAAI,QAAQ,GAAG,IAAI,QAAQ,QAAQ,GAAG,GAAG,QAAQ,KAAK,EAAE;YACtD,MAAM,IAAI,QAAA,yBAAyB,CACjC,CAAA,cAAA,EAAiB,QAAQ,KAAK,CAAA,uCAAA,EAA0C,QAAQ,GAAG,CAAA,CAAA,CAAG;QAE1F;QAEA,OAAO,CAAC,CAAC,SAAS,GAAG,KAAK,KAAK,CAAC,QAAQ,KAAK,GAAG,IAAI,SAAS,IAAI,IAAI,SAAS;QAC9E,OAAO,CAAC,CAAC,QAAQ,GAAG,KAAK,KAAK,CAAC,QAAQ,KAAK,GAAG,IAAI,SAAS;QAE5D,OAAO,QAAQ,KAAK,GAAG,OAAO,CAAC,CAAC,SAAS;IAC3C;IACA,MAAM,IAAI,QAAA,yBAAyB,CAAC;AACtC;AAEA,SAAS,gBACP,MAA8B,EAC9B,GAAa,EACb,MAA+B,EAC/B,OAAsC;IAEtC,IAAI,WAAW,QAAQ,GAAG,IAAI,MAAM;QAClC,IAAI,QAAQ,GAAG,GAAG,IAAI,MAAM,EAAE;YAC5B,MAAM,IAAI,QAAA,yBAAyB,CACjC,CAAA,YAAA,EAAe,QAAQ,GAAG,CAAA,gDAAA,EAAmD,IAAI,MAAM,CAAA,CAAA,CAAG;QAE9F;QACA,IAAI,QAAQ,KAAK,IAAI,QAAQ,QAAQ,KAAK,GAAG,GAAG;YAC9C,MAAM,IAAI,QAAA,yBAAyB,CAAC,CAAA,YAAA,EAAe,QAAQ,GAAG,CAAA,sBAAA,CAAwB;QACxF;QAEA,MAAM,QAAQ,QAAQ,KAAK,IAAI,OAAO,KAAK,KAAK,CAAC,QAAQ,KAAK,GAAG,IAAI,SAAS,IAAI;QAElF,OAAO,KAAK,CAAC,KAAK,IAAI,CAAC,QAAQ,GAAG,GAAG,IAAI,SAAS,IAAI;QAEtD,OAAO,CAAC,CAAC,WAAW,GAAG,KAAK,IAAI,CAAC,QAAQ,GAAG,GAAG,IAAI,SAAS;QAE5D,OAAO,KAAK,IAAI,CAAC,QAAQ,GAAG,GAAG,IAAI,SAAS,IAAI,IAAI,SAAS,GAAG,QAAQ,GAAG;IAC7E;IACA,MAAM,IAAI,QAAA,yBAAyB,CAAC;AACtC"}},
    {"offset": {"line": 13996, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 14000, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/gridfs/upload.ts"],"sourcesContent":["import { Writable } from 'stream';\n\nimport { type Document, ObjectId } from '../bson';\nimport type { Collection } from '../collection';\nimport { CursorTimeoutMode } from '../cursor/abstract_cursor';\nimport {\n  MongoAPIError,\n  MONGODB_ERROR_CODES,\n  MongoError,\n  MongoOperationTimeoutError\n} from '../error';\nimport { CSOTTimeoutContext } from '../timeout';\nimport { type Callback, resolveTimeoutOptions, squashError } from '../utils';\nimport type { WriteConcernOptions } from '../write_concern';\nimport { WriteConcern } from './../write_concern';\nimport type { GridFSFile } from './download';\nimport type { GridFSBucket } from './index';\n\n/** @public */\nexport interface GridFSChunk {\n  _id: ObjectId;\n  files_id: ObjectId;\n  n: number;\n  data: Buffer | Uint8Array;\n}\n\n/** @public */\nexport interface GridFSBucketWriteStreamOptions extends WriteConcernOptions {\n  /** Overwrite this bucket's chunkSizeBytes for this file */\n  chunkSizeBytes?: number;\n  /** Custom file id for the GridFS file. */\n  id?: ObjectId;\n  /** Object to store in the file document's `metadata` field */\n  metadata?: Document;\n  /**\n   * String to store in the file document's `contentType` field.\n   * @deprecated Will be removed in the next major version. Add a contentType field to the metadata document instead.\n   */\n  contentType?: string;\n  /**\n   * Array of strings to store in the file document's `aliases` field.\n   * @deprecated Will be removed in the next major version. Add an aliases field to the metadata document instead.\n   */\n  aliases?: string[];\n  /**\n   * @experimental\n   * Specifies the time an operation will run until it throws a timeout error\n   */\n  timeoutMS?: number;\n}\n\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\nexport class GridFSBucketWriteStream extends Writable {\n  bucket: GridFSBucket;\n  /** A Collection instance where the file's chunks are stored */\n  chunks: Collection<GridFSChunk>;\n  /** A Collection instance where the file's GridFSFile document is stored */\n  files: Collection<GridFSFile>;\n  /** The name of the file */\n  filename: string;\n  /** Options controlling the metadata inserted along with the file */\n  options: GridFSBucketWriteStreamOptions;\n  /** Indicates the stream is finished uploading */\n  done: boolean;\n  /** The ObjectId used for the `_id` field on the GridFSFile document */\n  id: ObjectId;\n  /** The number of bytes that each chunk will be limited to */\n  chunkSizeBytes: number;\n  /** Space used to store a chunk currently being inserted */\n  bufToStore: Buffer;\n  /** Accumulates the number of bytes inserted as the stream uploads chunks */\n  length: number;\n  /** Accumulates the number of chunks inserted as the stream uploads file contents */\n  n: number;\n  /** Tracks the current offset into the buffered bytes being uploaded */\n  pos: number;\n  /** Contains a number of properties indicating the current state of the stream */\n  state: {\n    /** If set the stream has ended */\n    streamEnd: boolean;\n    /** Indicates the number of chunks that still need to be inserted to exhaust the current buffered data */\n    outstandingRequests: number;\n    /** If set an error occurred during insertion */\n    errored: boolean;\n    /** If set the stream was intentionally aborted */\n    aborted: boolean;\n  };\n  /** The write concern setting to be used with every insert operation */\n  writeConcern?: WriteConcern;\n  /**\n   * The document containing information about the inserted file.\n   * This property is defined _after_ the finish event has been emitted.\n   * It will remain `null` if an error occurs.\n   *\n   * @example\n   * ```ts\n   * fs.createReadStream('file.txt')\n   *   .pipe(bucket.openUploadStream('file.txt'))\n   *   .on('finish', function () {\n   *     console.log(this.gridFSFile)\n   *   })\n   * ```\n   */\n  gridFSFile: GridFSFile | null = null;\n  /** @internal */\n  timeoutContext?: CSOTTimeoutContext;\n\n  /**\n   * @param bucket - Handle for this stream's corresponding bucket\n   * @param filename - The value of the 'filename' key in the files doc\n   * @param options - Optional settings.\n   * @internal\n   */\n  constructor(bucket: GridFSBucket, filename: string, options?: GridFSBucketWriteStreamOptions) {\n    super();\n\n    options = options ?? {};\n    this.bucket = bucket;\n    this.chunks = bucket.s._chunksCollection;\n    this.filename = filename;\n    this.files = bucket.s._filesCollection;\n    this.options = options;\n    this.writeConcern = WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n    // Signals the write is all done\n    this.done = false;\n\n    this.id = options.id ? options.id : new ObjectId();\n    // properly inherit the default chunksize from parent\n    this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n    this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n    this.length = 0;\n    this.n = 0;\n    this.pos = 0;\n    this.state = {\n      streamEnd: false,\n      outstandingRequests: 0,\n      errored: false,\n      aborted: false\n    };\n\n    if (options.timeoutMS != null)\n      this.timeoutContext = new CSOTTimeoutContext({\n        timeoutMS: options.timeoutMS,\n        serverSelectionTimeoutMS: resolveTimeoutOptions(this.bucket.s.db.client, {})\n          .serverSelectionTimeoutMS\n      });\n  }\n\n  /**\n   * @internal\n   *\n   * The stream is considered constructed when the indexes are done being created\n   */\n  override _construct(callback: (error?: Error | null) => void): void {\n    if (!this.bucket.s.calledOpenUploadStream) {\n      this.bucket.s.calledOpenUploadStream = true;\n\n      checkIndexes(this).then(\n        () => {\n          this.bucket.s.checkedIndexes = true;\n          this.bucket.emit('index');\n          callback();\n        },\n        error => {\n          if (error instanceof MongoOperationTimeoutError) {\n            return handleError(this, error, callback);\n          }\n          squashError(error);\n          callback();\n        }\n      );\n    } else {\n      return process.nextTick(callback);\n    }\n  }\n\n  /**\n   * @internal\n   * Write a buffer to the stream.\n   *\n   * @param chunk - Buffer to write\n   * @param encoding - Optional encoding for the buffer\n   * @param callback - Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.\n   */\n  override _write(\n    chunk: Buffer | string,\n    encoding: BufferEncoding,\n    callback: Callback<void>\n  ): void {\n    doWrite(this, chunk, encoding, callback);\n  }\n\n  /** @internal */\n  override _final(callback: (error?: Error | null) => void): void {\n    if (this.state.streamEnd) {\n      return process.nextTick(callback);\n    }\n    this.state.streamEnd = true;\n    writeRemnant(this, callback);\n  }\n\n  /**\n   * Places this write stream into an aborted state (all future writes fail)\n   * and deletes all chunks that have already been written.\n   */\n  async abort(): Promise<void> {\n    if (this.state.streamEnd) {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n      throw new MongoAPIError('Cannot abort a stream that has already completed');\n    }\n\n    if (this.state.aborted) {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n      throw new MongoAPIError('Cannot call abort() on a stream twice');\n    }\n\n    this.state.aborted = true;\n    const remainingTimeMS = this.timeoutContext?.getRemainingTimeMSOrThrow(\n      `Upload timed out after ${this.timeoutContext?.timeoutMS}ms`\n    );\n\n    await this.chunks.deleteMany({ files_id: this.id }, { timeoutMS: remainingTimeMS });\n  }\n}\n\nfunction handleError(stream: GridFSBucketWriteStream, error: Error, callback: Callback): void {\n  if (stream.state.errored) {\n    process.nextTick(callback);\n    return;\n  }\n  stream.state.errored = true;\n  process.nextTick(callback, error);\n}\n\nfunction createChunkDoc(filesId: ObjectId, n: number, data: Buffer): GridFSChunk {\n  return {\n    _id: new ObjectId(),\n    files_id: filesId,\n    n,\n    data\n  };\n}\n\nasync function checkChunksIndex(stream: GridFSBucketWriteStream): Promise<void> {\n  const index = { files_id: 1, n: 1 };\n\n  let remainingTimeMS;\n  remainingTimeMS = stream.timeoutContext?.getRemainingTimeMSOrThrow(\n    `Upload timed out after ${stream.timeoutContext?.timeoutMS}ms`\n  );\n\n  let indexes;\n  try {\n    indexes = await stream.chunks\n      .listIndexes({\n        timeoutMode: remainingTimeMS != null ? CursorTimeoutMode.LIFETIME : undefined,\n        timeoutMS: remainingTimeMS\n      })\n      .toArray();\n  } catch (error) {\n    if (error instanceof MongoError && error.code === MONGODB_ERROR_CODES.NamespaceNotFound) {\n      indexes = [];\n    } else {\n      throw error;\n    }\n  }\n\n  const hasChunksIndex = !!indexes.find(index => {\n    const keys = Object.keys(index.key);\n    if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n      return true;\n    }\n    return false;\n  });\n\n  if (!hasChunksIndex) {\n    remainingTimeMS = stream.timeoutContext?.getRemainingTimeMSOrThrow(\n      `Upload timed out after ${stream.timeoutContext?.timeoutMS}ms`\n    );\n    await stream.chunks.createIndex(index, {\n      ...stream.writeConcern,\n      background: true,\n      unique: true,\n      timeoutMS: remainingTimeMS\n    });\n  }\n}\n\nfunction checkDone(stream: GridFSBucketWriteStream, callback: Callback): void {\n  if (stream.done) {\n    return process.nextTick(callback);\n  }\n\n  if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n    // Set done so we do not trigger duplicate createFilesDoc\n    stream.done = true;\n    // Create a new files doc\n    const gridFSFile = createFilesDoc(\n      stream.id,\n      stream.length,\n      stream.chunkSizeBytes,\n      stream.filename,\n      stream.options.contentType,\n      stream.options.aliases,\n      stream.options.metadata\n    );\n\n    if (isAborted(stream, callback)) {\n      return;\n    }\n\n    const remainingTimeMS = stream.timeoutContext?.remainingTimeMS;\n    if (remainingTimeMS != null && remainingTimeMS <= 0) {\n      return handleError(\n        stream,\n        new MongoOperationTimeoutError(\n          `Upload timed out after ${stream.timeoutContext?.timeoutMS}ms`\n        ),\n        callback\n      );\n    }\n\n    stream.files\n      .insertOne(gridFSFile, { writeConcern: stream.writeConcern, timeoutMS: remainingTimeMS })\n      .then(\n        () => {\n          stream.gridFSFile = gridFSFile;\n          callback();\n        },\n        error => {\n          return handleError(stream, error, callback);\n        }\n      );\n    return;\n  }\n\n  process.nextTick(callback);\n}\n\nasync function checkIndexes(stream: GridFSBucketWriteStream): Promise<void> {\n  let remainingTimeMS = stream.timeoutContext?.getRemainingTimeMSOrThrow(\n    `Upload timed out after ${stream.timeoutContext?.timeoutMS}ms`\n  );\n  const doc = await stream.files.findOne(\n    {},\n    {\n      projection: { _id: 1 },\n      timeoutMS: remainingTimeMS\n    }\n  );\n  if (doc != null) {\n    // If at least one document exists assume the collection has the required index\n    return;\n  }\n\n  const index = { filename: 1, uploadDate: 1 };\n\n  let indexes;\n  remainingTimeMS = stream.timeoutContext?.getRemainingTimeMSOrThrow(\n    `Upload timed out after ${stream.timeoutContext?.timeoutMS}ms`\n  );\n  const listIndexesOptions = {\n    timeoutMode: remainingTimeMS != null ? CursorTimeoutMode.LIFETIME : undefined,\n    timeoutMS: remainingTimeMS\n  };\n  try {\n    indexes = await stream.files.listIndexes(listIndexesOptions).toArray();\n  } catch (error) {\n    if (error instanceof MongoError && error.code === MONGODB_ERROR_CODES.NamespaceNotFound) {\n      indexes = [];\n    } else {\n      throw error;\n    }\n  }\n\n  const hasFileIndex = !!indexes.find(index => {\n    const keys = Object.keys(index.key);\n    if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n      return true;\n    }\n    return false;\n  });\n\n  if (!hasFileIndex) {\n    remainingTimeMS = stream.timeoutContext?.getRemainingTimeMSOrThrow(\n      `Upload timed out after ${stream.timeoutContext?.timeoutMS}ms`\n    );\n\n    await stream.files.createIndex(index, { background: false, timeoutMS: remainingTimeMS });\n  }\n\n  await checkChunksIndex(stream);\n}\n\nfunction createFilesDoc(\n  _id: ObjectId,\n  length: number,\n  chunkSize: number,\n  filename: string,\n  contentType?: string,\n  aliases?: string[],\n  metadata?: Document\n): GridFSFile {\n  const ret: GridFSFile = {\n    _id,\n    length,\n    chunkSize,\n    uploadDate: new Date(),\n    filename\n  };\n\n  if (contentType) {\n    ret.contentType = contentType;\n  }\n\n  if (aliases) {\n    ret.aliases = aliases;\n  }\n\n  if (metadata) {\n    ret.metadata = metadata;\n  }\n\n  return ret;\n}\n\nfunction doWrite(\n  stream: GridFSBucketWriteStream,\n  chunk: Buffer | string,\n  encoding: BufferEncoding,\n  callback: Callback<void>\n): void {\n  if (isAborted(stream, callback)) {\n    return;\n  }\n\n  const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n\n  stream.length += inputBuf.length;\n\n  // Input is small enough to fit in our buffer\n  if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n    inputBuf.copy(stream.bufToStore, stream.pos);\n    stream.pos += inputBuf.length;\n    process.nextTick(callback);\n    return;\n  }\n\n  // Otherwise, buffer is too big for current chunk, so we need to flush\n  // to MongoDB.\n  let inputBufRemaining = inputBuf.length;\n  let spaceRemaining: number = stream.chunkSizeBytes - stream.pos;\n  let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n  let outstandingRequests = 0;\n  while (inputBufRemaining > 0) {\n    const inputBufPos = inputBuf.length - inputBufRemaining;\n    inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n    stream.pos += numToCopy;\n    spaceRemaining -= numToCopy;\n    let doc: GridFSChunk;\n    if (spaceRemaining === 0) {\n      doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n\n      const remainingTimeMS = stream.timeoutContext?.remainingTimeMS;\n      if (remainingTimeMS != null && remainingTimeMS <= 0) {\n        return handleError(\n          stream,\n          new MongoOperationTimeoutError(\n            `Upload timed out after ${stream.timeoutContext?.timeoutMS}ms`\n          ),\n          callback\n        );\n      }\n\n      ++stream.state.outstandingRequests;\n      ++outstandingRequests;\n\n      if (isAborted(stream, callback)) {\n        return;\n      }\n\n      stream.chunks\n        .insertOne(doc, { writeConcern: stream.writeConcern, timeoutMS: remainingTimeMS })\n        .then(\n          () => {\n            --stream.state.outstandingRequests;\n            --outstandingRequests;\n\n            if (!outstandingRequests) {\n              checkDone(stream, callback);\n            }\n          },\n          error => {\n            return handleError(stream, error, callback);\n          }\n        );\n\n      spaceRemaining = stream.chunkSizeBytes;\n      stream.pos = 0;\n      ++stream.n;\n    }\n    inputBufRemaining -= numToCopy;\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n  }\n}\n\nfunction writeRemnant(stream: GridFSBucketWriteStream, callback: Callback): void {\n  // Buffer is empty, so don't bother to insert\n  if (stream.pos === 0) {\n    return checkDone(stream, callback);\n  }\n\n  // Create a new buffer to make sure the buffer isn't bigger than it needs\n  // to be.\n  const remnant = Buffer.alloc(stream.pos);\n  stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n  const doc = createChunkDoc(stream.id, stream.n, remnant);\n\n  // If the stream was aborted, do not write remnant\n  if (isAborted(stream, callback)) {\n    return;\n  }\n\n  const remainingTimeMS = stream.timeoutContext?.remainingTimeMS;\n  if (remainingTimeMS != null && remainingTimeMS <= 0) {\n    return handleError(\n      stream,\n      new MongoOperationTimeoutError(\n        `Upload timed out after ${stream.timeoutContext?.timeoutMS}ms`\n      ),\n      callback\n    );\n  }\n  ++stream.state.outstandingRequests;\n  stream.chunks\n    .insertOne(doc, { writeConcern: stream.writeConcern, timeoutMS: remainingTimeMS })\n    .then(\n      () => {\n        --stream.state.outstandingRequests;\n        checkDone(stream, callback);\n      },\n      error => {\n        return handleError(stream, error, callback);\n      }\n    );\n}\n\nfunction isAborted(stream: GridFSBucketWriteStream, callback: Callback<void>): boolean {\n  if (stream.state.aborted) {\n    process.nextTick(callback, new MongoAPIError('Stream has been aborted'));\n    return true;\n  }\n  return false;\n}\n"],"names":[],"mappings":";;;;;AAAA,MAAA;AAEA,MAAA;AAEA,MAAA;AACA,MAAA;AAMA,MAAA;AACA,MAAA;AAEA,MAAA;AAqCA;;;;;IAMA,MAAa,gCAAgC,SAAA,QAAQ;IAuDnD;;;;;QAMA,YAAY,MAAoB,EAAE,QAAgB,EAAE,OAAwC,CAAA;QAC1F,KAAK;QAzBP;;;;;;;;;;;;;YAcA,IAAA,CAAA,UAAU,GAAsB;QAa9B,UAAU,WAAW,CAAA;QACrB,IAAI,CAAC,MAAM,GAAG;QACd,IAAI,CAAC,MAAM,GAAG,OAAO,CAAC,CAAC,iBAAiB;QACxC,IAAI,CAAC,QAAQ,GAAG;QAChB,IAAI,CAAC,KAAK,GAAG,OAAO,CAAC,CAAC,gBAAgB;QACtC,IAAI,CAAC,OAAO,GAAG;QACf,IAAI,CAAC,YAAY,GAAG,gBAAA,YAAY,CAAC,WAAW,CAAC,YAAY,OAAO,CAAC,CAAC,OAAO,CAAC,YAAY;QACtF,gCAAgC;QAChC,IAAI,CAAC,IAAI,GAAG;QAEZ,IAAI,CAAC,EAAE,GAAG,QAAQ,EAAE,GAAG,QAAQ,EAAE,GAAG,IAAI,OAAA,QAAQ;QAChD,qDAAqD;QACrD,IAAI,CAAC,cAAc,GAAG,QAAQ,cAAc,IAAI,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,OAAO,CAAC,cAAc;QACpF,IAAI,CAAC,UAAU,GAAG,OAAO,KAAK,CAAC,IAAI,CAAC,cAAc;QAClD,IAAI,CAAC,MAAM,GAAG;QACd,IAAI,CAAC,CAAC,GAAG;QACT,IAAI,CAAC,GAAG,GAAG;QACX,IAAI,CAAC,KAAK,GAAG;YACX,WAAW;YACX,qBAAqB;YACrB,SAAS;YACT,SAAS;;QAGX,IAAI,QAAQ,SAAS,IAAI,MACvB,IAAI,CAAC,cAAc,GAAG,IAAI,UAAA,kBAAkB,CAAC;YAC3C,WAAW,QAAQ,SAAS;YAC5B,0BAA0B,CAAA,GAAA,QAAA,qBAAqB,EAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,CAAC,MAAM,EAAE,CAAA,GACtE,wBAAwB;;IAEjC;IAEA;;;;QAKS,WAAW,QAAwC,EAAA;QAC1D,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,sBAAsB,EAAE;YACzC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,sBAAsB,GAAG;YAEvC,aAAa,IAAI,EAAE,IAAI,CACrB;gBACE,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,cAAc,GAAG;gBAC/B,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC;gBACjB;YACF,GACA,CAAA;gBACE,IAAI,iBAAiB,QAAA,0BAA0B,EAAE;oBAC/C,OAAO,YAAY,IAAI,EAAE,OAAO;gBAClC;gBACA,CAAA,GAAA,QAAA,WAAW,EAAC;gBACZ;YACF;QAEJ,OAAO;YACL,OAAO,QAAQ,QAAQ,CAAC;QAC1B;IACF;IAEA;;;;;;;QAQS,OACP,KAAsB,EACtB,QAAwB,EACxB,QAAwB,EAAA;QAExB,QAAQ,IAAI,EAAE,OAAO,UAAU;IACjC;IAEA,cAAA,GACS,OAAO,QAAwC,EAAA;QACtD,IAAI,IAAI,CAAC,KAAK,CAAC,SAAS,EAAE;YACxB,OAAO,QAAQ,QAAQ,CAAC;QAC1B;QACA,IAAI,CAAC,KAAK,CAAC,SAAS,GAAG;QACvB,aAAa,IAAI,EAAE;IACrB;IAEA;;;QAIA,MAAM,QAAK;QACT,IAAI,IAAI,CAAC,KAAK,CAAC,SAAS,EAAE;YACxB,wDAAwD;YACxD,MAAM,IAAI,QAAA,aAAa,CAAC;QAC1B;QAEA,IAAI,IAAI,CAAC,KAAK,CAAC,OAAO,EAAE;YACtB,wDAAwD;YACxD,MAAM,IAAI,QAAA,aAAa,CAAC;QAC1B;QAEA,IAAI,CAAC,KAAK,CAAC,OAAO,GAAG;QACrB,MAAM,kBAAkB,IAAI,CAAC,cAAc,EAAE,0BAC3C,CAAA,uBAAA,EAA0B,IAAI,CAAC,cAAc,EAAE,UAAS,EAAA,CAAI;QAG9D,MAAM,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC;YAAE,UAAU,IAAI,CAAC,EAAE;QAAA,GAAI;YAAE,WAAW;QAAe;IAClF;;AA1KF,QAAA,uBAAA,GAAA;AA6KA,SAAS,YAAY,MAA+B,EAAE,KAAY,EAAE,QAAkB;IACpF,IAAI,OAAO,KAAK,CAAC,OAAO,EAAE;QACxB,QAAQ,QAAQ,CAAC;QACjB;IACF;IACA,OAAO,KAAK,CAAC,OAAO,GAAG;IACvB,QAAQ,QAAQ,CAAC,UAAU;AAC7B;AAEA,SAAS,eAAe,OAAiB,EAAE,CAAS,EAAE,IAAY;IAChE,OAAO;QACL,KAAK,IAAI,OAAA,QAAQ;QACjB,UAAU;QACV;QACA;;AAEJ;AAEA,eAAe,iBAAiB,MAA+B;IAC7D,MAAM,QAAQ;QAAE,UAAU;QAAG,GAAG;IAAC;IAEjC,IAAI;IACJ,kBAAkB,OAAO,cAAc,EAAE,0BACvC,CAAA,uBAAA,EAA0B,OAAO,cAAc,EAAE,UAAS,EAAA,CAAI;IAGhE,IAAI;IACJ,IAAI;QACF,UAAU,MAAM,OAAO,MAAM,CAC1B,WAAW,CAAC;YACX,aAAa,mBAAmB,OAAO,kBAAA,iBAAiB,CAAC,QAAQ,GAAG;YACpE,WAAW;WAEZ,OAAO;IACZ,EAAE,OAAO,OAAO;QACd,IAAI,iBAAiB,QAAA,UAAU,IAAI,MAAM,IAAI,KAAK,QAAA,mBAAmB,CAAC,iBAAiB,EAAE;YACvF,UAAU,EAAE;QACd,OAAO;YACL,MAAM;QACR;IACF;IAEA,MAAM,iBAAiB,CAAC,CAAC,QAAQ,IAAI,CAAC,CAAA;QACpC,MAAM,OAAO,OAAO,IAAI,CAAC,MAAM,GAAG;QAClC,IAAI,KAAK,MAAM,KAAK,KAAK,MAAM,GAAG,CAAC,QAAQ,KAAK,KAAK,MAAM,GAAG,CAAC,CAAC,KAAK,GAAG;YACtE,OAAO;QACT;QACA,OAAO;IACT;IAEA,IAAI,CAAC,gBAAgB;QACnB,kBAAkB,OAAO,cAAc,EAAE,0BACvC,CAAA,uBAAA,EAA0B,OAAO,cAAc,EAAE,UAAS,EAAA,CAAI;QAEhE,MAAM,OAAO,MAAM,CAAC,WAAW,CAAC,OAAO;YACrC,GAAG,OAAO,YAAY;YACtB,YAAY;YACZ,QAAQ;YACR,WAAW;;IAEf;AACF;AAEA,SAAS,UAAU,MAA+B,EAAE,QAAkB;IACpE,IAAI,OAAO,IAAI,EAAE;QACf,OAAO,QAAQ,QAAQ,CAAC;IAC1B;IAEA,IAAI,OAAO,KAAK,CAAC,SAAS,IAAI,OAAO,KAAK,CAAC,mBAAmB,KAAK,KAAK,CAAC,OAAO,KAAK,CAAC,OAAO,EAAE;QAC7F,yDAAyD;QACzD,OAAO,IAAI,GAAG;QACd,yBAAyB;QACzB,MAAM,aAAa,eACjB,OAAO,EAAE,EACT,OAAO,MAAM,EACb,OAAO,cAAc,EACrB,OAAO,QAAQ,EACf,OAAO,OAAO,CAAC,WAAW,EAC1B,OAAO,OAAO,CAAC,OAAO,EACtB,OAAO,OAAO,CAAC,QAAQ;QAGzB,IAAI,UAAU,QAAQ,WAAW;YAC/B;QACF;QAEA,MAAM,kBAAkB,OAAO,cAAc,EAAE;QAC/C,IAAI,mBAAmB,QAAQ,mBAAmB,GAAG;YACnD,OAAO,YACL,QACA,IAAI,QAAA,0BAA0B,CAC5B,CAAA,uBAAA,EAA0B,OAAO,cAAc,EAAE,UAAS,EAAA,CAAI,GAEhE;QAEJ;QAEA,OAAO,KAAK,CACT,SAAS,CAAC,YAAY;YAAE,cAAc,OAAO,YAAY;YAAE,WAAW;QAAe,GACrF,IAAI,CACH;YACE,OAAO,UAAU,GAAG;YACpB;QACF,GACA,CAAA;YACE,OAAO,YAAY,QAAQ,OAAO;QACpC;QAEJ;IACF;IAEA,QAAQ,QAAQ,CAAC;AACnB;AAEA,eAAe,aAAa,MAA+B;IACzD,IAAI,kBAAkB,OAAO,cAAc,EAAE,0BAC3C,CAAA,uBAAA,EAA0B,OAAO,cAAc,EAAE,UAAS,EAAA,CAAI;IAEhE,MAAM,MAAM,MAAM,OAAO,KAAK,CAAC,OAAO,CACpC,CAAA,GACA;QACE,YAAY;YAAE,KAAK;QAAC;QACpB,WAAW;;IAGf,IAAI,OAAO,MAAM;QACf,+EAA+E;QAC/E;IACF;IAEA,MAAM,QAAQ;QAAE,UAAU;QAAG,YAAY;IAAC;IAE1C,IAAI;IACJ,kBAAkB,OAAO,cAAc,EAAE,0BACvC,CAAA,uBAAA,EAA0B,OAAO,cAAc,EAAE,UAAS,EAAA,CAAI;IAEhE,MAAM,qBAAqB;QACzB,aAAa,mBAAmB,OAAO,kBAAA,iBAAiB,CAAC,QAAQ,GAAG;QACpE,WAAW;;IAEb,IAAI;QACF,UAAU,MAAM,OAAO,KAAK,CAAC,WAAW,CAAC,oBAAoB,OAAO;IACtE,EAAE,OAAO,OAAO;QACd,IAAI,iBAAiB,QAAA,UAAU,IAAI,MAAM,IAAI,KAAK,QAAA,mBAAmB,CAAC,iBAAiB,EAAE;YACvF,UAAU,EAAE;QACd,OAAO;YACL,MAAM;QACR;IACF;IAEA,MAAM,eAAe,CAAC,CAAC,QAAQ,IAAI,CAAC,CAAA;QAClC,MAAM,OAAO,OAAO,IAAI,CAAC,MAAM,GAAG;QAClC,IAAI,KAAK,MAAM,KAAK,KAAK,MAAM,GAAG,CAAC,QAAQ,KAAK,KAAK,MAAM,GAAG,CAAC,UAAU,KAAK,GAAG;YAC/E,OAAO;QACT;QACA,OAAO;IACT;IAEA,IAAI,CAAC,cAAc;QACjB,kBAAkB,OAAO,cAAc,EAAE,0BACvC,CAAA,uBAAA,EAA0B,OAAO,cAAc,EAAE,UAAS,EAAA,CAAI;QAGhE,MAAM,OAAO,KAAK,CAAC,WAAW,CAAC,OAAO;YAAE,YAAY;YAAO,WAAW;QAAe;IACvF;IAEA,MAAM,iBAAiB;AACzB;AAEA,SAAS,eACP,GAAa,EACb,MAAc,EACd,SAAiB,EACjB,QAAgB,EAChB,WAAoB,EACpB,OAAkB,EAClB,QAAmB;IAEnB,MAAM,MAAkB;QACtB;QACA;QACA;QACA,YAAY,IAAI;QAChB;;IAGF,IAAI,aAAa;QACf,IAAI,WAAW,GAAG;IACpB;IAEA,IAAI,SAAS;QACX,IAAI,OAAO,GAAG;IAChB;IAEA,IAAI,UAAU;QACZ,IAAI,QAAQ,GAAG;IACjB;IAEA,OAAO;AACT;AAEA,SAAS,QACP,MAA+B,EAC/B,KAAsB,EACtB,QAAwB,EACxB,QAAwB;IAExB,IAAI,UAAU,QAAQ,WAAW;QAC/B;IACF;IAEA,MAAM,WAAW,OAAO,QAAQ,CAAC,SAAS,QAAQ,OAAO,IAAI,CAAC,OAAO;IAErE,OAAO,MAAM,IAAI,SAAS,MAAM;IAEhC,6CAA6C;IAC7C,IAAI,OAAO,GAAG,GAAG,SAAS,MAAM,GAAG,OAAO,cAAc,EAAE;QACxD,SAAS,IAAI,CAAC,OAAO,UAAU,EAAE,OAAO,GAAG;QAC3C,OAAO,GAAG,IAAI,SAAS,MAAM;QAC7B,QAAQ,QAAQ,CAAC;QACjB;IACF;IAEA,sEAAsE;IACtE,cAAc;IACd,IAAI,oBAAoB,SAAS,MAAM;IACvC,IAAI,iBAAyB,OAAO,cAAc,GAAG,OAAO,GAAG;IAC/D,IAAI,YAAY,KAAK,GAAG,CAAC,gBAAgB,SAAS,MAAM;IACxD,IAAI,sBAAsB;IAC1B,MAAO,oBAAoB,EAAG;QAC5B,MAAM,cAAc,SAAS,MAAM,GAAG;QACtC,SAAS,IAAI,CAAC,OAAO,UAAU,EAAE,OAAO,GAAG,EAAE,aAAa,cAAc;QACxE,OAAO,GAAG,IAAI;QACd,kBAAkB;QAClB,IAAI;QACJ,IAAI,mBAAmB,GAAG;YACxB,MAAM,eAAe,OAAO,EAAE,EAAE,OAAO,CAAC,EAAE,OAAO,IAAI,CAAC,OAAO,UAAU;YAEvE,MAAM,kBAAkB,OAAO,cAAc,EAAE;YAC/C,IAAI,mBAAmB,QAAQ,mBAAmB,GAAG;gBACnD,OAAO,YACL,QACA,IAAI,QAAA,0BAA0B,CAC5B,CAAA,uBAAA,EAA0B,OAAO,cAAc,EAAE,UAAS,EAAA,CAAI,GAEhE;YAEJ;YAEA,EAAE,OAAO,KAAK,CAAC,mBAAmB;YAClC,EAAE;YAEF,IAAI,UAAU,QAAQ,WAAW;gBAC/B;YACF;YAEA,OAAO,MAAM,CACV,SAAS,CAAC,KAAK;gBAAE,cAAc,OAAO,YAAY;gBAAE,WAAW;YAAe,GAC9E,IAAI,CACH;gBACE,EAAE,OAAO,KAAK,CAAC,mBAAmB;gBAClC,EAAE;gBAEF,IAAI,CAAC,qBAAqB;oBACxB,UAAU,QAAQ;gBACpB;YACF,GACA,CAAA;gBACE,OAAO,YAAY,QAAQ,OAAO;YACpC;YAGJ,iBAAiB,OAAO,cAAc;YACtC,OAAO,GAAG,GAAG;YACb,EAAE,OAAO,CAAC;QACZ;QACA,qBAAqB;QACrB,YAAY,KAAK,GAAG,CAAC,gBAAgB;IACvC;AACF;AAEA,SAAS,aAAa,MAA+B,EAAE,QAAkB;IACvE,6CAA6C;IAC7C,IAAI,OAAO,GAAG,KAAK,GAAG;QACpB,OAAO,UAAU,QAAQ;IAC3B;IAEA,yEAAyE;IACzE,SAAS;IACT,MAAM,UAAU,OAAO,KAAK,CAAC,OAAO,GAAG;IACvC,OAAO,UAAU,CAAC,IAAI,CAAC,SAAS,GAAG,GAAG,OAAO,GAAG;IAChD,MAAM,MAAM,eAAe,OAAO,EAAE,EAAE,OAAO,CAAC,EAAE;IAEhD,kDAAkD;IAClD,IAAI,UAAU,QAAQ,WAAW;QAC/B;IACF;IAEA,MAAM,kBAAkB,OAAO,cAAc,EAAE;IAC/C,IAAI,mBAAmB,QAAQ,mBAAmB,GAAG;QACnD,OAAO,YACL,QACA,IAAI,QAAA,0BAA0B,CAC5B,CAAA,uBAAA,EAA0B,OAAO,cAAc,EAAE,UAAS,EAAA,CAAI,GAEhE;IAEJ;IACA,EAAE,OAAO,KAAK,CAAC,mBAAmB;IAClC,OAAO,MAAM,CACV,SAAS,CAAC,KAAK;QAAE,cAAc,OAAO,YAAY;QAAE,WAAW;IAAe,GAC9E,IAAI,CACH;QACE,EAAE,OAAO,KAAK,CAAC,mBAAmB;QAClC,UAAU,QAAQ;IACpB,GACA,CAAA;QACE,OAAO,YAAY,QAAQ,OAAO;IACpC;AAEN;AAEA,SAAS,UAAU,MAA+B,EAAE,QAAwB;IAC1E,IAAI,OAAO,KAAK,CAAC,OAAO,EAAE;QACxB,QAAQ,QAAQ,CAAC,UAAU,IAAI,QAAA,aAAa,CAAC;QAC7C,OAAO;IACT;IACA,OAAO;AACT"}},
    {"offset": {"line": 14367, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 14371, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/gridfs/index.ts"],"sourcesContent":["import type { ObjectId } from '../bson';\nimport type { Collection } from '../collection';\nimport type { FindCursor } from '../cursor/find_cursor';\nimport type { Db } from '../db';\nimport { MongoOperationTimeoutError, MongoRuntimeError } from '../error';\nimport { type Filter, TypedEventEmitter } from '../mongo_types';\nimport type { ReadPreference } from '../read_preference';\nimport type { Sort } from '../sort';\nimport { CSOTTimeoutContext } from '../timeout';\nimport { noop, resolveOptions } from '../utils';\nimport { WriteConcern, type WriteConcernOptions } from '../write_concern';\nimport type { FindOptions } from './../operations/find';\nimport {\n  GridFSBucketReadStream,\n  type GridFSBucketReadStreamOptions,\n  type GridFSBucketReadStreamOptionsWithRevision,\n  type GridFSFile\n} from './download';\nimport {\n  GridFSBucketWriteStream,\n  type GridFSBucketWriteStreamOptions,\n  type GridFSChunk\n} from './upload';\n\nconst DEFAULT_GRIDFS_BUCKET_OPTIONS: {\n  bucketName: string;\n  chunkSizeBytes: number;\n} = {\n  bucketName: 'fs',\n  chunkSizeBytes: 255 * 1024\n};\n\n/** @public */\nexport interface GridFSBucketOptions extends WriteConcernOptions {\n  /** The 'files' and 'chunks' collections will be prefixed with the bucket name followed by a dot. */\n  bucketName?: string;\n  /** Number of bytes stored in each chunk. Defaults to 255KB */\n  chunkSizeBytes?: number;\n  /** Read preference to be passed to read operations */\n  readPreference?: ReadPreference;\n  /**\n   * @experimental\n   * Specifies the lifetime duration of a gridFS stream. If any async operations are in progress\n   * when this timeout expires, the stream will throw a timeout error.\n   */\n  timeoutMS?: number;\n}\n\n/** @internal */\nexport interface GridFSBucketPrivate {\n  db: Db;\n  options: {\n    bucketName: string;\n    chunkSizeBytes: number;\n    readPreference?: ReadPreference;\n    writeConcern: WriteConcern | undefined;\n    timeoutMS?: number;\n  };\n  _chunksCollection: Collection<GridFSChunk>;\n  _filesCollection: Collection<GridFSFile>;\n  checkedIndexes: boolean;\n  calledOpenUploadStream: boolean;\n}\n\n/** @public */\nexport type GridFSBucketEvents = {\n  index(): void;\n};\n\n/**\n * Constructor for a streaming GridFS interface\n * @public\n */\nexport class GridFSBucket extends TypedEventEmitter<GridFSBucketEvents> {\n  /** @internal */\n  s: GridFSBucketPrivate;\n\n  /**\n   * When the first call to openUploadStream is made, the upload stream will\n   * check to see if it needs to create the proper indexes on the chunks and\n   * files collections. This event is fired either when 1) it determines that\n   * no index creation is necessary, 2) when it successfully creates the\n   * necessary indexes.\n   * @event\n   */\n  static readonly INDEX = 'index' as const;\n\n  constructor(db: Db, options?: GridFSBucketOptions) {\n    super();\n    this.on('error', noop);\n    this.setMaxListeners(0);\n    const privateOptions = resolveOptions(db, {\n      ...DEFAULT_GRIDFS_BUCKET_OPTIONS,\n      ...options,\n      writeConcern: WriteConcern.fromOptions(options)\n    });\n    this.s = {\n      db,\n      options: privateOptions,\n      _chunksCollection: db.collection<GridFSChunk>(privateOptions.bucketName + '.chunks'),\n      _filesCollection: db.collection<GridFSFile>(privateOptions.bucketName + '.files'),\n      checkedIndexes: false,\n      calledOpenUploadStream: false\n    };\n  }\n\n  /**\n   * Returns a writable stream (GridFSBucketWriteStream) for writing\n   * buffers to GridFS. The stream's 'id' property contains the resulting\n   * file's id.\n   *\n   * @param filename - The value of the 'filename' key in the files doc\n   * @param options - Optional settings.\n   */\n\n  openUploadStream(\n    filename: string,\n    options?: GridFSBucketWriteStreamOptions\n  ): GridFSBucketWriteStream {\n    return new GridFSBucketWriteStream(this, filename, {\n      timeoutMS: this.s.options.timeoutMS,\n      ...options\n    });\n  }\n\n  /**\n   * Returns a writable stream (GridFSBucketWriteStream) for writing\n   * buffers to GridFS for a custom file id. The stream's 'id' property contains the resulting\n   * file's id.\n   */\n  openUploadStreamWithId(\n    id: ObjectId,\n    filename: string,\n    options?: GridFSBucketWriteStreamOptions\n  ): GridFSBucketWriteStream {\n    return new GridFSBucketWriteStream(this, filename, {\n      timeoutMS: this.s.options.timeoutMS,\n      ...options,\n      id\n    });\n  }\n\n  /** Returns a readable stream (GridFSBucketReadStream) for streaming file data from GridFS. */\n  openDownloadStream(\n    id: ObjectId,\n    options?: GridFSBucketReadStreamOptions\n  ): GridFSBucketReadStream {\n    return new GridFSBucketReadStream(\n      this.s._chunksCollection,\n      this.s._filesCollection,\n      this.s.options.readPreference,\n      { _id: id },\n      { timeoutMS: this.s.options.timeoutMS, ...options }\n    );\n  }\n\n  /**\n   * Deletes a file with the given id\n   *\n   * @param id - The id of the file doc\n   */\n  async delete(id: ObjectId, options?: { timeoutMS: number }): Promise<void> {\n    const { timeoutMS } = resolveOptions(this.s.db, options);\n    let timeoutContext: CSOTTimeoutContext | undefined = undefined;\n\n    if (timeoutMS) {\n      timeoutContext = new CSOTTimeoutContext({\n        timeoutMS,\n        serverSelectionTimeoutMS: this.s.db.client.s.options.serverSelectionTimeoutMS\n      });\n    }\n\n    const { deletedCount } = await this.s._filesCollection.deleteOne(\n      { _id: id },\n      { timeoutMS: timeoutContext?.remainingTimeMS }\n    );\n\n    const remainingTimeMS = timeoutContext?.remainingTimeMS;\n    if (remainingTimeMS != null && remainingTimeMS <= 0)\n      throw new MongoOperationTimeoutError(`Timed out after ${timeoutMS}ms`);\n    // Delete orphaned chunks before returning FileNotFound\n    await this.s._chunksCollection.deleteMany({ files_id: id }, { timeoutMS: remainingTimeMS });\n\n    if (deletedCount === 0) {\n      // TODO(NODE-3483): Replace with more appropriate error\n      // Consider creating new error MongoGridFSFileNotFoundError\n      throw new MongoRuntimeError(`File not found for id ${id}`);\n    }\n  }\n\n  /** Convenience wrapper around find on the files collection */\n  find(filter: Filter<GridFSFile> = {}, options: FindOptions = {}): FindCursor<GridFSFile> {\n    return this.s._filesCollection.find(filter, options);\n  }\n\n  /**\n   * Returns a readable stream (GridFSBucketReadStream) for streaming the\n   * file with the given name from GridFS. If there are multiple files with\n   * the same name, this will stream the most recent file with the given name\n   * (as determined by the `uploadDate` field). You can set the `revision`\n   * option to change this behavior.\n   */\n  openDownloadStreamByName(\n    filename: string,\n    options?: GridFSBucketReadStreamOptionsWithRevision\n  ): GridFSBucketReadStream {\n    let sort: Sort = { uploadDate: -1 };\n    let skip = undefined;\n    if (options && options.revision != null) {\n      if (options.revision >= 0) {\n        sort = { uploadDate: 1 };\n        skip = options.revision;\n      } else {\n        skip = -options.revision - 1;\n      }\n    }\n    return new GridFSBucketReadStream(\n      this.s._chunksCollection,\n      this.s._filesCollection,\n      this.s.options.readPreference,\n      { filename },\n      { timeoutMS: this.s.options.timeoutMS, ...options, sort, skip }\n    );\n  }\n\n  /**\n   * Renames the file with the given _id to the given string\n   *\n   * @param id - the id of the file to rename\n   * @param filename - new name for the file\n   */\n  async rename(id: ObjectId, filename: string, options?: { timeoutMS: number }): Promise<void> {\n    const filter = { _id: id };\n    const update = { $set: { filename } };\n    const { matchedCount } = await this.s._filesCollection.updateOne(filter, update, options);\n    if (matchedCount === 0) {\n      throw new MongoRuntimeError(`File with id ${id} not found`);\n    }\n  }\n\n  /** Removes this bucket's files collection, followed by its chunks collection. */\n  async drop(options?: { timeoutMS: number }): Promise<void> {\n    const { timeoutMS } = resolveOptions(this.s.db, options);\n    let timeoutContext: CSOTTimeoutContext | undefined = undefined;\n\n    if (timeoutMS) {\n      timeoutContext = new CSOTTimeoutContext({\n        timeoutMS,\n        serverSelectionTimeoutMS: this.s.db.client.s.options.serverSelectionTimeoutMS\n      });\n    }\n\n    if (timeoutContext) {\n      await this.s._filesCollection.drop({ timeoutMS: timeoutContext.remainingTimeMS });\n      const remainingTimeMS = timeoutContext.getRemainingTimeMSOrThrow(\n        `Timed out after ${timeoutMS}ms`\n      );\n      await this.s._chunksCollection.drop({ timeoutMS: remainingTimeMS });\n    } else {\n      await this.s._filesCollection.drop();\n      await this.s._chunksCollection.drop();\n    }\n  }\n}\n"],"names":[],"mappings":";;;;;AAIA,MAAA;AACA,MAAA;AAGA,MAAA;AACA,MAAA;AACA,MAAA;AAEA,MAAA;AAMA,MAAA;AAMA,MAAM,gCAGF;IACF,YAAY;IACZ,gBAAgB,MAAM;;AAwCxB;;;IAIA,MAAa,qBAAqB,cAAA,iBAAqC;IAcrE,YAAY,EAAM,EAAE,OAA6B,CAAA;QAC/C,KAAK;QACL,IAAI,CAAC,EAAE,CAAC,SAAS,QAAA,IAAI;QACrB,IAAI,CAAC,eAAe,CAAC;QACrB,MAAM,iBAAiB,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI;YACxC,GAAG,6BAA6B;YAChC,GAAG,OAAO;YACV,cAAc,gBAAA,YAAY,CAAC,WAAW,CAAC;;QAEzC,IAAI,CAAC,CAAC,GAAG;YACP;YACA,SAAS;YACT,mBAAmB,GAAG,UAAU,CAAc,eAAe,UAAU,GAAG;YAC1E,kBAAkB,GAAG,UAAU,CAAa,eAAe,UAAU,GAAG;YACxE,gBAAgB;YAChB,wBAAwB;;IAE5B;IAEA;;;;;;;QASA,iBACE,QAAgB,EAChB,OAAwC,EAAA;QAExC,OAAO,IAAI,SAAA,uBAAuB,CAAC,IAAI,EAAE,UAAU;YACjD,WAAW,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,SAAS;YACnC,GAAG,OAAO;;IAEd;IAEA;;;;QAKA,uBACE,EAAY,EACZ,QAAgB,EAChB,OAAwC,EAAA;QAExC,OAAO,IAAI,SAAA,uBAAuB,CAAC,IAAI,EAAE,UAAU;YACjD,WAAW,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,SAAS;YACnC,GAAG,OAAO;YACV;;IAEJ;IAEA,4FAAA,GACA,mBACE,EAAY,EACZ,OAAuC,EAAA;QAEvC,OAAO,IAAI,WAAA,sBAAsB,CAC/B,IAAI,CAAC,CAAC,CAAC,iBAAiB,EACxB,IAAI,CAAC,CAAC,CAAC,gBAAgB,EACvB,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,cAAc,EAC7B;YAAE,KAAK;QAAE,GACT;YAAE,WAAW,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,SAAS;YAAE,GAAG,OAAO;QAAA;IAErD;IAEA;;;;QAKA,MAAM,OAAO,EAAY,EAAE,OAA+B,EAAA;QACxD,MAAM,EAAE,SAAS,EAAE,GAAG,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE;QAChD,IAAI,iBAAiD;QAErD,IAAI,WAAW;YACb,iBAAiB,IAAI,UAAA,kBAAkB,CAAC;gBACtC;gBACA,0BAA0B,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,MAAM,CAAC,CAAC,CAAC,OAAO,CAAC,wBAAwB;;QAEjF;QAEA,MAAM,EAAE,YAAY,EAAE,GAAG,MAAM,IAAI,CAAC,CAAC,CAAC,gBAAgB,CAAC,SAAS,CAC9D;YAAE,KAAK;QAAE,GACT;YAAE,WAAW,gBAAgB;QAAe;QAG9C,MAAM,kBAAkB,gBAAgB;QACxC,IAAI,mBAAmB,QAAQ,mBAAmB,GAChD,MAAM,IAAI,QAAA,0BAA0B,CAAC,CAAA,gBAAA,EAAmB,UAAS,EAAA,CAAI;QACvE,uDAAuD;QACvD,MAAM,IAAI,CAAC,CAAC,CAAC,iBAAiB,CAAC,UAAU,CAAC;YAAE,UAAU;QAAE,GAAI;YAAE,WAAW;QAAe;QAExF,IAAI,iBAAiB,GAAG;YACtB,uDAAuD;YACvD,2DAA2D;YAC3D,MAAM,IAAI,QAAA,iBAAiB,CAAC,CAAA,sBAAA,EAAyB,GAAE,CAAE;QAC3D;IACF;IAEA,4DAAA,GACA,KAAK,SAA6B,CAAA,CAAE,EAAE,UAAuB,CAAA,CAAE,EAAA;QAC7D,OAAO,IAAI,CAAC,CAAC,CAAC,gBAAgB,CAAC,IAAI,CAAC,QAAQ;IAC9C;IAEA;;;;;;QAOA,yBACE,QAAgB,EAChB,OAAmD,EAAA;QAEnD,IAAI,OAAa;YAAE,YAAY,CAAC;QAAC;QACjC,IAAI,OAAO;QACX,IAAI,WAAW,QAAQ,QAAQ,IAAI,MAAM;YACvC,IAAI,QAAQ,QAAQ,IAAI,GAAG;gBACzB,OAAO;oBAAE,YAAY;gBAAC;gBACtB,OAAO,QAAQ,QAAQ;YACzB,OAAO;gBACL,OAAO,CAAC,QAAQ,QAAQ,GAAG;YAC7B;QACF;QACA,OAAO,IAAI,WAAA,sBAAsB,CAC/B,IAAI,CAAC,CAAC,CAAC,iBAAiB,EACxB,IAAI,CAAC,CAAC,CAAC,gBAAgB,EACvB,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,cAAc,EAC7B;YAAE;QAAQ,GACV;YAAE,WAAW,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,SAAS;YAAE,GAAG,OAAO;YAAE;YAAM;QAAI;IAEjE;IAEA;;;;;QAMA,MAAM,OAAO,EAAY,EAAE,QAAgB,EAAE,OAA+B,EAAA;QAC1E,MAAM,SAAS;YAAE,KAAK;QAAE;QACxB,MAAM,SAAS;YAAE,MAAM;gBAAE;YAAQ;QAAE;QACnC,MAAM,EAAE,YAAY,EAAE,GAAG,MAAM,IAAI,CAAC,CAAC,CAAC,gBAAgB,CAAC,SAAS,CAAC,QAAQ,QAAQ;QACjF,IAAI,iBAAiB,GAAG;YACtB,MAAM,IAAI,QAAA,iBAAiB,CAAC,CAAA,aAAA,EAAgB,GAAE,UAAA,CAAY;QAC5D;IACF;IAEA,+EAAA,GACA,MAAM,KAAK,OAA+B,EAAA;QACxC,MAAM,EAAE,SAAS,EAAE,GAAG,CAAA,GAAA,QAAA,cAAc,EAAC,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE;QAChD,IAAI,iBAAiD;QAErD,IAAI,WAAW;YACb,iBAAiB,IAAI,UAAA,kBAAkB,CAAC;gBACtC;gBACA,0BAA0B,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,MAAM,CAAC,CAAC,CAAC,OAAO,CAAC,wBAAwB;;QAEjF;QAEA,IAAI,gBAAgB;YAClB,MAAM,IAAI,CAAC,CAAC,CAAC,gBAAgB,CAAC,IAAI,CAAC;gBAAE,WAAW,eAAe,eAAe;YAAA;YAC9E,MAAM,kBAAkB,eAAe,yBAAyB,CAC9D,CAAA,gBAAA,EAAmB,UAAS,EAAA,CAAI;YAElC,MAAM,IAAI,CAAC,CAAC,CAAC,iBAAiB,CAAC,IAAI,CAAC;gBAAE,WAAW;YAAe;QAClE,OAAO;YACL,MAAM,IAAI,CAAC,CAAC,CAAC,gBAAgB,CAAC,IAAI;YAClC,MAAM,IAAI,CAAC,CAAC,CAAC,iBAAiB,CAAC,IAAI;QACrC;IACF;;AA7LF,QAAA,YAAA,GAAA;AAIE;;;;;;;IAQgB,aAAA,KAAK,GAAG"}},
    {"offset": {"line": 14557, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 14561, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/mongodb/src/index.ts"],"sourcesContent":["import { Admin } from './admin';\nimport { OrderedBulkOperation } from './bulk/ordered';\nimport { UnorderedBulkOperation } from './bulk/unordered';\nimport { ChangeStream } from './change_stream';\nimport { Collection } from './collection';\nimport { AbstractCursor } from './cursor/abstract_cursor';\nimport { AggregationCursor } from './cursor/aggregation_cursor';\nimport { FindCursor } from './cursor/find_cursor';\nimport { ListCollectionsCursor } from './cursor/list_collections_cursor';\nimport { ListIndexesCursor } from './cursor/list_indexes_cursor';\nimport type { RunCommandCursor } from './cursor/run_command_cursor';\nimport { Db } from './db';\nimport { ExplainableCursor } from './explain';\nimport { GridFSBucket } from './gridfs';\nimport { GridFSBucketReadStream } from './gridfs/download';\nimport { GridFSBucketWriteStream } from './gridfs/upload';\nimport { MongoClient } from './mongo_client';\nimport { CancellationToken } from './mongo_types';\nimport { ClientSession } from './sessions';\n\n/** @public */\nexport { BSON } from './bson';\nexport {\n  Binary,\n  BSONRegExp,\n  BSONSymbol,\n  BSONType,\n  Code,\n  DBRef,\n  Decimal128,\n  Double,\n  Int32,\n  Long,\n  MaxKey,\n  MinKey,\n  ObjectId,\n  Timestamp,\n  UUID\n} from './bson';\nexport {\n  type AnyBulkWriteOperation,\n  type BulkWriteOptions,\n  MongoBulkWriteError\n} from './bulk/common';\nexport { ClientEncryption } from './client-side-encryption/client_encryption';\nexport { ChangeStreamCursor } from './cursor/change_stream_cursor';\nexport {\n  MongoAPIError,\n  MongoAWSError,\n  MongoAzureError,\n  MongoBatchReExecutionError,\n  MongoChangeStreamError,\n  MongoClientBulkWriteCursorError,\n  MongoClientBulkWriteError,\n  MongoClientBulkWriteExecutionError,\n  MongoClientClosedError,\n  MongoCompatibilityError,\n  MongoCursorExhaustedError,\n  MongoCursorInUseError,\n  MongoDecompressionError,\n  MongoDriverError,\n  MongoError,\n  MongoExpiredSessionError,\n  MongoGCPError,\n  MongoGridFSChunkError,\n  MongoGridFSStreamError,\n  MongoInvalidArgumentError,\n  MongoKerberosError,\n  MongoMissingCredentialsError,\n  MongoMissingDependencyError,\n  MongoNetworkError,\n  MongoNetworkTimeoutError,\n  MongoNotConnectedError,\n  MongoOIDCError,\n  MongoOperationTimeoutError,\n  MongoParseError,\n  MongoRuntimeError,\n  MongoServerClosedError,\n  MongoServerError,\n  MongoServerSelectionError,\n  MongoStalePrimaryError,\n  MongoSystemError,\n  MongoTailableCursorError,\n  MongoTopologyClosedError,\n  MongoTransactionError,\n  MongoUnexpectedServerResponseError,\n  MongoWriteConcernError,\n  WriteConcernErrorResult\n} from './error';\nexport { configureExplicitResourceManagement } from './resource_management';\nexport {\n  AbstractCursor,\n  // Actual driver classes exported\n  Admin,\n  AggregationCursor,\n  CancellationToken,\n  ChangeStream,\n  ClientSession,\n  Collection,\n  Db,\n  ExplainableCursor,\n  FindCursor,\n  GridFSBucket,\n  GridFSBucketReadStream,\n  GridFSBucketWriteStream,\n  ListCollectionsCursor,\n  ListIndexesCursor,\n  MongoClient,\n  OrderedBulkOperation,\n  RunCommandCursor,\n  UnorderedBulkOperation\n};\n\n// enums\nexport { BatchType } from './bulk/common';\nexport { AutoEncryptionLoggerLevel } from './client-side-encryption/auto_encrypter';\nexport { GSSAPICanonicalizationValue } from './cmap/auth/gssapi';\nexport { AuthMechanism } from './cmap/auth/providers';\nexport { Compressor } from './cmap/wire_protocol/compression';\nexport { CURSOR_FLAGS, CursorTimeoutMode } from './cursor/abstract_cursor';\nexport { MongoErrorLabel } from './error';\nexport { ExplainVerbosity } from './explain';\nexport { ServerApiVersion } from './mongo_client';\nexport { MongoLoggableComponent, SeverityLevel } from './mongo_logger';\nexport { ReturnDocument } from './operations/find_and_modify';\nexport { ProfilingLevel } from './operations/set_profiling_level';\nexport { ReadConcernLevel } from './read_concern';\nexport { ReadPreferenceMode } from './read_preference';\nexport { ServerType, TopologyType } from './sdam/common';\n\n// Helper classes\nexport type { AWSCredentialProvider } from './cmap/auth/aws_temporary_credentials';\nexport type { AWSCredentials } from './deps';\nexport { ReadConcern } from './read_concern';\nexport { ReadPreference } from './read_preference';\nexport { WriteConcern } from './write_concern';\n// events\nexport {\n  CommandFailedEvent,\n  CommandStartedEvent,\n  CommandSucceededEvent\n} from './cmap/command_monitoring_events';\nexport {\n  ConnectionCheckedInEvent,\n  ConnectionCheckedOutEvent,\n  ConnectionCheckOutFailedEvent,\n  ConnectionCheckOutStartedEvent,\n  ConnectionClosedEvent,\n  ConnectionCreatedEvent,\n  ConnectionPoolClearedEvent,\n  ConnectionPoolClosedEvent,\n  ConnectionPoolCreatedEvent,\n  ConnectionPoolMonitoringEvent,\n  ConnectionPoolReadyEvent,\n  ConnectionReadyEvent\n} from './cmap/connection_pool_events';\nexport {\n  ServerClosedEvent,\n  ServerDescriptionChangedEvent,\n  ServerHeartbeatFailedEvent,\n  ServerHeartbeatStartedEvent,\n  ServerHeartbeatSucceededEvent,\n  ServerOpeningEvent,\n  TopologyClosedEvent,\n  TopologyDescriptionChangedEvent,\n  TopologyOpeningEvent\n} from './sdam/events';\nexport {\n  ServerSelectionEvent,\n  ServerSelectionFailedEvent,\n  ServerSelectionStartedEvent,\n  ServerSelectionSucceededEvent,\n  WaitingForSuitableServerEvent\n} from './sdam/server_selection_events';\nexport { SrvPollingEvent } from './sdam/srv_polling';\n\n// type only exports below, these are removed from emitted JS\nexport type { AdminPrivate } from './admin';\nexport type { BSONElement, BSONSerializeOptions, Document } from './bson';\nexport type { deserialize, serialize } from './bson';\nexport type {\n  BulkResult,\n  BulkWriteOperationError,\n  BulkWriteResult,\n  DeleteManyModel,\n  DeleteOneModel,\n  InsertOneModel,\n  ReplaceOneModel,\n  UpdateManyModel,\n  UpdateOneModel,\n  WriteConcernError,\n  WriteError\n} from './bulk/common';\nexport type {\n  Batch,\n  BulkOperationBase,\n  BulkOperationPrivate,\n  FindOperators,\n  WriteConcernErrorData\n} from './bulk/common';\nexport type {\n  ChangeStreamCollModDocument,\n  ChangeStreamCreateDocument,\n  ChangeStreamCreateIndexDocument,\n  ChangeStreamDeleteDocument,\n  ChangeStreamDocument,\n  ChangeStreamDocumentCollectionUUID,\n  ChangeStreamDocumentCommon,\n  ChangeStreamDocumentKey,\n  ChangeStreamDocumentOperationDescription,\n  ChangeStreamDropDatabaseDocument,\n  ChangeStreamDropDocument,\n  ChangeStreamDropIndexDocument,\n  ChangeStreamEvents,\n  ChangeStreamInsertDocument,\n  ChangeStreamInvalidateDocument,\n  ChangeStreamNameSpace,\n  ChangeStreamOptions,\n  ChangeStreamRefineCollectionShardKeyDocument,\n  ChangeStreamRenameDocument,\n  ChangeStreamReplaceDocument,\n  ChangeStreamReshardCollectionDocument,\n  ChangeStreamShardCollectionDocument,\n  ChangeStreamSplitEvent,\n  ChangeStreamUpdateDocument,\n  OperationTime,\n  ResumeOptions,\n  ResumeToken,\n  UpdateDescription\n} from './change_stream';\nexport type { AutoEncrypter } from './client-side-encryption/auto_encrypter';\nexport type { AutoEncryptionOptions } from './client-side-encryption/auto_encrypter';\nexport type { AutoEncryptionExtraOptions } from './client-side-encryption/auto_encrypter';\nexport type {\n  AWSEncryptionKeyOptions,\n  AzureEncryptionKeyOptions,\n  ClientEncryptionCreateDataKeyProviderOptions,\n  ClientEncryptionEncryptOptions,\n  ClientEncryptionOptions,\n  ClientEncryptionRewrapManyDataKeyProviderOptions,\n  ClientEncryptionRewrapManyDataKeyResult,\n  DataKey,\n  GCPEncryptionKeyOptions,\n  KMIPEncryptionKeyOptions,\n  RangeOptions\n} from './client-side-encryption/client_encryption';\nexport {\n  MongoCryptAzureKMSRequestError,\n  MongoCryptCreateDataKeyError,\n  MongoCryptCreateEncryptedCollectionError,\n  MongoCryptError,\n  MongoCryptInvalidArgumentError,\n  MongoCryptKMSRequestNetworkTimeoutError\n} from './client-side-encryption/errors';\nexport type { MongocryptdManager } from './client-side-encryption/mongocryptd_manager';\nexport type {\n  AWSKMSProviderConfiguration,\n  AzureKMSProviderConfiguration,\n  ClientEncryptionDataKeyProvider,\n  CredentialProviders,\n  GCPKMSProviderConfiguration,\n  KMIPKMSProviderConfiguration,\n  KMSProviders,\n  LocalKMSProviderConfiguration\n} from './client-side-encryption/providers/index';\nexport type {\n  ClientEncryptionSocketOptions,\n  ClientEncryptionTlsOptions,\n  CSFLEKMSTlsOptions,\n  StateMachineExecutable\n} from './client-side-encryption/state_machine';\nexport type { AuthContext, AuthProvider } from './cmap/auth/auth_provider';\nexport type {\n  AuthMechanismProperties,\n  MongoCredentials,\n  MongoCredentialsOptions\n} from './cmap/auth/mongo_credentials';\nexport type {\n  IdPInfo,\n  IdPServerResponse,\n  OIDCCallbackFunction,\n  OIDCCallbackParams,\n  OIDCResponse\n} from './cmap/auth/mongodb_oidc';\nexport type { Workflow } from './cmap/auth/mongodb_oidc';\nexport type { TokenCache } from './cmap/auth/mongodb_oidc/token_cache';\nexport type {\n  MessageHeader,\n  OpCompressedRequest,\n  OpMsgOptions,\n  OpMsgRequest,\n  OpMsgResponse,\n  OpQueryOptions,\n  OpQueryRequest,\n  OpReply,\n  WriteProtocolMessageType\n} from './cmap/commands';\nexport type { HandshakeDocument } from './cmap/connect';\nexport type { LEGAL_TCP_SOCKET_OPTIONS, LEGAL_TLS_SOCKET_OPTIONS, Stream } from './cmap/connect';\nexport type {\n  CommandOptions,\n  Connection,\n  ConnectionEvents,\n  ConnectionOptions,\n  ProxyOptions\n} from './cmap/connection';\nexport type {\n  CloseOptions,\n  ConnectionPool,\n  ConnectionPoolEvents,\n  ConnectionPoolOptions,\n  PoolState,\n  WaitQueueMember,\n  WithConnectionCallback\n} from './cmap/connection_pool';\nexport type { ClientMetadata, ClientMetadataOptions } from './cmap/handshake/client_metadata';\nexport type { ConnectionPoolMetrics } from './cmap/metrics';\nexport type { StreamDescription, StreamDescriptionOptions } from './cmap/stream_description';\nexport type { CompressorName } from './cmap/wire_protocol/compression';\nexport type {\n  JSTypeOf,\n  OnDemandDocument,\n  OnDemandDocumentDeserializeOptions\n} from './cmap/wire_protocol/on_demand/document';\nexport type {\n  CursorResponse,\n  MongoDBResponse,\n  MongoDBResponseConstructor\n} from './cmap/wire_protocol/responses';\nexport type {\n  CollectionOptions,\n  CollectionPrivate,\n  CountDocumentsOptions,\n  ModifyResult\n} from './collection';\nexport type {\n  COMMAND_FAILED,\n  COMMAND_STARTED,\n  COMMAND_SUCCEEDED,\n  CONNECTION_CHECK_OUT_FAILED,\n  CONNECTION_CHECK_OUT_STARTED,\n  CONNECTION_CHECKED_IN,\n  CONNECTION_CHECKED_OUT,\n  CONNECTION_CLOSED,\n  CONNECTION_CREATED,\n  CONNECTION_POOL_CLEARED,\n  CONNECTION_POOL_CLOSED,\n  CONNECTION_POOL_CREATED,\n  CONNECTION_POOL_READY,\n  CONNECTION_READY,\n  MONGO_CLIENT_EVENTS,\n  SERVER_CLOSED,\n  SERVER_DESCRIPTION_CHANGED,\n  SERVER_HEARTBEAT_FAILED,\n  SERVER_HEARTBEAT_STARTED,\n  SERVER_HEARTBEAT_SUCCEEDED,\n  SERVER_OPENING,\n  SERVER_SELECTION_FAILED,\n  SERVER_SELECTION_STARTED,\n  SERVER_SELECTION_SUCCEEDED,\n  TOPOLOGY_CLOSED,\n  TOPOLOGY_DESCRIPTION_CHANGED,\n  TOPOLOGY_OPENING,\n  WAITING_FOR_SUITABLE_SERVER\n} from './constants';\nexport type {\n  AbstractCursorEvents,\n  AbstractCursorOptions,\n  CursorFlag,\n  CursorStreamOptions\n} from './cursor/abstract_cursor';\nexport type {\n  CursorTimeoutContext,\n  InitialCursorResponse,\n  InternalAbstractCursorOptions\n} from './cursor/abstract_cursor';\nexport type { AggregationCursorOptions } from './cursor/aggregation_cursor';\nexport type { ChangeStreamCursorOptions } from './cursor/change_stream_cursor';\nexport type {\n  ListSearchIndexesCursor,\n  ListSearchIndexesOptions\n} from './cursor/list_search_indexes_cursor';\nexport type { RunCursorCommandOptions } from './cursor/run_command_cursor';\nexport type { DbOptions, DbPrivate } from './db';\nexport type { Encrypter, EncrypterOptions } from './encrypter';\nexport type { AnyError, ErrorDescription, MongoNetworkErrorOptions } from './error';\nexport type {\n  Explain,\n  ExplainCommandOptions,\n  ExplainOptions,\n  ExplainVerbosityLike\n} from './explain';\nexport type {\n  GridFSBucketReadStreamOptions,\n  GridFSBucketReadStreamOptionsWithRevision,\n  GridFSBucketReadStreamPrivate,\n  GridFSFile\n} from './gridfs/download';\nexport type { GridFSBucketEvents, GridFSBucketOptions, GridFSBucketPrivate } from './gridfs/index';\nexport type { GridFSBucketWriteStreamOptions, GridFSChunk } from './gridfs/upload';\nexport type {\n  Auth,\n  DriverInfo,\n  MongoClientEvents,\n  MongoClientOptions,\n  MongoClientPrivate,\n  MongoOptions,\n  PkFactory,\n  ServerApi,\n  SupportedNodeConnectionOptions,\n  SupportedSocketOptions,\n  SupportedTLSConnectionOptions,\n  SupportedTLSSocketOptions,\n  WithSessionCallback\n} from './mongo_client';\nexport { MongoClientAuthProviders } from './mongo_client_auth_providers';\nexport type {\n  Log,\n  LogComponentSeveritiesClientOptions,\n  LogConvertible,\n  Loggable,\n  LoggableCommandFailedEvent,\n  LoggableCommandSucceededEvent,\n  LoggableEvent,\n  LoggableServerHeartbeatFailedEvent,\n  LoggableServerHeartbeatStartedEvent,\n  LoggableServerHeartbeatSucceededEvent,\n  MongoDBLogWritable,\n  MongoLogger,\n  MongoLoggerEnvOptions,\n  MongoLoggerMongoClientOptions,\n  MongoLoggerOptions\n} from './mongo_logger';\nexport type {\n  Abortable,\n  CommonEvents,\n  EventsDescription,\n  GenericListener,\n  TypedEventEmitter\n} from './mongo_types';\nexport type {\n  AcceptedFields,\n  AddToSetOperators,\n  AlternativeType,\n  ArrayElement,\n  ArrayOperator,\n  BitwiseFilter,\n  BSONTypeAlias,\n  Condition,\n  EnhancedOmit,\n  Filter,\n  FilterOperations,\n  FilterOperators,\n  Flatten,\n  InferIdType,\n  IntegerType,\n  IsAny,\n  Join,\n  KeysOfAType,\n  KeysOfOtherType,\n  MatchKeysAndValues,\n  NestedPaths,\n  NestedPathsOfType,\n  NonObjectIdLikeDocument,\n  NotAcceptedFields,\n  NumericType,\n  OneOrMore,\n  OnlyFieldsOfType,\n  OptionalId,\n  OptionalUnlessRequiredId,\n  PropertyType,\n  PullAllOperator,\n  PullOperator,\n  PushOperator,\n  RegExpOrString,\n  RootFilterOperators,\n  SchemaMember,\n  SetFields,\n  StrictFilter,\n  StrictMatchKeysAndValues,\n  StrictUpdateFilter,\n  UpdateFilter,\n  WithId,\n  WithoutId\n} from './mongo_types';\nexport type {\n  AggregateOperation,\n  AggregateOptions,\n  DB_AGGREGATE_COLLECTION\n} from './operations/aggregate';\nexport type {\n  AnyClientBulkWriteModel,\n  ClientBulkWriteError,\n  ClientBulkWriteModel,\n  ClientBulkWriteOptions,\n  ClientBulkWriteResult,\n  ClientDeleteManyModel,\n  ClientDeleteOneModel,\n  ClientDeleteResult,\n  ClientInsertOneModel,\n  ClientInsertOneResult,\n  ClientReplaceOneModel,\n  ClientUpdateManyModel,\n  ClientUpdateOneModel,\n  ClientUpdateResult,\n  ClientWriteModel\n} from './operations/client_bulk_write/common';\nexport type {\n  CollationOptions,\n  CommandOperation,\n  CommandOperationOptions,\n  OperationParent\n} from './operations/command';\nexport type { CountOptions } from './operations/count';\nexport type {\n  ClusteredCollectionOptions,\n  CreateCollectionOptions,\n  TimeSeriesCollectionOptions\n} from './operations/create_collection';\nexport type { DeleteOptions, DeleteResult, DeleteStatement } from './operations/delete';\nexport type { DistinctOptions } from './operations/distinct';\nexport type { DropCollectionOptions, DropDatabaseOptions } from './operations/drop';\nexport type { EstimatedDocumentCountOptions } from './operations/estimated_document_count';\nexport type { FindOptions } from './operations/find';\nexport type {\n  FindOneAndDeleteOptions,\n  FindOneAndReplaceOptions,\n  FindOneAndUpdateOptions\n} from './operations/find_and_modify';\nexport type { IndexInformationOptions } from './operations/indexes';\nexport type {\n  CreateIndexesOptions,\n  DropIndexesOptions,\n  IndexDescription,\n  IndexDescriptionCompact,\n  IndexDescriptionInfo,\n  IndexDirection,\n  IndexSpecification,\n  ListIndexesOptions\n} from './operations/indexes';\nexport type { InsertManyResult, InsertOneOptions, InsertOneResult } from './operations/insert';\nexport type { CollectionInfo, ListCollectionsOptions } from './operations/list_collections';\nexport type { ListDatabasesOptions, ListDatabasesResult } from './operations/list_databases';\nexport type { AbstractOperation, Hint, OperationOptions } from './operations/operation';\nexport type { ProfilingLevelOptions } from './operations/profiling_level';\nexport type { RemoveUserOptions } from './operations/remove_user';\nexport type { RenameOptions } from './operations/rename';\nexport type { RunCommandOptions } from './operations/run_command';\nexport type { SearchIndexDescription } from './operations/search_indexes/create';\nexport type { SetProfilingLevelOptions } from './operations/set_profiling_level';\nexport type { DbStatsOptions } from './operations/stats';\nexport type {\n  ReplaceOptions,\n  UpdateOptions,\n  UpdateResult,\n  UpdateStatement\n} from './operations/update';\nexport type { ValidateCollectionOptions } from './operations/validate_collection';\nexport type { ReadConcernLike } from './read_concern';\nexport type {\n  HedgeOptions,\n  ReadPreferenceFromOptions,\n  ReadPreferenceLike,\n  ReadPreferenceLikeOptions,\n  ReadPreferenceOptions\n} from './read_preference';\nexport type { AsyncDisposable } from './resource_management';\nexport type { ClusterTime } from './sdam/common';\nexport type {\n  Monitor,\n  MonitorEvents,\n  MonitorInterval,\n  MonitorIntervalOptions,\n  MonitorOptions,\n  MonitorPrivate,\n  RTTPinger,\n  RTTPingerOptions,\n  RTTSampler,\n  ServerMonitoringMode\n} from './sdam/monitor';\nexport type {\n  Server,\n  ServerCommandOptions,\n  ServerEvents,\n  ServerOptions,\n  ServerPrivate\n} from './sdam/server';\nexport type {\n  ServerDescription,\n  ServerDescriptionOptions,\n  TagSet,\n  TopologyVersion\n} from './sdam/server_description';\nexport type { ServerSelector } from './sdam/server_selection';\nexport type { SrvPoller, SrvPollerEvents, SrvPollerOptions } from './sdam/srv_polling';\nexport type {\n  ConnectOptions,\n  SelectServerOptions,\n  ServerCapabilities,\n  ServerSelectionCallback,\n  ServerSelectionRequest,\n  Topology,\n  TopologyEvents,\n  TopologyOptions,\n  TopologyPrivate\n} from './sdam/topology';\nexport type { TopologyDescription, TopologyDescriptionOptions } from './sdam/topology_description';\nexport type {\n  ClientSessionEvents,\n  ClientSessionOptions,\n  EndSessionOptions,\n  ServerSession,\n  ServerSessionId,\n  ServerSessionPool,\n  WithTransactionCallback\n} from './sessions';\nexport type { Sort, SortDirection, SortDirectionForCmd, SortForCmd } from './sort';\nexport type {\n  CSOTTimeoutContext,\n  CSOTTimeoutContextOptions,\n  LegacyTimeoutContext,\n  LegacyTimeoutContextOptions,\n  Timeout,\n  TimeoutContext,\n  TimeoutContextOptions\n} from './timeout';\nexport type { Transaction, TransactionOptions, TxnState } from './transactions';\nexport type {\n  BufferPool,\n  Callback,\n  EventEmitterWithState,\n  HostAddress,\n  List,\n  MongoDBCollectionNamespace,\n  MongoDBNamespace\n} from './utils';\nexport type { W, WriteConcernOptions, WriteConcernSettings } from './write_concern';\n"],"names":[],"mappings":";;;;;;;AAAA,MAAA;AA6FE,OAAA,cAAA,CAAA,SAAA,SAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OA7FO,QAAA,KAAK;IAAA;AAAA;AACd,MAAA;AA2GE,OAAA,cAAA,CAAA,SAAA,wBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OA3GO,UAAA,oBAAoB;IAAA;AAAA;AAC7B,MAAA;AA4GE,OAAA,cAAA,CAAA,SAAA,0BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OA5GO,YAAA,sBAAsB;IAAA;AAAA;AAC/B,MAAA;AA6FE,OAAA,cAAA,CAAA,SAAA,gBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OA7FO,gBAAA,YAAY;IAAA;AAAA;AACrB,MAAA;AA8FE,OAAA,cAAA,CAAA,SAAA,cAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OA9FO,aAAA,UAAU;IAAA;AAAA;AACnB,MAAA;AAsFE,OAAA,cAAA,CAAA,SAAA,kBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAtFO,kBAAA,cAAc;IAAA;AAAA;AACvB,MAAA;AAwFE,OAAA,cAAA,CAAA,SAAA,qBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAxFO,qBAAA,iBAAiB;IAAA;AAAA;AAC1B,MAAA;AA8FE,OAAA,cAAA,CAAA,SAAA,cAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OA9FO,cAAA,UAAU;IAAA;AAAA;AACnB,MAAA;AAiGE,OAAA,cAAA,CAAA,SAAA,yBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAjGO,0BAAA,qBAAqB;IAAA;AAAA;AAC9B,MAAA;AAiGE,OAAA,cAAA,CAAA,SAAA,qBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAjGO,sBAAA,iBAAiB;IAAA;AAAA;AAE1B,MAAA;AAwFE,OAAA,cAAA,CAAA,SAAA,MAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAxFO,KAAA,EAAE;IAAA;AAAA;AACX,MAAA;AAwFE,OAAA,cAAA,CAAA,SAAA,qBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAxFO,UAAA,iBAAiB;IAAA;AAAA;AAC1B,MAAA;AAyFE,OAAA,cAAA,CAAA,SAAA,gBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAzFO,SAAA,YAAY;IAAA;AAAA;AACrB,MAAA;AAyFE,OAAA,cAAA,CAAA,SAAA,0BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAzFO,WAAA,sBAAsB;IAAA;AAAA;AAC/B,MAAA;AAyFE,OAAA,cAAA,CAAA,SAAA,2BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAzFO,SAAA,uBAAuB;IAAA;AAAA;AAChC,MAAA;AA2FE,OAAA,cAAA,CAAA,SAAA,eAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OA3FO,eAAA,WAAW;IAAA;AAAA;AACpB,MAAA;AA8EE,OAAA,cAAA,CAAA,SAAA,qBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OA9EO,cAAA,iBAAiB;IAAA;AAAA;AAC1B,MAAA;AA+EE,OAAA,cAAA,CAAA,SAAA,iBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OA/EO,WAAA,aAAa;IAAA;AAAA;AAEtB,YAAA,GACA,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,QAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,IAAI;IAAA;AAAA;AACb,IAAA;AACE,OAAA,cAAA,CAAA,SAAA,UAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,MAAM;IAAA;AAAA;AACN,OAAA,cAAA,CAAA,SAAA,cAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,UAAU;IAAA;AAAA;AACV,OAAA,cAAA,CAAA,SAAA,cAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,UAAU;IAAA;AAAA;AACV,OAAA,cAAA,CAAA,SAAA,YAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,QAAQ;IAAA;AAAA;AACR,OAAA,cAAA,CAAA,SAAA,QAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,IAAI;IAAA;AAAA;AACJ,OAAA,cAAA,CAAA,SAAA,SAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,KAAK;IAAA;AAAA;AACL,OAAA,cAAA,CAAA,SAAA,cAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,UAAU;IAAA;AAAA;AACV,OAAA,cAAA,CAAA,SAAA,UAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,MAAM;IAAA;AAAA;AACN,OAAA,cAAA,CAAA,SAAA,SAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,KAAK;IAAA;AAAA;AACL,OAAA,cAAA,CAAA,SAAA,QAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,IAAI;IAAA;AAAA;AACJ,OAAA,cAAA,CAAA,SAAA,UAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,MAAM;IAAA;AAAA;AACN,OAAA,cAAA,CAAA,SAAA,UAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,MAAM;IAAA;AAAA;AACN,OAAA,cAAA,CAAA,SAAA,YAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,QAAQ;IAAA;AAAA;AACR,OAAA,cAAA,CAAA,SAAA,aAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,SAAS;IAAA;AAAA;AACT,OAAA,cAAA,CAAA,SAAA,QAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,OAAA,IAAI;IAAA;AAAA;AAEN,IAAA;AAGE,OAAA,cAAA,CAAA,SAAA,uBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,mBAAmB;IAAA;AAAA;AAErB,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,oBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,oBAAA,gBAAgB;IAAA;AAAA;AACzB,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,sBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,uBAAA,kBAAkB;IAAA;AAAA;AAC3B,IAAA;AACE,OAAA,cAAA,CAAA,SAAA,iBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,aAAa;IAAA;AAAA;AACb,OAAA,cAAA,CAAA,SAAA,iBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,aAAa;IAAA;AAAA;AACb,OAAA,cAAA,CAAA,SAAA,mBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,eAAe;IAAA;AAAA;AACf,OAAA,cAAA,CAAA,SAAA,8BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,0BAA0B;IAAA;AAAA;AAC1B,OAAA,cAAA,CAAA,SAAA,0BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,sBAAsB;IAAA;AAAA;AACtB,OAAA,cAAA,CAAA,SAAA,mCAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,+BAA+B;IAAA;AAAA;AAC/B,OAAA,cAAA,CAAA,SAAA,6BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,yBAAyB;IAAA;AAAA;AACzB,OAAA,cAAA,CAAA,SAAA,sCAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,kCAAkC;IAAA;AAAA;AAClC,OAAA,cAAA,CAAA,SAAA,0BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,sBAAsB;IAAA;AAAA;AACtB,OAAA,cAAA,CAAA,SAAA,2BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,uBAAuB;IAAA;AAAA;AACvB,OAAA,cAAA,CAAA,SAAA,6BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,yBAAyB;IAAA;AAAA;AACzB,OAAA,cAAA,CAAA,SAAA,yBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,qBAAqB;IAAA;AAAA;AACrB,OAAA,cAAA,CAAA,SAAA,2BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,uBAAuB;IAAA;AAAA;AACvB,OAAA,cAAA,CAAA,SAAA,oBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,gBAAgB;IAAA;AAAA;AAChB,OAAA,cAAA,CAAA,SAAA,cAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,UAAU;IAAA;AAAA;AACV,OAAA,cAAA,CAAA,SAAA,4BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,wBAAwB;IAAA;AAAA;AACxB,OAAA,cAAA,CAAA,SAAA,iBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,aAAa;IAAA;AAAA;AACb,OAAA,cAAA,CAAA,SAAA,yBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,qBAAqB;IAAA;AAAA;AACrB,OAAA,cAAA,CAAA,SAAA,0BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,sBAAsB;IAAA;AAAA;AACtB,OAAA,cAAA,CAAA,SAAA,6BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,yBAAyB;IAAA;AAAA;AACzB,OAAA,cAAA,CAAA,SAAA,sBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,kBAAkB;IAAA;AAAA;AAClB,OAAA,cAAA,CAAA,SAAA,gCAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,4BAA4B;IAAA;AAAA;AAC5B,OAAA,cAAA,CAAA,SAAA,+BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,2BAA2B;IAAA;AAAA;AAC3B,OAAA,cAAA,CAAA,SAAA,qBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,iBAAiB;IAAA;AAAA;AACjB,OAAA,cAAA,CAAA,SAAA,4BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,wBAAwB;IAAA;AAAA;AACxB,OAAA,cAAA,CAAA,SAAA,0BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,sBAAsB;IAAA;AAAA;AACtB,OAAA,cAAA,CAAA,SAAA,kBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,cAAc;IAAA;AAAA;AACd,OAAA,cAAA,CAAA,SAAA,8BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,0BAA0B;IAAA;AAAA;AAC1B,OAAA,cAAA,CAAA,SAAA,mBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,eAAe;IAAA;AAAA;AACf,OAAA,cAAA,CAAA,SAAA,qBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,iBAAiB;IAAA;AAAA;AACjB,OAAA,cAAA,CAAA,SAAA,0BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,sBAAsB;IAAA;AAAA;AACtB,OAAA,cAAA,CAAA,SAAA,oBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,gBAAgB;IAAA;AAAA;AAChB,OAAA,cAAA,CAAA,SAAA,6BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,yBAAyB;IAAA;AAAA;AACzB,OAAA,cAAA,CAAA,SAAA,0BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,sBAAsB;IAAA;AAAA;AACtB,OAAA,cAAA,CAAA,SAAA,oBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,gBAAgB;IAAA;AAAA;AAChB,OAAA,cAAA,CAAA,SAAA,4BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,wBAAwB;IAAA;AAAA;AACxB,OAAA,cAAA,CAAA,SAAA,4BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,wBAAwB;IAAA;AAAA;AACxB,OAAA,cAAA,CAAA,SAAA,yBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,qBAAqB;IAAA;AAAA;AACrB,OAAA,cAAA,CAAA,SAAA,sCAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,kCAAkC;IAAA;AAAA;AAClC,OAAA,cAAA,CAAA,SAAA,0BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,sBAAsB;IAAA;AAAA;AAGxB,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,uCAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,sBAAA,mCAAmC;IAAA;AAAA;AAwB5C,QAAQ;AACR,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,aAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,SAAS;IAAA;AAAA;AAClB,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,6BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,iBAAA,yBAAyB;IAAA;AAAA;AAClC,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,+BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,2BAA2B;IAAA;AAAA;AACpC,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,iBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,YAAA,aAAa;IAAA;AAAA;AACtB,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,cAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,cAAA,UAAU;IAAA;AAAA;AACnB,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,gBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,kBAAA,YAAY;IAAA;AAAA;AAAE,OAAA,cAAA,CAAA,SAAA,qBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,kBAAA,iBAAiB;IAAA;AAAA;AACxC,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,mBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,QAAA,eAAe;IAAA;AAAA;AACxB,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,oBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,UAAA,gBAAgB;IAAA;AAAA;AACzB,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,oBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,eAAA,gBAAgB;IAAA;AAAA;AACzB,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,0BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,eAAA,sBAAsB;IAAA;AAAA;AAAE,OAAA,cAAA,CAAA,SAAA,iBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,eAAA,aAAa;IAAA;AAAA;AAC9C,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,kBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,kBAAA,cAAc;IAAA;AAAA;AACvB,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,kBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,sBAAA,cAAc;IAAA;AAAA;AACvB,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,oBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,eAAA,gBAAgB;IAAA;AAAA;AACzB,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,sBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,kBAAA,kBAAkB;IAAA;AAAA;AAC3B,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,cAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,UAAU;IAAA;AAAA;AAAE,OAAA,cAAA,CAAA,SAAA,gBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,YAAY;IAAA;AAAA;AAKjC,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,eAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,eAAA,WAAW;IAAA;AAAA;AACpB,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,kBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,kBAAA,cAAc;IAAA;AAAA;AACvB,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,gBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,gBAAA,YAAY;IAAA;AAAA;AACrB,SAAS;AACT,IAAA;AACE,OAAA,cAAA,CAAA,SAAA,sBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,4BAAA,kBAAkB;IAAA;AAAA;AAClB,OAAA,cAAA,CAAA,SAAA,uBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,4BAAA,mBAAmB;IAAA;AAAA;AACnB,OAAA,cAAA,CAAA,SAAA,yBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,4BAAA,qBAAqB;IAAA;AAAA;AAEvB,IAAA;AACE,OAAA,cAAA,CAAA,SAAA,4BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,yBAAA,wBAAwB;IAAA;AAAA;AACxB,OAAA,cAAA,CAAA,SAAA,6BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,yBAAA,yBAAyB;IAAA;AAAA;AACzB,OAAA,cAAA,CAAA,SAAA,iCAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,yBAAA,6BAA6B;IAAA;AAAA;AAC7B,OAAA,cAAA,CAAA,SAAA,kCAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,yBAAA,8BAA8B;IAAA;AAAA;AAC9B,OAAA,cAAA,CAAA,SAAA,yBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,yBAAA,qBAAqB;IAAA;AAAA;AACrB,OAAA,cAAA,CAAA,SAAA,0BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,yBAAA,sBAAsB;IAAA;AAAA;AACtB,OAAA,cAAA,CAAA,SAAA,8BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,yBAAA,0BAA0B;IAAA;AAAA;AAC1B,OAAA,cAAA,CAAA,SAAA,6BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,yBAAA,yBAAyB;IAAA;AAAA;AACzB,OAAA,cAAA,CAAA,SAAA,8BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,yBAAA,0BAA0B;IAAA;AAAA;AAC1B,OAAA,cAAA,CAAA,SAAA,iCAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,yBAAA,6BAA6B;IAAA;AAAA;AAC7B,OAAA,cAAA,CAAA,SAAA,4BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,yBAAA,wBAAwB;IAAA;AAAA;AACxB,OAAA,cAAA,CAAA,SAAA,wBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,yBAAA,oBAAoB;IAAA;AAAA;AAEtB,IAAA;AACE,OAAA,cAAA,CAAA,SAAA,qBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,iBAAiB;IAAA;AAAA;AACjB,OAAA,cAAA,CAAA,SAAA,iCAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,6BAA6B;IAAA;AAAA;AAC7B,OAAA,cAAA,CAAA,SAAA,8BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,0BAA0B;IAAA;AAAA;AAC1B,OAAA,cAAA,CAAA,SAAA,+BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,2BAA2B;IAAA;AAAA;AAC3B,OAAA,cAAA,CAAA,SAAA,iCAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,6BAA6B;IAAA;AAAA;AAC7B,OAAA,cAAA,CAAA,SAAA,sBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,kBAAkB;IAAA;AAAA;AAClB,OAAA,cAAA,CAAA,SAAA,uBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,mBAAmB;IAAA;AAAA;AACnB,OAAA,cAAA,CAAA,SAAA,mCAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,+BAA+B;IAAA;AAAA;AAC/B,OAAA,cAAA,CAAA,SAAA,wBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,oBAAoB;IAAA;AAAA;AAEtB,IAAA;AACE,OAAA,cAAA,CAAA,SAAA,wBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,0BAAA,oBAAoB;IAAA;AAAA;AACpB,OAAA,cAAA,CAAA,SAAA,8BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,0BAAA,0BAA0B;IAAA;AAAA;AAC1B,OAAA,cAAA,CAAA,SAAA,+BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,0BAAA,2BAA2B;IAAA;AAAA;AAC3B,OAAA,cAAA,CAAA,SAAA,iCAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,0BAAA,6BAA6B;IAAA;AAAA;AAC7B,OAAA,cAAA,CAAA,SAAA,iCAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,0BAAA,6BAA6B;IAAA;AAAA;AAE/B,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,mBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,cAAA,eAAe;IAAA;AAAA;AAwExB,IAAA;AACE,OAAA,cAAA,CAAA,SAAA,kCAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,8BAA8B;IAAA;AAAA;AAC9B,OAAA,cAAA,CAAA,SAAA,gCAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,4BAA4B;IAAA;AAAA;AAC5B,OAAA,cAAA,CAAA,SAAA,4CAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,wCAAwC;IAAA;AAAA;AACxC,OAAA,cAAA,CAAA,SAAA,mBAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,eAAe;IAAA;AAAA;AACf,OAAA,cAAA,CAAA,SAAA,kCAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,8BAA8B;IAAA;AAAA;AAC9B,OAAA,cAAA,CAAA,SAAA,2CAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,SAAA,uCAAuC;IAAA;AAAA;AAmKzC,IAAA;AAAS,OAAA,cAAA,CAAA,SAAA,4BAAA;IAAA,YAAA;IAAA,KAAA;QAAA,OAAA,8BAAA,wBAAwB;IAAA;AAAA"}},
    {"offset": {"line": 15436, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}}]
}